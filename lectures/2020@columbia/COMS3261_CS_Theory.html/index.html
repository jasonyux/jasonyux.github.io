<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>COMS3261 CS Theory | Lecture Notes</title>
<meta name="generator" content="Jekyll v4.3.1" />
<meta property="og:title" content="COMS3261 CS Theory" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="An inexhaustive collection of markdown/latex(PDF) notes that I took since college." />
<meta property="og:description" content="An inexhaustive collection of markdown/latex(PDF) notes that I took since college." />
<link rel="canonical" href="/lectures/2020@columbia/COMS3261_CS_Theory.html/" />
<meta property="og:url" content="/lectures/2020@columbia/COMS3261_CS_Theory.html/" />
<meta property="og:site_name" content="Lecture Notes" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-12-12T00:00:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="COMS3261 CS Theory" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2020-12-12T00:00:00+00:00","datePublished":"2020-12-12T00:00:00+00:00","description":"An inexhaustive collection of markdown/latex(PDF) notes that I took since college.","headline":"COMS3261 CS Theory","mainEntityOfPage":{"@type":"WebPage","@id":"/lectures/2020@columbia/COMS3261_CS_Theory.html/"},"url":"/lectures/2020@columbia/COMS3261_CS_Theory.html/"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/lectures/assets/main.css"><link type="application/atom+xml" rel="alternate" href="/lectures/feed.xml" title="Lecture Notes" /></head>
<body><header class="site-header">

	<div class="wrapper"><a class="site-title" rel="author" href="/lectures/">Lecture Notes</a>

		<nav class="site-nav">
			<input type="checkbox" id="nav-trigger" class="nav-trigger" />
			<label for="nav-trigger">
			<span class="menu-icon">
				<svg viewBox="0 0 18 15" width="18px" height="15px">
				<path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
				</svg>
			</span>
			</label>
			<div class="trigger">
				<a class="page-link" href="/">home</a>
				<!-- <a class="page-link" href="/projects">Projects</a> -->
				<a class="page-link" href="/research">research</a>
				<span class="page-link" href="#">[education]</span>
				<!-- <a class="page-link" href="/learning">Blog</a> -->
			</div>
		</nav>
	</div>
  </header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">
  <head>
  <script>
    MathJax = {
      // 
      loader: {
        load: ['[tex]/ams', '[tex]/textmacros', '[tex]/boldsymbol']
      },
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']],
        packages: {'[+]': ['ams', 'textmacros', 'boldsymbol']}
      }
    };
  </script>
  <script id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
  </script>
  </head>
  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">COMS3261 CS Theory</h1>
    <p class="post-meta"><time class="dt-published" datetime="2020-12-12T00:00:00+00:00" itemprop="datePublished">
        Dec 12, 2020
      </time></p>
  </header>

  <div class="section-nav" id="toc-all">
    <button type="button" id="toc-close" class="toc_collapsible hidden" title="collapse">
      <span><strong>Table of Contents</strong></span>
    </button>
    <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" mirror-in-rtl="true" fill="#000000" style="width: 18px;" id="toc-reopen" class="toc_collapsible">
      <g id="SVGRepo_bgCarrier" stroke-width="0"></g><g id="SVGRepo_tracerCarrier" stroke-linecap="round" stroke-linejoin="round"></g><g id="SVGRepo_iconCarrier"> <circle fill="#494c4e" cx="2" cy="2" r="2"></circle> <circle fill="#494c4e" cx="2" cy="8" r="2"></circle> <circle fill="#494c4e" cx="2" cy="20" r="2"></circle> <circle fill="#494c4e" cx="2" cy="14" r="2"></circle> <path fill="#494c4e" d="M23.002 3H7.998C7.448 3 7 2.55 7 2.002v-.004c0-.55.45-.998.998-.998H23c.55 0 1 .45 1 .998V2c0 .55-.45 1-.998 1zM23.002 9H7.998C7.448 9 7 8.55 7 8.002v-.004c0-.55.45-.998.998-.998H23c.55 0 1 .45 1 .998V8c0 .55-.45 1-.998 1zM23.002 15H7.998c-.55 0-.998-.45-.998-.998V14c0-.55.45-1 .998-1H23c.55 0 1 .45 1 .998V14c0 .55-.45 1-.998 1zM23.002 21H7.998c-.55 0-.998-.45-.998-.998V20c0-.55.45-1 .998-1H23c.55 0 1 .45 1 .998V20c0 .55-.45 1-.998 1z"></path> </g>
    </svg>
    <ul id="toc" class="section-nav">
<li class="toc-entry toc-h1"><a href="#logistics">Logistics</a></li>
<li class="toc-entry toc-h1"><a href="#week-1---introduction">Week 1 - Introduction</a>
<ul>
<li class="toc-entry toc-h2"><a href="#definitions">Definitions</a></li>
<li class="toc-entry toc-h2"><a href="#usages">Usages</a></li>
<li class="toc-entry toc-h2"><a href="#deterministic-finite-automata-dfa">Deterministic Finite Automata (DFA)</a>
<ul>
<li class="toc-entry toc-h3"><a href="#regular-language">Regular Language</a></li>
<li class="toc-entry toc-h3"><a href="#theorems">Theorems</a></li>
<li class="toc-entry toc-h3"><a href="#more-practice-questions">More Practice Questions</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#week-2">Week 2</a>
<ul>
<li class="toc-entry toc-h2"><a href="#non-deterministic-finite-automata-nfa">Non-deterministic Finite Automata (NFA)</a>
<ul>
<li class="toc-entry toc-h3"><a href="#regular-language-1">Regular Language</a></li>
<li class="toc-entry toc-h3"><a href="#dfa-and-nfa">DFA and NFA</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#week-3">Week 3</a>
<ul>
<li class="toc-entry toc-h2"><a href="#operations-on-languages-and-closure-properties">Operations on Languages and Closure Properties</a>
<ul>
<li class="toc-entry toc-h3"><a href="#operation-definitions">Operation Definitions</a></li>
<li class="toc-entry toc-h3"><a href="#closed-property">Closed Property</a></li>
<li class="toc-entry toc-h3"><a href="#regular-operations-and-expressions">Regular Operations and Expressions</a>
<ul>
<li class="toc-entry toc-h4"><a href="#examples">Examples</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#regular-language-2">Regular Language</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#generalized-nfa">Generalized NFA</a>
<ul>
<li class="toc-entry toc-h3"><a href="#transform-gnfa-to-nfa">Transform GNFA to NFA</a></li>
<li class="toc-entry toc-h3"><a href="#transform-gnfa-to-regex">Transform GNFA to Regex</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#week-4">Week 4</a>
<ul>
<li class="toc-entry toc-h2"><a href="#proving-irregular-language---part-1">Proving Irregular Language - Part 1</a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#week-5">Week 5</a>
<ul>
<li class="toc-entry toc-h2"><a href="#proving-irregular-language---part-2">Proving Irregular Language - Part 2</a>
<ul>
<li class="toc-entry toc-h3"><a href="#using-closure-properties">Using Closure Properties</a></li>
<li class="toc-entry toc-h3"><a href="#myhill-nerode-theorem">Myhill-Nerode Theorem</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#context-free-language">Context Free Language</a>
<ul>
<li class="toc-entry toc-h3"><a href="#definitions-1">Definitions</a></li>
<li class="toc-entry toc-h3"><a href="#ambiguity">Ambiguity</a></li>
<li class="toc-entry toc-h3"><a href="#proving-the-language-of-cfg">Proving the Language of CFG</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#week-6">Week 6</a>
<ul>
<li class="toc-entry toc-h2"><a href="#regular-and-context-free-language">Regular and Context Free Language</a>
<ul>
<li class="toc-entry toc-h3"><a href="#proof-for-context-free-grammar-closure">Proof for Context Free Grammar Closure</a></li>
<li class="toc-entry toc-h3"><a href="#regular-and-context-free-language-1">Regular and Context-Free Language</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#not-context-free-grammar">Not Context-Free Grammar</a>
<ul>
<li class="toc-entry toc-h3"><a href="#example-tandem-pumping-lemma">Example: Tandem Pumping Lemma</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#week-7">Week 7</a>
<ul>
<li class="toc-entry toc-h2"><a href="#other-closure-properties-on-cfl">Other Closure Properties on CFL</a></li>
<li class="toc-entry toc-h2"><a href="#push-down-automata-of-cfl">Push-Down Automata of CFL</a></li>
<li class="toc-entry toc-h2"><a href="#turing-machine">Turing Machine</a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#week-8">Week 8</a>
<ul>
<li class="toc-entry toc-h2"><a href="#turing-machine-continued">Turing Machine (Continued)</a>
<ul>
<li class="toc-entry toc-h3"><a href="#input-output-tm">Input-Output TM</a></li>
<li class="toc-entry toc-h3"><a href="#variants-of-tm">Variants of TM</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#non-deterministic-tm">Non-Deterministic TM</a></li>
<li class="toc-entry toc-h2"><a href="#historical-background-of-tm">Historical Background of TM</a></li>
<li class="toc-entry toc-h2"><a href="#church-turing-thesis">Church-Turing Thesis</a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#week-9">Week 9</a>
<ul>
<li class="toc-entry toc-h2"><a href="#closure-property-for-tm">Closure Property for TM</a></li>
<li class="toc-entry toc-h2"><a href="#application-of-tm-decidable-languages">Application of TM Decidable Languages</a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#week-10">Week 10</a>
<ul>
<li class="toc-entry toc-h2"><a href="#tm-recognizable-languages">TM Recognizable Languages</a></li>
<li class="toc-entry toc-h2"><a href="#undecidability-and-unrecognizability">Undecidability and Unrecognizability</a>
<ul>
<li class="toc-entry toc-h3"><a href="#definitions-2">Definitions</a></li>
<li class="toc-entry toc-h3"><a href="#uncountable-languages">Uncountable Languages</a>
<ul>
<li class="toc-entry toc-h4"><a href="#using-diagonalization-for-tm-proofs">Using Diagonalization for TM Proofs</a></li>
<li class="toc-entry toc-h4"><a href="#using-reduction-for-tm-proofs">Using Reduction for TM Proofs</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#week-11">Week 11</a>
<ul>
<li class="toc-entry toc-h2"><a href="#using-reduction-for-tm-proofs-continued">Using Reduction for TM Proofs (Continued)</a></li>
<li class="toc-entry toc-h2"><a href="#rices-theorem">Rice’s Theorem</a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#week-12">Week 12</a>
<ul>
<li class="toc-entry toc-h2"><a href="#unrecognizable-languages">Unrecognizable Languages</a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#week-13">Week 13</a>
<ul>
<li class="toc-entry toc-h2"><a href="#computation-history-extension">Computation History (Extension)</a></li>
<li class="toc-entry toc-h2"><a href="#introduction-to-complexity-theory">Introduction to Complexity Theory</a>
<ul>
<li class="toc-entry toc-h3"><a href="#examples-of-poly-computable">Examples of Poly-Computable</a></li>
<li class="toc-entry toc-h3"><a href="#p-vs-np">P vs NP</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#week-14">Week 14</a>
<ul>
<li class="toc-entry toc-h2"><a href="#np-complete-class">NP Complete Class</a>
<ul>
<li class="toc-entry toc-h3"><a href="#using-reductions">Using Reductions</a></li>
<li class="toc-entry toc-h3"><a href="#closure-properties">Closure Properties</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#examples-of-np-complete">Examples of NP-Complete</a>
<ul>
<li class="toc-entry toc-h3"><a href="#examples-using-np-complete-reductions">Examples using NP-Complete Reductions</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#non-deterministic-tm-with-complexity">Non-Deterministic TM with Complexity</a>
<ul>
<li class="toc-entry toc-h3"><a href="#examples-of-np-using-ntm">Examples of NP using NTM</a></li>
<li class="toc-entry toc-h3"><a href="#example-of-np-complete-using-ntm">Example of NP-Complete using NTM</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#tips">Tips</a>
<ul>
<li class="toc-entry toc-h2"><a href="#tips-on-proving-regularity-with-dfanfa">Tips on Proving Regularity with DFA/NFA</a></li>
<li class="toc-entry toc-h2"><a href="#tips-on-proving-if-and-only-if">Tips on Proving If and Only If</a></li>
<li class="toc-entry toc-h2"><a href="#tips-on-converting-regex-to-nfa">Tips on Converting Regex to NFA</a></li>
<li class="toc-entry toc-h2"><a href="#tips-on-writing-regular-expressions">Tips on Writing Regular Expressions</a></li>
<li class="toc-entry toc-h2"><a href="#tips-on-proving-regular-expressions">Tips on Proving Regular Expressions</a></li>
<li class="toc-entry toc-h2"><a href="#tips-on-constructing-context-free-grammar">Tips on Constructing Context-Free Grammar</a></li>
<li class="toc-entry toc-h2"><a href="#tips-on-constructing-tm-reduction">Tips on Constructing TM Reduction</a></li>
<li class="toc-entry toc-h2"><a href="#tips-on-diagonalization-for-undecidability">Tips on Diagonalization for Undecidability</a></li>
<li class="toc-entry toc-h2"><a href="#tips-on-constructing-mapping-reduction">Tips on Constructing Mapping Reduction</a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#appendix">Appendix</a>
<ul>
<li class="toc-entry toc-h2"><a href="#list-of-known-tm-languages">List of Known TM Languages</a></li>
</ul>
</li>
</ul>
  </div>

  <div class="post-content e-content" itemprop="articleBody">
    <style type="text/css">@page { margin-left: 2in; margin-right: -0.25in; }</style>

<h1 id="logistics">Logistics</h1>

<ul>
  <li>Quizzes - 10%
    <ul>
      <li>frequent</li>
    </ul>
  </li>
  <li>Homework - 20%
    <ul>
      <li>challenging</li>
    </ul>
  </li>
  <li>Exam - 70%
    <ul>
      <li>expected four (breaking midterm and final)</li>
    </ul>
  </li>
  <li>Office Hours:
    <ul>
      <li>Professor Tal, Thurs 8:40computable-9:50am; 3:30-4:30pm</li>
    </ul>
  </li>
  <li>Webpage:
    <ul>
      <li>http://www.cs.columbia.edu/~tal/3261/fall20/</li>
    </ul>
  </li>
</ul>

<h1 id="week-1---introduction">Week 1 - Introduction</h1>

<p>Related Reading:</p>

<h2 id="definitions">Definitions</h2>

<ul>
  <li>an <strong>Alphabet</strong> $\Sigma$
    <ul>
      <li>an non-empty, finite set of <strong>symbols</strong></li>
      <li>e.g.
        <ul>
          <li>${0,1}$, ASCII table, …</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>a <strong>String</strong> over alphabet $\Sigma$
    <ul>
      <li>a finite sequence of symbols from $\Sigma$</li>
    </ul>
  </li>
  <li><strong>Length</strong> of string $s$, $\vert s\vert$
    <ul>
      <li>number of symbols in a string</li>
      <li>e.g.
        <ul>
          <li>$\vert 1001\vert =4$</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>empty string</strong> $\epsilon$
    <ul>
      <li>string of length 0</li>
      <li>you will see that $\empty^{*}=\epsilon$ or $\empty^{0} = \epsilon$ (see the <strong>Kleene Star</strong> definition in Week 3)</li>
    </ul>
  </li>
  <li><strong>concatenation</strong> is denoted with $\circ$</li>
  <li>$\Sigma^k$ means a set of strings with length $k$
    <ul>
      <li>e.g., let $\Sigma = {0,1}$, $k=2$
        <ul>
          <li>then you get $\Sigma^2 = {00,01,10,11}$</li>
        </ul>
      </li>
      <li>e.g., let $k=0$,
        <ul>
          <li>then you get $\Sigma^0 = {\epsilon}$</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>$\Sigma^*$ means a set of all strings over $\Sigma$ with length varying from $0 \to \infty$
    <ul>
      <li>therefore, it is infinite</li>
    </ul>
  </li>
  <li>a <strong>language</strong> is a subset of $\Sigma^*$
    <ul>
      <li>basically some <em>set</em> of strings</li>
    </ul>
  </li>
</ul>

<h2 id="usages">Usages</h2>

<ul>
  <li>a language $L$ can be thought of as a yes/no problem solver:
    <ul>
      <li>e.g.
        <ul>
          <li>given input string $s$, does $s \in L$?</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p>This means that you can think of <strong>a language $L$ as a (yes/no) function $f$</strong> such that:</p>

\[f: x \in \Sigma^* \to \{1,0\}\]

<p>where:</p>

<ul>
  <li>$f(x\in \Sigma^*)=1$ if $x \in L$</li>
  <li>$f(x\in \Sigma^*)=0$ if $x \notin L$</li>
</ul>

<blockquote>
  <p>Notice:</p>

  <ul>
    <li>You might think that a yes/no function would be quite limited in its capacity, but in later part of the course, you will see that it actually quite capable.</li>
  </ul>
</blockquote>

<h2 id="deterministic-finite-automata-dfa">Deterministic Finite Automata (DFA)</h2>

<p>For example, a DFA might look like</p>

<p><img src="\lectures\images\typora-user-images\image-20200911003259447.png" alt="image-20200911003259447" style="zoom:50%;" /></p>

<p>where:</p>

<ul>
  <li>circles represent <strong>states</strong>
    <ul>
      <li>so in this case, we have four states</li>
      <li>a <strong>start state</strong> always exists, with an additional arrow</li>
      <li>an <strong>accepting state</strong> is denote by a double circle (the bottom right)
        <ul>
          <li>an <strong>accepting state</strong> would be the only state that the output would be <strong>true/yes</strong> (see sample usage below)</li>
          <li>though it is called an accepting state, it <strong>does not</strong> have to be always accepting/being a sink</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>arrows represent <strong>transitions</strong>
    <ul>
      <li>a transition is uniquely defined/denoted by coming from <strong><em>a specific state + having an alphabet</em></strong> (in this case, $1$ and $0$)</li>
      <li>for every state, there has to be a transition for <strong>every element in the alphabet</strong>
        <ul>
          <li>again, in this case the alphabet would be ${1,0}$</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p>A sample usage would be:</p>

<ul>
  <li>Consider the string $101$:</li>
</ul>

<p>By putting the string into the above DFA, you get:</p>

<p><img src="\lectures\images\typora-user-images\image-20200911004438037.png" alt="image-20200911004438037" style="zoom:50%;" /></p>

<p>where:</p>

<ul>
  <li>you end up in a normal <strong>state</strong>, which means the output of $101$ into this DFA would be a <strong>false/no</strong></li>
  <li>the only state where you could reach a <strong>true/yes</strong></li>
</ul>

<blockquote>
  <p><strong>DFA Def:</strong></p>

  <ul>
    <li>
      <p>A DFA $M$ is a 5-tuple</p>

\[M=(Q,\Sigma, \delta, q_0, F)\]

      <p>where:</p>

      <ul>
        <li>$Q$ is a finite set of states</li>
        <li>$\Sigma$ is a finite alphabet</li>
        <li>$\delta$ is the transition function $Q \times \Sigma \to Q$
          <ul>
            <li>takes a state and a symbol to another state</li>
          </ul>
        </li>
        <li>$q_0 \in Q$ is called the start state</li>
        <li>$F \subseteq Q$ is called the accepting states</li>
      </ul>
    </li>
  </ul>
</blockquote>

<p>For example, we can <em>identify the previous diagram</em> with:</p>

<ul>
  <li>
    <p>$Q = {q_0, q_1, q_2, q_3, q_4}$</p>

    <ul>
      <li>we see that there are four states (including accepting state) in total</li>
    </ul>
  </li>
  <li>
    <p>$\Sigma = {0,1}$</p>
  </li>
  <li>
    <p>$\delta$ is a function, but here can be represented by</p>

    <p><img src="\lectures\images\typora-user-images\image-20200911030309803.png" alt="image-20200911030309803" style="zoom: 50%;" /></p>
  </li>
  <li>
    <p>$q_0$ is the start state at top left</p>
  </li>
  <li>
    <p>$F={q_3}$ is the accepting state at bottom right</p>
  </li>
</ul>

<blockquote>
  <p><strong>Computation Def:</strong></p>

  <ul>
    <li>
      <p>If there is a string $w=w_1, w_2, …w_n$ where $w_i \in \Sigma$, then a DFA $M$ accepts $W$ iff</p>

\[\exist \, r_0,r_1,r_2,...r_n \in Q\]

      <p>such that</p>

      <ol>
        <li>$r_0 = q_0$
          <ul>
            <li>$r_i$ you can see as the $i$th computation/step you had</li>
          </ul>
        </li>
        <li>$\delta(r_{i-1},w_i)=r_i$, for $\forall \, i\in {1,2,3,…n}$
          <ul>
            <li>the $i-1$ comes from the notion that you take the transition <strong>from $r_{i-1}$</strong> with $w_i$.</li>
            <li>$\delta$ would be some computation on $w$</li>
          </ul>
        </li>
        <li>$r_n \in F$</li>
      </ol>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Language of a DFA Def:</strong></p>

  <ul>
    <li>
      <p>for a DFA $M$, we define:</p>

\[L(M)=\{ w \in \Sigma^* | M \,\,accepts \,\,w \}\]

      <p>to be the language of a DFA $M$, or the language that <strong>$M$ computes/recognizes</strong>.</p>
    </li>
  </ul>
</blockquote>

<p>For example, a DFA that accepts all strings/a language of a DFA that (recognizes) is a set of all strings:</p>

<p><img src="\lectures\images\typora-user-images\image-20200911031929077.png" alt="image-20200911031929077" style="zoom: 50%;" /></p>

<p>another DFA that accepts all strings would be:</p>

<p><img src="\lectures\images\typora-user-images\image-20200911032127292.png" alt="image-20200911032127292" style="zoom: 50%;" /></p>

<h3 id="regular-language">Regular Language</h3>

<blockquote>
  <p><strong>Regular Language Def</strong></p>

  <ul>
    <li>
      <p>A language $L$ is regular if:</p>

\[\exists \, M,\, s.t.\, L=L(M)\]

      <p>this says that a language is regular if there <strong>exists a DFA that computes to it</strong>. This means being “regular” is just a property.</p>
    </li>
  </ul>
</blockquote>

<p>Now, the question becomes:</p>

<ul>
  <li>Which languages are regular? How could you prove whether if a language is regular or not?</li>
</ul>

<hr />

<p><strong><em>For example:</em></strong></p>

<ul>
  <li>
    <p>Question:</p>

    <p>What is the language of this DFA?</p>

    <p><img src="\lectures\images\typora-user-images\image-20200911003259447.png" alt="image-20200911003259447" style="zoom:50%;" /></p>
  </li>
  <li>
    <p>Solution:</p>

    <p>Realize that whenever you have $111$ in a row, you will get to the accepting state.</p>

    <ul>
      <li>e.g. $0011101$, $01110$, and etc.</li>
    </ul>

    <p>Propose:</p>

\[L(M)=\{w\in\{0,1\}^*\,|\, w\,\,contains\,\,substring\,\,111\}\]

    <p>Prove by induction on length of $w$, $\vert w\vert$</p>
  </li>
</ul>

<hr />

<p>The general procedure would be:</p>

<ol>
  <li>Trying manually some strings that will get accepted</li>
  <li>Try finding a pattern of the above and propose</li>
  <li>Prove the proposition</li>
</ol>

<p>However, the hard part is the below:</p>

<hr />

<p><strong><em>For example:</em></strong></p>

<ul>
  <li>
    <p>Question</p>

    <p>Is such a language $L(M)={w\in{0,1}^*\,\vert \,w\,\,has\,\,an\,\,even\,\,number\,\,of\,\,0}$ regular?</p>
  </li>
  <li>
    <p>Solution:</p>

    <p>First, examples such as $0110$ and $\epsilon$ passes, so if we find a DFA, it has to recognize those.</p>

    <p>Second, you need to come up with an <strong><em>finite memory algorithm</em></strong> to do the job.</p>

    <ul>
      <li>For instance, the algorithm (bad for DFA) could be:
        <ol>
          <li>go through the string, count number of $0$</li>
          <li>if even, then accept. else reject</li>
        </ol>
      </li>
      <li>however, the problem occurs as a DFA has a fixed number of states, you cannot simply use this algorithm as it would potential take an unbounded number of states</li>
    </ul>

    <p>Another better algorithm would be:</p>

    <ul>
      <li>start with a start state being accepting</li>
      <li>once you get a $1$, switch to normal state</li>
      <li>once you get another $0$ switch back
        <ul>
          <li>notice that this algorithm does not care about how many zeros you have, but just knows whether if it is even or odd. This makes it efficient.</li>
        </ul>
      </li>
    </ul>

    <p>Then <strong><em>convert the algorithm to DFA</em></strong> corresponding DFA looks like:</p>

    <p><img src="\lectures\images\typora-user-images\image-20200911035211780.png" alt="image-20200911035211780" style="zoom: 50%;" /></p>
  </li>
</ul>

<hr />

<blockquote>
  <p>Note:</p>

  <ul>
    <li>the general difference/problem with a DFA as compared to an actual piece of algorithm is that:
      <ul>
        <li>it has a fixed finite memory
          <ul>
            <li>as it has a fixed amount of states</li>
          </ul>
        </li>
        <li>its input is read only once</li>
      </ul>
    </li>
  </ul>
</blockquote>

<p>The last example for thinking is:</p>

<ul>
  <li>
    <p>Question:</p>

    <p>Is the following language regular?</p>

    <p><img src="\lectures\images\typora-user-images\image-20200911035344935.png" alt="image-20200911035344935" style="zoom: 50%;" /></p>

    <p>where:</p>

    <ul>
      <li>$xy$ means concatenating a string $x$ and a string $y$.</li>
    </ul>
  </li>
  <li>
    <p>My Solution:</p>

    <p>The problem with this statement is that we cannot define a way to parse the string, deciding where to break it.</p>

    <ul>
      <li>to solve this, you can try to find another equivalent way to state this problem</li>
      <li>if the first part satisfied the condition, then the second part fails iff it has an odd number of 0 left over and ended with $01^n$, where $n$ is also odd
        <ul>
          <li>?</li>
        </ul>
      </li>
    </ul>

    <p>Using a NFA</p>

    <ul>
      <li>see the section <a href="#Non-deterministic Finite Automata">NFA</a></li>
      <li>we can change the question into: given any first part of the string which contains even 0, check if the second part contains even 1</li>
    </ul>

    <p><img src="\lectures\images\typora-user-images\image-20200917223831298.png" alt="image-20200917223831298" style="zoom: 50%;" /></p>
  </li>
  <li>
    <p>Solution:</p>

    <p>Using a DFA</p>

    <ul>
      <li>a</li>
    </ul>

    <p>Using NFA</p>

    <ul>
      <li>Professor had the same solution</li>
    </ul>
  </li>
</ul>

<hr />

<h3 id="theorems">Theorems</h3>

<blockquote>
  <p>Theorem:</p>

  <ul>
    <li>If $L$ is finite, then $L$ is regular</li>
  </ul>
</blockquote>

<p>Proof Sketch:</p>

<ul>
  <li>Can construct a DFA with a state for any possible string of length $\le$ max-length of any word in $L$, and mark appropriate states as accepting.</li>
</ul>

<p>In fact, the converse is also false.</p>

<blockquote>
  <p>Theorem:</p>

  <ul>
    <li>If $L$ is regular, $L$ can be infinite.</li>
  </ul>
</blockquote>

<p>Remember the example of DFA with even number of $1$’s, which has infinite number of elements in the language, <strong>yet a DFA can be built to decide</strong> whether  an input fits in the language or not.</p>

<h3 id="more-practice-questions">More Practice Questions</h3>

<ol>
  <li></li>
</ol>

<p><img src="\lectures\images\typora-user-images\image-20200915205700286.png" alt="image-20200915205700286" style="zoom: 50%;" /></p>

<hr />

<p>My Solution:</p>

<ul>
  <li></li>
</ul>

<hr />

<ol>
  <li>
    <p><img src="\lectures\images\typora-user-images\image-20200915205830506.png" alt="image-20200915205830506" style="zoom: 50%;" /></p>

    <p>(This is actually simple. <strong>Since $L$ is finite</strong>, then we can just construct a state for every word in the dictionary)</p>
  </li>
</ol>

<h1 id="week-2">Week 2</h1>

<h2 id="non-deterministic-finite-automata-nfa">Non-deterministic Finite Automata (NFA)</h2>

<p>An example of a NFA looks like</p>

<p><img src="\lectures\images\typora-user-images\image-20200915211427203.png" alt="image-20200915211427203" style="zoom: 50%;" /></p>

<p>where, as compared to a DFA, we see:</p>

<ul>
  <li><strong>not each alphabet</strong> correspond to a <strong>transition</strong>
    <ul>
      <li>therefore, if there is no matching transition for an alphabet at a state, it “dies”/”disappears”</li>
    </ul>
  </li>
  <li>there is always the <strong>option of having a $\epsilon$ transition</strong>, which gives the possibility to spontaneously jump forward one state
    <ul>
      <li>though this is <em>not included in the example above</em></li>
    </ul>
  </li>
  <li>the $1$ in the first state has <strong>two possible transitions</strong>
    <ul>
      <li>therefore, you need to compute all the possible routes</li>
    </ul>
  </li>
</ul>

<p>For example, for the word $1010010$:</p>

<p><img src="\lectures\images\typora-user-images\image-20200915212018205.png" alt="image-20200915212018205" style="zoom: 50%;" /></p>

<p>where:</p>

<ul>
  <li>the string is accepted iff there is <strong><em>at least one “token” finishes and landing in an accepting state</em></strong></li>
</ul>

<p>Another way to represent the process traversing a NFA looks like:</p>

<p><img src="\lectures\images\typora-user-images\image-20200915212303712.png" alt="image-20200915212303712" style="zoom: 50%;" /></p>

<blockquote>
  <p><strong>NFA Definition:</strong></p>

  <ul>
    <li>
      <p>An NFA with</p>

\[N=(Q,\Sigma, \delta, q_0, F)\]

      <p>where:</p>

      <ul>
        <li>$Q$ is a finite set of states</li>
        <li>$\Sigma$ is a finite alphabet</li>
        <li>$\delta$ is the transition function $Q \times {\Sigma \cup \epsilon} = Q \times \Sigma_{\epsilon} \to P(Q)$
          <ul>
            <li>$\Sigma_{\epsilon}=\Sigma \cup \epsilon$</li>
            <li>$P(Q)$ is a power <strong>set</strong>/a set containing all subsets of $Q$
              <ul>
                <li>it becomes a set because you can have <strong><em>more than 1 transition</em></strong> for the same alphabet (hence <strong><em>landing in more than one state</em></strong>)</li>
              </ul>
            </li>
          </ul>
        </li>
        <li>$q_0 \in Q$ is called the start state</li>
        <li>$F \subseteq Q$ is called the accepting states</li>
      </ul>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p>Note:</p>

  <ul>
    <li>
      <p>A power set is basically a <strong>a set</strong> containing all subsets:</p>

      <p><img src="\lectures\images\typora-user-images\image-20200915214934451.png" alt="image-20200915214934451" style="zoom:50%;" /></p>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Definition:</strong></p>

  <ul>
    <li>An NFA $N$ accepts a string $w$ if $w$ can be written as $w=w_1 \circ w_2 \circ w_3…w_n$ where $w_i \in \Sigma_{\epsilon}$ and there is a sequence of states $r_0, r_1, r_2,…r_n \in Q$ such that:
      <ul>
        <li>$r_0 = q_0$</li>
        <li>for all $i=1,2,3,…n$, $r_i \in \delta(r_{i-1}, w_i)$
          <ul>
            <li>the DFA version is $\delta(r_{i-1},w_i)=r_i$, and the difference is again that you can have <strong>multiple transitions</strong> for a single alphabet</li>
          </ul>
        </li>
        <li>$r_n \in F$</li>
      </ul>
    </li>
  </ul>
</blockquote>

<p>Interestingly, we used $\circ$ explicitly in the definition with NFA $w=w_1 \circ w_2 \circ w_3…w_n$, instead of $w=w_1, w_2, …w_n$, because technically an empty string is <strong>not</strong> a string, so it is not legal to have:</p>

<ul>
  <li>$100\epsilon1$</li>
</ul>

<p>but legal to have:</p>

<ul>
  <li>$1\circ 0\circ 0\circ \epsilon\circ 1=1001$</li>
</ul>

<blockquote>
  <p><strong>Definition</strong></p>

  <ul>
    <li>
      <p>For a NFA $N$, the language recognized by $N$ is</p>

\[L(N) =\{ w\in \Sigma^*\,|\, N \,\,accepts \,\,w \}\]
    </li>
  </ul>

</blockquote>

<h3 id="regular-language-1">Regular Language</h3>

<blockquote>
  <p><strong>Theorem</strong>:</p>

  <ul>
    <li>$L$ is a regular language iff $\exists$ <strong><em>NFA</em></strong> that recognizes L.
      <ul>
        <li>notice the other version with <strong>DFA</strong> is the same</li>
      </ul>
    </li>
  </ul>
</blockquote>

<p>Simple Proof:</p>

<ul>
  <li>If $L$ is regular, it is recognized by a DFA. Since a DFA is a special case of NFA, the above theorem also holds.
    <ul>
      <li>since NFA is just a DFA with more optional power.</li>
    </ul>
  </li>
</ul>

<blockquote>
  <p><strong>Difficult Proof</strong></p>

  <ul>
    <li>Here we try to prove the reverse, that a NFA can also be converted to a DFA.</li>
    <li>Let</li>
  </ul>

\[N=(Q_N,\Sigma_N, \delta_N, q_{0_N}, F_N)\]

  <p>​	need to show that for every token/intermediate state in a NFA, there exists a state that correspond to it in the DFA.</p>

  <p>​	One approach is to construct a DFA from</p>

  <p>​	Since every <strong><em>set of states that is reached by the same substring in NFA</em></strong> must be a state in DFA:</p>

\[Q_D = P(Q_N)=\{S\,|\,S \subseteq Q_N\}\]

  <p>​	and</p>

\[q_{0_D}= \{q_{0_N}\}\cup\{q\in Q_N\,|\,q\,is\,reachable\,via\,\epsilon\,from\,q_{0_N} \}\]

  <ul>
    <li>where:
      <ul>
        <li>this means $q_{0_D}$ corresponds to a set of states in $Q_N$</li>
      </ul>

      <p>and</p>
    </li>
  </ul>

\[F_D=\{S\subseteq Q_N\,|\,S \cap F_N \neq \empty\}\]

  <ul>
    <li>where
      <ul>
        <li>$F_D$ does not have to be same as as $F_N$</li>
      </ul>
    </li>
  </ul>

\[\delta_D(S,a)\to S_1 \cup \{q\,|\,q\,is\,reachable\,via\,some\,\epsilon\,transition\,from\,some\,q^{\prime}\,in\,S_1\}\]

  <ul>
    <li>where:
      <ul>
        <li>$\delta_D(S,a)$ means transition <strong>from a state $S$</strong> (which contains a set of states) with <strong>a symbol $a$</strong></li>
        <li>$S_1={q^{\prime} \in Q_N\, \vert \, q^{\prime}\in\delta_N(q,a)\,for\,all\,q\in S}$
          <ul>
            <li>basically states <em>reachable in the <strong>NFA</strong></em>, <em>from</em> states $S$ in a <strong><em>DFA</em></strong>, with the same symbol $a$</li>
          </ul>
        </li>
        <li>You basically get a <strong>set of states</strong> to be transitioned to, and they together <strong><em>forms a single state in DFA</em></strong></li>
      </ul>
    </li>
  </ul>
</blockquote>

<p>For example:</p>

<ul>
  <li>If we need to convert the following NFA to a DFA</li>
</ul>

<p><img src="\lectures\images\typora-user-images\image-20200917232220751.png" alt="image-20200917232220751" style="zoom: 50%;" /></p>

<ul>
  <li>
    <p>we first construct the following result</p>

    <p><img src="\lectures\images\typora-user-images\image-20200917232805325.png" alt="image-20200917232805325" style="zoom: 50%;" /></p>

    <p>where</p>

    <ul>
      <li><strong>accepting states</strong> are just states that include state $q_2$, which is an accepting state in the NFA</li>
      <li>size of NFA becomes bigger than DFA (though this is not the only solution)</li>
    </ul>
  </li>
</ul>

<h3 id="dfa-and-nfa">DFA and NFA</h3>

<p>Above we have seen that you can convert between DFA and NFA, and notice the size changed.</p>

<blockquote>
  <p><strong>Theorem:</strong></p>

  <ul>
    <li>$\forall n \in N$, there is a language $L_n$ <strong><em>such that</em></strong> <strong>there is an $(n+1)$ state NFA</strong> recognizing $L_n$ but every <strong>DFA recognizing $L_n$ has at least $2^n$ states</strong>.
      <ul>
        <li>the variable $n$ could be arbitrary, but here for showing the exponential blow up</li>
        <li>obviously, there are also <strong>other languages that DFA does not blow up</strong></li>
      </ul>
    </li>
  </ul>
</blockquote>

<p>Proof (Sketch):</p>

<ul>
  <li>
    <p>Define $L_n = {w \in {0,1}^*} \vert  \,last\,nth\,symbol\,is\,0$</p>

    <p>Then:</p>

    <ul>
      <li><strong>Claim:</strong> $L_n$ has an NFA with $n+1$ states</li>
      <li>Proof: <mark>(try if yourself)</mark></li>
    </ul>

    <p>And:</p>

    <ul>
      <li>
        <p><strong>Claim:</strong> Any DFA for $L_n$ has at least $2^n$ states</p>
      </li>
      <li>
        <p>Proof: Assume $\exist DFA$ for $L_n$ with <strong>fewer</strong> than $2^n$ states, by pigeon hole principle (p.h.p), there $\exists$ two different $n-bit$ strings that end on the same state.</p>

        <p><mark>(continue by yourself)</mark></p>
      </li>
    </ul>
  </li>
</ul>

<h1 id="week-3">Week 3</h1>

<h2 id="operations-on-languages-and-closure-properties">Operations on Languages and Closure Properties</h2>

<p>Though a language is basically just a set, there are additional features on it such that we have additional operations.</p>

<p>This section here is to show that <strong>a class of regular languages</strong> is <strong>closed</strong> under <strong>a variety of specific operations</strong>.</p>

<ul>
  <li>if you take a regular language in a class and apply some operations, it is still a member of a class.</li>
</ul>

<h3 id="operation-definitions">Operation Definitions</h3>

<p>Assume we have, for the below languages, they are composed of <strong>some alphabet $\Sigma$</strong></p>

<ul>
  <li>
    <p><strong>Complement</strong></p>
  </li>
  <li>
    <p>$\bar{L_1}={w \in \Sigma^*\vert w\notin L_1}$</p>
  </li>
  <li>
    <p><strong>Union</strong></p>

    <ul>
      <li>$L_1 \cup L_2 ={ w \in \Sigma^* \vert  w\in L_1 or\, w\in L_2 }$</li>
    </ul>
  </li>
  <li>
    <p><strong>Intersection</strong></p>

    <ul>
      <li>$L_1 \cap L_2 ={ w \in \Sigma^* \vert  w\in L_1 and\, w\in L_2 }$</li>
    </ul>
  </li>
  <li>
    <p><strong>Concatenation</strong></p>
    <ul>
      <li>$L_1 \circ L_2={ w \in \Sigma^* \vert  w=xy\,\,s.t.\,\,\forall x\in L_1\,and\,\forall y\in L_2 }$</li>
      <li><strong>order matters, only $xy$ is allowed</strong>
        <ul>
          <li>like a cartesian product but concatenation</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<blockquote>
  <p><strong>Theorem/Facts:</strong></p>

  <ul>
    <li>
      <p>For any $L_1,L_2$:</p>

\[L_2 \subseteq L_1 \circ L_2 \iff \epsilon \in L_1\,or\, L_2 = \empty\]
    </li>
  </ul>

</blockquote>

<ul>
  <li>
    <p><strong>Power</strong></p>

    <ul>
      <li>
\[\begin{align*}
L^0&amp;=\{\epsilon\}\\
L^{i+1}&amp;=L^i\circ L\,\,for\,all\,i\ge0
\end{align*}\]

        <p>basically a recursive definition of <strong>concatenating a language like a cartesian product</strong></p>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>Kleene Star</strong></p>

    <ul>
      <li>
\[L^*=\cup_{k=0}^{\infty}L^k	\\
L^*=\{\epsilon\}\cup L^{1}\cup L^{2}\cup L^{3}...\]
      </li>
      <li>notice that this means $\empty^* = \epsilon$, or $\empty^{0} = \epsilon$</li>
    </ul>
  </li>
</ul>

<p>There are also other operations, but those are the ones we are interested in.</p>

<h3 id="closed-property">Closed Property</h3>

<p>We need to show that the <strong><em>class of regular language</em></strong> is <strong><em>closed</em></strong> <strong>under all the above operations</strong>.</p>

<ul>
  <li>in other words, <strong><em>any language</em> produced by those operations with a regular language</strong> is still <strong><em>regular</em></strong>.</li>
</ul>

<blockquote>
  <p><strong>Proof for Complement Operation</strong></p>

  <ul>
    <li>
      <p>suppose $L$ is regular, let $M=(Q,\Sigma,\delta, q_0, F)$ be a DFA for $L$.</p>

      <p>we will construct a new DFA $M’$ recognizing $\bar{L}$ such that:</p>

      <ul>
        <li>$M’=(Q,\Sigma,\delta,q_0,Q-F)$</li>
      </ul>

      <p>and we need <strong>show that it works</strong>:</p>

      <ul>
        <li>$x\in \bar{L}$ iff $M’ \,\,accepts\,\,x$
          <ul>
            <li>trivially show that $x \in \bar{L}$ <strong>implies</strong> $M’$ accepts $x$</li>
            <li>trivially show that $M’$ accept $x$ if $x\notin \bar{L}$</li>
          </ul>
        </li>
      </ul>

      <p>This completes the Proof that complement is closed.</p>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p>Note:</p>

  <ul class="task-list">
    <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked" />If you use a NFA for the same construction above, it will not work, because an input/string can be at <strong>multiple states</strong>, and <strong>flipping <em>some</em> of the non-accepting token to accepting, and other accepting token to non-accepting</strong> would still make this input accepted (at least one token being accepted)</li>
    <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked" />However, the proof obviously work with a NFA, it’s just that we need to use another construction.</li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Proof for Union Operation</strong></p>

  <ul>
    <li>suppose $L_1$ and $L_2$ are regular, and we use NFA here, which is easier
      <ul>
        <li>we have $N_1=(Q_1,\Sigma_1, \delta_{1}, q_{0<em>1}, F_1)$ and $N_2=(Q_2,\Sigma_2, \delta</em>{2}, q_{0_2}, F_2)$</li>
        <li>this is trivial as we just need to have a start state $q_0$ that has two $\epsilon$ transaction to the $N_1$ and $N_2$ NFAs.</li>
      </ul>

      <p>Then we have the new $N$ to be defined as:</p>

\[N=(Q_1 \cup Q_2 \cup \{\epsilon\}, \Sigma_1 \cup \Sigma_2, \delta, q_0, F_1 \cup F_2)\]

      <p>where:</p>

      <ul>
        <li>
          <p>we redefined some transitions $\delta$ to be</p>

          <p><img src="\lectures\images\typora-user-images\image-20200925003556253.png" alt="image-20200925003556253" /></p>
        </li>
      </ul>

      <p>And then we need to show (<strong>argue that it works</strong>):</p>

\[w\in L_1 \cup L_2 \iff N\,\,accepts\,\, w\]

      <p>which is quite easy:</p>

      <p><img src="\lectures\images\typora-user-images\image-20200925003924445.png" alt="image-20200925003924445" /></p>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Alternative Proof for Union Operation</strong></p>

  <ul>
    <li>
      <p>Instead of using NFA, we use a <strong>DFA</strong> for the proof. The idea would be to somehow to run a string in “parallel” in the two DFAs:</p>

\[D_1=(Q_1,\Sigma, \delta_1, q_1, F_1);\,D_2=(Q_2,\Sigma, \delta_2, q_2, F_2)\]

      <p>and we construct a new DFA $D$:</p>

\[D=(Q,\Sigma, \delta, q_0, F)\]

      <p>where:</p>

      <ul>
        <li>$Q=Q_1 \times Q_2={(r_1,r_2)\,\vert \,\forall r_1\in Q_1,\,\forall r_2 \in Q_2}$
          <ul>
            <li>so basically you can run “in-parallel”</li>
          </ul>
        </li>
        <li>$q_0=(q_1,q_2)$</li>
        <li>$F={(r_1,r_2)\,\vert \,r_1\in F_1 \,or\,r_2\in F_2}=F_1\times Q_1 \cup F_2 \times Q_2$</li>
        <li>$\delta((r_1,r_2),a)=(\delta_1(r_1,a), \delta_2(r_2,a))$</li>
      </ul>
    </li>
  </ul>
</blockquote>

<p>With the above proof, we can easily prove the <strong>intersection operation</strong></p>

<ul>
  <li>the only difference is defining $F={(r_1,r_2)\,\vert \,r_1\in F_1 \,AND\,r_2\in F_2}=F_1\times Q_1 \cap F_2 \times Q_2$</li>
</ul>

<blockquote>
  <p><strong>DFA Proof for Intersection Operation</strong></p>

  <ul>
    <li>
      <p>The idea would be the same: to run a string in “parallel” in the two DFAs:</p>

\[D_1=(Q_1,\Sigma, \delta_1, q_1, F_1);\,D_2=(Q_2,\Sigma, \delta_2, q_2, F_2)\]

      <p>and we construct a new DFA $D$:</p>

\[D=(Q,\Sigma, \delta, q_0, F)\]

      <p>where:</p>

      <ul>
        <li>$Q=Q_1 \times Q_2={(r_1,r_2)\,\vert \,\forall r_1\in Q_1,\,\forall r_2 \in Q_2}$
          <ul>
            <li>so basically you can run “in-parallel”</li>
          </ul>
        </li>
        <li>$q_0=(q_1,q_2)$</li>
        <li>$F={(r_1,r_2)\,\vert \,r_1\in F_1 \,AND\,r_2\in F_2}=F_1\times Q_1 \cap F_2 \times Q_2$</li>
        <li>$\delta((r_1,r_2),a)=(\delta_1(r_1,a), \delta_2(r_2,a))$</li>
      </ul>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Alternative Proof for Intersection Operation</strong></p>

  <ul>
    <li>
      <p>This basically uses De Morgan’s Law:</p>

      <ul>
        <li>if $L_1$ and $L_2$ are regular, then we know $\bar{L_1}$ and $\bar{L_2}$ are also regular. Then this means that $\bar{L_1}\cup \bar{L_2}$ is still regular. Therefore, since:</li>
      </ul>

\[L_1 \cap L_2 = \overline{(\overline{L}_1 \cup \overline{L}_2)}\]

      <p>Hence $L_1 \cup L_2$ is <strong>still regular</strong>.</p>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>NFA Proof for Concatenation Operation</strong></p>

  <ul>
    <li>Basically, we can imagine starting with $N_1$ (or in fact, $D_1$ with DFA would work as well), and make $\epsilon$ transition from every accepting state in $N_1$ to the starting state of $N_2$ (again, this could be $D_2$).</li>
    <li><mark>TODO: the formal proof</mark></li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Notice:</strong></p>

  <ul class="task-list">
    <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked" />For those kind of closure proof, we generally find it easy to <strong>start with a strict DFA</strong>, and <strong>construct a NFA from it</strong>, which is looser in terms of transitions/states, and works as it proves a language being regular.</li>
  </ul>
</blockquote>

<p>Lastly:</p>

<blockquote>
  <p><strong>Proof for Kleene Star Operation</strong></p>

  <ul>
    <li>
      <p>Let $N$ be an NFA recognizing $L$, then we should be able to construct an NFA recognizing $L^*$ (hence <strong>making $L^*$ still regular, which is what we meant by closed</strong>)</p>
    </li>
    <li>Since now we need to deal with <strong>accepted strings concatenated with each other</strong> (i.e. $L^k$), then we know we just need to <strong>add an $\epsilon$ transition from all accepted state to the initial state</strong> (hence allowing concatenation)</li>
    <li>However, the above does not take into account the only case left $L^0=\epsilon$, which can be <strong><em>properly</em></strong> fixed by:</li>
  </ul>

  <p><img src="\lectures\images\typora-user-images\image-20200925015117647.png" alt="image-20200925015117647" /></p>

  <ul>
    <li><mark>TODO: Properly prove it</mark></li>
  </ul>

  <p>Note:</p>

  <ul>
    <li>If instead of adding a new state with $\epsilon$ transition only, you made the starting state accepting. This would cause the problem that, if there is a loop that goes from the starting state, then it will accept that string as well, even if that string might not be defined in the language $L^*$. Therefore, that approach would be wrong.</li>
  </ul>
</blockquote>

<h3 id="regular-operations-and-expressions">Regular Operations and Expressions</h3>

<p>We define <strong><em>regular operations</em></strong> being:</p>

<ul>
  <li><strong>union $\cup$</strong></li>
  <li>
    <p><strong>concatenation $\circ$</strong></p>
  </li>
  <li><strong>Kleene star $*$</strong></li>
</ul>

<p>This means that a <strong><em>regular expression is defined as:</em></strong></p>

<blockquote>
  <p><strong>Regular Expression Definition</strong></p>

  <ul>
    <li>An expression is a regular expression $R$ over an alphabet $\Sigma$ if:
      <ul>
        <li>$R=a$ for $a\in \Sigma$</li>
        <li>$R=\epsilon$</li>
        <li>$R=\empty$</li>
        <li>$R=(R_1 \cup R_2)$</li>
        <li>$R=(R_1 \circ R_2)$</li>
        <li>$R=(R_1)^*$
          <ul>
            <li>for $R_1$ and $R_2$ being regular expressions</li>
            <li>also notice that the definitions are <strong>recursive</strong></li>
          </ul>
        </li>
      </ul>
    </li>
    <li>
      <p>In other words, a regular expression is a <strong>string</strong> together with additional symbols allowed:</p>

\[\Sigma \cup \{\cup, *,\circ,(,)\}\]
    </li>
  </ul>

</blockquote>

<p>And regular expressions are <strong>special strings</strong>, because:</p>

<ul>
  <li>$L(a)={a}$ for $a\in \Sigma$</li>
  <li>$L(\epsilon)={\epsilon}$</li>
  <li>$L(\empty)={}$
    <ul>
      <li><strong>interestingly, this means</strong> $L(R\circ \empty)=L(\empty\circ R)=\empty$</li>
    </ul>
  </li>
  <li>$L(R_1 \cup R_2)=L(R_1)\cup L(R_2)$</li>
  <li>$L(R_1 \circ R_2)=L(R_1)\circ L(R_2)$</li>
  <li>$L(R^<em>)=L(R)^</em>$</li>
</ul>

<p>Therefore you can <strong>define a language to be regular if it is composed of regular expressions, beside constructing NFA/DFA</strong>.</p>

<h4 id="examples">Examples</h4>

<p>Consider regular expressions over $\Sigma={a,b}$</p>

<ul>
  <li>
    <p><strong>Question</strong></p>

    <p>then think about the language of the following regular expressions:</p>

    <ul>
      <li>$(a\cup bb)^*$</li>
      <li>$(abb \cup bbb)\circ (baa \cup b)$</li>
      <li>$aa^*$</li>
      <li>$(a \cup b)^*a(a\cup b)(a\cup b)(a\cup b)$</li>
    </ul>
  </li>
  <li>
    <p><strong>Solution</strong></p>
    <ul>
      <li>a language that has all contiguous blocks of $b$ of even length</li>
      <li>${abbbaa,abbb,bbbbaa,bbbb}$</li>
      <li>a language that has ${a^i \vert  i\ge 1}$
        <ul>
          <li>sometimes, also referred to as $a^+$</li>
        </ul>
      </li>
      <li>a language that has its 4th last symbol being $a$</li>
    </ul>
  </li>
</ul>

<h3 id="regular-language-2">Regular Language</h3>

<blockquote>
  <p><strong>Theorem:</strong></p>

  <ul>
    <li>A language $L$ can be generated by a Regular Expression <strong>if and only if</strong> that language is regular.</li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Proof:</strong></p>

  <ul>
    <li>
      <p>In the first direction, we need to show that for any regular expression $R$, $L(R)$ is regular (recognized by a NFA).</p>

      <p>Usually those proofs use induction:</p>

      <ul>
        <li>
          <p><strong>Base Cases</strong>:</p>

          <p><img src="\lectures\images\typora-user-images\image-20200929211140562.png" alt="image-20200929211140562" style="zoom: 50%;" /></p>

          <p><strong>Advancement</strong></p>

          <p><img src="\lectures\images\typora-user-images\image-20200929211305690.png" alt="image-20200929211305690" style="zoom:50%;" /></p>

          <p>where we used the <strong>closure</strong> property, which are already proven.</p>
        </li>
      </ul>
    </li>
    <li>
      <p>In the other direction, we show that if $L$ is regular/has an NFA, then $L=L(R)$ for some regular expression $R$.</p>

      <p>So that for any NFA $N$, there is a regular expression $R$ such that $L(N)=L(R)$ (basically every word in the language can be expressed <strong><em>as a single regular language</em></strong>)</p>

      <ul>
        <li>Overview:</li>
      </ul>

      <p><img src="\lectures\images\typora-user-images\image-20200929211732634.png" alt="image-20200929211732634" style="zoom: 50%;" /></p>

      <p>where a GNFA is defined in the section <a href="#Generalized NFA">Generalized NFA</a>.</p>

      <ul>
        <li>
          <p>First, we know that a string $w$ is accepted by a GNFA, if there $\exists$ a path from start state to accept state s.t. the <strong>concatenating of regular expressions along the path</strong> gives a regular expression such that $w \in L(R)$.</p>
        </li>
        <li>
          <p>Next, we construct a GNFA with one fewer state:</p>

          <ul>
            <li>
              <p>choose a state to remove $q_{rip}$ (obviously not a start/accept state)</p>
            </li>
            <li>
              <p>then, for <strong>every</strong> other pairs of states $q_i,q_j$ ($q_i,q_j \neq q_{rip}$), do the following:</p>
            </li>
          </ul>

          <p><img src="\lectures\images\typora-user-images\image-20200929213940068.png" alt="image-20200929213940068" style="zoom: 50%;" /></p>

          <p>​	where:</p>

          <ul>
            <li>it is all about recursive picking out any <strong>triplet into a doublet</strong> transitions:
              <ul>
                <li>$q_i \to q_{rip} \to q_j \Rightarrow q_i  \to q_j$</li>
              </ul>
            </li>
            <li>$q_j \to q_{rip} \to q_i \Rightarrow q_j  \to q_i$
              <ul>
                <li>$q_i \to q_{rip} \to q_i \Rightarrow q_i  \to q_i$</li>
              </ul>
            </li>
            <li>$q_j \to q_{rip} \to q_j \Rightarrow q_j  \to q_j$</li>
            <li>basically compute all the possible paths in regular expression going from $q_i$ to $q_j$</li>
          </ul>
        </li>
        <li>
          <p>Now, we do it recursively, such that the GNFA has <strong>only the start state and the accept state</strong></p>

          <p><img src="\lectures\images\typora-user-images\image-20200929214441449.png" alt="image-20200929214441449" style="zoom:50%;" /></p>

          <p>Then we <strong>arrive at a single regular expression</strong>. Therefore, $L(R)=$ language recognized by the original NFA.</p>
        </li>
      </ul>
    </li>
  </ul>
</blockquote>

<hr />

<p><strong><em>For example:</em></strong></p>

<ul>
  <li>
    <p><strong>Question</strong></p>

    <p>Consider the language that has strings with even number of $0$, and turn it into a regular expression using the GNFA procedure.</p>

    <p><img src="\lectures\images\typora-user-images\image-20200929214640977.png" alt="image-20200929214640977" style="zoom:50%;" /></p>
  </li>
  <li>
    <p><strong>Solution</strong></p>

    <p>First, we build the GNFA with</p>

    <p><img src="\lectures\images\typora-user-images\image-20200929214756644.png" alt="image-20200929214756644" style="zoom: 50%;" /></p>

    <p>where</p>

    <ul>
      <li>technically we also need to <strong>add all the other transitions between any two states labelled with $\empty$</strong>, but since they are $\empty$ transitions, they <strong>do not accept the below computation</strong>.</li>
    </ul>

    <p>Now, we rip $q_1$:</p>

    <p><img src="\lectures\images\typora-user-images\image-20200929215308386.png" alt="image-20200929215308386" style="zoom: 50%;" /></p>

    <p>Lastly, we rip $q_0$:</p>

    <p><img src="\lectures\images\typora-user-images\image-20200929215346417.png" alt="image-20200929215346417" style="zoom: 50%;" /></p>

    <p>and the regular expression $(1 \cup 01^<em>0)^</em>$</p>

    <ul>
      <li>
        <p>for example, this works:</p>

        <p><img src="\lectures\images\typora-user-images\image-20200929215746354.png" alt="image-20200929215746354" style="zoom: 50%;" /></p>
      </li>
    </ul>
  </li>
</ul>

<h2 id="generalized-nfa">Generalized NFA</h2>

<p>It is a special case of a NFA, such that:</p>

<ul>
  <li>it has exactly one start state, and one accept state</li>
  <li><strong>transitions</strong> are labeled with <strong>regular expressions</strong></li>
  <li>no incoming transition into start state, and no outgoing transition from accept state</li>
  <li>for all the transitions are present (like the requirement for DFA)</li>
</ul>

<h3 id="transform-gnfa-to-nfa">Transform GNFA to NFA</h3>

<p>Given an NFA, can transform to equivalent GNFA:</p>

<ul>
  <li>add new start state $q_{start}$, with $\epsilon$ transition to the old start state</li>
  <li>add new accept state $q_{accept}$, add $\epsilon$ any old accept states to $q_{accept}$, and make $q_{accept}$ the only accept state</li>
  <li>if a transition was labeled by multiple symbols (e.g. ${a,b}$), label it as a union of symbols (e.g. $a \cup b$)</li>
  <li>label any previously non-existing transitions going to $\empty$</li>
</ul>

<h3 id="transform-gnfa-to-regex">Transform GNFA to Regex</h3>

<p>Whenever you rip one state off, you need to compute, recursively, the states that are affected by that removal.</p>

<p>For example:</p>

<p><img src="\lectures\images\typora-user-images\image-20201007143816740.png" alt="image-20201007143816740" style="zoom: 50%;" /></p>

<h1 id="week-4">Week 4</h1>

<p>Up to now, we have:</p>

<p><img src="\lectures\images\typora-user-images\image-20201001222412581.png" alt="image-20201001222412581" style="zoom: 50%;" /></p>

<p>However, we need to also discuss the case of <strong>proving that a language is not regular</strong>.</p>

<hr />

<p><strong><em>For example:</em></strong></p>

<ul>
  <li>
    <p><strong>Question:</strong></p>

    <p>Prove that the following language is not regular:</p>

\[L=\{ a^i b^i \,|\,i\ge 0\}\]
  </li>
  <li>
    <p><strong>Solution</strong></p>

    <p>First, we need to understand the language. <strong>Some examples would be</strong>:</p>

\[\{\epsilon, ab, aabb, aaabbb, ...\}\]

    <p>The intuition would be that you would need an infinite number of states to know if you had the same number of $a$ and $b$.</p>

    <p>We do this by contradiction:</p>

    <ul>
      <li>
        <p>Assume $L$ is regular. Let $D$ be a DFA that recognizes $L$. Let $p$ be the number of states in $D$.</p>

        <p>Consider the string $a^pb^p \in L$.</p>

        <p>Consider the computation of $D$ on $a^pb^p$</p>

\[r_0(a) \to r_1(a) \to r_2(a) \to... \to r_p(a) \to r_{p+1}(b) \to  r_{p+2}(b)\to ... r_{2p}(b)\]

        <p>where:</p>

        <ul>
          <li>$r_{2p}$ an accepting state</li>
          <li>and those states do not have to be unique</li>
        </ul>

        <p>Yet, since we said there are only $p$ states, there must be a repetition among the states.</p>

        <ul>
          <li>
            <p>Let $r_k = r_l$ where $k &lt;l \le p$</p>

            <p><img src="\lectures\images\typora-user-images\image-20201001224223961.png" alt="image-20201001224223961" style="zoom: 50%;" /></p>
          </li>
        </ul>

        <p>Then:</p>

        <ul>
          <li>
            <p>$a^pb^p = a^ia^{i-k}a^{p-l}b^p = xyz$</p>

            <ul>
              <li>where $x=a^i, y=a^{i-k}, z=a^{p-l}b^p$</li>
            </ul>

            <p>But this means that even if we dropped $y$ from the string, $xz = a^i a^{i-k}b^p$ is still accepted.</p>

            <p><strong>Therefore, as soon as you have a cycle, other strings not in the language will also get accepted. This contradicts the settings.</strong></p>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<hr />

<h2 id="proving-irregular-language---part-1">Proving Irregular Language - Part 1</h2>

<p>Now, we generalize the above proof.</p>

<ol>
  <li>First we want to show that <strong><em>all regular language satisfy some property “pumping lemma”</em></strong>
    <ul>
      <li>any long enough string in the language have a cycle that can be pumped</li>
    </ul>
  </li>
  <li>Use the above to show that $L$ is not regular:
    <ul>
      <li>Assume <strong>towards contradiction</strong>, that $L$ is regular, then pumping lemma holds. <strong>Then choose long enough words, pump it in a way that we find a string $\notin L$.</strong> (basically the cycle we made)</li>
    </ul>
  </li>
</ol>

<blockquote>
  <p><strong>Pumping Lemma:</strong></p>

  <ul>
    <li>
      <p>For <strong>any regular language $L$</strong>, there exists a number $p$ (“pumping number”), such that for $\forall w \in L$, $\vert w\vert  \ge p$,:</p>

\[\exists \,\,a\,\,way\,\,to\,\,parse\,\,w=xyz\]

      <p>such that:</p>

      <ul>
        <li>$\vert xy\vert  \le p$</li>
        <li>$\vert y\vert  &gt; 0$</li>
        <li>$\forall i,\,\,xy^iz\in L$
          <ul>
            <li><strong><em>the key part</em></strong></li>
            <li>basically <strong>parsing/transitioning the $y$ part will have a cycle, and a regular language NEEDS to take it</strong></li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</blockquote>

<p>Now, we need to first show that all regular languages fulfill this lemma.</p>

<blockquote>
  <p><strong>Proof</strong>:</p>

  <ul>
    <li>
      <p>Let $L$ be regular, and let $D$ be some DFA recognizing $L$, and let $p$ be the number of states in $D$.</p>

\[\forall w \in L, |w|\ge p,\,\,write\,w=w_1w_2...w_p...w_m\]

      <p>Now, consider a computation of $D$ on $w$:</p>

      <p><img src="\lectures\images\typora-user-images\image-20201001230309308.png" alt="image-20201001230309308" style="zoom: 50%;" /></p>

      <p>Since there are only $p$ states, then there must be a repetition/cycle in the states $r_0,r_1…r_p$. because we have only $p$ states.</p>

      <p>Therefore, $\exists i&lt;j\le p,\,\,r_i=r_j$.</p>

      <ul>
        <li>notice it is $\exists$, so we <strong>cannot freely choose where that $i$ is, but only know that $i&lt;p$.</strong></li>
      </ul>

      <p>Then we have:</p>

      <p><img src="\lectures\images\typora-user-images\image-20201001230458206.png" alt="image-20201001230458206" style="zoom: 50%;" /></p>

      <p>Then it follows that we can break down</p>

      <ul>
        <li>
          <p>$w=xyz$</p>

          <p>where:</p>

          <ul>
            <li>$x=w_1..w_i$</li>
          </ul>
        </li>
        <li>
          <p>$y=w_{i+1}..w_j$</p>

          <ul>
            <li>$z=w_{j+1}..w_m$</li>
          </ul>
        </li>
      </ul>

      <p>As a result, in this construction, we have shown that all the required properties hold:</p>

      <ul>
        <li>$\vert xy\vert =j\le p$</li>
        <li><strong>$\vert y\vert =j-i &gt; 0$</strong>
          <ul>
            <li>this $y$ has to be made such that $x$ CANNOT be pumped. So you actually <strong>cannot choose $y$.</strong></li>
          </ul>
        </li>
        <li><strong>$\exists\,i=0,1,2…\vert xy^iz\in L$</strong></li>
      </ul>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Note:</strong></p>

  <ul class="task-list">
    <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked" />In general, you cannot use a specific parsing of $y$ in $w=xyz$. To <strong>reach a contradiction</strong> to the pumping lemma, you <strong>need to be able to handle (find a contradiction for) any possible parsing</strong> – you cannot choose one specific one.</li>
    <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked" />When using the pumping lemma, <strong>all you can choose/make up is the parameter $w$ and the $i$.</strong> All the other parameters have to fall off from your choice of $w$ and $i$.</li>
  </ul>
</blockquote>

<p>Therefore, we can use the pumping lemma to prove that some $L$ is <strong>not regular</strong>:</p>

<ol>
  <li>Assume towards contradiction $L$ is regular.</li>
  <li>Then there must be <strong>$p$ being the pumping number</strong>.</li>
  <li>I <strong>choose</strong> some string $w\,\vert \,w\in L \,\,and \,\,\vert w\vert \ge p$
    <ul>
      <li>this is the tricky part that you need to figure out yourself</li>
    </ul>
  </li>
  <li>Then, whenever you parse the string $w$, there will be a cycle due to the lemma with the pumping number.</li>
  <li>Therefore, we <strong>know $w=xyz$ where</strong>
    <ul>
      <li>$\vert xy\vert \le p$</li>
      <li>$\vert y\vert &gt;0$</li>
      <li>$\exist i,\,\,s.t.\,\,xy^iz \notin L$</li>
    </ul>
  </li>
  <li>Therefore, this contradicts the pumping lemma, and $L$ is not regular.</li>
</ol>

<blockquote>
  <p><strong>Theorem:</strong></p>

  <ul>
    <li>
      <p>If we have a language:</p>

\[L=\{w \in \{ a,b\}^*\,|\,w\,\,is\,\,a\,\,palindrome\}\]

      <p>Then $L$ is not regular.</p>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Proof:</strong></p>

  <ul>
    <li>Try 1:
      <ul>
        <li>Assume towards contradiction that it is regular</li>
        <li>Then we choose $w=a^p$, where $\vert w\vert \ge p$ and we want to find a $w=xyz$ and by pumping, it will produce a word that is not in $L$.</li>
        <li>But it seems all the words are still in $L$. Hence it does not work.</li>
      </ul>
    </li>
    <li>Try 2:
      <ul>
        <li>Assume towards contradiction that it is regular</li>
        <li>Then we choose $w=a^pba^p$, where $\vert w\vert \ge p$</li>
        <li>we want to find a $w=xyz$, such that $\vert xy\vert \le p$, and $\vert y\vert &gt;1$.
          <ul>
            <li>this means that $y$ must be consisting only $a$s. This $w$ has to be constructed nicely so that this result falls out.</li>
          </ul>
        </li>
        <li>Then, we can construct a string, for example: $xyyz=a^{p+\vert y\vert }ba^p \notin L$.
          <ul>
            <li>In general $\exists i,\,\,xy^iz=a^{p+i}ba^p \notin L$</li>
          </ul>
        </li>
        <li>Hence we reach a contradiction. $L$ is not regular.</li>
      </ul>
    </li>
  </ul>
</blockquote>

<hr />

<p><strong><em>Another Example</em></strong>:</p>

<ul>
  <li>
    <p><strong>Question</strong></p>

    <p>Show that the language:</p>

\[L = \{1^n\,|\,n\,\,is\,\,prime\}\]
  </li>
  <li>
    <p><strong>Solution</strong></p>

    <p><img src="\lectures\images\typora-user-images\image-20201006205524361.png" alt="image-20201006205524361" style="zoom: 50%;" /></p>

    <p>where:</p>

    <ul>
      <li>basically, <strong>all you can choose is $i$.</strong></li>
    </ul>
  </li>
</ul>

<h1 id="week-5">Week 5</h1>

<h2 id="proving-irregular-language---part-2">Proving Irregular Language - Part 2</h2>

<p>There are also <strong>other methods</strong> to prove that a language is not regular.</p>

<h3 id="using-closure-properties">Using Closure Properties</h3>

<p>Let’s start by looking at one example:</p>

<ul>
  <li>
    <p>Question:</p>

    <p>Show that $L={w\in{a,b}^*\,\vert \,#a=#b}$</p>
  </li>
  <li>
    <p>Solution:</p>

    <p>Basically we need to know something else being non-regular (the ones we have seen before).</p>

    <p>Assume $L$ is regular, then we can take the $L_1 = a^<em>b^</em>$, which is <strong>regular</strong>.</p>

    <p>Now, since regular languages are closed under operations $\cap$, consider:</p>

\[L \cap L_1 = L_1 = a^pb^p\,,\,\,\forall p \in \mathbb{Z}\]

    <p>which we have proved to be <strong>non-regular</strong>.</p>

    <p>Therefore, <strong>it is not closed</strong>, and we reached a contradiction.</p>

    <p>Therefore, $L$ is also non-regular.</p>
  </li>
</ul>

<p><strong>In general</strong>, the template for the proof would be:</p>

<ol>
  <li><strong>Assume $L$</strong> is regular. Then take another regular language $L_1$ (e.g. built from a regular language).</li>
  <li>Then, the following language $L \cap L_1 = L_2$, or $L \circ L_1 = L_2$, or any closed operation is should still be regular.</li>
  <li>But $L_2$ is known to be irregular.</li>
  <li>Therefore, a contradiction, as those operations should be <strong>closed</strong>. So $L$ must also be irregular.</li>
</ol>

<h3 id="myhill-nerode-theorem">Myhill-Nerode Theorem</h3>

<blockquote>
  <p><strong>Definitions:</strong></p>

  <ul>
    <li>
      <p>Let $L \in \Sigma^<em>$ be some language over $\Sigma$, and $x,y\in \Sigma^</em>$ be strings. We say $z \in \Sigma^*$ is a <strong>distinguishing extension</strong> of $x,y$ w.r.t. $L$, if exactly one $xz$, $yz$ is in $L$ and the other string $\notin L$.</p>

      <ul>
        <li>notice that <strong>$z$ can be $\epsilon$</strong></li>
      </ul>
    </li>
    <li>
      <p>If such $z$ exists, then we say that <strong>$x,y$ are distinguishable by $L$</strong>.</p>
    </li>
    <li>
      <p>If no such string exists, then we say $x,y$ are <strong>indistinguishable by</strong> $L$. (So they are either both in $L$ or both not.) Denote it by</p>

\[x \sim_L y\]
    </li>
  </ul>

</blockquote>

<p>Basically,  $x$ and $y$ are <strong>indistinguishable</strong> if <strong>both of them landed at the same state in a DFA/NFA</strong>, so that any ending you add to them will affect both the same way.</p>

<ul>
  <li>if obviously $x$ and $y$ are in different states (e.g. $x$ is accepted and $y$ is not), then you simply have $z=\epsilon$</li>
</ul>

<blockquote>
  <p><strong>Claim</strong>:</p>

  <ul>
    <li>
      <p>Then $\sim_L$ is an <strong>equivalence relation</strong>.</p>

\[[x] = \{y \in \Sigma^*\,|\,x\sim_Ly\}\]

      <ul>
        <li>where you basically have <strong>a set</strong> of those strings <strong>being indistinguishable in the same manner</strong></li>
      </ul>
    </li>
    <li>
      <p>This means that, if $L \subseteq \Sigma^*$ is a regular language, and $D$ is a DFA recognizing it, <strong>then $x \sim_L y$  also means that $x$ and $y$</strong> <strong>end in the same state</strong>.</p>

      <ul>
        <li>so if $x$ and $y$ ended at different state, then <strong>automatically they are distinguishable.</strong></li>
      </ul>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Corollary:</strong></p>

  <ul>
    <li>If $L$ is regular, and $D$ is a DFA for $L$, then it has to be that <strong>$#$ of equivalent classes induced by $\sim_L$ must be $\le#$ states in $D$</strong>.
      <ul>
        <li>kind of obvious because the equivalent class will land on the same state</li>
      </ul>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Myhill-Nerode Theorem</strong>:</p>

  <ul>
    <li>For any $L \subseteq \Sigma^*$, $L$ is regular $\iff$ $#$ of equivalent classes for $\sim_L$ is finite.
      <ul>
        <li>Obvious since a regular language must have a finite number of states.</li>
      </ul>
    </li>
    <li>If $L$ is <strong>regular</strong>, then <strong>$#$ of equivalence classes</strong> for $\sim_L$ <strong>is exactly the $#$ of states in the <em>minimal</em> DFA recognizing $L$.</strong></li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Note:</strong></p>

  <ul class="task-list">
    <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked" />This means that we can prove <strong>how many states the minimized DFA for language has.</strong>
      <ul>
        <li>In fact, there is an efficient algorithm, s.t. given a DFA, it minimizes it to be the smallest DFA for $L$.</li>
      </ul>
    </li>
    <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked" />This also means that we can <strong>prove that a language is not regular</strong>, by showing infinitely many strings, where no two strings $x,y$ are equivalent to each other $\sim_L$, then there must be <strong>infinitely many equivalence classes</strong>. Hence it is not regular.</li>
  </ul>
</blockquote>

<hr />

<p><strong><em>For example:</em></strong></p>

<ul>
  <li>
    <p><strong>Question:</strong></p>

    <p>Consider the palindrome example:</p>

\[L_{pali} = \{ w\in\{a,b\}^*\,|\,w=w^R \}\]
  </li>
  <li>
    <p><strong>Solution</strong>:</p>

    <p><img src="\lectures\images\typora-user-images\image-20201011133822848.png" alt="image-20201011133822848" style="zoom:50%;" /></p>

    <p>where:</p>

    <ul>
      <li>remember that all we need to show is that there <strong>exists an infinite number of “palindromes” that are not similar</strong>.
        <ul>
          <li>the proof above works because $a^n$ is a palindrome itself</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<hr />

<hr />

<p><strong><em>For example</em></strong></p>

<ul>
  <li>
    <p><strong>Question:</strong></p>

    <p>Consider the language:</p>

\[L=\{a^nb^n\,|\,n\ge0\}\]

    <p>is not regular.</p>
  </li>
  <li>
    <p><strong>Solution:</strong></p>
  </li>
</ul>

<p><img src="\lectures\images\typora-user-images\image-20201006214051846.png" alt="image-20201006214051846" style="zoom:67%;" /></p>

<hr />

<p><strong>In general, the template would be:</strong></p>

<ol>
  <li>Think about two words $w(n),w(n+k)$, and $k\neq 0$</li>
  <li>Find a <strong>distinguishing extension that would make exactly one of them in the language</strong> and the other not
    <ul>
      <li>so that the two words that are <strong>not equivalent</strong></li>
    </ul>
  </li>
  <li>Make $n\to \infty$. You have found an infinite number of equivalent sets, because $w(0)\neq w(1) \neq w(2) \neq w(3) \neq …$
    <ul>
      <li>we <strong>don’t care if $w(n)$ is accepted or not at this point</strong>, we just need to show that they are all different from each other (lands in different states)</li>
    </ul>
  </li>
  <li>Finished, there are infinite number of equivalent class, hence infinite number of states needed.</li>
</ol>

<hr />

<p><strong><em>Other Usage:</em></strong></p>

<ul>
  <li>
    <p><strong>Question</strong>:</p>

    <p>Show that there are exactly $2^n$ equivalent classes (states) in a language:</p>

\[L = \{0,1\}^*\,|\,nth\,\,last\,\,symbol\,\,is\,\,0\]
  </li>
  <li>
    <p><strong>Solution:</strong></p>

    <p>First, we can show that there are at least $2^n$ equivalent classes:</p>

    <p><img src="\lectures\images\typora-user-images\image-20201006220045181.png" alt="image-20201006220045181" style="zoom:67%;" /></p>

    <p>Then, we show that there are exactly $2^n$ equivalent classes.</p>

    <p><img src="\lectures\images\typora-user-images\image-20201006215810450.png" alt="image-20201006215810450" style="zoom: 67%;" /></p>
  </li>
</ul>

<hr />

<h2 id="context-free-language">Context Free Language</h2>

<p>Basically, all we have discussed were the regular languages, but there are <strong>other wider/richer class of languages</strong> out there:</p>

<p><img src="\lectures\images\typora-user-images\image-20201009003127156.png" alt="image-20201009003127156" style="zoom: 67%;" /></p>

<p>Alike regular languages, you can also define context free languages in two ways:</p>

<ul>
  <li><strong>language generated</strong> (alike regex), this would be the most common for context free language</li>
  <li><strong>algorithm generated</strong> (alike DFA/NFA)</li>
</ul>

<p>One example of a context-free language is:</p>

\[\Sigma = \{0,1\};\,\,\\
V=\{S\};\\
\begin{cases}
S\to \epsilon\\
S\to 0S1
\end{cases}\]

<p>Then, a word in the language would be:</p>

\[S \Rightarrow 0S1 \Rightarrow 00S11 \Rightarrow 0011 \in L(G)\]

<p>where:</p>

<ul>
  <li>you started with a start variable $S$, and then generated to $0S1$, and etc.</li>
</ul>

<p>And, in general, you have:</p>

\[L(G) = \{ 0^n1^n \,|\,n\ge0 \}\]

<p>and you get a sense that <strong>context free languages are basically production rules</strong>:</p>

<ul>
  <li>strings you can produced from those rules are in the language.</li>
</ul>

<h3 id="definitions-1">Definitions</h3>

<blockquote>
  <p><strong>Definition of Context Free Grammar:</strong></p>

  <ul>
    <li>
      <p>A context-free grammar is a tuple $(V, \Sigma, R, S)$,</p>

      <p>where</p>

      <ul>
        <li>
          <p>$V$ is a finite set of <strong>single variables</strong></p>

          <ul>
            <li>it is exactly because it only allow a single variable, it is context free because it only depends on that variable without context</li>
          </ul>
        </li>
        <li>
          <p>$\Sigma$ is an alphabet (finite)</p>
        </li>
        <li>
          <p>$R$ is a finite set of <strong>rules</strong> of the form:</p>

\[A \to w;\,\,A\in V;\,\,w\in(V\cup\Sigma)^*\]

          <p>so basically, you can <strong>have more than one variables</strong>, and <strong>each variable points to either a string or a string+another variable</strong>.</p>

          <ul>
            <li>in general, for generating an <strong>non-empty language</strong>, you need to have <strong><em>at least one rule that points to a symbol only</em></strong>.</li>
          </ul>
        </li>
        <li>
          <p>$S \in V$ is the <strong>start</strong> variable</p>
        </li>
      </ul>
    </li>
  </ul>
</blockquote>

<p>This means the following:</p>

<blockquote>
  <p><strong>Definitions</strong></p>

  <ul>
    <li>
      <p>If two string $u,v \in (V \cup \Sigma)^*$, and there is a rule $A \to w \in R$, then we can write:</p>

\[uAv \Rightarrow uwv\]

      <p>which reads: $uAv$ yields $uwv$.</p>
    </li>
    <li>
      <p>If two string $u,v\in (V \cup \Sigma)^<em>$, we say <strong>that $u \Rightarrow ^* v$ if</strong> some $u_1, u_2, …,u_n \in (V \cup \Sigma)^</em>$ we have:</p>

\[u \Rightarrow u_1 \Rightarrow u_2 \Rightarrow ... \Rightarrow v\]

      <p>where:</p>

      <ul>
        <li>$u_1,u_2,…,u_n$ are just strings that you can reach from its previous string.</li>
      </ul>

      <p>This basically means that <strong>$u$ generates to $v$</strong> if there is an arbitrary number of step that can make we <strong>start with $u$ and end in $v$.</strong></p>

      <ul>
        <li>e.g. $S \Rightarrow^* 0011$ in the example above</li>
      </ul>
    </li>
  </ul>
</blockquote>

<p>Notice that:</p>

<ul>
  <li>when you <strong>specify rules, you use $\to$,</strong> when you <strong>show derivations, you use $\Rightarrow$</strong></li>
</ul>

<p>And correspondingly:</p>

<blockquote>
  <p><strong>Context Free Language Def:</strong></p>

  <ul>
    <li>A language $L$ is a context-free language if there <strong>exists a context free grammar</strong> $G$ such that $L(G)=L$.</li>
  </ul>
</blockquote>

<p>Therefore:</p>

<blockquote>
  <p><strong>Definition:</strong></p>

  <ul>
    <li>
      <p>We say context free language $G = (V, \Sigma, R, S)$ has the language $L(G)$ if:
$$ {mathtools}
L(G) = {w \in \Sigma^* \,|\,S\Rightarrow ^* w}</p>

      <p>$$</p>
    </li>
  </ul>
</blockquote>

<hr />

<p><strong><em>For example</em></strong>:</p>

<ul>
  <li>
    <p><strong>Question:</strong></p>

\[G=(\{S\},\{a,b\},R,S)\\
R:\begin{cases}
S \to \epsilon \\
S \to aSa\,|\,bSb
\end{cases}\]
  </li>
  <li>
    <p><strong>Solution:</strong></p>

    <p>We see that it is the language of:</p>

\[L(G) = \{w \in \{a,b\}^*\,|\,w\,\,in\,\,an\,\,even\,\,length\,\,palindrome\}\]

    <p>To prove it, we need to show the $\iff$ relationship:</p>

    <ol>
      <li>That all $S \Rightarrow^* w$ is in fact an even length palindrome</li>
      <li>All even length palindromes are captured by $L$/can be derived in $L$.</li>
    </ol>

    <p><mark>TODO: look at the proof in the book</mark></p>
  </li>
</ul>

<hr />

<hr />

<p><strong><em>For example:</em></strong></p>

<ul>
  <li>
    <p><strong>Question:</strong></p>

\[G=\{ \{G\},\{a,b,+,*,(,)\},R,E \}\\
E: \begin{cases}
E \to E+E\,|\,E*E\,|\,(E)\,|\,a\,|\,b
\end{cases}\]

    <p>Derive the string $a+b*a$</p>
  </li>
  <li>
    <p><strong>Solution:</strong></p>

    <p>The solution is trivial:</p>

\[E \Rightarrow E+E \Rightarrow E+E*E \Rightarrow a+E*E\Rightarrow a+b*E \Rightarrow a+b*a\]

    <p>in fact, its corresponding derivation tree looks like:</p>

    <p><img src="\lectures\images\typora-user-images\image-20201009013908878.png" alt="image-20201009013908878" style="zoom:50%;" /></p>

    <p>or, another way is:</p>

\[E \Rightarrow E*E \Rightarrow E+E*E \Rightarrow a+E*E\Rightarrow a+b*E \Rightarrow a+b*a\]

    <p>and its derivation tree looks like:</p>

    <p><img src="\lectures\images\typora-user-images\image-20201009014007870.png" alt="image-20201009014007870" style="zoom:50%;" /></p>

    <p>which means that you can <strong>interpret as both</strong>:</p>

    <ul>
      <li>$a+(b*a)$</li>
      <li>$(a+b)*a$</li>
    </ul>
  </li>
</ul>

<hr />

<h3 id="ambiguity">Ambiguity</h3>

<p>In fact, the above two examples leads to two different types of derivations as well:</p>

<blockquote>
  <p><strong>Rightmost Derivation</strong></p>

  <ul>
    <li>A derivation where, in each step, the rightmost <strong>variable</strong> gets replaced.
      <ul>
        <li>the first derivation tree above is not a rightmost derivation tree</li>
      </ul>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Leftmost Derivation</strong></p>

  <ul>
    <li>A derivation where, in each step, the leftmost <strong>variable</strong> gets replaced.
      <ul>
        <li>the second derivation tree above is also not a leftmost derivation tree</li>
        <li>this is also a left most derivation: $E \Rightarrow E+E \Rightarrow a+E\Rightarrow a+E*E \Rightarrow …$</li>
      </ul>
    </li>
    <li>There <strong>exists a 1:1 correspondence between a <em>derivation tree</em> and a leftmost <em>derivation</em>.</strong></li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Definition</strong></p>

  <ul>
    <li>A context free grammar is <strong>ambiguous</strong> if $\exist w\in L(G)$ s.t. <strong>the same string $w$ has two different <em>derivation trees (not derivations)</em></strong></li>
    <li>Equivalently, it is also ambiguous if it has <strong>two or more leftmost <em>derivations (not derivation trees)</em></strong>.
      <ul>
        <li>an application to think about it is how compiler compiles this, there should be only one way to compile/parse it.</li>
        <li>the example above is <strong>ambiguous</strong>.</li>
      </ul>
    </li>
  </ul>
</blockquote>

<p>A <strong>inambiguous context-free language</strong> would be:</p>

\[G=G'(\{E,F,G\},\{a,b,+,*,(,)\},R,E)\\
R:\begin{cases}
E \to E+F \,|\, F\\
F \to E*G \,|\, G\\
G \to (E) \,|\, a\,|\,b
\end{cases}\]

<p>where:</p>

<ul>
  <li>
    <p>the strings generated by this $G’$ is the <strong>same</strong> as $G$ defined above ($G={ {G},{a,b,+,*,(,)},R,E }$), but this one is inambiguous</p>
  </li>
  <li>in general, it is <strong>difficult to prove</strong> that any language is <strong>inambiguous</strong></li>
  <li>an <strong>inambiguous language might not exists</strong> for a specific context-free grammar</li>
</ul>

<blockquote>
  <p><strong>Definition:</strong></p>

  <ul>
    <li>A context free language $L$ is <strong>inherently ambiguous</strong>, if <strong>every context free grammar</strong> that generates $L$ is <strong>ambiguous</strong>.</li>
  </ul>
</blockquote>

<p>An example would be:</p>

\[L =\{a^nb^nc^md^m\,|\,n,m\ge0\} \cup \{a^nb^mc^md^n\,|\,n,m\ge0\}\]

<p>where:</p>

<ul>
  <li>again, this would be hard to prove, but it is <strong>inherently ambiguous</strong>.</li>
  <li>in fact, <strong>if you take the string $a^+b^+c^+d^+$ always have two derivation trees, no matter what $G$ you have that generates $L$.</strong></li>
</ul>

<h3 id="proving-the-language-of-cfg">Proving the Language of CFG</h3>

<p>In general, the proof has to do in both directions, and usually induction will be helpful.</p>

<p>For example:</p>

<ul>
  <li><strong>Question:</strong></li>
</ul>

<p><img src="\lectures\images\typora-user-images\image-20201013210819713.png" alt="image-20201013210819713" style="zoom:50%;" /></p>

<p>​	and we want to prove the claim.</p>

<ul>
  <li>
    <p><strong>Solution</strong></p>

    <p><img src="\lectures\images\typora-user-images\image-20201013211245301.png" alt="image-20201013211245301" style="zoom:50%;" /></p>

    <p><img src="\lectures\images\typora-user-images\image-20201013211544079.png" alt="image-20201013211544079" style="zoom:50%;" /></p>

    <p><img src="\lectures\images\typora-user-images\image-20201013212007539.png" alt="image-20201013212007539" style="zoom:50%;" /></p>

    <p><img src="\lectures\images\typora-user-images\image-20201013212416065.png" alt="image-20201013212416065" style="zoom:50%;" /></p>

    <p><img src="\lectures\images\typora-user-images\image-20201013212447392.png" alt="image-20201013212447392" style="zoom:50%;" /></p>
  </li>
</ul>

<h1 id="week-6">Week 6</h1>

<h2 id="regular-and-context-free-language">Regular and Context Free Language</h2>

<p>Consider the <strong>set of all valid regular expression</strong> over $\Sigma = {a,b}$.</p>

<p>That is, take alphabet ${a,b,(,),\cup,\circ,<em>,\empty, \epsilon}$ and the language $REGEX:{w \in {a,b,(,),\cup,\circ,</em>,\empty, \epsilon}^*\vert \text{$w$in in the regular expression}}$</p>

<ul>
  <li>e.g. $w=((a\circ*$ is not a regular expression, so it is not in $REGEX$, but $w=((a))$ is.</li>
</ul>

<blockquote>
  <p><strong>Claim</strong>:</p>

  <ul>
    <li>$REGEX$ defined above is <strong>not a regular language</strong>, but context free.</li>
    <li>basically, there is no DFA/NFA to tell if a regular expression is regular.</li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Proof</strong>: (Using pumping lemma)</p>

  <ul>
    <li>
      <p>Assume it was (so have a DFA/NFA for it), let $p$ be the pumping number.</p>
    </li>
    <li>
      <p>Choose $w=((((..(a^<em>)^</em>..)^*)))$ which is a valid regular expression, and $((((..($ is length $p$.</p>

      <ul>
        <li>so we have $\vert w\vert  &gt; p$</li>
      </ul>
    </li>
    <li>
      <p>For any possible parsing $w=xyz$, where $\vert xy\vert \le p$, $\vert y\vert &gt;0$.</p>
    </li>
    <li>
      <p>Then it has to be the cases that $y$ contains only $($.</p>
    </li>
    <li>
      <p>Now, we can simply choose any $i$, for example $i=2$</p>

      <ul>
        <li>$xyyz=(^{p+\vert y\vert } a)^<em>)^</em>…)$ is not balanced in brackets, so it is not regular.</li>
      </ul>
    </li>
    <li>
      <p>Now, we show that it is context-free:</p>

      <ul>
        <li>
\[G=(\{S\},\{a,b,(,),\cup,\circ,*,\empty, \epsilon\},R,S)\\
R: \begin{cases} 
S \to a|b|\epsilon|\empty \\
S\to (S \cup S) | (S \circ S)|(S^*)
\end{cases}\]
        </li>
        <li>and from here, we can <strong>prove</strong> that this generates the language $w \in {a,b,(,),\cup,\circ,<em>}^</em>$</li>
      </ul>
    </li>
  </ul>
</blockquote>

<p>Therefore, <strong>the set of regular expressions are context-free</strong>.</p>

<ul>
  <li>The class of context-free languages is <strong>closed</strong> under $\circ,\cup,*$</li>
  <li>every regular language is context free</li>
</ul>

<h3 id="proof-for-context-free-grammar-closure">Proof for Context Free Grammar Closure</h3>

<blockquote>
  <p><strong>Theorem:</strong></p>

  <ul>
    <li>The class of context-free languages is <strong>closed</strong> under $\circ,\cup,*$
      <ul>
        <li>actually other operations such as complement is not closed</li>
      </ul>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Proof for Union</strong>:</p>

  <ul>
    <li>
      <p>Start by constructing the grammars</p>

      <p><img src="\lectures\images\typora-user-images\image-20201015223108209.png" alt="image-20201015223108209" style="zoom:50%;" /></p>

      <p>Now, we need to show that it works.</p>

      <p><strong>Claim:</strong></p>

      <ul>
        <li>
          <p>$L(G) = L(G_1) \cup L(G_2)$</p>

          <p>so we need to show that $S \Rightarrow ^* w \iff S_1 \Rightarrow^<em>w \vert S_2 \Rightarrow^</em>w$</p>

          <ul>
            <li>this will be trivial as if you start with $S$, it must go either first to $S_1$ or $S_2$. Then the rest follows.</li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Proof for Concatenation</strong></p>

  <ul>
    <li>
      <p>Again, start by the definition of the grammars:</p>

      <p><img src="\lectures\images\typora-user-images\image-20201015223611461.png" alt="image-20201015223611461" style="zoom:50%;" /></p>

      <p>Now, we need to show that it works:</p>

      <p><strong>Claim:</strong></p>

      <ul>
        <li>$L(G) = L(G_1) \circ L(G_2)$</li>
      </ul>

      <p><img src="\lectures\images\typora-user-images\image-20201015223717066.png" alt="image-20201015223717066" style="zoom:50%;" /></p>
    </li>
  </ul>
</blockquote>

<p>Note:</p>

<ul>
  <li>usually, the trick is to see that a <strong>starting variable $S_i$ of a grammar $G_i$ is representative of the <em>entire context-free language</em> that it can reach</strong></li>
</ul>

<blockquote>
  <p><strong>Proof for Kleene Star</strong></p>

  <ul>
    <li>
      <p>Same thing, start with</p>

      <p><img src="\lectures\images\typora-user-images\image-20201015224202566.png" alt="image-20201015224202566" style="zoom:50%;" /></p>

      <p>Now, we need to show that it work:</p>

      <p><strong>Claim:</strong></p>

      <ul>
        <li>$L(G)=L(G_1)^*$</li>
      </ul>

      <p>seems to be true by definition</p>

      <p><mark>TODO</mark></p>
    </li>
  </ul>
</blockquote>

<h3 id="regular-and-context-free-language-1">Regular and Context-Free Language</h3>

<blockquote>
  <p><strong>Theorem:</strong></p>

  <ul>
    <li>Every <strong>regular</strong> language is <strong>context free</strong></li>
  </ul>
</blockquote>

<p>There are also other ways to prove it, for example using a DFA. Look at the book to see more.</p>

<blockquote>
  <p><strong>Proof</strong>:</p>

  <ul>
    <li>
      <p>Let $L$ be regular, and generated from a regular expression $R$. We want to show that $L(R)$ is also generated by some CFG $G$.</p>
    </li>
    <li>
      <p>basically, we want to show that <strong>all words in the $L(R)$ is generated by a grammar $G$.</strong></p>
    </li>
    <li>
      <p>We prove this by induction:</p>

      <p><img src="\lectures\images\typora-user-images\image-20201015230623242.png" alt="image-20201015230623242" style="zoom:50%;" /></p>

      <ul>
        <li>this part is basically the same as the procedure mentioned in <a href="#Tips on Proving Regular Expressions">Tips on Proving Regular Expressions</a></li>
      </ul>

      <p><img src="\lectures\images\typora-user-images\image-20201015230810598.png" alt="image-20201015230810598" style="zoom:50%;" /></p>

      <ul>
        <li>this is also the same as mentioned in the tips section</li>
      </ul>

      <p>Lastly, it works out by the <strong>closure property</strong>, because for each:</p>

      <ul>
        <li>$R_1,R_2$ involved above, we can use a $G_1$ and $G_2$ which is true by induction.</li>
        <li>now, since $G_1$ and $G_2$ using the operations are closed, hence this completes the proof that you can have a $G$.</li>
      </ul>
    </li>
  </ul>
</blockquote>

<h2 id="not-context-free-grammar">Not Context-Free Grammar</h2>

<p>There is a lemma similar to the pumping lemma, called the “tandem pumping lemma”</p>

<blockquote>
  <p><strong>Tandem Pumping Lemma:</strong></p>

  <ul>
    <li>
      <p>If $L$ is a CFL, then there exists a constant $p$, s.t. $\forall w,\,w\in L$, and $\vert w\vert  \ge p$, there exists a way to parse $w$ into:</p>

\[w=uvxyz\]

      <p>where:</p>

      <ul>
        <li>this is the <strong>different part from the normal pumping lemma</strong></li>
        <li>$\vert vxy\vert  \le p$
          <ul>
            <li>different from the normal pumping lemma as well</li>
          </ul>
        </li>
        <li>$\vert vy\vert &gt;0$
          <ul>
            <li>again, this and the above has to come out by themselves. You <strong>cannot choose</strong> them.</li>
            <li><strong>this is the part where we can pump</strong>
              <ul>
                <li>notice that $v$ or $y$ themselves could be empty</li>
              </ul>
            </li>
          </ul>
        </li>
        <li>$uv^i xy^i z \in L,\,\,\forall i$
          <ul>
            <li>notice that here you can <strong>pump two of them at the same time</strong></li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Proof Idea</strong>:</p>

  <ul>
    <li>
      <p>Let $A$ be a CFL and let $G$ be a CFG that generates it. We must show that <strong>any sufficiently long string $s$ in $A$ can be pumped and remain in $A$</strong>.</p>
    </li>
    <li>
      <p>Let $s$ be <strong>a very long string in $A$</strong>. (We make clear later what we mean by “very long.”) Because $s$ is in $A$, it is derivable from $G$ and so has a parse tree. The <strong>parse tree for $s$ must be very tall</strong> because $s$ is very long. That is, the <strong>parse tree must contain some long path from the start variable at the root of the tree to one of the terminal symbols at a leaf</strong>. On this long path, some <strong><em>variable symbol $R$ must repeat</em></strong> because of the pigeonhole principle.</p>

      <ul>
        <li>e.g.</li>
        <li><img src="\lectures\images\typora-user-images\image-20201021004016727.png" alt="image-20201021004016727" style="zoom: 80%;" /></li>
      </ul>
    </li>
    <li>
      <p>As the following figure shows, this repetition allows us to <strong>replace the subtree under the second occurrence of $R$ with the subtree under the first occurrence of R</strong> and still get a legal parse tree (and once it repeated once, you can repeat infinite number of times). Therefore, we may cut s into five pieces $uvxyz$ as the figure indicates, and we may repeat the second and fourth pieces and obtain a string still in the language. In other words, $uv^ixy^iz$ is in $A$ for any $i\ge0$.</p>

      <p><img src="\lectures\images\typora-user-images\image-20201021004419653.png" alt="image-20201021004419653" style="zoom:50%;" /></p>

      <ul>
        <li>where $v$ or $y$ could be empty, but <strong>at least one of them is not.</strong></li>
        <li>we don’t care what $u,z$ are, we just know that you can repeat $R$ many times and <strong>get infinite $R\to vRy$, and finish with $R\to x$.</strong></li>
      </ul>
    </li>
  </ul>
</blockquote>

<p><strong>Template for proving non-context-free grammar</strong>:</p>

<ol>
  <li>
    <p>Assume CF, then you get a pumping number $p$.</p>
  </li>
  <li>
    <p>Choose a string $w \in L$, such that $\vert w\vert$ is <strong>long enough hence</strong> $\vert w\vert \ge p$</p>
  </li>
  <li>
    <p>Think about <strong>all possible parsing of $v,y$,</strong> such that:</p>

    <ul>
      <li>$\vert vxy\vert \le p$
        <ul>
          <li>essentially, since $x$ can be $\epsilon$, we need to make sure $\vert vy\vert \le p$</li>
        </ul>
      </li>
      <li>and $\vert vy\vert  &gt; 0$
        <ul>
          <li>as otherwise, you wouldn’t have an really long word shown in the proof sketch above</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>Show that for <strong>all possible parsing</strong>, you can choose an $i$ such that:</p>

\[uv^i xy^i z \notin L\]
  </li>
</ol>

<h3 id="example-tandem-pumping-lemma">Example: Tandem Pumping Lemma</h3>

<p>The following two languages are <strong>not context-free</strong> (hence not regular as well):</p>

<p>For example:</p>

<ul>
  <li>
    <p><strong>Question</strong>:</p>

    <p>Show the following language is not CF:</p>

\[L=\{a^i b^i c^i | i \ge 0\}\]
  </li>
  <li>
    <p><strong>Solution:</strong></p>

    <p><img src="\lectures\images\typora-user-images\image-20201020205617351.png" alt="image-20201020205617351" style="zoom:50%;" /></p>

    <p><img src="\lectures\images\typora-user-images\image-20201020210031078.png" alt="image-20201020210031078" style="zoom:50%;" /></p>

    <ul>
      <li>so since $vxy$ can only hold up to two different characters, $v,y$ to be pumped can be at most two different characters. Therefore, since $\vert vy\vert &gt;0$, you will have <strong>at least one character unchanged</strong>.</li>
    </ul>
  </li>
</ul>

<hr />

<p><strong><em>For example:</em></strong></p>

<ul>
  <li>
    <p><strong>Question:</strong></p>

    <p>Show that the following language is not context-free:</p>

\[L=\{ ww \ | \ w \in\{a,b\}^* \}\]
  </li>
  <li>
    <p><strong>Solution:</strong></p>

    <p>The draft attempts are:</p>

    <p><img src="\lectures\images\typora-user-images\image-20201020211323817.png" alt="image-20201020211323817" style="zoom:50%;" /></p>

    <ul>
      <li>the correct way is that we need to show that for <strong><em>every parsing of $vxy$, it is not in the language</em></strong></li>
    </ul>

    <p>The <strong>attempt</strong> is:</p>

    <p><img src="\lectures\images\typora-user-images\image-20201020211753480.png" alt="image-20201020211753480" style="zoom:50%;" /></p>

    <ul>
      <li>
        <p>and here, you will see that in <strong>all three cases/parsing</strong>, the pumping will work:</p>

        <p><img src="\lectures\images\typora-user-images\image-20201020211855618.png" alt="image-20201020211855618" style="zoom:50%;" /></p>
      </li>
    </ul>
  </li>
</ul>

<hr />

<h1 id="week-7">Week 7</h1>

<h2 id="other-closure-properties-on-cfl">Other Closure Properties on CFL</h2>

<blockquote>
  <p><strong>Theorem:</strong></p>

  <ul>
    <li>The class of context-free languages is <strong><em>not closed</em> under intersection</strong>.</li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Proof:</strong></p>

  <ul>
    <li>
      <p>We will show two specific languages, $L_1,L_2$ being context free, but $L_1 \cap L_2$ is not. This is already enough to prove the theorem.</p>

      <ul>
        <li>this means that there are <strong>some CFL being closed under intersection, but some not</strong>.</li>
      </ul>
    </li>
    <li>
      <p>Define:</p>

\[L_1 =\{ a^ib^ic^j \,|\, i,j\ge 0 \}\\
L_2 =\{ a^ib^jc^j \,|\, i,j\ge 0 \}\]

      <ul>
        <li>
          <p>Claim 1: $L_1,L_2$ are context free.</p>

          <ul>
            <li>
              <p>Quite simple, for $L_1$ just need:</p>

\[S\to \epsilon\,|\,aSbV \\
V \to c \,|\,VV\]
            </li>
            <li>
              <p>For $L_2$, you need:</p>

\[S\to \epsilon\,|\,VbSc \\
V \to a \,|\,VV\]
            </li>
          </ul>
        </li>
        <li>
          <p>Claim 2: $L_1 \cap L_2 = { a^ib^ic^i \,\vert \, i\ge 0 }$</p>

          <ul>
            <li>which is <strong>not context free</strong>.</li>
          </ul>
        </li>
      </ul>

      <p>This <strong>completes the proof</strong>, since we just need to <strong>show one</strong> “counter”-example.</p>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Theorem:</strong></p>

  <ul>
    <li>The class of context-free languages is <strong><em>not closed</em> under complement</strong>.</li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Proof:</strong></p>

  <ul>
    <li>
      <p>Assume towards contradiction, that it was closed.</p>
    </li>
    <li>
      <p>Now, using De Morgen:</p>

\[L_1 \cap L_2 = \overline{(\overline{L_1} \cup \overline{L_2})}\]

      <p>However, we know that:</p>

      <ul>
        <li>$LHS$ is not closed</li>
        <li><strong>union operation IS closed</strong></li>
        <li>Therefore, it <strong>cannot be that complement is closed</strong>.</li>
      </ul>

      <p>This completes the proof.</p>
    </li>
  </ul>
</blockquote>

<h2 id="push-down-automata-of-cfl">Push-Down Automata of CFL</h2>

<p>(This part is not on the syllabus, will not be tested.)</p>

<ul>
  <li>A pushdown automata is like an NFA, but also has a stack memory.</li>
</ul>

<p>This part is interesting, because it can be shown that:</p>

<blockquote>
  <p><strong>Theorem:</strong></p>

  <ul>
    <li>$L$ is a $CFL$ $\iff$ it is recognized by a $PDA$.
      <ul>
        <li>then we can also show that every regular language is context-free, since a <strong>NFA is just a special case of a PDA</strong> without a stack.</li>
      </ul>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Note:</strong></p>

  <ul class="task-list">
    <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked" />If we have 0 stack of a PDA, we have a NFA</li>
    <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked" />If we use 1 stack, we have a PDA.</li>
    <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked" />If we have 2 stacks, or if we use a queue, we get something equivalent to a <strong>Turing Machine</strong>.</li>
  </ul>
</blockquote>

<p><mark>There will be no exam on CFL</mark></p>

<p><mark>Exam 2 Starts Here</mark></p>

<h2 id="turing-machine">Turing Machine</h2>

<p>Basically, this is the model that captures what computers can do.</p>

<p>The definition of a <strong>Turing Machine</strong> is as follows:</p>

<blockquote>
  <p><strong>Definition Sketch:</strong></p>

  <ul>
    <li>
      <p><img src="\lectures\images\typora-user-images\image-20201023012210964.png" alt="image-20201023012210964" style="zoom: 50%;" /></p>

      <p>where:</p>

      <ul>
        <li>input is on a <strong>tape</strong>, which is infinite (s.t. after the finite input, it is filled with “blanks”)</li>
        <li>at each step of computation:
          <ul>
            <li>depending on:
              <ul>
                <li>the current state</li>
                <li>symbol on the tape</li>
              </ul>
            </li>
            <li>can do:
              <ul>
                <li>switch to another state</li>
                <li><strong>write</strong> on the tape at the current head position
                  <ul>
                    <li>(different from DFA)</li>
                  </ul>
                </li>
                <li>move the head <strong>to the left</strong> or to the right
                  <ul>
                    <li>(different from DFA)</li>
                  </ul>
                </li>
                <li>e.g. from state $q_1$ with input $a$, you could write a $b$, go to $q_2$, and move the head to the left.</li>
              </ul>
            </li>
          </ul>
        </li>
        <li>there are two special states $q_{acc}, q_{rej}$ (different from DFA):
          <ul>
            <li>$q_{acc}$: accept and <strong>halt/exit</strong></li>
            <li>$q_{rej}$: reject and <strong>halt/exit</strong></li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</blockquote>

<p>Hence, the summaries of <strong>difference between a Turing Machine and a DFA</strong> is:</p>

<ul>
  <li>reading input can go left or right</li>
  <li>infinite memory
    <ul>
      <li>yet still finite amount of states in the state control</li>
    </ul>
  </li>
  <li>can write as well</li>
  <li>immediately halts upon entering $q_{acc}$ or $q_{rej}$</li>
</ul>

<blockquote>
  <p><strong>Formal Definition of a TM</strong></p>

  <ul>
    <li>
      <p>A Turing Machine is a 7-tuple:</p>

\[M=(Q,\Sigma, \Gamma, \delta, q_0, q_{acc},q_{rej})\]

      <p>where:</p>

      <ul>
        <li>$Q$: a finite set of states</li>
        <li>$\Sigma$: a finite set of alphabet (for input)</li>
        <li>$\Gamma$: a finite set of alphabet (for output/writing)
          <ul>
            <li>this means $\Sigma \subseteq \Gamma$, and blank $\textvisiblespace \in \Gamma$ (but $\textvisiblespace \notin \Sigma$)</li>
          </ul>
        </li>
        <li>$q_0, q_{acc},q_{rej} \in Q$
          <ul>
            <li>$q_0$ is the starting state</li>
            <li>$q_{acc}$ is the accepting state</li>
            <li>$q_{rej}$ is the rejecting state</li>
          </ul>
        </li>
        <li>$\delta: Q \times \Gamma \to Q \times \Gamma \times {L,R}$
          <ul>
            <li>i.e. it <strong>takes</strong> a state an a symbol on the tape, and <strong>do</strong> a state transition, write a symbol, move head to left or right</li>
            <li>e.g. $\delta(q_2,a) = (q_4,b,R)$</li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Computation Def Sketch:</strong></p>

  <ul>
    <li>A computation of a TM on input $w \in \Sigma^*$ (at the start, before modification/write) can:
      <ul>
        <li><strong>start</strong> with $w$ followed by infinitely many $\textvisiblespace$ on the tape, with reading head pointing to first character</li>
        <li><strong>apply</strong> $\delta$ repeatedly
          <ul>
            <li>read, transition, move, and write</li>
          </ul>
        </li>
        <li>if ever enter $q_{acc}$ or $q_{rej}$, <strong>halt</strong></li>
      </ul>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Note:</strong></p>

  <ul class="task-list">
    <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />If head is pointing to left most location, and $\delta$ says to move left, we assume that it <strong>stays remained</strong>.</li>
  </ul>
</blockquote>

<p>For example:</p>

<ul>
  <li>
    <p>Consider a TM with $\Sigma={a,b}$:</p>

    <p><img src="\lectures\images\typora-user-images\image-20201023014822520.png" alt="image-20201023014822520" style="zoom: 50%;" /></p>
  </li>
  <li>
    <p>This recognized $L={w \in {a,b}^*\,\vert \, w \,\text{contains a$b$} }$</p>
  </li>
</ul>

<hr />

<p><strong><em>For example:</em></strong></p>

<ul>
  <li>
    <p><strong>Question:</strong></p>

    <p>Is the following TM the same as before?</p>
  </li>
</ul>

<p><img src="\lectures\images\typora-user-images\image-20201023015648871.png" alt="image-20201023015648871" style="zoom: 50%;" /></p>

<ul>
  <li>
    <p><strong>Solution</strong>:</p>

    <p>It is the <strong>same language</strong>, but <strong>not the same program</strong> (e.g. once reached the end, meet $\textvisiblespace$ and terminate. But the other one in black will hang forever).</p>
  </li>
</ul>

<hr />

<blockquote>
  <p><strong>Language:</strong></p>

  <ul>
    <li>Since a TM $M$, on input $w$, may be:
      <ul>
        <li>accepted - met accept state</li>
        <li>not accepted - met reject state <strong>or run forever</strong></li>
      </ul>
    </li>
    <li>
      <p>Then the language of a TM $M$ is defined as:</p>

\[L(M)=\{w \,|\,\text{$M$ accepts $w$}\}\]
    </li>
  </ul>

</blockquote>

<blockquote>
  <p><strong>Configuration Def:</strong></p>

  <ul>
    <li>
      <p>A configuration represents the <strong>status of computation at a certain point</strong>. The configuration is:</p>

\[C=uqv\]

      <p>where:</p>

      <ul>
        <li>$u,v \in \Gamma^*$</li>
        <li>$q\in Q$</li>
      </ul>

      <p>and it <strong>means</strong>:</p>

      <ul>
        <li>the <strong>tape</strong> currently has $uv$ followed by infinitely many $\textvisiblespace$
          <ul>
            <li>$u,v$ could also contain $\textvisiblespace$</li>
          </ul>
        </li>
        <li>the current <strong>state</strong> is $q$</li>
        <li>reading head is <strong>pointing</strong> to the first symbol of $v$
          <ul>
            <li><strong>haven’t read it yet</strong>, it is point</li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</blockquote>

<p>Therefore, it means:</p>

<blockquote>
  <p><strong>Initial Configuration:</strong></p>

  <ul>
    <li>
      <p>the initial configuration would always be:</p>

\[C_{ini}=q_0w\]

      <p>where:</p>

      <ul>
        <li>$w$ is the input string</li>
      </ul>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Yielding Configuration</strong>:</p>

  <ul>
    <li>
      <p>$C_1 \vdash C_2$ ($C_1$ configuration <strong>yields</strong> $C_2$ configuration) if applying a $\delta$ on $C_1$ gives $C_2$</p>

      <ul>
        <li>
          <p>e.g. $C_1 =aq_1bab$, and $\delta(q_1,b)=(q_0,a,R)$, then $C_2=aaq_0ab$</p>
        </li>
        <li>
          <p>schematically:</p>

          <p><img src="\lectures\images\typora-user-images\image-20201023021820086.png" alt="image-20201023021820086" style="zoom:50%;" /></p>
        </li>
      </ul>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Accepting and Rejecting Configuration:</strong></p>

  <ul>
    <li>Any $C=uq_{acc}v$ is an <strong>accepting</strong> configuration, $u,v\in \Gamma^*$</li>
    <li>Any $C=uq_{rej}v$ is an <strong>rejecting</strong> configuration, $u,v\in \Gamma^*$
      <ul>
        <li>and there will be no further configurations once the above two is reached</li>
      </ul>
    </li>
  </ul>
</blockquote>

<p>Therefore, this means that:</p>

<blockquote>
  <p><strong>Accepted String Def:</strong></p>

  <ul>
    <li>For a TM $M=(Q,\Sigma, \Gamma, \delta, q_0, q_{acc},q_{rej})$, a (input) string $w \in \Sigma^*$ is <strong>accepted</strong> by $M$ if there exists a sequence of configurations, $C_1,C_2,…C_n$, such that:
      <ul>
        <li>$C_1=q_0 w$</li>
        <li>$C_i \vdash C_{i+1},\, \forall\,i=1,2,…n-1$</li>
        <li>$C_n=uq_{acc}v,$ and $u,v\in\Gamma^*$</li>
      </ul>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>TM Recognizable Language:</strong></p>

  <ul>
    <li>A language $L$ is <strong>TM-recognizable</strong> if there exists a Turing Machine $M$ such that $L(M)=L$.
      <ul>
        <li>sometimes, people also call this $L$ <strong><em>recursively-enumerable</em></strong></li>
        <li>$x\in L \to$ $M$ accepts $x$</li>
        <li>$x\notin L \to$ $M$ rejects $x$ <strong>or run forever</strong></li>
      </ul>
    </li>
  </ul>
</blockquote>

<p>For example:</p>

<ul>
  <li>
    <p>Consider the non-regular but context-free language:</p>

\[L=\{0^i1^i\,|\,i\ge0\}\]
  </li>
  <li>
    <p>The TM for it would be:</p>

    <ul>
      <li>the idea is to write a $X$ for a $0$, and move to the right</li>
      <li>to write a $Y$ for a $1$, and move to the left</li>
    </ul>

    <p><img src="\lectures\images\typora-user-images\image-20201023023403544.png" alt="image-20201023023403544" style="zoom:50%;" /></p>

    <p><img src="\lectures\images\typora-user-images\image-20201023024014826.png" alt="image-20201023024014826" style="zoom: 50%;" /></p>
  </li>
</ul>

<blockquote>
  <p><strong>Note:</strong></p>

  <ul class="task-list">
    <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />Some transitions are <strong>omitted</strong> in the above diagram, and those transitions will be <strong>assumed to go to</strong> $q_{rej}$.</li>
  </ul>
</blockquote>

<hr />

<p><strong><em>For example:</em></strong></p>

<ul>
  <li>
    <p><strong>Question:</strong></p>

    <p>Construct the TM for:</p>

\[\{1^{2n}\,|\,n\ge0\}\]
  </li>
  <li>
    <p><strong>My Solution</strong>:</p>

    <ul>
      <li>the idea is to cut off every pair of $1$ at left and right end, recursively
        <ul>
          <li>if it is power of 2, then you should end put exactly cutting off everything on the last iteration</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<hr />

<h1 id="week-8">Week 8</h1>

<h2 id="turing-machine-continued">Turing Machine (Continued)</h2>

<blockquote>
  <p><strong>Definition:</strong></p>

  <ul>
    <li>A TM $M$ is a decider if $M$ halts for every $w \in \Sigma^*$
      <ul>
        <li>i.e. every word can either be accepted, or rejected (cannot have an infinite loop)</li>
      </ul>
    </li>
  </ul>
</blockquote>

<p>This means that:</p>

<blockquote>
  <p><strong>TM-Decidable</strong></p>

  <ul>
    <li>A language $L$ is a TM decidable if if there exist a TM $M$ such that :
      <ul>
        <li>$M$ recognizes $L$</li>
        <li>$M$ is a <strong>decider</strong>
          <ul>
            <li>$x\in L \to$ $M$ accepts $x$</li>
            <li>$x\notin L \to$ $M$ rejects $x$</li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</blockquote>

<p>So the relationship look like:</p>

<p><img src="\lectures\images\typora-user-images\image-20201027205946408.png" alt="image-20201027205946408" style="zoom: 33%;" /></p>

<p>where:</p>

<ul>
  <li>one important thing implied from the above (which is true), is that some sets (regular and CF) are actually <strong>proper subsets</strong>:</li>
</ul>

\[\{ L \subseteq \Sigma^* | L\,\text{is regular}\} \subsetneq\\ \{ L \subseteq \Sigma^* | L\,\text{is CFL}\}\subsetneq\\\\ \{ L \subseteq \Sigma^* | L\,\text{is TM-Decidable}\}\subseteq\\\\ \{ L \subseteq \Sigma^* | L\,\text{is TM-Recognizable}\}\subseteq\\ \{L \subseteq \Sigma^*\}\]

<ul>
  <li>this will be proven later in the course</li>
</ul>

<h3 id="input-output-tm">Input-Output TM</h3>

<blockquote>
  <p><strong>Definition:</strong></p>

  <ul>
    <li>
      <p>An input-output TM:</p>

\[\{Q, \Sigma, \Gamma, \delta, q_{start}, q_{halt}\}\]

      <p>starts with input written on tape ($C_1=q_{start}w$). <strong>If/when</strong> it changes to state $q_{halt}$, then the <strong>machine stops, and the string written on tape (w/o the trailing infinite blanks) is the output</strong>.</p>

      <ul>
        <li>in general, those TM could also go into infinite loop</li>
      </ul>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Computable Function Definition</strong></p>

  <ul>
    <li>
      <p>A function:</p>

\[f: \Sigma^* \to \Sigma^*\]

      <p>is <strong>computable</strong> if there exists a TM $M$, such that $\forall w \in \Sigma^*$ (notice the <strong>for all</strong> here) , <strong>$M$ halts with output $f(w)$ written on the tape.</strong></p>

      <ul>
        <li>this also means it does not go into loop</li>
      </ul>
    </li>
  </ul>
</blockquote>

<p><strong>For example:</strong></p>

<ul>
  <li>A computation function could be: insert $#$ symbol in the beginning of the input (i.e. $w\to #w$)
    <ul>
      <li><mark>TODO: implement this</mark></li>
    </ul>
  </li>
  <li>another one would be: insert first block of string to end of second block (i.e. $w_1#w_2\to w_1#w_2w_1$)
    <ul>
      <li><mark>TODO: implement this</mark></li>
    </ul>
  </li>
  <li>a more useful example would be unary addition: $1^n # 1^m \to 1^{n+m}$
    <ul>
      <li><mark>TODO: implement this</mark></li>
    </ul>
  </li>
</ul>

<blockquote>
  <p><strong>In fact:</strong> anything you can implement in your computer programming language can be expressed via such a function.</p>
</blockquote>

<h3 id="variants-of-tm">Variants of TM</h3>

<p>Essentially, they are the same thing, but there could be useful for solving problems.</p>

<blockquote>
  <p><strong>Definition:</strong></p>

  <ul>
    <li>Two TM are equivalent, if for $\forall x \in \Sigma^*$, both TMs <strong>do the same for each string</strong>, s.t. it either:
      <ul>
        <li>halt + accept for both</li>
        <li>halt + reject for both</li>
        <li>run forever for both</li>
      </ul>
    </li>
  </ul>
</blockquote>

<ul>
  <li>
    <p><strong>TM with Doubly Infinite Tape</strong></p>

    <p><img src="\lectures\images\typora-user-images\image-20201027211832514.png" alt="image-20201027211832514" style="zoom:50%;" /></p>

    <ul>
      <li>where left side of the head in the beginning will just be blanks</li>
    </ul>

    <p>we claim that this is the <strong>same as a one-sided tape</strong>.</p>

    <blockquote>
      <p><strong>Proof Idea:</strong></p>

      <ul>
        <li>
          <p>First, we need to have a 1-sided TM, and show that we can construct an equivalent two-sided one</p>

          <ul>
            <li>this will be easy</li>
          </ul>
        </li>
        <li>
          <p>Second, we need to show that if we have a 2-sided TM, we can construct an equivalent one-sided one</p>

          <ul>
            <li>
              <p>this is more trickly, but the idea will be folding the tape:</p>

              <p><img src="\lectures\images\typora-user-images\image-20201027212641474.png" alt="image-20201027212641474" style="zoom:50%;" /></p>
            </li>
          </ul>
        </li>
      </ul>
    </blockquote>
  </li>
  <li>
    <p><strong>TM with command of not moving</strong>:</p>

    <p>So you have:</p>

\[\delta : Q\times \Gamma \to Q\times \Gamma \times \{L,R,S\}\]

    <p>where:</p>

    <ul>
      <li>$S$ means not to move/stay</li>
    </ul>

    <blockquote>
      <p><strong>Proof Idea:</strong></p>

      <ul>
        <li>Easy to simulate staying at the same place by moving right and then moving left</li>
      </ul>
    </blockquote>
  </li>
  <li>
    <p><strong>Multi-tape TM</strong></p>

    <p>This will be very useful. Basically it is a TM with a <strong><em>fixed number of tape</em></strong> (i.e. you can have 3 tapes, or 6 tapes, etc.). This means the following change:</p>

    <ul>
      <li>
        <p>you will have three reading heads:</p>

        <p><img src="\lectures\images\typora-user-images\image-20201027213613527.png" alt="image-20201027213613527" style="zoom:50%;" /></p>

        <p>in the beginning, all heads will point to the left most character</p>
      </li>
      <li>
        <p>transition/movement</p>

        <ul>
          <li>
\[\delta: Q \times \Gamma^k \to  Q \times \Gamma^k\times \{L,R\}^k,\,\,\text{where $k$ is the number of tapes}\]
          </li>
        </ul>
      </li>
      <li>
        <p>and at the beginning of the computation, input $w$ is on first tape, every thing else is $\textvisiblespace$ (space)</p>
      </li>
      <li>
        <p>accept state and reject state is the same as the one-tape definition</p>
      </li>
    </ul>

    <blockquote>
      <p><strong>Proof Sketch:</strong></p>

      <ul>
        <li>
          <p>We simulate one-tape using the $k$ tape TM</p>

          <ul>
            <li>this is trivial, done by just ignoring the other tapes.</li>
          </ul>
        </li>
        <li>
          <p>Conversely, we can simulate a $k$ tape TM <strong>using a 1-tape TM</strong> as follows:</p>

          <p><img src="\lectures\images\typora-user-images\image-20201027214108185.png" alt="image-20201027214108185" style="zoom: 67%;" /></p>

          <p>where, in the end it looks like:</p>

          <ul>
            <li>keep content of all tapes separator $#$</li>
            <li>keep a special marked version of a symbol (e.g. using  a star, $<em>$, so $w_1 \to w_1 ^</em>$), representing the head position</li>
            <li>transition function:
              <ul>
                <li>scan input from left to right on the above, recording the state of each special marked symbol (basically the head).
                  <ul>
                    <li>for example, in the above example, you have state of $w_2 ^<em>,  x_1^</em>$</li>
                  </ul>
                </li>
                <li>then update the tape based on the transition function of multi-tape TM, since now you know exactly current state of the multi-tape, and the input (which you need to come back to the first part of the tape)</li>
              </ul>
            </li>
          </ul>
        </li>
      </ul>

      <p>In the end, <strong>you will have a quadratic overhead in runtime</strong>, since you will need to run back and forth to know what is the current state and what is the next input symbol.</p>
    </blockquote>
  </li>
</ul>

<h2 id="non-deterministic-tm">Non-Deterministic TM</h2>

<blockquote>
  <p><strong>Definition:</strong></p>

  <ul>
    <li>
      <p>Basically, it is the same as a TM, except for the transition function:
$$</p>

      <p>\delta : Q \times \Gamma \to \mathbb{P}(Q \times \Gamma \times {L,R})</p>

      <p>$$
so that:</p>

      <ul>
        <li>a string is accepted by a NTM $N$, if there exists at least one accepting computation.</li>
      </ul>
    </li>
  </ul>
</blockquote>

<p>This means, given a string $w$ for a NTM, you can draw a <strong>configuration tree</strong>:</p>

<p><img src="\lectures\images\typora-user-images\image-20201029222458766.png" alt="image-20201029222458766" style="zoom:50%;" /></p>

<p>where:</p>

<ul>
  <li>each node is a configuration</li>
</ul>

<blockquote>
  <p><strong>Claim:</strong></p>

  <ul>
    <li>For every <strong>non-deterministic</strong> TM, $N$, there <strong>exists an equivalent (deterministic)</strong> TM, $M$.
      <ul>
        <li>i.e. they are the same</li>
      </ul>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Proof:</strong></p>

  <ul>
    <li>
      <p>the direction to simulate a TM using a NTM is simple.</p>
    </li>
    <li>
      <p>The reverse would be: given $N$, construct a $M$ as follows:</p>

      <ul>
        <li>the idea is to simulate a $N$ using $M$, by trying to <strong>simulate the tree (so we simulate all computations of $N$).</strong></li>
        <li>If the word $w$ ever gets accepted on the tree, we accept.
          <ul>
            <li>this will be done using a <strong>BFS</strong> manner. Because if you use DFS, then you might get into an infinite loop due to the possible existence of an infinitely deep branch. (Notice that one challenge here is to find a way to “backtrack” in the tree).</li>
          </ul>
        </li>
      </ul>
    </li>
    <li>
      <p>The solution is to use a 3-Tape TM (which is the same as a normal TM $M$ as proven before):</p>

      <ul>
        <li>
          <p>the first tape has the <strong>input</strong> (we won’t write on this tape)</p>
        </li>
        <li>
          <p>the second tape has the content of the tape of $N$ in the <strong>current execution point</strong></p>

          <ul>
            <li>i.e. contains what is <strong>written</strong></li>
          </ul>
        </li>
        <li>
          <p>the third <strong>tape keeps track of the path of the node</strong> on the tree we are simulating.</p>
        </li>
        <li>
          <p><strong><em>and the detailed steps are as follows:</em></strong></p>

          <ul>
            <li>initially, we have only tape 1 being non-empty, and tape 3 initialized with filling in a $\epsilon$
              <ul>
                <li>the $\epsilon$ would represent exploring the root node, as you will see in the behavior of tape 3 below</li>
              </ul>
            </li>
          </ul>

          <ol>
            <li>then, we copy tape 1 to tape 2
              <ul>
                <li>erase whatever we had before on tape 2</li>
                <li>basically, tape 1 would be intact, and will be our backup</li>
              </ul>
            </li>
            <li>simulate the <strong>computation of $N$ on tape 2</strong>, so that:
              <ul>
                <li>each time we meet a non-deterministic choice, we <strong>look at tape 3</strong> to determine which one to take.</li>
                <li>if choice is not valid from tape 3, or the content of the tape 3 ran out (or rejected already), it means we are <strong><em>done with this path</em></strong>. So we <strong>replace string</strong> on tape 3 with <strong>next string telling the next path to explore (see tape 3 behavior below)</strong></li>
              </ul>
            </li>
            <li>go back to step 1)</li>
          </ol>

          <ul>
            <li>now, for <strong><em>tape 3</em></strong>:
              <ul>
                <li>Since the <strong>total number of states is finite</strong> (bounded by the power set), then we can let $b$ being the maximum branching factor (i.e. <strong><em>maximum number of children a node can have</em></strong>).</li>
                <li>This means you have the alphabet $\Gamma_b={1,2,…,b}$
                  <ul>
                    <li>then, at each level of tree, we basically contains an address, so that:
                      <ul>
                        <li>for the first level, you can have <strong>address ${1},{2},…{b}$</strong>
                          <ul>
                            <li>where ${2}$ would mean start by the root, going to its $2nd$ child, and finish</li>
                            <li>so if you <strong>finished with ${2}$, your next string is ${3}$.</strong></li>
                          </ul>
                        </li>
                        <li>for the second level, you can have <strong>address ${11},{12},…{bb}$</strong>
                          <ul>
                            <li>where ${12}$ would mean start by the root, going to its $1st$ child, then go to that node’s $2nd$ child, then finish</li>
                          </ul>
                        </li>
                        <li>…</li>
                        <li>at most have up to $b$ level, we you have address ${111…1},{111…2},…{bbb…b}$ (each of length $b$).</li>
                      </ul>
                    </li>
                  </ul>
                </li>
              </ul>
            </li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Note:</strong></p>

  <ul>
    <li>Though the above algorithm would work, the overhead in the running time is <strong>exponential</strong>.
      <ul>
        <li>this is because we <strong>backtracked and recomputed every step from the root to the next node/choice</strong>, by our construction.</li>
        <li>however, we don’t know, until today, whether if such an overhead is inherent (necessary) or not. (P vs NP)</li>
      </ul>
    </li>
  </ul>
</blockquote>

<h2 id="historical-background-of-tm">Historical Background of TM</h2>

<p><strong>Turing</strong> wanted to show that there exists a mathematical problems that are not computable.</p>

<ul>
  <li>then, he found that at the time, there is no definition of a computation (there were no computers even)</li>
  <li>therefore, in the end he came up with his model of a TM defining a computation</li>
</ul>

<p>Later on, there comes more models, but it turns out all of them are equivalent of a TM:</p>

<ul>
  <li>NFA + 2 stacks</li>
  <li>NFA + 1 queue</li>
  <li>general grammar</li>
  <li>lambda calculus
    <ul>
      <li>invented by Church</li>
    </ul>
  </li>
  <li>random access machines</li>
  <li>any programming language
    <ul>
      <li>either equivalent in power, or weaker</li>
    </ul>
  </li>
</ul>

<h2 id="church-turing-thesis">Church-Turing Thesis</h2>

<blockquote>
  <p><strong>Church-Turing Thesis Definition:</strong></p>

  <ul>
    <li>Every reasonable model of computation (i.e. algorithm) <strong>can be simulated by a TM</strong>.
      <ul>
        <li>note that this is not a theorem, because we don’t know what will happen in the future about our computer/computation.</li>
        <li>however, up to today, pretty much everyone takes the thesis as correct/sensible.</li>
      </ul>
    </li>
  </ul>
</blockquote>

<p>Therefore, from now on, we will specify <strong>every algorithm in “pseudo code”</strong>, such that:</p>

<ul>
  <li>each line needs to be <strong>computable/implementable by a TM</strong>
    <ul>
      <li>equivalently, each instruction can be implemented in a programming language</li>
    </ul>
  </li>
  <li>if you want a TM <strong>decider</strong>, then you need to make sure that <strong>each step of computation is finite</strong>, and your <strong>description is finite</strong>
    <ul>
      <li>i.e. you cannot run to infinity</li>
    </ul>
  </li>
</ul>

<blockquote>
  <p><strong>Theorem</strong></p>

  <ul>
    <li>
      <p><strong>Every algorithm (TM)</strong> can be encoded as a string/finite symbol description. We will denote:
$$</p>

      <p>\langle M \rangle</p>

      <p>$$
being the string representing the TM, $M$.</p>

      <ul>
        <li>also implies that we can make a DFA/NFA/TM/Graph/etc. themselves being an <strong>input</strong></li>
      </ul>
    </li>
  </ul>
</blockquote>

<h1 id="week-9">Week 9</h1>

<h2 id="closure-property-for-tm">Closure Property for TM</h2>

<blockquote>
  <p><strong>Theorem:</strong></p>

  <ul>
    <li>The class of TM-<strong><em>Decidable</em></strong> language is closed under complement.</li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Proof:</strong></p>

  <ul>
    <li>This works <strong>only</strong> with a TM-<strong>Decidable</strong> language:
      <ul>
        <li>Set $M’$ to be the same as $M$, but flip the $q_{acc}$ and $q_{rej}$ states.</li>
        <li>Then, whenever $w \in L(M) \iff \text{$M$accepts$w$} \iff \text{$M’$rejects$w$}\iff w \notin L(M’)$</li>
        <li>and conversely $w \notin L(M) \iff \text{$M$rejects$w$} \iff \text{$M’$accepts$w$}\iff w \in L(M’)$
          <ul>
            <li>note, the line above only works if $M$ is a <strong>decider</strong>. If it is not, we also need to think about the cases of rejected due to running forever</li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Theorem:</strong></p>

  <ul>
    <li>The language $L$ is TM Decidable $\iff$ both $L$ and $\bar{L}$ are TM recognizable.</li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Proof:</strong></p>

  <ul>
    <li>The forward direction is easy:
      <ul>
        <li>Assume $L$ is TM decidable
          <ul>
            <li>then $\exists M$ s.t. it is a decider.</li>
            <li>then $L$ is recognizable because $L$ is decidable</li>
            <li>and by the above theorem, we can make a decidable $\bar{L}$ from flipping the states in $M$. So $\bar{L}$ is recognizable.</li>
          </ul>
        </li>
      </ul>
    </li>
    <li>The reverse direction is harder:
      <ul>
        <li>Assume $L$ and $\bar{L}$ are both TM recognizable.
          <ul>
            <li>then there $\exists M_1, M_2$ s.t.
              <ul>
                <li>$M_1$ recognizes $L$ $\begin{cases}x\in L \Rarr \text{$M_1$accepts$x$}\x\notin L \Rarr \text{$M_1$rejects or run forever for$x$}\end{cases}$</li>
                <li>$M_2$ recognizes $\bar{L}$ $\begin{cases}x\in \bar{L} \Rarr \text{$M_2$accepts$x$}\x\notin \bar{L} \Rarr \text{$M_2$rejects or run forever for$x$}\end{cases}$</li>
              </ul>
            </li>
            <li>Use $M_1, M_2$ to <strong>construct a decider</strong> for $L$:
              <ul>
                <li>on input $x$, run $M_1$ on $x$, and run $M_2$ on $x$ in parallel
                  <ul>
                    <li>e.g. run them on two tapes simultaneously. (Copy input on the second tape, and run on both)</li>
                  </ul>
                </li>
                <li>Now, we <strong>construct $M$</strong> such that:
                  <ul>
                    <li>if $M_1$ accepts $x$, return accept</li>
                    <li>if $M_2$ accepts $x$, return reject</li>
                  </ul>
                </li>
                <li>Therefore, we have $\begin{cases}x\in L\Rarr \text{$M_1$will accept} \Rarr \text{$M$accepts}\x\notin L\Rarr x\in \bar{L}\Rarr\text{$M_2$will accept} \Rarr \text{$M$rejects}\end{cases}$</li>
              </ul>
            </li>
            <li>Hence we have found a decider for $L$ using $M$ above. So $L$ is TM Decidable.</li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</blockquote>

<p><mark>TODO: Union of TM</mark></p>

<h2 id="application-of-tm-decidable-languages">Application of TM Decidable Languages</h2>

<p>Now, we can use a <strong>decider</strong> TM for simulating the output of a DFA/NFA/etc.</p>

<blockquote>
  <p><strong>Application:</strong></p>

  <ul>
    <li>
      <p>The acceptance problem of performing the DFA task is <strong>decidable</strong>:
$$</p>

      <table>
        <tbody>
          <tr>
            <td>A_{DFA}={ \langle D,w \rangle</td>
            <td>\text{$D$ is a DFA and $D$ accepts $w$}}</td>
          </tr>
        </tbody>
      </table>

      <p>$$
where:</p>

      <ul>
        <li>now, the “<strong>input</strong>” is a <strong>tuple of DFA $D$ and a word $w$.</strong>
          <ul>
            <li>notice this means $w$ could be either <strong>recognized by $D$ but being rejected</strong>, or $w$ could be in the <strong>wrong format that</strong> <strong>$D$ does not even recognized</strong>, and hence rejected.</li>
          </ul>
        </li>
      </ul>
    </li>
    <li>
      <p>The construction of the TM would be:</p>

      <p><img src="\lectures\images\typora-user-images\image-20201106134347732.png" alt="image-20201106134347732" style="zoom:50%;" /></p>

      <p>where</p>

      <ul>
        <li>if given the encoding of a DFA, $\langle D\rangle$, it will be easy to <strong>check</strong> if that input is in the right format of $w$.</li>
        <li>this also means we have a way to <strong>check</strong> if $\langle D\rangle$ is a DFA or not (by definition).</li>
      </ul>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>High Level Proof</strong></p>

  <ul>
    <li><img src="\lectures\images\typora-user-images\image-20201106134714599.png" alt="image-20201106134714599" style="zoom:50%;" /></li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Application</strong></p>

  <ul>
    <li>
      <p>Similarly, doing the job of a NFA:
$$</p>

      <table>
        <tbody>
          <tr>
            <td>A_{NFA}={ \langle N,w \rangle</td>
            <td>\text{$N$ is a NFA and $N$ accepts $w$}}</td>
          </tr>
        </tbody>
      </table>

      <p>$$
is also decidable.</p>
    </li>
    <li>
      <p>Construction of decidable TM:</p>

      <p><img src="\lectures\images\typora-user-images\image-20201106135616723.png" alt="image-20201106135616723" style="zoom:50%;" /></p>

      <p>where:</p>

      <ul>
        <li>“on $\langle D,w\rangle$” just means the same thing as “checking if input $x$ is a valid encoding of $\langle D,w\rangle$. If not, reject.”</li>
        <li>and this will be a <strong>decider</strong> for $A_{NFA}$</li>
      </ul>
    </li>
  </ul>
</blockquote>

<p>Now, a more interesting example would be:</p>

<blockquote>
  <p><strong>Application:</strong></p>

  <ul>
    <li>
      <p>We can use a TM decider to check whether if a DFA has no acceptations:
$$</p>

      <table>
        <tbody>
          <tr>
            <td>E_{DFA}={\langle D\rangle</td>
            <td>\text{$D$ is a DFA and $L(D)=\empty$}}</td>
          </tr>
        </tbody>
      </table>

      <p>$$</p>
    </li>
    <li>
      <p>Construction of decidable TM:</p>

      <ul>
        <li>the idea is to check whether or not a DFA $D$ has any <strong>reachable</strong> accept states.
          <ul>
            <li>took care of the edge cases that you might have an accept state that is not reachable</li>
          </ul>
        </li>
        <li>basically, this will be done backwards: we <strong>start with the accepting states</strong>:</li>
      </ul>

      <p><img src="\lectures\images\typora-user-images\image-20201106140705877.png" alt="image-20201106140705877" style="zoom:50%;" /></p>

      <p>where:</p>

      <ul>
        <li>remember, when met statements like “repeat …”, make sure it is in finite time. (In this cases, it is)</li>
        <li>and this algorithm is <strong>decidable</strong>.</li>
      </ul>
    </li>
  </ul>
</blockquote>

<p>One take home message from the above is that the below construction will <strong>not</strong> work:</p>

<p><img src="\lectures\images\typora-user-images\image-20201106140919752.png" alt="image-20201106140919752" style="zoom:50%;" /></p>

<p>where:</p>

<ul>
  <li>the step of checking $w \in \Sigma^<em>$ will <strong>run forever</strong>, which means it is a <strong>*recognizer</strong></em> but <strong>not a decider</strong>.</li>
</ul>

<blockquote>
  <p><strong>Application:</strong></p>

  <ul>
    <li>We can use a TM <strong>decider</strong> to check whether if two DFA are the same:
$$</li>
  </ul>

  <table>
    <tbody>
      <tr>
        <td>EQ_{DFA}={\langle D_1, D_2\rangle</td>
        <td>\text{$D_1,D_2$ are DFA and $L(D_1)=L(D_2)$}}</td>
      </tr>
    </tbody>
  </table>

  <p>$$</p>

  <ul>
    <li>Construction:</li>
    <li>Using the idea of symmetric difference, and construct $L(C)$ as follows.
      <ul>
        <li>since we have $DFA$s, using the closure property, we can get a $L(C)$ using DFA $C$.</li>
        <li>to see if $C$ is empty, we use the above $E_{DFA}$
          <ul>
            <li>if $C$ is empty, then $L(D_1)=L(D_2)$, otherwise, false</li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>

  <p><img src="\lectures\images\typora-user-images\image-20201110214253108.png" alt="image-20201110214253108" /></p>
</blockquote>

<blockquote>
  <p><strong>Application:</strong></p>

  <ul>
    <li>
      <p>We can also use a decider to do the job of a CFG:
$$</p>

      <table>
        <tbody>
          <tr>
            <td>A_{CFG}={ \langle G,w \rangle</td>
            <td>\text{$G$ is a CFG and $G$ accepts $w$}}</td>
          </tr>
        </tbody>
      </table>

      <p>$$</p>
    </li>
    <li>
      <p>Construction skipped.</p>

      <p><img src="\lectures\images\typora-user-images\image-20201110214143400.png" alt="image-20201110214143400" /></p>
    </li>
  </ul>

</blockquote>

<p>Therefore, this means we can also construct a decider for:</p>

<ul>
  <li>$A_{Regular Language}$ since $A_{CFG}$ works</li>
</ul>

<blockquote>
  <p><strong>Not TM decidable Languages</strong></p>

  <ul>
    <li>$EQ_{CFG} = { \langle G_1,G_2 \rangle \vert  \text{$G_1$,$G_2$are CFG,$L(G_1)=L(G_2)$} }$</li>
    <li>$AMB_{G} = { \langle G\rangle \vert  \text{$G$is a CFG that is ambiguous} }$</li>
  </ul>
</blockquote>

<h1 id="week-10">Week 10</h1>

<h2 id="tm-recognizable-languages">TM Recognizable Languages</h2>

<p>Now, for languages that are recognizable, means that there <strong>exists</strong> a TM that solved the problem.</p>

<ul>
  <li>note that now, we don’t need to have finite steps as compared to before, because this is about <strong>recognizers</strong>.</li>
  <li>hence we <strong>could have the case of infinite loop</strong>, as long as the correct output could be <strong>reached</strong> (e.g. accept=halt)</li>
</ul>

<blockquote>
  <p><strong>Examples of Recognizable Languages</strong></p>

  <ul>
    <li>
      <p>The acceptance problem of TM, such that using this I get whether the input is accepted or not (including running forever): $A_{TM}$
$$</p>

      <table>
        <tbody>
          <tr>
            <td>A_{TM}= { \langle M,w\rangle</td>
            <td>\text{$M$ is a TM, and $M$ accepts $w$} }</td>
          </tr>
        </tbody>
      </table>

      <p>$$
where:</p>

      <ul>
        <li>note that this $A_{TM}$ <strong>could</strong> run forever. As we are dealing with recognizers, and <strong>acceptance</strong> is purely dependent on accepting + halting.</li>
        <li>$A_{TM}$ could basically be understood as a general Input-Output TM, such that we have $1$ output as accepted and $0$ output as rejected, infinite loop as infinite loop.</li>
      </ul>
    </li>
    <li>
      <p><strong>Proof/Construction</strong></p>

      <p><img src="\lectures\images\typora-user-images\image-20201110215759113.png" alt="image-20201110215759113" style="zoom:50%;" /></p>

      <p><img src="\lectures\images\typora-user-images\image-20201110220128308.png" alt="image-20201110220128308" style="zoom:50%;" /></p>

      <p>where:</p>

      <ul>
        <li>notice that if $M$ is running forever, then $U$ also runs forever. However, this is fine because <strong>if $U$ runs forever</strong> and is a recognizer, $U$ <strong>rejects</strong> by definition
          <ul>
            <li>$U$ is <strong>not a decider</strong>, but a recognizer.</li>
            <li>this $U$ is also called a <strong>Universal Turing Machine</strong>, because it is general in the sense that <strong>this TM can run any other algorithm</strong></li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</blockquote>

<p>Interestingly, we can also prove that the above is <strong>not decidable:</strong></p>

<blockquote>
  <p><strong>Examples of TM Non-decidable Languages</strong></p>

  <ul>
    <li>
      <p>The same acceptance problem of TM, $A_{TM}$, is <strong>not decidable</strong>
$$</p>

      <table>
        <tbody>
          <tr>
            <td>A_{TM}= { \langle M,w\rangle</td>
            <td>\text{$M$ is a TM, and $M$ accepts $w$} }</td>
          </tr>
        </tbody>
      </table>

      <p>$$</p>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Proof:</strong></p>

  <ul>
    <li>
      <p>Assume towards contradiction, that it is decidable. Then we have a decider $D$ for $A_{TM}$, such that it is a TM decider and hence always halts.</p>
    </li>
    <li>
      <p><img src="\lectures\images\typora-user-images\image-20201113011316669.png" alt="image-20201113011316669" style="zoom:50%;" /></p>

      <p>where:</p>

      <ul>
        <li>we see that $T$ is a decider, and this is because $D$ is a decider.</li>
        <li>Now, consider the output of $T$ on $\lang T\rang$:
          <ul>
            <li>If $T$ accepts $\lang T\rang$:
              <ul>
                <li>then by definition of $D$ for $A_{TM}$, it means $D$ accepts $\lang T, \lang T\rang\rang$.</li>
                <li>however, by construction of $T$, it means $D$ rejects. Hence contradiction</li>
              </ul>
            </li>
            <li>If $T$ rejects $\lang T\rang$:
              <ul>
                <li>then by definition of $D$ for $A_{TM}$, it means $D$ rejects $\lang T, \lang T\rang\rang$.</li>
                <li>however, by construction of $T$, it means $D$ accepts. Hence contradiction</li>
              </ul>
            </li>
          </ul>
        </li>
      </ul>

      <p>Therefore, $D$ as a decider <strong>cannot</strong> exist.</p>
    </li>
    <li>
      <p>In fact, this is the same as doing a diagonalization:</p>

      <p><img src="\lectures\images\typora-user-images\image-20201113001720011.png" alt="image-20201113001720011" style="zoom: 67%;" /></p>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Examples of Recognizable TM</strong></p>

  <ul>
    <li>
      <p>The TM that tells me if a TM is <strong>not empty</strong>
$$</p>

      <table>
        <tbody>
          <tr>
            <td>NE_{TM} = { \langle M \rangle</td>
            <td>\text{$M$ is a $TM$ and $L(M)\neq \empty$} }</td>
          </tr>
        </tbody>
      </table>

      <p>$$</p>
    </li>
    <li>
      <p><strong>Proof/Construction</strong></p>

      <ul>
        <li>
          <p>first attempt</p>

          <ul>
            <li>on input $\langle M\rangle$, where $M$ is a TM:
              <ul>
                <li>For all strings $s \in \Sigma^*$ (this infinite loop is fine, as it is implementable for a recognizer)</li>
                <li>Run $M$ on $s$
                  <ul>
                    <li>if accepts, accept</li>
                    <li>if rejects, go on to the next string (might be <strong><em>stuck</em></strong> here)</li>
                  </ul>
                </li>
              </ul>
            </li>
          </ul>
        </li>
      </ul>

      <p>where this does <strong>not</strong> work because:</p>

      <ul>
        <li>is implementable for recognizers, because our recognizer <strong>can</strong> run forever
          <ul>
            <li>but the problem is that some cases of <strong>accepted string cannot be accepted by this construction</strong>, because the <strong><em>earlier string will loop forever</em></strong></li>
          </ul>
        </li>
        <li>
          <p>therefore, it does not recognize $NE_{TM}$</p>
        </li>
        <li>
          <p>second attempt</p>

          <ul>
            <li>on input $\langle M\rangle$:</li>
            <li>for $i = 1,2,3…$
              <ul>
                <li>for all $s \in \Sigma^*$, $\vert s\vert  \le i$</li>
                <li>Run $M$ on $s$ for $i$ steps (hence this step is always <strong>finite</strong>)</li>
                <li>if accepts, accept (so this step can <strong><em>always</em> be reached</strong>)</li>
              </ul>
            </li>
          </ul>
        </li>
      </ul>

      <p>where this works because:</p>

      <ul>
        <li>the idea is that now, everything <strong>inside the loop</strong> will <strong><em>always</em> be finite</strong>, so if a string will be accepted, then it will be accepted
          <ul>
            <li>remember, the fact that this loop is infinite does not matter</li>
          </ul>

          <p>This will work because:</p>

          <ul>
            <li>
              <p>first, on input $\langle M\rangle$</p>
            </li>
            <li>
              <p><img src="\lectures\images\typora-user-images\image-20201110223621127.png" alt="image-20201110223621127" style="zoom:50%;" /></p>

              <p>$\Rarr$ then $R$ does not accept</p>
            </li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</blockquote>

<h2 id="undecidability-and-unrecognizability">Undecidability and Unrecognizability</h2>

<p>In fact, many languages are <strong>not</strong> recognizable.</p>

<ul>
  <li>here, we show some examples of language that are not decidable/not recognizable</li>
  <li>and that many natural examples (in real life) are not decidable/not recognizable</li>
</ul>

<h3 id="definitions-2">Definitions</h3>

<blockquote>
  <p><strong>Definition:</strong></p>

  <ul>
    <li>
      <p>Two sets $A,B$ have the same <strong>cardinality</strong>  ($\vert A\vert =\vert B\vert$) if there is a bijection function (<strong>one-to-one</strong> and onto function)
$$</p>

      <p>f: A \to B</p>

      <p>$$</p>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Definition:</strong></p>

  <ul>
    <li>
      <p>A set $A$ is <strong>countable</strong>, if $A$ is either <strong>finite</strong>, <strong><em>or</em></strong> there is a bijection function:
$$</p>

      <p>f:\N \to A</p>

      <p>$$
where:</p>

      <ul>
        <li>$\N$ is the set of <strong>natural numbers</strong> (which is infinite)</li>
      </ul>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Fact:</strong></p>

  <ul>
    <li>If $A \subseteq B$, then $\vert A\vert  \le \vert B\vert$</li>
    <li>If $A \subseteq B$, and $B$ is countable, then $A$ is also countable.</li>
    <li>A countable or finite <strong>union</strong> of countable sets is <strong>countable</strong>.</li>
  </ul>
</blockquote>

<p><strong><em>For example,</em></strong></p>

<ul>
  <li>a countable set could be all even positive integers</li>
  <li>for a finite alphabet $\Sigma$, $\Sigma^*$ is countable
    <ul>
      <li>we could use the lexicographical <strong>order</strong>, and <strong>order</strong> strings into length $i=0,1,2,3…$</li>
      <li>hence, we can map them to the set of natural numbers</li>
    </ul>
  </li>
</ul>

<blockquote>
  <p><strong>Countability with TM</strong></p>

  <ul>
    <li>The set of <strong>all TM is countable,</strong> because each TM can be encoded into a string, which is countable</li>
    <li>The set of all TM recognizable languages is countable.
      <ul>
        <li>obviously, same for decidable</li>
      </ul>
    </li>
  </ul>
</blockquote>

<ul>
  <li>basically, if you can go through everything in some defined order, then you can map it to real numbers.</li>
</ul>

<h3 id="uncountable-languages">Uncountable Languages</h3>

<p>However, there are many things that are uncountable.</p>

<h4 id="using-diagonalization-for-tm-proofs">Using Diagonalization for TM Proofs</h4>

<blockquote>
  <p><strong>Claim:</strong></p>

  <ul>
    <li>For all the reals between $(0,1)$, it is <strong>not</strong> countable.</li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Proof:</strong></p>

  <ul>
    <li>
      <p>Assume towards contradiction that it is countable.</p>
    </li>
    <li>
      <p>Then we can write a all members into a set, such that we get a one-to-one mapping with the natural numbers:
$$</p>

      <p>{r_1, r_2,r_3, … }\text{, members of $r_i$, $\forall i \in \N$}</p>

      <p>$$</p>

      <ul>
        <li>
          <p>Then suppose we have the following order for numbers:</p>

          <p><img src="\lectures\images\typora-user-images\image-20201113005239383.png" alt="image-20201113005239383" style="zoom: 67%;" /></p>

          <p>where:</p>

          <ul>
            <li>it does not matter what number we pick for each $r_i$, they can be any number</li>
          </ul>
        </li>
        <li>
          <p>Now, we construct a real number $r$ that is $100\%$ not in the set because it is different from every one of them by <strong>diagonalization</strong></p>

          <ul>
            <li>
              <p>picking $r=0.d_1d_2d_3…$, such that $d_i \neq r_{i,i}$, where $r_{i,i}$ means the $ith$ digit of $r_i$.</p>

              <ul>
                <li>one edge case to care is to pick $d_i \in {1,2,…,8}$, so we take care of the case that $0.0999… = 0.1000…$, even if the digit is different</li>
              </ul>
            </li>
            <li>
              <p>so the $r$ basically picks a different number than all the highlighted ones:</p>

              <p><img src="\lectures\images\typora-user-images\image-20201113005532412.png" alt="image-20201113005532412" style="zoom: 67%;" /></p>

              <p>(e.g. you can have $r=0.253…$)</p>
            </li>
          </ul>
        </li>
        <li>
          <p>Therefore, we obtain a $r$ that is different from all the members of $r_i$, because $r$ is <strong>different from <em>each</em> one of them</strong> as at least one digit is different ($d_i \neq r_{i,i}$).</p>
        </li>
      </ul>
    </li>
  </ul>
</blockquote>

<p>The idea of <strong>diagonalization</strong> works often when:</p>

<ul>
  <li>the representation of <strong>each member</strong> of the set is <strong>infinite</strong>.
    <ul>
      <li>As a result, you can always construct a member that is different from each of them by <strong><em>not</em></strong> picking the diagonal members</li>
    </ul>
  </li>
</ul>

<blockquote>
  <p>Remember, the idea is that if it is countable, then there is a <strong><em>one-ton-one and onto MAPPING (ORDERING)</em></strong> to the $\N$ (bijection), or whatever is countable.</p>
</blockquote>

<blockquote>
  <p><strong>Claim:</strong></p>

  <ul>
    <li>
      <p>For finite $\Sigma$, the set of all <strong>languages</strong>
$$</p>

      <p>{ L \subseteq \Sigma^* } = \mathbb{P}(\Sigma^*)</p>

      <p>$$
is <strong>not</strong> countable</p>
    </li>
    <li>
      <p>Therefore, it means <strong>a lot of languages are not TM-recognizable</strong> (if all are recognizable, then this set would also be countable since a TM-recognizable language is countable)</p>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Proof:</strong></p>

  <ul>
    <li>
      <p>Again, assume towards contradiction that it is countable, so you can write ${L_1, L_2, L_3,…}$ is a way that covers all languages.</p>
    </li>
    <li>
      <p>Since any language is essentially telling whether if a string is accepted, we construct:</p>

      <ul>
        <li>
          <p>break $\Sigma^<em>$ into $\Sigma^</em>={ s_1, s_2, s_3, … }$</p>

          <ul>
            <li>remember, that $\Sigma^*$ is countable, since each member ($s_i$) is finite and we can put them in lexicographical order</li>
          </ul>
        </li>
        <li>
          <p>Then a language is just telling you the T/F output of each string $s_i$:</p>

          <ul>
            <li>notice that the <strong>representation</strong> of each $L_i$ is <strong>infinite</strong>, hence hints us of diagonalization.</li>
          </ul>

          <p><img src="\lectures\images\typora-user-images\image-20201112235009083.png" alt="image-20201112235009083" style="zoom:50%;" /></p>

          <p>and the diagonal way to construct $L$ is evident from above, as:</p>

          <ul>
            <li>Construct $L = { s_i \in \Sigma^* \vert  s_i \notin L_i }$</li>
            <li>Then, there is at least one string that:
              <ul>
                <li>was accepted by $L_i$ but not accepted by $L$</li>
                <li>was not accepted by $L_i$ but accepted by $L$</li>
              </ul>
            </li>
          </ul>
        </li>
        <li>
          <p>Therefore, we have found a $L$ that differs for every one of $L_i$, and it means it is not countable.</p>
        </li>
      </ul>

      <p>Therefore, the set of <strong>all languages</strong> is <strong>not</strong> countable.</p>

      <ul>
        <li>there <strong><em>exists</em></strong> some countable languages that are not TM recognizable (e.g. the $L$ we have constructed above)</li>
      </ul>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Corollary</strong>:</p>

  <ul>
    <li>Since we know:
      <ul>
        <li>the set of all languages is not countable</li>
        <li>the set of all TM-recognizable language is countable</li>
      </ul>
    </li>
    <li>Therefore, there is at least one language (actually uncountable many of them) that is <strong>not</strong> TM recognizable.</li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Claim:</strong></p>

  <ul>
    <li>
      <p>We say that the problem:
$$</p>

      <p>\overline{A_{TM}} \text{ is not recognizable}</p>

      <p>$$</p>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Proof:</strong></p>

  <ul>
    <li>
      <p>This is purely logical</p>
    </li>
    <li>
      <p>Since we know if $L$ is decidable, then $L$ and $\overline{L}$ are both recognizable.</p>

      <ul>
        <li>We know that $A_{TM}$ is recognizable, and $A_{TM}$ is not decidable</li>
        <li>Therefore, if $\overline{A_{TM}}$ is recognizable, then there is a contradiction as it means $A_{TM}$ is decidable
          <ul>
            <li>since it would mean both $A_{TM}$ and $\overline{A_{TM}}$ being recognizable</li>
          </ul>
        </li>
        <li>Therefore, we have a contradiction</li>
      </ul>

      <p>Hence $\overline{A_{TM}}$ is <strong>not</strong> recognizable.</p>
    </li>
  </ul>
</blockquote>

<p>One consequence of the above is that:</p>

<blockquote>
  <p><strong>Corollary:</strong></p>

  <ul>
    <li>The class of TM-recognizable languages is <strong>not</strong> closed under complement.</li>
  </ul>
</blockquote>

<h4 id="using-reduction-for-tm-proofs">Using Reduction for TM Proofs</h4>

<p>Basically, the idea of reduction is that, we can construct (towards contradiction) a TM $R$, and use it to <strong>build up a TM</strong> that <strong>contradicts</strong> what we <strong>have known so far</strong>:</p>

<ul>
  <li>$A_{TM}$ is not decidable</li>
  <li>$\overline{A_{TM}}$ is not recognizable</li>
  <li>etc.</li>
</ul>

<blockquote>
  <p><strong>Claim:</strong></p>

  <ul>
    <li>
      <p>The halting problem:
$$</p>

      <table>
        <tbody>
          <tr>
            <td>\text{$Halt_{TM}$ = { $\lang M,w\rang$</td>
            <td>$M$ is a TM, $M$ halts on $w$ }}</td>
          </tr>
        </tbody>
      </table>

      <p>$$
is <strong>undecidable</strong></p>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Proof:</strong></p>

  <ul>
    <li>
      <p>Again, assume towards contradiction that $Halt_{TM}$ is decidable, so has a decider $R$.</p>
    </li>
    <li>
      <p>Now, the <strong>reduction</strong> method is to build up towards something we know would contradict</p>

      <ul>
        <li>
          <p>we use $R$ to construct a decider $S$, such that</p>

          <p><img src="\lectures\images\typora-user-images\image-20201113002806469.png" alt="image-20201113002806469" style="zoom:50%;" /></p>

          <p>where:</p>

          <ul>
            <li>each step is a deciding (finite) step, so $S$ is a decider</li>
          </ul>
        </li>
        <li>
          <p>Now, notice we have constructed a TM $S$ that is decidable for $A_{TM}$.</p>

          <ul>
            <li>but we know $A_{TM}$ is not decidable. Hence a contradiction.</li>
          </ul>
        </li>
      </ul>
    </li>
    <li>
      <p>In more formal detailed words:</p>
    </li>
  </ul>

  <p><img src="\lectures\images\typora-user-images\image-20201113003056188.png" alt="image-20201113003056188" style="zoom: 67%;" /></p>
</blockquote>

<h1 id="week-11">Week 11</h1>

<h2 id="using-reduction-for-tm-proofs-continued">Using Reduction for TM Proofs (Continued)</h2>

<p>Now, we come to the formal definition of reduction:</p>

<blockquote>
  <p><strong>Reduction:</strong></p>

  <ul>
    <li>We say a <strong>language $A$</strong> is Turing-reducible to a language $B$, written $A \le_T B$, if given a subroutine/decider/oracle that decides $B$, there <strong>exists a decider for $A$.</strong>
      <ul>
        <li>i.e. if we know how to <strong>solve</strong> $B$ (harder part), then we <strong>also know how to solve</strong> $A$ (easier part).</li>
        <li>i.e. $A$ would be easier to decide than $B$, such that when we decide $B$, we have already decided $A$.</li>
      </ul>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Theorem:</strong></p>

  <ul>
    <li>If $A \le_T B$ and $B$ is decidable, then $A$ is decidable.
      <ul>
        <li>i.e. if we can solve the hard part $B$, then we can decide the easy part $A$ <strong>using it</strong>.</li>
      </ul>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Proof:</strong></p>

  <ul>
    <li><img src="\lectures\images\typora-user-images\image-20201117221019640.png" alt="image-20201117221019640" style="zoom:50%;" /></li>
  </ul>
</blockquote>

<p>Equivalently, the opposite is also useful for proofs:</p>

<blockquote>
  <p><strong>Equivalent Theorem:</strong></p>

  <ul>
    <li>If $A \le_T B$ and <strong>$A$ is undecidable</strong>, then $B$ is undecidable.
      <ul>
        <li>intuitively, if $A$ is the smaller part of $B$, and $A$ is undecidable already, then $B$ is hard/undecidable.</li>
        <li>logically, if we can solve $B$, then we should be able to solve $A$. But since $A$ cannot be solved, then $B$ cannot be solved.</li>
      </ul>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p>Therefore, <strong>the above would be used</strong> as follows:</p>

  <ul>
    <li>
      <p>To <strong>prove $B$</strong> is <strong>undecidable</strong>, we can prove using contradiction:</p>

      <ol>
        <li>
          <p>Assume $B$ is decidable (harder problem), then we get a decider for $B$.</p>
        </li>
        <li>
          <p>Then we can <strong>use $B$</strong> to solve the problem $A$, such that $A$ would be decidable as well</p>

          <ul>
            <li>
              <p>obviously, we need to <strong>know $A$ to be undecidable</strong> for contradiction</p>
            </li>
            <li>
              <p>the construction of <strong>using $B$</strong> to solve $A$ takes work</p>
            </li>
          </ul>
        </li>
        <li>
          <p>Since $A$ is undecidable, this contradicts the assumption that $B$ decides.</p>
        </li>
        <li>
          <p>Hence $B$ is undecidable.</p>
        </li>
      </ol>
    </li>
    <li>
      <p>The idea is that if you can solve $B$, the harder problem, then you can use $B$ to easily solve $A$.</p>

      <ul>
        <li>e.g. if we can solve $B=Halt_{TM}$, then we can use to solve $A=A_{TM}$ (look at the proof in the previous section). But $A_{TM}$ is not decidable, then $Halt_{TM}$ is not decidable.</li>
      </ul>
    </li>
  </ul>
</blockquote>

<hr />

<p><strong><em>For example:</em></strong></p>

<ul>
  <li>
    <p><strong>Claim:</strong>
$$</p>

    <table>
      <tbody>
        <tr>
          <td>E_{TM}={ \lang M\rang\,</td>
          <td>\, \text{$M$ is a TM, and $L(M)\neq \empty$} }</td>
        </tr>
      </tbody>
    </table>

    <p>$$
is <strong>not</strong> decidable.</p>
  </li>
  <li>
    <p><strong>Proof using reduction:</strong></p>

    <p>This will be a proof by reduction from $A_{TM}$, namely, we will show that <strong>$A_{TM}$ is Turing reducible to $E_{TM}$,</strong> i.e. $A_{TM} \le_TE_{TM}$.</p>

    <ul>
      <li>i.e. if we can decide $E_{TM}$, then we can also decide $A_{TM}$ (contradiction)</li>
    </ul>

    <p>Assume towards contradiction that we <strong>have a decider</strong> $O$ that solves $E_{TM}$. Then we construct a $R$ that <strong>uses $O$</strong> as follows:</p>

    <p><img src="\lectures\images\typora-user-images\image-20201117223127076.png" alt="image-20201117223127076" style="zoom: 50%;" /></p>

    <p>where:</p>

    <ul>
      <li>the <strong>general format</strong> for $O$ (assumed decider) would <strong>always</strong> be:
        <ul>
          <li>if accepts, <code class="language-plaintext highlighter-rouge">(here you need to implement)</code></li>
          <li>if rejects, <code class="language-plaintext highlighter-rouge">(here you need to implement)</code></li>
          <li>think of this as: we are <strong>given the library of $O$,</strong> such that we can use it right away</li>
        </ul>
      </li>
    </ul>

    <p>This $R$ would be a decider for $A_{TM}$:</p>

    <p><img src="\lectures\images\typora-user-images\image-20201117223554515.png" alt="image-20201117223554515" style="zoom:50%;" /></p>

    <p>So we showed that we can use $E_{TM}$ to <strong>decide</strong> $A_{TM}$, such that $A_{TM} \le_T E_{TM}$. But $A_{TM}$ is not decidable, this means $E_{TM}$ cannot be decidable.</p>
  </li>
</ul>

<hr />

<hr />

<p><strong><em>For example:</em></strong></p>

<ul>
  <li>
    <p><strong>Claim:</strong>
$$</p>

    <table>
      <tbody>
        <tr>
          <td>EQ_{TM}={ \lang M_1, M_2 \rang</td>
          <td>\text{$M_1, M_2$ are TMs and $L(M_1)=L(M_2)$} }</td>
        </tr>
      </tbody>
    </table>

    <p>$$
is <strong>not decidable</strong>.</p>

    <ul>
      <li>this means that, in general, we <strong>cannot</strong> have a way to decide whether if the two programs are the same or not.</li>
    </ul>
  </li>
  <li>
    <p><strong>Proof Using Reduction:</strong></p>

    <p>We do it with a reduction from $E_{TM}$.</p>

    <ol>
      <li>We assume $O$ being a decider for the language $EQ_{TM}$.</li>
      <li>We want to use $O$ to decide $E_{TM}$, which we know is not decidable.</li>
      <li><img src="\lectures\images\typora-user-images\image-20201117225446342.png" alt="image-20201117225446342" style="zoom: 50%;" /></li>
    </ol>
  </li>
</ul>

<p>As a result, we have used $O$ to make a decider $R$ for the language $E_{TM}$, because:</p>

<p><img src="\lectures\images\typora-user-images\image-20201117225744481.png" alt="image-20201117225744481" style="zoom:50%;" /></p>

<p>so we have showed that $E_{TM} \le_T EQ_{TM}$, since $E_{TM}$ is not decidable, <strong>then $EQ_{TM}$ is also not decidable.</strong></p>

<hr />

<hr />

<p><strong><em>For example:</em></strong></p>

<ul>
  <li>
    <p><strong>Claim:</strong>
$$</p>

    <table>
      <tbody>
        <tr>
          <td>REG_{TM}={ \lang M\rang</td>
          <td>\text{$M$ is a TM, $L(M)$ is regular} }</td>
        </tr>
      </tbody>
    </table>

    <p>$$
is <strong>not decidable</strong></p>
  </li>
  <li>
    <p><strong>Proof using Reduction</strong></p>

    <p>Assume that we have a decider $O$ for $REG_{TM}$, then we can construct a decider for $A_{TM}$ using the algorithm below:</p>

    <p><img src="\lectures\images\typora-user-images\image-20201120102037597.png" alt="image-20201120102037597" style="zoom: 50%;" /></p>

    <p>and we see this $R$ being the decider for $A_{TM}$ because:</p>

    <ul>
      <li>recall that $0^n1^n$ is <strong>not</strong> regular due to pumping lemma</li>
    </ul>

    <p><img src="\lectures\images\typora-user-images\image-20201120102342608.png" alt="image-20201120102342608" style="zoom:50%;" /></p>
  </li>
</ul>

<hr />

<p>One definition not explicitly addressed is as follows:</p>

<blockquote>
  <p><strong>TM Implementable:</strong></p>

  <ul>
    <li>An iteration “for $s$ in $S$, do…” is implementable if and only if:
      <ul>
        <li>the <strong>set $S$</strong> is countable</li>
        <li>each <strong>member</strong> of the set $S$ is computable (can be found using a decider TM/<strong>halting</strong> TM)</li>
      </ul>
    </li>
  </ul>
</blockquote>

<p><strong><em>For example:</em></strong></p>

<ul>
  <li>for every $w$ in $\Sigma^*$, it works trivially and <strong>is implementable</strong></li>
  <li>for every $\lang M\rang$ for all TM, where $M$ is a decider, this <strong>is not implementable</strong>
    <ul>
      <li>the set of all TM is a countable set, but</li>
      <li>$\lang M\rang$ being a <strong>decider</strong> is <strong>not computable</strong>, because it is <strong>not decidable</strong></li>
    </ul>
  </li>
</ul>

<p><strong>In summary, we have the following UNDECIDABLE languages:</strong></p>

<ul>
  <li>$A_{TM}$</li>
  <li>$Halt_{TM}$</li>
  <li>$E_{TM}$</li>
  <li>
    <p>$EQ_{TM}$</p>
  </li>
  <li>$REG_{TM}$</li>
</ul>

<h2 id="rices-theorem">Rice’s Theorem</h2>

<blockquote>
  <p><strong>(Informal) Rice’s Theorem</strong>:</p>

  <ul>
    <li>
      <p>Any non-trivial language of the form:
$$</p>

      <table>
        <tbody>
          <tr>
            <td>{ \lang M\rang</td>
            <td>\text{M is a TM and $L(M)$ satisfies…}}</td>
          </tr>
        </tbody>
      </table>

      <p>$$
is <strong>not decidable</strong></p>

      <ul>
        <li>i.e. we <strong>cannot decide</strong> the <strong>properties of a language</strong> of a TM machine.</li>
      </ul>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Definition:</strong></p>

  <ul>
    <li>$P$ is a <strong>non-trivial</strong> property of a <strong><em>recognizable</em></strong> languages:
      <ul>
        <li>$P \subseteq {\lang M\rang \vert \text{$M$is a TM }}$ (defining <strong>property</strong>)
          <ul>
            <li><strong>then</strong> if $M_1, M_2$ are TMs and $L(M_1)=L(M_2)$, then either:
              <ul>
                <li><strong>both</strong> have the property $\lang M_1 \rang, \lang M_2 \rang \in P$</li>
                <li>or <strong>neither</strong> has the property $\lang M_1 \rang, \lang M_2 \rang \notin P$</li>
              </ul>
            </li>
            <li>so the property is a property of the <strong>LANGUAGE</strong> of the TM, <strong>not</strong> of the <strong>implementation</strong> of TM</li>
          </ul>
        </li>
        <li><strong>and</strong> $P \neq \empty$, $P \neq { \lang M \rang \vert  \text{$M$is a TM} }$ (defining <strong>non-trivial</strong>)
          <ul>
            <li>i.e. $P$ is a proper, non-empty subset of all TM $\lang M\rang$</li>
            <li>i.e. there exists <strong>at least one</strong> $\lang M \rang \in P$, and <strong>at least one</strong> $\lang M \rang \notin P$</li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Rice Theorem:</strong></p>

  <ul>
    <li>Let $P$ be a non-trivial property of <strong>recognizable</strong> languages. Then $P$ is <strong><em>not</em></strong> <strong><em>decidable</em></strong>.
      <ul>
        <li>e.g. a non-trivial property could be $L(M)$ being regular</li>
      </ul>
    </li>
  </ul>
</blockquote>

<p>Therefore, it means:</p>

<ol>
  <li>once you know a property $P$ of a TM language is <strong>non-trivial</strong></li>
  <li>the language is <strong>not decidable</strong> by Rice’s Theorem</li>
</ol>

<blockquote>
  <p><strong>Proof</strong>:</p>

  <ul>
    <li>
      <p>We will use <strong>reduction</strong> from $A_{TM}$.</p>

      <ul>
        <li>the idea is that all those proofs use the same logic/construction.</li>
      </ul>
    </li>
    <li>
      <p>Assume $O$ is a decider for (Turing machine of a language with) non-trivial property $P$. We will construct a decider for $A_{TM}$.</p>
    </li>
    <li>
      <p><img src="\lectures\images\typora-user-images\image-20201125143044644.png" alt="image-20201125143044644" style="zoom: 50%;" /></p>
    </li>
    <li>
      <p>Now, we <strong>construct the decider</strong> $R$:</p>

      <p><img src="\lectures\images\typora-user-images\image-20201125143358767.png" alt="image-20201125143358767" style="zoom: 50%;" /></p>
    </li>
    <li>
      <p>Now, we prove that this is a decider for $A_{TM}$:</p>

      <p><img src="\lectures\images\typora-user-images\image-20201125144355374.png" alt="image-20201125144355374" style="zoom: 50%;" /></p>
    </li>
    <li>
      <p><strong>Therefore, since $A_{TM}$ is undecidable, then $P$ is also undecidable (by contradiction).</strong></p>
    </li>
  </ul>
</blockquote>

<p>So we see that the general idea for reduction to $A_{TM}$ is that:</p>

<ul>
  <li>We can construct the $M’$ such that it:
    <ul>
      <li>is <strong>empty</strong> and $\notin P$, if $M$ <strong>rejects</strong> <strong>or run forever on</strong> $w$</li>
      <li>is <strong>non-empty</strong> and $\in P$, if $M$ <strong>accepts</strong> $w$</li>
      <li>or vice versa for $P$ in the above</li>
    </ul>
  </li>
  <li>Then, we can run $O(\lang M’\rang)$ to decide $A_{TM}$</li>
</ul>

<blockquote>
  <p><strong>Extension:</strong></p>

  <ul>
    <li>
      <p>The proof above for Rice’s Theorem, which showed $A_{TM} \le_T P$ can be rephrased to show that
$$</p>

      <p>\begin{cases}
\overline{A_{TM}} \le_M P &amp; \text{if $\lang M_{\empty}\rang \in P$} <br />
\overline{A_{TM}} \le_M \overline{P} &amp; \text{if $\lang M_{\empty}\rang \notin P$}
\end{cases}</p>

      <p>$$
which is <strong>mapping reduction</strong>, which shows the <strong>refined Rice’s Theorem</strong>:</p>

      <ul>
        <li>If $P$ is a <strong>non-trivial property</strong> of a <strong><em>recognizable</em></strong> language, then:
          <ul>
            <li>if $\lang M_{\empty}\rang \in P$, $P$ is <strong>not recognizable</strong> (because $\overline{A_{TM}}$ is not recognizable)</li>
            <li>if $\lang M_{\empty}\rang \notin P$, $\overline{P}$ is <strong>not recognizable</strong> (because $\overline{A_{TM}}$ is not recognizable)</li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</blockquote>

<hr />

<p><strong><em>For example:</em></strong></p>

<ul>
  <li>
    <p><strong>Question:</strong></p>

    <p>The language:
$$</p>

    <table>
      <tbody>
        <tr>
          <td>P={\lang M\rang</td>
          <td>\text{$M$ is a TM, and every string accepted by $M$ starts with $0$}  }</td>
        </tr>
      </tbody>
    </table>

    <p>$$
is <strong>undecidable <em>by Rice’s Theorem</em></strong></p>
  </li>
  <li>
    <p><strong>Solution</strong></p>

    <p>We just need to prove that this $P$ is a <strong>property</strong>, <strong>and</strong> is <strong>non-trivial</strong>:</p>

    <ul>
      <li>This $P$ is a <strong>property</strong> because:
        <ul>
          <li>if $M_1, M_2$ are TMs such that $L(M_1)=L(M_2)$, then it means $\lang M_1\rang \in P \iff \lang M_2\rang \in P$</li>
        </ul>
      </li>
      <li>This $P$ is <strong>non-trivial</strong> because:
        <ul>
          <li>we <strong>can</strong> find a $M$ such that $\lang M\rang \in P$
            <ul>
              <li>e.g. accepted the string if the first character is $0$</li>
            </ul>
          </li>
          <li>and we <strong>can</strong> find a $M$ such that $\lang M\rang \notin P$
            <ul>
              <li>e.g. accepted the string if the first character is $1$</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>

    <p>Therefore, by Rice’s Theorem, $P$ is not decidable.</p>
  </li>
</ul>

<hr />

<blockquote>
  <p><strong>When does Rice’s Theorem <em>not work?</em></strong></p>

  <ul>
    <li>If we have a property, <strong>but</strong>:
      <ul>
        <li>it is a property of a DFA, graph, integers, etc. such that it <strong>cannot</strong> be rephrased as a <strong>TM property</strong></li>
        <li>it is a property that <strong>depends on implementation</strong>
          <ul>
            <li>e.g. ${ \lang M\rang \vert  \text{$M$is a TM,$M$accepts$\epsilon$, and$M$has at least 17 states} }$</li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>In summary, to show that a language is <em>undecidable:</em></strong></p>

  <ul>
    <li>Diagonalization</li>
    <li>Turing reduction</li>
    <li>Rice’s Theorem</li>
  </ul>
</blockquote>

<p>Next, we move on to prove whether if $L$ is not recognizable.</p>

<h1 id="week-12">Week 12</h1>

<h2 id="unrecognizable-languages">Unrecognizable Languages</h2>

<p><strong>One way</strong> to prove that $L$ is not recognizable would be:</p>

<ul>
  <li>$L$ is not decidable, but $\bar{L}$ is recognizable, then $L$ cannot be recognizable
    <ul>
      <li>this we already know, because if $L$ and $\bar{L}$ is recognizable, then $L$ is decidable.</li>
    </ul>
  </li>
</ul>

<p>One application of the above would be:</p>

<blockquote>
  <p><strong>Claim:</strong></p>

  <ul>
    <li>$E_{TM}$ is not recognizable</li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Proof:</strong></p>

  <ul>
    <li>We have seen that $E_{TM}$ is not decidable, but $\overline{E_{TM}}$ is recognizable.
      <ul>
        <li>in fact, for $\overline{E_{TM}}$, we have already proved with $NE_{TM}$, which is recognizable.</li>
      </ul>
    </li>
    <li>Therefore, $E_{TM}$ is not recognizable</li>
  </ul>
</blockquote>

<p>Other ways include:</p>

<ul>
  <li>Diagonalization (possible for some languages)
    <ul>
      <li>not on exam</li>
    </ul>
  </li>
  <li>Refined Rice’s Theorem
    <ul>
      <li>not on exam</li>
    </ul>
  </li>
  <li><strong>Mapping Reduction</strong>
    <ul>
      <li>on exam</li>
    </ul>
  </li>
</ul>

<blockquote>
  <p>In fact, just <strong>TM reduction</strong> would <strong>not work</strong> for recognizability, because:</p>

  <ul>
    <li>if $A \le_T B$, and $B$ is recognizable, we <strong>cannot conclude</strong> that $A$ would always have a <strong>working recognizer</strong>:
      <ul>
        <li>the idea is that if $w \in  A$, but we called $B$ multiple times <strong>and</strong> $w$ hangs <strong>forever</strong> for $B$, then we have a trouble producing a correct recognizer.
          <ul>
            <li>basically our program could not reach the end/<strong>hangs in <em>middle</em></strong></li>
          </ul>
        </li>
      </ul>
    </li>
    <li>however, <strong>the above behavior would work</strong>, if and only if:
      <ul>
        <li>$B$ is run <strong>exactly once</strong></li>
        <li>and $A$ <strong>outputs the same</strong> as $B$ (i.e. if $w$ hangs on $B$, then it <strong>should have</strong> also hangs on $A$)
          <ul>
            <li>i.e. if we hang, we need to <strong>hang in the <em>end</em></strong></li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Formal Definition of Mapping Reduction</strong></p>

  <ul>
    <li>
      <p>A language $A$ is <strong>mapping reducible to a language</strong> $B$, denoted as $A \le_{M} B$, if there <strong>exists a computable function</strong>
$$</p>

      <p>f:\Sigma^* \to \Sigma^*</p>

      <p>$$
<strong>such</strong> that:</p>

      <ul>
        <li>
          <p>$w \in A \iff f(w) \in B$</p>
        </li>
        <li>
          <p>i.e. every input in $A$ maps to $f(w)$ also in $B$, and every input not in $A$, then $f(w)$ also not in $B$.</p>

          <p><img src="\lectures\images\typora-user-images\image-20201124220822773.png" alt="image-20201124220822773" style="zoom:67%;" /></p>
        </li>
      </ul>
    </li>
  </ul>
</blockquote>

<p><strong><em>For example:</em></strong></p>

<ul>
  <li>
    <p><strong>Question</strong>:
$$</p>

    <p>\overline{A_{TM}} \le_M REG_{TM}</p>

    <p>$$
where:</p>

    <ul>
      <li>recall that $REG_{TM}={ \lang M\rang \vert  \text{$M$is a TM,$L(M)$is regular} }$</li>
    </ul>
  </li>
  <li>
    <p><strong>Solution:</strong></p>

    <p>We first figure out the mapping function $f$:</p>

    <p><img src="\lectures\images\typora-user-images\image-20201124221412871.png" alt="image-20201124221412871" style="zoom: 50%;" /></p>

    <p>where:</p>

    <ul>
      <li>this $f$ is <strong>computable</strong></li>
    </ul>

    <p>then, we need to prove that:</p>

    <ul>
      <li>$w \in A \iff f(w) \in B$:</li>
    </ul>

    <p><img src="\lectures\images\typora-user-images\image-20201124221548386.png" alt="image-20201124221548386" style="zoom:67%;" /></p>

    <p>where:</p>

    <ul>
      <li>we basically mapped $\lang M,w\rang$ to $\lang M’\rang$</li>
    </ul>
  </li>
</ul>

<blockquote>
  <p><strong>Theorem:</strong></p>

  <ul>
    <li>If $A \le_M B$, then $A \le_T B$
      <ul>
        <li>note that the reverse might not be true</li>
      </ul>
    </li>
    <li>if $A \le_M B$, then $\bar{A} \le_M \bar{B}$
      <ul>
        <li>follows trivially from the definition of mapping reducible</li>
      </ul>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Proof:</strong></p>

  <ul>
    <li>
      <p>Proving: if $A \le_M B$, then $A \le_T B$</p>
    </li>
    <li>
      <p><strong>Suppose</strong> $A \le_M B$. The we get a computable mapping function $f$, such that $w \in A \iff f(w) \in B$</p>
    </li>
    <li>
      <p>Now, using that $f$, we need to <strong>show $A \le_T B$</strong></p>

      <ul>
        <li>we basically <strong>construct decider for $A$</strong> if we know $B$ is a decider <strong>and</strong> $f$ maps the inputs of $A$ to $B$:</li>
      </ul>

      <p><img src="\lectures\images\typora-user-images\image-20201125030725362.png" alt="image-20201125030725362" style="zoom:50%;" /></p>

      <ul>
        <li>
          <p>and the above would be a <strong>decider</strong> for $A$, because:</p>

          <p><img src="\lectures\images\typora-user-images\image-20201124223147755.png" alt="image-20201124223147755" style="zoom:50%;" /></p>
        </li>
      </ul>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Proof:</strong></p>

  <ul>
    <li>Proving: if $A \le_M B$, then $\bar{A} \le_M \bar{B}$</li>
    <li><img src="\lectures\images\typora-user-images\image-20201124223306787.png" alt="image-20201124223306787" style="zoom: 50%;" /></li>
  </ul>
</blockquote>

<p>The more relevant theorems are the follows:</p>

<blockquote>
  <p><strong>Using Mapping Reduction for Recognizability:</strong></p>

  <ul>
    <li>If $A \le_M B$, and $B$ is <strong>recognizable</strong>, then $A$ is <strong>recognizable</strong></li>
    <li>If $A \le_M B$, and $A$ is <strong>not recognizable</strong>, then $B$ is <strong>not recognizable.</strong>
      <ul>
        <li>i.e. if $A$ called $B$ exactly once in the subroutine, and $A$ outputs the same as $B$:
          <ul>
            <li>then if $A$ is not recognizable, $B$ cannot be recognizable. Otherwise, we would have solved $A$ to be recognizable.</li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Proof:</strong></p>

  <ul>
    <li>
      <p>If $A \le_M B$, and $B$ is <strong>recognizable</strong>, then $A$ is <strong>recognizable</strong></p>
    </li>
    <li>
      <p><strong>Suppose</strong> $A \le_M B$. The we get a computable mapping function $f$, such that $w \in A \iff f(w) \in B$</p>
    </li>
    <li>
      <p>If $B$ is recognizable, then we get a TM recognizer $M$ for $B$. We use the the $M$ <strong>and</strong> $f$ to <strong>construct a recognizer for $A$:</strong></p>

      <p>Then simply:</p>

      <p><img src="\lectures\images\typora-user-images\image-20201124223540835.png" alt="image-20201124223540835" style="zoom:50%;" /></p>

      <p>And $R$ would be a <strong>recognizer</strong> for $A$, because:</p>

      <ul>
        <li><img src="\lectures\images\typora-user-images\image-20201124223656292.png" alt="image-20201124223656292" style="zoom:50%;" /></li>
      </ul>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Proving</strong> “If $A \le_M B$, and $A$ is <strong>not recognizable</strong>, then $B$ is <strong>not recognizable.</strong>” would just work the same way as above.</p>

  <ul>
    <li>For instance, <strong>prove by contradiction</strong>.</li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Definition:</strong></p>

  <ul>
    <li>$L$ is <strong>co-recognizable</strong> if <strong>$\bar{L}$</strong> is recognizable.
      <ul>
        <li>there is no co-decidable, because if $L$ is decidable, then $L$ is co-decidable automatically.</li>
      </ul>
    </li>
  </ul>
</blockquote>

<hr />

<p><strong><em>For example:</em></strong></p>

<ul>
  <li>
    <p><strong>Theorem</strong>:
$$</p>

    <table>
      <tbody>
        <tr>
          <td>ALL_{TM} = { \lang M\rang</td>
          <td>\text{$M$ is a TM, and $L(M)=\Sigma^*$ } }</td>
        </tr>
      </tbody>
    </table>

    <p>$$
is <strong>neither recognizable nor co-recognizable</strong></p>
  </li>
  <li>
    <p><strong>Proof</strong>:</p>

    <p><strong>First</strong>, we show that $ALL_{TM}$ is not co-recognizable, namely, $\overline{ALL_{TM}}$ is <strong>not recognizable</strong>.</p>

    <p><img src="\lectures\images\typora-user-images\image-20201124224422173.png" alt="image-20201124224422173" style="zoom: 50%;" /></p>

    <p>In particular:</p>

    <p><img src="\lectures\images\typora-user-images\image-20201124224506895.png" alt="image-20201124224506895" style="zoom:50%;" /></p>

    <p>where:</p>

    <ul>
      <li>we would like to <strong>map</strong>:
        <ul>
          <li>if $M$ accepts $w$, <strong>then</strong> $M’$ accepts all possible strings</li>
          <li>if $M$ does not accept $w$, <strong>then</strong> $M’$ rejects at least one string</li>
        </ul>
      </li>
    </ul>

    <p>Now, we construct the mapping as follows:</p>

    <p><img src="\lectures\images\typora-user-images\image-20201124224819900.png" alt="image-20201124224819900" style="zoom:50%;" /></p>

    <p>and this <strong>mapping works as we wanted</strong>, because:</p>

    <p><img src="\lectures\images\typora-user-images\image-20201124225010675.png" alt="image-20201124225010675" style="zoom:50%;" /></p>

    <p>Therefore:</p>

    <p><img src="\lectures\images\typora-user-images\image-20201124225026240.png" alt="image-20201124225026240" style="zoom:50%;" /></p>

    <p><strong>Next,</strong> we will show that $ALL_{TM}$ is not recognizable. This means we need to construct a mapping $\overline{A_{TM}} \le_M ALL_{TM}$:</p>

    <p>Again, the idea is to map (the reverse):</p>

    <ul>
      <li>if $M$ accepts $w$, <strong>then</strong> $M’$ rejects at least one string</li>
      <li>if $M$ does not accept $w$, <strong>then</strong> $M’$ accepts all possible strings</li>
    </ul>

    <p>and the <strong>mapping functions</strong> is as follows:</p>

    <p><img src="\lectures\images\typora-user-images\image-20201124225418156.png" alt="image-20201124225418156" style="zoom:50%;" /></p>

    <p>where:</p>

    <ul>
      <li>notice we cannot write: “if $M$ does not accept, accept $x$”. This is because we might deal with the infinite loop.</li>
    </ul>

    <p>Now, we claim that this <strong>mapping function works</strong>:</p>

    <p><img src="\lectures\images\typora-user-images\image-20201124225801015.png" alt="image-20201124225801015" style="zoom:50%;" /></p>

    <p><img src="\lectures\images\typora-user-images\image-20201124225956862.png" alt="image-20201124225956862" style="zoom:50%;" /></p>

    <p>where:</p>

    <ul>
      <li>notice that we just needed to construct $M’$ that <strong>rejects at least one string</strong> if $\lang M,w\rang \in A_{TM}$</li>
    </ul>
  </li>
</ul>

<hr />

<p><strong>In summary</strong>, the <strong>unrecognizable</strong> languages we know so far are:</p>

<ul>
  <li>$\overline{A_{TM}}$
    <ul>
      <li>but $A_{TM}$ is recognizable</li>
    </ul>
  </li>
  <li>$ALL_{TM}$</li>
</ul>

<blockquote>
  <p><strong>In general:</strong></p>

  <ul>
    <li>
      <p>If we have a <strong>TM reducibility</strong>, then:
$$</p>

      <p>A \le_T B \iff \bar{A} \le_T B \iff A \le_T \bar{B} \iff \bar{A} \le_T \bar{B}</p>

      <p>$$</p>

      <ul>
        <li>since we have decidability, then we can easily flip them to <strong>still be decidable</strong></li>
      </ul>
    </li>
    <li>
      <p>If we have <strong>Mapping reducibility</strong>, we only have:
$$</p>

      <p>A \le_M B \iff \bar{A} \le_M \bar{B}</p>

\[\]

      <p>\bar{A} \le_M B \iff A \le_M \bar{B}</p>

      <p>$$</p>

      <ul>
        <li>since now, we are talking about <strong>mapping function</strong> $f$</li>
      </ul>
    </li>
  </ul>
</blockquote>

<h1 id="week-13">Week 13</h1>

<h2 id="computation-history-extension">Computation History (Extension)</h2>

<p>This will be another technique we can use to prove:</p>

<ul>
  <li>undecidability</li>
</ul>

<blockquote>
  <p><strong>This computation history technique will be useful if</strong></p>

  <ul>
    <li>The language you need to prove to be recognizable/unrecognizable/decidable/undecidable <strong>might not have an obvious TM</strong>.</li>
    <li>Then, you cannot use what we have done before: <mark>TODO: finish this</mark>
      <ul>
        <li>need to use this technique</li>
      </ul>
    </li>
  </ul>
</blockquote>

<p>Another technique to prove unrecognizability.</p>

<p><img src="\lectures\images\typora-user-images\image-20201201215529548.png" alt="image-20201201215529548" style="zoom:50%;" /></p>

<p>Using this, we can prove the following are <strong>not decidable</strong></p>

<p><img src="\lectures\images\typora-user-images\image-20201201215857366.png" alt="image-20201201215857366" style="zoom:50%;" /></p>

<h2 id="introduction-to-complexity-theory">Introduction to Complexity Theory</h2>

<p>Now, our question comes:</p>

<blockquote>
  <p><strong>How efficiently can we solve problems that we know are decidable?</strong></p>
</blockquote>

<p>In the context of complexity, we will <strong><em>only</em></strong> look at <strong>decidable problems</strong>, for computing their running time/complexity.</p>

<blockquote>
  <p><strong>Definition:</strong></p>

  <ul>
    <li>
      <p>Given a TM $M$, the <strong>running time/time complexity</strong> of $M$ is a <strong>function</strong>:
$$</p>

      <p>f: \N \to \N</p>

      <p>$$
where:</p>

      <ul>
        <li>$f(n)$ is the <strong>max number of steps</strong> taken by $M$ on <strong><em>any</em> input</strong> of length $n$.
          <ul>
            <li>e.g. $f(12)$ is the maximum number of steps that a decider $M$ can run on all input of length $12$</li>
          </ul>
        </li>
        <li>a step would be defined as a delta function</li>
      </ul>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Note:</strong></p>

  <ul>
    <li>Running time is a <strong>function on input length</strong></li>
    <li>It is to deal with <strong>worst-case</strong> for each input length</li>
  </ul>
</blockquote>

<p>However, this means we need to figure out the formal definition of a TM machine, which will take quite a lot of time.</p>

<ul>
  <li>so we need a way to still work with this <strong>even with high level definitions</strong>.</li>
</ul>

<blockquote>
  <p><strong>Definition:</strong></p>

  <ul>
    <li>
      <p>We define a <strong>set</strong> of language:
$$</p>

      <table>
        <tbody>
          <tr>
            <td>\text{TIME}(t(n)) = { L</td>
            <td>L \text{ is decidable by a TM that runs in time } O(t(n)) }</td>
          </tr>
        </tbody>
      </table>

      <p>$$</p>
      <ul>
        <li>note that:
          <ul>
            <li>e.g. $L \in \text{TIME}(n^3+n)$ if we can <strong>find <em>one</em> implementation</strong> of $M$ that has running time of $O(n^3)$.</li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Reminder:</strong></p>

  <ul>
    <li>
      <p>For functions $f,g: \N \to \R^+$, we say that:
$$</p>

      <p>f(n)=O(g(n))</p>

      <p>$$
if there exists a positive constant $c, n_0$ such that:</p>

      <ul>
        <li>
          <p>$\forall n \ge n_0$, $f(n) \le c \cdot g(n)$</p>
        </li>
        <li>
          <p>basically, $g(n)$ grows <strong><em>at least</em></strong> as fast as $f(n)$ <strong>for $n$ being large</strong></p>
        </li>
      </ul>
    </li>
  </ul>
</blockquote>

<p>As a result:</p>

<blockquote>
  <p><strong>From the definition of $\text{TIME}(t(n))$</strong>:</p>

  <ul>
    <li>
      <p>it follows that <strong>if $t(n)=O(t’(n))$</strong>, then:
$$</p>

      <p>\text{TIME}(t(n)) \subseteq \text{TIME}(t’(n))</p>

      <p>$$</p>
      <ul>
        <li>i.e. obviously, if a TM $M$ runs in $t(n)$, then it also runs in $O(t’(n))$</li>
      </ul>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Definition:</strong></p>

  <ul>
    <li>
      <p>The class <strong>poly-time computable languages</strong> is defined as:
$$</p>

      <p>P = \bigcup_{k=1}^\infty \text{TIME}(n^k)</p>

      <p>$$</p>
      <ul>
        <li>
          <p>note that this means:</p>

          <ul>
            <li>
              <p>e.g. a language $L \in P$ if $L$ runs in time $O(n^{100})$</p>
            </li>
            <li>
              <p>since $log(n) \subseteq O(n)$, we would also have $\text{TIME}(log(n)) \in P$</p>
            </li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</blockquote>

<p>Now, this means:</p>

<ul>
  <li>if we have different models of computation/implementation of TM, we might have different running time.
    <ul>
      <li>therefore $\text{TIME}(t(n))$ is <strong>sensitive to our implementation</strong>.</li>
      <li>e.g. RAM (random access TM, being able to jump with its head) being transformed into an equivalent single tape, standard TM requires cubic overhead.</li>
    </ul>
  </li>
  <li>However, the notion of <strong>poly-time</strong> is <strong>robust</strong> to the <strong><em>above example</em></strong>, and many other variations.
    <ul>
      <li>therefore, we will <strong>identify $P$ (poly-time computable)</strong> with “<strong>efficient computation</strong>”.
        <ul>
          <li>this might sound to be too broad, because if you have $n^{100}$, it does not sound very efficient</li>
          <li>however, it has the broad use that <strong>if</strong> $L \notin P$, then it is <strong>definitely not efficient</strong></li>
          <li>even if we have $n^{100}$ to a high power, we then at least know it is solvable, and over time, could come up with a better solution.</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<blockquote>
  <p><strong>In fact, one important property of $P$ would be:</strong></p>

  <ul>
    <li>$P$ is <strong>invariant</strong> for all models of computation that are <strong>polynomially equivalent</strong> to the <strong>deterministic single-tape Turing machine</strong>
      <ul>
        <li>this covers, if not all, most decidable TMs we have, due to the strong Church-Turing Thesis.</li>
      </ul>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Strong Church-Turing Thesis:</strong></p>

  <ul>
    <li>Every <strong>reasonable/natural</strong> notion of algorithm (model of computation) can be simulated by a TM <strong>with polynomial overhead</strong>.
      <ul>
        <li>i.e. <strong>all</strong> reasonable deterministic computational models are <strong>polynomially equivalent</strong>.
          <ul>
            <li>That is, any one of them can simulate another with only a polynomial increase in running time</li>
          </ul>
        </li>
        <li>this is more <strong>controversial</strong> than the original Church-Turing thesis</li>
        <li>the original Church-Turing thesis was that: every reasonable model of algorithm can be modelled by a TM machine.
          <ul>
            <li>this is quite widely accepted</li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p>Therefore:</p>

  <ul>
    <li>
      <p>An algorithm is poly-time if it’s <strong>poly-time in terms of its input length</strong>:
$$</p>

      <p>f(n) \in P</p>

      <p>$$
however:</p>

      <ul>
        <li>this means that the <strong>representation</strong> of an input matters:
          <ul>
            <li>in turns out that the following representation only adds a polynomial overhead:
              <ul>
                <li>binary</li>
                <li>hex</li>
                <li>decimal</li>
                <li>…</li>
              </ul>
            </li>
            <li><strong><em>except</em></strong> for <strong>unary</strong> representation</li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Fact:</strong></p>

  <ul>
    <li>
      <p>If you have an <strong>algorithm</strong> that takes an integer as input, and it runs <strong>poly-time of length of input</strong>.</p>
    </li>
    <li>
      <p>This means that if input is a number $N$, then if you want to run poly-time in terms of $N$ as well, we <strong>need to only take up to $log(N)$ bits to represent it.</strong></p>

      <ul>
        <li>
          <p>proof sketch:</p>

          <p>we know:
$$</p>

          <p>O(n^k), \text{where $k$ is some constant}</p>

\[to represent a number in base $k$, and $k \neq 1$, we have\]

          <p>N = k^n</p>

          <p>$$</p>
        </li>
      </ul>

      <p>where:</p>

      <ul>
        <li>$k$ is the base. (e.g. base 2 for binary)</li>
        <li>therefore, if $n=log(N)$, we have:
$$</li>
      </ul>

      <p>f(N)=O(({log_k(N)}^k))=O(N^k)</p>
    </li>
  </ul>

\[however, if we use unary: so $n=N$, (unary) then:\]

  <p>f(N)=O(N^k)</p>

  <p>$$</p>

  <ul>
    <li>still works? <mark>TODO</mark></li>
  </ul>
</blockquote>

<hr />

<p><strong><em>For example:</em></strong></p>

<ul>
  <li>
    <p><strong>Question</strong></p>

    <p>For a grade-school algorithm for checking if a given input is <strong>prime</strong>, is it a <strong>poly-time algorithm</strong>?</p>

    <ul>
      <li>assuming that a <strong>number $a$ divides another $b$</strong> can be done in <strong>poly-time</strong>, which is <strong>true</strong>.</li>
      <li>assuming the input format is <strong>not unary</strong></li>
    </ul>
  </li>
  <li>
    <p><strong>Solution</strong></p>

    <p>A simple algorithm would be:</p>

    <p><img src="\lectures\images\typora-user-images\image-20201203232703586.png" alt="image-20201203232703586" style="zoom: 67%;" /></p>

    <p>where:</p>

    <ul>
      <li>first, prove that the above is <strong>implementable</strong> (each step is <strong>computable</strong>), which is in this case</li>
    </ul>

    <p>Running time in $\vert x\vert$:</p>

    <blockquote>
      <ul>
        <li>
          <p>Each Iteration of loop is poly-time in $\vert x\vert$ (since division is polytime)</p>
        </li>
        <li>
          <p>the number of iterations is $\sqrt{x}$</p>

          <ul>
            <li>
              <p>since $x = 2^{\vert x\vert }$ in binary</p>
            </li>
            <li>
              <p>or $x=k^{\vert x\vert }=2^{log_k(2)\cdot \vert x\vert }=2^{O(\vert x\vert )}$, for $k$ being the base except for unary</p>
            </li>
            <li>
              <p>hence:
\(\sqrt{x}=2^{O(x)/2}=2^{O(x)}\)
Therefore, the runtime for this algorithm is in fact <strong>exponential</strong>:
\(\text{TIME}=2^{O(|x|)}\cdot O(|x|^k) \notin P\)</p>
            </li>
          </ul>
        </li>
      </ul>
    </blockquote>
  </li>
</ul>

<hr />

<p>However, for <strong>this</strong> problem of $\text{PRIME}$, it turns out that there is <strong>actually a poly-time algorithm</strong>, which is very sophisticated so not shown here.</p>

<ul>
  <li>so in fact, $\text{PRIME} \in P$ even if the above construction doesn’t work to be in $P$.</li>
</ul>

<h3 id="examples-of-poly-computable">Examples of Poly-Computable</h3>

<p>Basically, from now on we are:</p>

<ul>
  <li>only talking about <strong>decidable</strong> <strong><em>languages</em></strong>
    <ul>
      <li>i.e. by default, our algorithm will be boolean outputs</li>
      <li>however, in the end it does not matter, as long as it halts</li>
    </ul>
  </li>
  <li>algorithms are <strong>efficient</strong> if they run within <strong>poly-time</strong></li>
</ul>

<h3 id="p-vs-np">P vs NP</h3>

<ul>
  <li><strong>P</strong>: intuitively, language that can be <strong>decided</strong> in polytime</li>
  <li><strong>NP</strong>: intuitively, language that can be <strong>verified</strong> in polytime</li>
</ul>

<blockquote>
  <p><strong>Verifier Definition</strong></p>

  <ul>
    <li>
      <p>A <strong>verifier</strong> for a language $A$, is a TM (algorithm) $V$, s.t. $V$ gets input $(x,c)$ and outputs accept/reject, where:
$$</p>

      <table>
        <tbody>
          <tr>
            <td>A={ x</td>
            <td>\text{$V(x,c)$ accepts for some $c$} }</td>
          </tr>
        </tbody>
      </table>

\[- i.e. $V$ is a verifier for $A$, if $A$ consists of all strings $x$ where there **exists some $c$ (certificate/"solution")**, such that $V(x,c)$ accepts.

  - so\]

      <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>\begin{cases}
x \in A \Rarr \exists c, &amp; V(x,c)\,accepts\\
x \notin A \Rarr \forall c, &amp; V(x,c)\,rejects
\end{cases}
  
  
  
  
  
  
$$
</code></pre></div>      </div>
    </li>
  </ul>

</blockquote>

<blockquote>
  <p><strong>Polytime Verifier</strong></p>

  <ul>
    <li>A polytime verifier for a language $A$ is a verifier $V$, such that $V$ runs in time $O(\vert x\vert ^k)$, i.e. polytime in length</li>
  </ul>
</blockquote>

<p>Therefore:</p>

<blockquote>
  <p><strong>Polytime Verifiable</strong></p>

  <ul>
    <li>A language $L$ is polytime verifiable if $\exists$ a polytime verifier $V$ for $L$.</li>
  </ul>
</blockquote>

<p>Hence the formal definition of P and NP are:</p>

<blockquote>
  <p><strong>Formal Definition of P and NP</strong>
$$</p>

  <table>
    <tbody>
      <tr>
        <td>NP = { L</td>
        <td>\text{$L$ is polytime verifiable in length of input} }</td>
      </tr>
    </tbody>
  </table>

\[\]

  <table>
    <tbody>
      <tr>
        <td>P = { L</td>
        <td>\text{$L$ is polytime computable in length of input} }</td>
      </tr>
    </tbody>
  </table>

  <p>$$</p>
</blockquote>

<hr />

<p><strong><em>For example:</em></strong></p>

<ul>
  <li>
    <p>Consider the language:
$$</p>

    <table>
      <tbody>
        <tr>
          <td>Composite={ \lang x\rang</td>
          <td>\text{$x$ is not prime} }</td>
        </tr>
      </tbody>
    </table>

    <p>$$
where:</p>

    <ul>
      <li>I claim that this language is <strong>NP</strong></li>
    </ul>
  </li>
  <li>
    <p>Proof:</p>

    <p>There is a simple polytime verification algorithm:</p>

    <ul>
      <li>recall that the verifier will get $\lang x, c\rang$</li>
      <li>where $c$ would be some “proof/solution”, which might or might not be correct
        <ul>
          <li>if verifier works:</li>
          <li>if $x$ is not prime then there will be <strong>some “solution”</strong> $c$ that works</li>
          <li>if $x$ is prime, then all “solutions” $c$ will not work</li>
        </ul>
      </li>
    </ul>

    <p><img src="\lectures\images\typora-user-images\image-20201203235454337.png" alt="image-20201203235454337" style="zoom:50%;" /></p>

    <p>Now, we need to <strong>show 2 things</strong>:</p>

    <ul>
      <li>
        <p>$V$ runs in time $poly(\vert x\vert )$</p>

        <ul>
          <li>every step is in polytime</li>
        </ul>
      </li>
      <li>
        <p>and prove that such a construction works</p>

        <p><img src="\lectures\images\typora-user-images\image-20201204000156006.png" alt="image-20201204000156006" style="zoom:50%;" /></p>
      </li>
    </ul>
  </li>
</ul>

<hr />

<hr />

<p><strong><em>For example:</em></strong></p>

<ul>
  <li>
    <p><strong>Question</strong></p>

    <p>Is the algorithm $PRIME$ also NP?</p>
  </li>
  <li>
    <p><strong>Solution</strong></p>

    <p>It turns out yes, because we know that $PRIME$ can be <strong><em>solved</em> in polytime</strong>, so we just need to <strong>use that solution wired in</strong>:</p>

    <p><img src="\lectures\images\typora-user-images\image-20201204000614156.png" alt="image-20201204000614156" style="zoom:50%;" /></p>

    <p>where:</p>

    <ul>
      <li>we basically ignored $c$, and <strong>solved it directly.</strong></li>
      <li>but this is like a “trick” $NP$ problem, because every solvable $P$ is also a $NP$ problem.</li>
    </ul>
  </li>
</ul>

<hr />

<blockquote>
  <p><strong>Claim:</strong>
$$</p>

  <p>P \subseteq NP</p>

  <p>$$</p>

  <ul>
    <li>where:
      <ul>
        <li>we basically see this in the example above</li>
      </ul>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Proof:</strong></p>

  <ul>
    <li>
      <p>If $L \in P$, there is a polytime decider for $L$</p>

      <p><img src="\lectures\images\typora-user-images\image-20201204000957008.png" alt="image-20201204000957008" style="zoom:50%;" /></p>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Claim:</strong></p>

  <ul>
    <li>
      <p>However, this is <strong>not known:</strong>
$$</p>

      <p>NP \subseteq P  \,\,??\,\,NP \nsubseteq P</p>

      <p>$$
where:</p>

      <ul>
        <li>if $NP \subseteq P$, then $P=NP$
          <ul>
            <li>one consequence would be that cryptography is dead</li>
          </ul>
        </li>
        <li>if $NP \nsubseteq P$, then $P \neq NP$</li>
      </ul>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Definition</strong></p>

  <ul>
    <li><strong>exponential time</strong> is defined as:</li>
  </ul>

\[\text{EXP} = \bigcup_{k=1}^\infty \text{TIME}(2^{k\cdot n})\]
</blockquote>

<blockquote>
  <p><strong>Claim:</strong>
$$</p>

  <p>P \subseteq NP \subseteq \text{EXP}</p>

  <p>$$</p>
</blockquote>

<blockquote>
  <p><strong>Proof:</strong></p>

  <ul>
    <li>
      <p>We have already seen that $P \subseteq NP$</p>
    </li>
    <li>
      <p>We then just need to show $NP \subseteq \text{EXP}$</p>

      <ul>
        <li>If $L \in NP$, then there exists a polytime verifier $V$ for $L$, <strong>such that $V(x,c)$ runs in time $O(\vert x\vert ^k)​</strong>$
          <ul>
            <li>note that, since $V(x,c)$ is polytime, is immediately made $\vert c\vert  \le O(\vert x\vert ^k)$. Because if it were, then simply reading the input $c$ would have exceeded the polytime, then this contradicts the verifier $V$</li>
          </ul>
        </li>
        <li>Let us fix a constant $a$, such that $V$ runs in $a\vert x\vert ^k$ time, for some constant $a,k$.</li>
        <li>Then, we just <strong>check all</strong> $c$ <strong>up to</strong> $\vert c\vert  \le a\vert x\vert ^k$</li>
      </ul>

      <p><img src="\lectures\images\typora-user-images\image-20201204012600475.png" alt="image-20201204012600475" style="zoom:50%;" /></p>

      <p>where:</p>

      <ul>
        <li>this would be <strong>loop</strong> for all numbers $c$ up to $2^{O(\vert c\vert )}=2^{a\cdot \vert x\vert ^k}= O(2^{\vert x\vert ^k})$ <strong>times</strong></li>
      </ul>

      <p>where, the <strong>runtime</strong> analysis would be:</p>

      <p><img src="\lectures\images\typora-user-images\image-20201204002619779.png" alt="image-20201204002619779" style="zoom:50%;" /></p>
    </li>
  </ul>
</blockquote>

<p><strong>Additionally:</strong></p>

<blockquote>
  <p><strong>Claim:</strong>
$$</p>

  <p>P \subsetneq \text{EXP}</p>

  <p>$$</p>

  <ul>
    <li>this is <strong>provable</strong>. However, we will not prove them</li>
  </ul>
</blockquote>

<p>Consequently, we now do not know where $NP$ fits:</p>

<ul>
  <li>
    <p>the following cases could <strong>all</strong> be <strong>possible</strong>
$$</p>

    <p>\begin{cases}
P = NP \subsetneq EXP<br />
P \subsetneq NP \subsetneq EXP<br />
P \subseteq NP = EXP<br />
…
\end{cases}</p>

    <p>$$</p>
  </li>
</ul>

<h1 id="week-14">Week 14</h1>

<h2 id="np-complete-class">NP Complete Class</h2>

<p><strong>Heuristics</strong>:</p>

<ul>
  <li>NP Complete Class are <strong>languages</strong> that has the property: if the language $L$ is in NP Complete, then we can use it to show that:
    <ul>
      <li><strong>if</strong> $L \in NP-Complete$, and that language can be solved in polynomial time $P$,  <strong>then</strong> $P = NP$</li>
    </ul>
  </li>
</ul>

<p>The <strong>NP Complete Class</strong> plays such a role:</p>

<p><img src="\lectures\images\typora-user-images\image-20201208221519005.png" alt="image-20201208221519005" style="zoom: 67%;" /></p>

<p>where:</p>

<ul>
  <li>$\text{NP-Complete}$ is of course in $NP$, and we have only two possible cases</li>
  <li>if we show that $L \in \text{NP-Complete}$ is <strong>also</strong> $L \in P$ (can be solved in polytime) then every other language in $NP$ would also be in $P$
    <ul>
      <li>intuition: those $L \in \text{NP-Complete}$ would be languages that are “hardest” in $NP$. If you can solve the hardest one, then you can use it to solve the easier ones/all in $NP$.</li>
    </ul>
  </li>
</ul>

<h3 id="using-reductions">Using Reductions</h3>

<blockquote>
  <p><strong>Definition</strong></p>

  <ul>
    <li>
      <p>A language <strong>$A$ is polytime reducible to $B$</strong>, ($A \le_P B$), if $\exist$ polytime computable function $f: \Sigma^<em>: \Sigma^</em>$, such that
$$</p>

      <p>x \in A \iff f(x) \in B</p>

      <p>$$
where again we are just <strong>mapping inputs</strong> from one into another:</p>

      <p><img src="\lectures\images\typora-user-images\image-20201211183456563.png" alt="image-20201211183456563" /></p>

      <ul>
        <li>i.e. this is basically the same as <strong>mapping reduction</strong></li>
      </ul>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Theorem</strong></p>

  <ul>
    <li>If $A \le_P B$ and $B \in P$, then $A \in P$.
      <ul>
        <li>i.e. then by definition, we can map $A$ to $B$, and since $B$ is easy (polytime solvable)</li>
      </ul>
    </li>
    <li>If $A \le_P B$, and $B \in NP$, then $A \in NP$</li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Proof</strong></p>

  <ul>
    <li>
      <p>For If $A \le_P B$ and $B \in P$, then $A \in P$.</p>
    </li>
    <li>
      <p>Suppose $A \le_P B$, then there is a polytime algorithm $F$ computing a function $f$ such that
$$</p>

      <p>x \in A \iff f(x) \in B</p>

      <p>$$
Suppose $B \in P$, then there is a polytime algorithm $M_B$ that decides $B$.</p>

      <p>I use the two elements to <strong>construct an algorithm that decides $A$</strong></p>

      <ul>
        <li>then the construction would be simply <strong>using $M_B$ and the function $f$</strong></li>
      </ul>

      <p><img src="\lectures\images\typora-user-images\image-20201208222514064.png" alt="image-20201208222514064" style="zoom: 50%;" /></p>

      <p>Now, we need to show that:</p>

      <ul>
        <li>the construction is <strong>in polynomial time</strong>
          <ul>
            <li>since every step above is polytime, and there is no loop</li>
          </ul>
        </li>
        <li>show that the construction <strong>decides</strong> $A$:
          <ul>
            <li><img src="\lectures\images\typora-user-images\image-20201208222654632.png" alt="image-20201208222654632" style="zoom:50%;" /></li>
          </ul>
        </li>
      </ul>

      <p>This completes the proof.</p>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Proof</strong></p>

  <ul>
    <li>
      <p>If $A \le_P B$, and $B \in NP$, then $A \in NP$</p>
    </li>
    <li>
      <p>This is simple, in fact similar to above</p>
    </li>
    <li>
      <p>Suppose $A \le_P B$, then I get a polytime decidable function $f$
$$</p>

      <p>w \in A \iff f(w) \in B</p>

      <p>$$</p>
    </li>
    <li>
      <p>Suppose $B \in NP$, then I get a polytime verifier $V_B(x,c)$ that verifies $B$.</p>
    </li>
    <li>
      <p>I construct a verifier for $A$:</p>

      <p>$V_A:$ On input $\lang w, c\rang$,</p>

      <ol>
        <li>Compute $f(w)$</li>
        <li>Run $V_B(f(w), c)$
          <ul>
            <li>output same</li>
          </ul>
        </li>
      </ol>
    </li>
    <li>
      <p>Now, I prove that this is polytime and this works.</p>

      <ul>
        <li>this is skipped</li>
      </ul>
    </li>
    <li>
      <p>Note:</p>

      <ul>
        <li>all that matters for a verifier is that, for an input  $w \in L$, there $\exists c$ (no matter what format) that works</li>
      </ul>
    </li>
  </ul>
</blockquote>

<p>What is the <strong>use</strong> of this:</p>

<ul>
  <li>This means that if <strong>a language $L$ is harder or equal than every other language $\in NP$</strong>, and we show that <strong>that language can be solved in polytime</strong>, then $P = NP$.</li>
</ul>

<blockquote>
  <p><strong>Definition</strong></p>

  <ul>
    <li>A language $L$ is $\text{NP-Hard}$ if $\forall A \in NP$, $A \le_P L$.
      <ul>
        <li>so that if we can <strong>solve $L$ in polytime</strong>, then <strong>all the $A$</strong> can be reduced to solve in polytime</li>
      </ul>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Definition of NP Complete</strong></p>

  <ul>
    <li>A language $L$ is $\text{NP-Complete}$ if:
      <ol>
        <li>$L \in NP$</li>
        <li>$L \in \text{NP-Hard}$</li>
      </ol>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Theorem:</strong></p>

  <ul>
    <li>If $A, B$ are $\text{NP-Complete}$, <strong>then $A \le_P B$ and $B \le_P A$</strong>
      <ul>
        <li>this <strong>follows</strong> from the <strong><em>definition of NP-Completeness</em></strong></li>
      </ul>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Proof</strong></p>

  <ul>
    <li>If $A,B$ are both NP-Complete, then
      <ul>
        <li>$A,B \in NP$</li>
        <li>$A,B$ both NP-Hard</li>
      </ul>
    </li>
    <li>I show first $A \le_P B$:
      <ul>
        <li>by definition of NP-Hard, since $A \in NP$ and $B$ is NP-Hard, then I can reduce $B$ to $A$</li>
      </ul>
    </li>
    <li>similarly, show $B \le_P A$:
      <ul>
        <li>by definition of NP-Hard, since $B \in NP$ and $A$ is NP-Hard, then I can reduce $A$ to $B$</li>
      </ul>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Theorem:</strong></p>

  <ul>
    <li>If $A \le_P B$, <strong>and $A$ is $\text{NP-Hard}$</strong>, then $B$ is $\text{NP-Hard}$
      <ul>
        <li>i.e. if $B$ is harder (at least as hard) as $A$, which is already $\text{NP-Hard}$, then $B$ is $\text{NP-Hard}$</li>
        <li><strong>this will be mostly used for proving NP-Complete problems</strong>
          <ul>
            <li>so that we first how $B \in NP$, then we use this for reduction</li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Proof</strong></p>

  <ul>
    <li>
      <p>Suppose \(A \le_P B\). Then I can have a polytime computable function $f$ such that:
$$</p>

      <p>x \in A \iff f(x) \in B</p>

      <p>$$</p>
    </li>
    <li>
      <p>Suppose $A$ is $\text{NP-Hard}$</p>
    </li>
    <li>
      <p>Now, to prove $B$ is $\text{NP-Hard}$:</p>

      <ul>
        <li>Let any <strong>arbitrary</strong> language $C \in NP$</li>
        <li><strong>need to show $C \le_P B$</strong></li>
      </ul>

      <p>Because $A$ is $\text{NP-Hard}$, then $C \le_P A$. This means that I get a polytime computable function $g$:
$$</p>

      <p>w \in C \iff g(w) \in A</p>

\[Now, since I know $C \le_P A$ and $A \le_P B$, I can show $C \le_P B$ by constructing the **mapping (using transitivity)**\]

      <p>w \in C \iff f(g(w)) \in B</p>

      <p>$$</p>
    </li>
    <li>
      <p>this completes the proof</p>
    </li>
  </ul>
</blockquote>

<p>This means that, to find another language is $\text{NP-Hard}$:</p>

<ul>
  <li>reduce from $Ham_{cycle}$ to that language $L$</li>
  <li>then $L$ is also $\text{NP-Hard}$</li>
</ul>

<blockquote>
  <p><strong>But what is the hardest was</strong></p>

  <ul>
    <li>how to prove the <strong>first language</strong> (e.g. $Ham_{cycle}$ here ) is $\text{NP-Hard}$</li>
  </ul>
</blockquote>

<p><strong>In general, to prove a language is $\text{NP-Complete}$</strong></p>

<ol>
  <li>Show that the language $L \in NP$, by <strong>showing a polytime verifier</strong></li>
  <li>Show that, for some $A \in \text{NP-Hard}$, I can <strong>reduce</strong> $A\le_P L$
    <ul>
      <li>i.e. $L$ is hard er (at least as hard as) the $\text{NP-Hard}$ problems</li>
    </ul>
  </li>
</ol>

<blockquote>
  <p><strong>Claim:</strong></p>

  <ul>
    <li>$Ham_{cycyle}$ is $\text{NP-Complete}$
      <ul>
        <li>proof skipped.</li>
      </ul>
    </li>
  </ul>
</blockquote>

<h3 id="closure-properties">Closure Properties</h3>

<blockquote>
  <p><strong>Theorem:</strong></p>

  <ul>
    <li>$P$ is closed under completement</li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Proof</strong>:</p>

  <ul>
    <li>If $L \in P$, then there is a polytime decider $M_L$ for $L$.</li>
    <li>I just <strong>flip</strong> the accept/reject of the decider to get a polytime decider for $\overline{L}$</li>
  </ul>
</blockquote>

<p>However,</p>

<ul>
  <li>we <strong>do not know</strong> whether $NP$ is closed under complement
    <ul>
      <li>i.e. <strong>don’t know</strong> whether $NP=Co-NP$</li>
      <li>e.g. come up with a <strong>verifier</strong> to tell whether a graph $G$ <strong>does not have</strong> a Hamiltonian cycle</li>
    </ul>
  </li>
</ul>

<h2 id="examples-of-np-complete">Examples of NP-Complete</h2>

<p><strong><em>For example:</em></strong></p>

<ul>
  <li>
    <p><strong>Question</strong></p>

    <p>Given an <strong>undirected</strong> graph $G$, tells whether $G$ has a Hamiltonian Cycle (a cycle that goes <strong>through each nodes exactly once</strong>):
$$</p>

    <table>
      <tbody>
        <tr>
          <td>Ham_{cycyle}={ \lang G\rang</td>
          <td>\text{$G$ is an undirected graph and $G$ has a Hamiltonian Cycle} }</td>
        </tr>
      </tbody>
    </table>

    <p>$$
this problem is NP</p>
  </li>
  <li>
    <p><strong>Proof</strong></p>

    <p>Consider the following algorithm $V$:</p>

    <p><img src="\lectures\images\typora-user-images\image-20201208215757106.png" alt="image-20201208215757106" style="zoom:50%;" /></p>

    <ul>
      <li>where it basically it needs $c$ to <strong>contain</strong> all <strong>vertices</strong>
        <ul>
          <li>assuming $c$ contains the <strong>“solution” as an ordered list of vertices</strong></li>
        </ul>
      </li>
    </ul>

    <p><img src="\lectures\images\typora-user-images\image-20201208215911171.png" alt="image-20201208215911171" style="zoom:50%;" /></p>

    <ul>
      <li>
        <p>where now, we just need to <strong>check if we can follow the sequence</strong> of vertices given the $E$ edge configuration</p>

        <p><img src="\lectures\images\typora-user-images\image-20201208220054525.png" alt="image-20201208220054525" style="zoom:50%;" /></p>
      </li>
    </ul>

    <p>Therefore, we have showed that this is a NP.</p>

    <p>(In fact, $Ham_{cycle}$ is <strong>NP-Complete</strong>)</p>
  </li>
</ul>

<blockquote>
  <p><strong>However</strong></p>

  <ul>
    <li>We <strong>do not</strong> know if $Ham_{cycyle} \in P$, but we <strong>do</strong> know that $Ham_{cycyle} \in EXP$</li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Proof Sketch for $Ham_{cycyle} \in EXP$</strong></p>

  <ul>
    <li>In short, we need to give an algorithm that solves it in $EXP$</li>
    <li>The idea is simple, <strong>try all permutations of $c$,</strong> which has $\vert V\vert !$ of it, which is exponential, and <strong>use</strong> the $V$ we had above</li>
  </ul>
</blockquote>

<hr />

<p><strong><em>Another Example</em></strong></p>

<ul>
  <li>
    <p><strong>Question</strong></p>

    <p>The sudoku problem
$$</p>

    <table>
      <tbody>
        <tr>
          <td>sudoku:{ P</td>
          <td>\text{$P$ is a $n^2 \times  n^2$ grid, partially filled with integers from $1$ to $n^2$, such that there exists a valid solution} }</td>
        </tr>
      </tbody>
    </table>

    <p>$$
is NP-Complete.</p>
  </li>
  <li>
    <p><strong>Solution</strong></p>

    <p>Skipped</p>
  </li>
</ul>

<hr />

<hr />

<p><strong><em>Another Example</em></strong></p>

<ul>
  <li>
    <p><strong>Question</strong></p>

    <p>The problem
$$</p>

    <table>
      <tbody>
        <tr>
          <td>\text{SUBSET-SUM}: { (x_1, x_2, …x_n, t)</td>
          <td>x_1, …,x_n,t \text{ are integers such that there exists non-empty $S \subseteq {1,2,…,n}$ such that $\sum_{i\in S} x_i = t$} }</td>
        </tr>
      </tbody>
    </table>

    <p>$$
where:</p>

    <ul>
      <li>since $S$ is a set, the <strong>index</strong> inside <strong>cannot</strong> be repeated.</li>
      <li>However, the <strong>numbers</strong> could be repeated, such that $x_2=x_5$, for example</li>
    </ul>

    <p>this problem is NP-Complete</p>
  </li>
  <li>
    <p><strong>Solution</strong></p>
  </li>
</ul>

<hr />

<hr />

<p><strong><em>Another Example</em></strong></p>

<ul>
  <li>
    <p><strong>Question</strong></p>

    <p>The problem
$$</p>

    <table>
      <tbody>
        <tr>
          <td>SAT={ \varphi</td>
          <td>\varphi \text{ is a satifiable Boolean formula} }</td>
        </tr>
      </tbody>
    </table>

    <p>$$
where:</p>

    <ul>
      <li>a boolean formula includes
        <ul>
          <li>variables $(x_1, x_2, …x_n)$</li>
          <li>operators $(\land, \lor, \neg)$</li>
        </ul>
      </li>
      <li>$\varphi$ is satisfiable if there <strong>exists</strong> a $T/F$ assignment to each variable, <strong>such that the output $\varphi$ will be</strong> $True$</li>
    </ul>

    <p>this problem is NP-Complete</p>
  </li>
</ul>

<hr />

<hr />

<p><strong><em>Another Example</em></strong></p>

<ul>
  <li>
    <p><strong>Question</strong></p>

    <p>The variation of $SAT$
$$</p>

    <table>
      <tbody>
        <tr>
          <td>\text{CNF-SAT}={ \varphi</td>
          <td>\varphi \text{ is a CNF of a Boolean formula and is a satifiable} }</td>
        </tr>
      </tbody>
    </table>

    <p>$$
where:</p>

    <ul>
      <li>a CNF (conjunctive normal form) has:
        <ul>
          <li>variables $(x_1, x_2, …x_n)$</li>
          <li>literals $(x_i, \overline{x_i})$</li>
          <li><strong>clauses</strong>: composed of literals $l_i$
            <ul>
              <li>takes the form $(l_1 \lor l_2 \lor l_3 …)$</li>
              <li>only $\lor$ (OR) are included</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>$\varphi$ is a CNF form is it is composed of clauses $C_i$
        <ul>
          <li>$\varphi = C_1 \land C_2 \land C_3 …$</li>
          <li>only $\land$ (AND) are included between clauses</li>
        </ul>
      </li>
      <li>for example:
        <ul>
          <li>$(x_1 \lor \overline{x_2}) \land (x_2 \lor \overline{x_3} \lor x_4)$ is a CNF</li>
        </ul>
      </li>
    </ul>

    <p>this problem is also NP-Complete</p>
  </li>
</ul>

<hr />

<hr />

<p><strong><em>Another Example</em></strong></p>

<ul>
  <li>
    <p><strong>Question:</strong></p>

    <p>The problem/variation of $SAT$:
$$</p>

    <table>
      <tbody>
        <tr>
          <td>3SAT = {  \varphi</td>
          <td>\varphi \text{ is a 3-CNF of a Boolean formula and is a satifiable}  }</td>
        </tr>
      </tbody>
    </table>

    <p>$$
where:</p>

    <ul>
      <li>$3CNF$ is basically the CNF of a boolean formula, except that:
        <ul>
          <li><strong>each</strong> clauses of $\varphi = C_1 \land C_2 …$ <strong>consists of exactly $3$ literals</strong></li>
        </ul>
      </li>
    </ul>

    <p>is also NP-Complete</p>
  </li>
</ul>

<hr />

<h3 id="examples-using-np-complete-reductions">Examples using NP-Complete Reductions</h3>

<blockquote>
  <p><strong>Theorem</strong></p>

  <ul>
    <li>$SAT$ is NP-Complete</li>
    <li>$SAT \le_P \text{CNF-SAT} \le_P \text{3SAT}$
      <ul>
        <li>as a result, all of them is NP-Hard</li>
        <li>in fact, proving them to be $\in NP$ is easy (easy to built a polytime verifier for them)
          <ul>
            <li>therefore, from the above, all of them can be proved to be NP-Complete</li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Proof</strong></p>

  <ul>
    <li>
      <p>$\text{CNF-SAT} \le_P \text{3SAT}$</p>
    </li>
    <li>
      <p>Remember, we are essentially doing a mapping reduction, so all we need to show is that</p>

      <ul>
        <li>given a $\varphi \in CNF$, I can <strong>convert/map it</strong> using a polytime computable $f$ to $\varphi’ \in$  <strong>$3SAT$</strong> form, such that
          <ul>
            <li>if $\varphi$ satisfiable $\iff$ $f(\varphi)=\varphi’$ satisfiable</li>
          </ul>
        </li>
      </ul>
    </li>
    <li>
      <p>Now, the function would be:</p>

      <p><img src="\lectures\images\typora-user-images\image-20201211145744218.png" alt="image-20201211145744218" style="zoom:50%;" /></p>

      <p><img src="\lectures\images\typora-user-images\image-20201211150104072.png" alt="image-20201211150104072" style="zoom:50%;" /></p>

      <p>Therefore, since this function is polytime computable, and it works, we have completed the proof.</p>
    </li>
  </ul>
</blockquote>

<h2 id="non-deterministic-tm-with-complexity">Non-Deterministic TM with Complexity</h2>

<blockquote>
  <p><strong>Definition</strong></p>

  <ul>
    <li>
      <p>A non-deterministic TM machine runs in time $t(n)$, if for <strong>every input $x$ of length $n$,</strong> all <strong>possible</strong> <strong>computations</strong> on $x$ take <strong>at most $t(n)$</strong> steps.</p>

      <ul>
        <li>i.e. the <strong>worst guess</strong> you can have takes $t(n)$ steps, so that the machine always <strong>halts in $O(n^k)$</strong></li>
      </ul>

      <p><img src="\lectures\images\typora-user-images\image-20201211180408444.png" alt="image-20201211180408444" /></p>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Definition</strong></p>

  <ul>
    <li>
      <p>A non-deterministic time:
$$</p>

      <table>
        <tbody>
          <tr>
            <td>\text{NTIME}(t(n))={ L</td>
            <td>\exists \text{ a NTM $N$ that decides $L$, and runs in time $O(t(n))$} }</td>
          </tr>
        </tbody>
      </table>

      <p>$$</p>
    </li>
  </ul>

</blockquote>

<blockquote>
  <p><strong>Theorem</strong>
$$</p>

  <p>NP=\bigcup_{k=1}^{\infty}\text{NTIME}(n^k)</p>

  <p>$$</p>

  <ul>
    <li>i.e. to show that a language is in $NP$, instead of giving a verifier, we could show by giving a <strong>non-deterministic TM</strong> that actually <strong>solves</strong> it, with <strong>longest path being the order of $O(n^k)$.</strong></li>
  </ul>
</blockquote>

<p>Note:</p>

<ul>
  <li>this only works for proving that a language is in $NP$.</li>
</ul>

<blockquote>
  <p><strong>Proof Sketch</strong></p>

  <ul>
    <li>
      <p>forward direction $NP\implies \bigcup_{k=1}^{\infty}\text{NTIME}(n^k)$</p>

      <ul>
        <li>
          <p>The idea is that if $L \in NP$, then I can construct a NTM that runs in polynomial time:</p>

          <ul>
            <li>
              <p>If $L \in NP$, then I get a verifier $V$ that verifiers $L$ in polynomial time</p>
            </li>
            <li>
              <p>Construct:</p>

              <p>N = “On input $w$ of length $n$:</p>
              <ol>
                <li><strong>Non-deterministically select string</strong> $c$ of length at most $O(n^k)$</li>
                <li><strong>Run</strong> $V$ on input $\lang w, c \rang$
                  <ul>
                    <li>this is in fact same as testing all possible $c$ one by one, then running $V$ for a deterministic TM</li>
                  </ul>
                </li>
                <li>If V accepts, accept ; otherwise, reject .”</li>
              </ol>
            </li>
          </ul>

          <p>where:</p>

          <ul>
            <li>basically you are just trying different $c$ simultaneously, <strong>on the premise that $\exist c$ that works</strong></li>
            <li>by <strong>definition</strong> of $\text{NTIME}(n^k)$, this <strong>works</strong> because the <strong>longest branch</strong> will have ran the same time as $V \in O(n^k)$
              <ul>
                <li>however, if we <strong>convert it to a deterministic TM</strong>, then the <strong>total run time</strong> would be $EXP$, which makes sense since $NP \subseteq EXP$</li>
              </ul>
            </li>
          </ul>
        </li>
      </ul>
    </li>
    <li>
      <p>backward direction $\bigcup_{k=1}^{\infty}\text{NTIME}(n^k) \implies NP$</p>

      <ul>
        <li>
          <p>Assume you have a NTM $N$ deciding $L$, then construct verifier $V$ as follows</p>

          <p>$V$ = “On input $\lang w, c \rang$, where $w$ and $c$ are strings:</p>
          <ol>
            <li>Simulate $N$ on input $w$, treating <strong>each</strong> symbol of $c$ as a <strong>description</strong>
 <strong>of the nondeterministic choice</strong> to make at each step (as we did for the proof of simulating multi-tape TM to single-tape TM).
              <ul>
                <li><strong>i.e. $c$ tells us which branch to take</strong></li>
              </ul>
            </li>
            <li>If this branch of $N$’s computation accepts, accept ; otherwise,
 reject .”</li>
          </ol>
        </li>
      </ul>
    </li>
  </ul>
</blockquote>

<h3 id="examples-of-np-using-ntm">Examples of NP using NTM</h3>

<p>Though building a verifier $V$ that proves $NP$ would usually be more easier, this construction of NTM is sometimes useful. The overall idea is:</p>

<ul>
  <li>the NTM $N$ will <strong>non-deterministically</strong> try all $c$</li>
  <li>if there is a certificate $c$ that works, then $\vert c\vert  \in O(n^k)$</li>
  <li>hence we are just <strong>testing all branches up to depth</strong> $O(n^k)$, which would be $\in \text{NTIME}(n^k)$</li>
</ul>

<hr />

<p><strong><em>For example</em></strong></p>

<ul>
  <li>
    <p><strong>Question</strong></p>

    <p>The problem $\text{SUBSET-SUM}$ is in NP, using a NTM.</p>
  </li>
  <li>
    <p><strong>Solution</strong></p>

    <p>$N$ = “On input $\lang S, t \rang$:</p>
    <ol>
      <li>Non-deterministically select a subset $c$ of the numbers in $S$.</li>
      <li>Test whether $c$ is a collection of numbers that sum to $t$.</li>
      <li>If the test passes, accept ; otherwise, reject .”</li>
    </ol>

    <p>In fact, the <strong>verifier would also be simple</strong>, and perhaps more intuitive</p>

    <p>$V$ = “On input$\lang \lang S, t \rang, c\rang$</p>
    <ol>
      <li>Test whether $c$ is a collection of numbers that sum to $t$.</li>
      <li>Test whether $S$ contains all the numbers in $c$.</li>
      <li>If both pass, accept ; otherwise, reject .”</li>
    </ol>
  </li>
</ul>

<hr />

<p>However, this NTM technique, when applied with depth, <strong>could be used for proving NP-Complete problems</strong> without reduction</p>

<h3 id="example-of-np-complete-using-ntm">Example of NP-Complete using NTM</h3>

<blockquote>
  <p><strong>Cook-Levin Theorem</strong></p>

  <ul>
    <li>$SAT$ is NP-Complete</li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Proof Sketch</strong></p>

  <ul>
    <li>This uses the non-deterministic TM</li>
    <li>And they proved that $\forall L \in NP$, $L \le_P SAT$
      <ul>
        <li>if $L \in NP$, then there is a NTM $N$ that decides $x \in L \iff$ $\exists$ an accepting computation/configuration of $N$ on $x$</li>
        <li>let $\varphi$ be the formula that is satisfiable $\iff$ $\exist$ an accepting sequence of configuration (an <strong>accepting</strong> branch in configuration tree)</li>
      </ul>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>More detailed Proof Sketch</strong></p>

  <ul>
    <li>Showing that $SAT$ is in $NP$ is easy, and we do so shortly. The hard part of the proof is showing that any language in $NP$ is polynomial time reducible to $SAT$.</li>
    <li>To do so, we <strong>construct a polynomial time reduction</strong> for each language $A$ in $NP$ to $SAT$. The reduction for $A$ takes a string $w$ and <strong>produces a Boolean formula $\varphi$</strong> that <strong>simulates the NP machine for $A$ on input $w$</strong>. If the machine accepts, $\varphi$ has a <strong>satisfying assignment that corresponds to the accepting computation</strong>. If the machine doesn’t accept, no assignment satisfies $\varphi$.
      <ul>
        <li><strong><em>Therefore, $w$ is in $A$ if and only if $\varphi$ is satisfiable.</em></strong></li>
      </ul>
    </li>
    <li>Actually constructing the reduction to work in this way is a conceptually
simple task, though we must cope with many details. A Boolean formula may
contain the Boolean operations AND, OR, and NOT, and these operations form
the basis for the circuitry used in electronic computers. Hence the fact that <strong>we</strong>
<strong>can design a Boolean formula to simulate a Turing machine isn’t surprising</strong>. The details are in the implementation of this idea.</li>
  </ul>
</blockquote>

<h1 id="tips">Tips</h1>

<p><strong>General Tips</strong>:</p>

<ul>
  <li>During proofs, the <strong>length</strong> of a string/word could be a useful parameter
    <ul>
      <li>e.g. assuming $w$ is a word accepted having the <strong>smallest length</strong> in $L$.</li>
    </ul>
  </li>
</ul>

<h2 id="tips-on-proving-regularity-with-dfanfa">Tips on Proving Regularity with DFA/NFA</h2>

<p>If you are given a regular language, and asked to prove that some modification of that language is also regular:</p>

<ol>
  <li>List out the <strong>constraints/rules</strong> you have to fulfill
    <ul>
      <li>e.g. at the second state, I should have had <em>stored the information</em>/string of $a\circ b$.</li>
    </ul>
  </li>
  <li>Try to <strong>sum them up in one line</strong></li>
  <li>Using the modification summarized above, <strong>draw</strong> the modified DFA/NFA
    <ul>
      <li>one thing that is usually a correct step is to make sure the <strong>original DFA/NFA is intact</strong>
        <ul>
          <li>this is to take care that they might be some <strong>potential loops/cycles</strong></li>
          <li><strong>more than one connection to a specific state</strong></li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Write out formally</li>
</ol>

<h2 id="tips-on-proving-if-and-only-if">Tips on Proving If and Only If</h2>

<p>If proving the claim, $\text{Claim 1} \iff \text{Claim/Condition 2}$</p>

<ol>
  <li>Show that, if I have $\text{Claim/Condition 2}$, then <strong>putting it into</strong> $\text{Claim 1}$, it is true.
    <ul>
      <li>this part usually is trivial, and sometimes can be <strong>proved by words/logics</strong></li>
    </ul>
  </li>
  <li>Conversely, if I have $\text{Claim 1}$, then it <strong>implies/derives to</strong> $\text{Claim 2}$.
    <ul>
      <li>this part usually needs the help of <strong>variables</strong>, such as a word $w$, and splitting it up into $w_1 \circ w_2$, and etc.</li>
    </ul>
  </li>
</ol>

<h2 id="tips-on-converting-regex-to-nfa">Tips on Converting Regex to NFA</h2>

<p>If given a regular expression, and need to convert to NFA:</p>

<ol>
  <li>For example, if the alphabet is ${a,b}$</li>
  <li>Start with drawing NFAs $L(a)$ and $L(b)$ for <strong>each symbol in the alphabet</strong> as the <strong>base case</strong></li>
  <li>Draw a NFA with regular expression <strong>only using one of</strong> $\circ, \cup,*$. Such as $(a \cup b)$</li>
  <li>Doing the above recursively
    <ul>
      <li>here, you could either choose to process it in one go, <strong>straight from left to right</strong></li>
      <li>or, you could <strong>split the expression into smaller ones</strong> such as $R_1 \circ R_2$, and then assemble them</li>
    </ul>
  </li>
</ol>

<h2 id="tips-on-writing-regular-expressions">Tips on Writing Regular Expressions</h2>

<p>If given a language in words, you need to write a regular expression for it:</p>

<ol>
  <li><strong>Break the conditions down to smaller conditions</strong>.
    <ul>
      <li>for example, no two consecutive symbols are the same $=$ alternating + all 1s + all 0s</li>
    </ul>
  </li>
  <li>Write out the smaller conditions in diagram/figure out the <strong>expression</strong></li>
  <li><strong>Assemble</strong> the expressions together</li>
</ol>

<h2 id="tips-on-proving-regular-expressions">Tips on Proving Regular Expressions</h2>

<p>If given a regular <strong>expression $\alpha$</strong>, and we need to prove some <strong>properties</strong> of it:</p>

<ol>
  <li>Usually, using Induction will work</li>
  <li>Show that it is true for $\vert \alpha\vert =1$
    <ul>
      <li>$L(a)$</li>
      <li>$L(\epsilon)$</li>
      <li>$L(\empty)$</li>
    </ul>
  </li>
  <li>Assume that the property is true for $\vert \alpha\vert  = k$</li>
  <li>Show that, for $\vert \alpha\vert =k+1$, we can have:
    <ul>
      <li>$\alpha = (\alpha_1 \circ \alpha_2)$, $L(\alpha) = L(\alpha_1)\circ L(\alpha_2)$ still has that property
        <ul>
          <li>notice <strong>that $\vert \alpha_1\vert ,\vert \alpha_2\vert$ are now smaller than $k$</strong>, so assumption from (3) can be used</li>
        </ul>
      </li>
      <li>$\alpha = (\alpha_1 \cup \alpha_2)$, $L(\alpha) = L(\alpha_1)\cup L(\alpha_2)$ still has that property</li>
      <li>$\alpha = (\alpha_1)^<em>$, $L(\alpha) = L(\alpha_1)^</em>$ still has that property
        <ul>
          <li>for this, you can split the word into $w = w_1 \circ w_2 \circ…\circ w_n$, where each $w_i \in L(\alpha_1)$, and $n$ can grow up to infinity by definition</li>
        </ul>
      </li>
    </ul>
  </li>
</ol>

<p>If given a regular <strong>expression</strong> $\alpha$, and we need to prove that <strong>it is the same as</strong> $\beta$</p>

<ol>
  <li><strong>Unless</strong> you can <strong>manipulate the expression directly</strong>, you will need to do the following</li>
  <li>Prove that $\alpha \subseteq \beta$ (<strong>strings generated</strong> from $\alpha$ is a subset of strings generated from $\beta$)
    <ul>
      <li>sometimes, one of the two will be straightforward and you can say by words</li>
    </ul>
  </li>
  <li>Prove that $\beta \subseteq \alpha$
    <ul>
      <li>usually, along the way you will need to <strong><em>create</em></strong> several other $\subseteq$ sets for reaching the conclusion</li>
    </ul>
  </li>
</ol>

<h2 id="tips-on-constructing-context-free-grammar">Tips on Constructing Context-Free Grammar</h2>

<p>If given a language that has some requirement on the length of the string or its sub-substrings, we can think about the following:</p>

<ol>
  <li>Split the question into its essential, <strong>smaller parts</strong>
    <ul>
      <li>e.g. if we needed the string $0^i1^{i+j}0^j$, then we could use the idea:
        <ul>
          <li>first part is to get $0^i1^i$, then get $1^j0^j$,</li>
          <li>so you have $\begin{cases}S \to UT\ U\to 0U1 \vert  \epsilon \ T\to 1T0 \vert  \epsilon\end{cases}$</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Since each variable is context-free, <strong>what can a variable know</strong>?
    <ul>
      <li>e.g. $w$ starts with a $1$ and has a middle element $0$
        <ul>
          <li>this implies the $1$ and $0$ needs to be hardcoded, <strong><em>since the variable has no idea</em></strong> if it is at the front or in the middle of the string</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>What must happen when you <strong>add exactly one more</strong> variable? (Think about it in terms of symmetry, what part does not matter (could be any symbol), and what part matters)
    <ul>
      <li>e.g.  $w$ starts with a $1$ and has a middle element $0$ and is of odd length
        <ul>
          <li>when one more variable is added, it must exactly add one symbol to the front and back:</li>
          <li>$\begin{cases}S \to 1T0 \vert  1T1\ T\to UTU \vert  0 \ U \to 1\vert 0\end{cases}$</li>
          <li>where $T\to UTU\vert 0$ populates the string to have $UUU…0UUU…$</li>
        </ul>
      </li>
    </ul>
  </li>
</ol>

<h2 id="tips-on-constructing-tm-reduction">Tips on Constructing TM Reduction</h2>

<p>If we need to <strong>reduce a language</strong> $B$ to a language $A$:</p>

<ul>
  <li>if reducible, get a decider for $B$.</li>
  <li>know the input of $A$ and $B$</li>
  <li>show towards contradiction that you can construct decider for $A$, which is not decidable
    <ul>
      <li>i.e. <strong>having a decider for $B$ means too much power</strong></li>
    </ul>
  </li>
</ul>

<p><strong>Remember,</strong> the construction will look like:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>R: on &lt;input of A&gt;:
	1. Construct &lt;input of B&gt;:
		- ...
	2. Run decider for B on &lt;input of B&gt;:
		- if B accept, ...
		- if B reject, ...

</code></pre></div></div>

<ol>
  <li>First think about the <strong>input</strong> of <code class="language-plaintext highlighter-rouge">&lt;input of A&gt;​</code>
    <ul>
      <li>e.g. reduce $E_{TM}$ to $A_{TM}$, (construct a decider for $A_{TM}$) then input is for $A_{TM}$</li>
    </ul>
  </li>
  <li>Think about <strong>input</strong> of <code class="language-plaintext highlighter-rouge">&lt;input of B&gt;</code>, which is the <strong>assumed decider</strong></li>
  <li>Think about what we need to <strong>map:</strong>
    <ul>
      <li>e.g. if we need to reduce $E_{TM}$ to $A_{TM}$
        <ul>
          <li><strong>map</strong> $\lang M, w\rang \in A_{TM}$ to
            <ul>
              <li><strong>construct</strong> $\lang M’\rang \in E_{TM}$ or</li>
              <li>construct $\lang M’\rang \notin E_{TM}$ (easier in this case)</li>
            </ul>
          </li>
          <li><strong>map</strong> $\lang M, w\rang \notin A_{TM}$ to
            <ul>
              <li><strong>construct</strong> <strong>$\lang M’\rang \notin E_{TM}$</strong> or</li>
              <li>construct $\lang M’\rang \in E_{TM}$ (easier in this case)</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ol>

<h2 id="tips-on-diagonalization-for-undecidability">Tips on Diagonalization for Undecidability</h2>

<p>It will only work nicely on some problems, and the idea is just three steps:</p>

<ol>
  <li>Assume that a decider exists. Then we can get a <strong>table</strong>.</li>
  <li>Formalize the input/output in to a table</li>
  <li>Flip the diagonal, and verify this is <strong>not in the table</strong></li>
  <li><strong>prove that</strong> what you produced is constructable/exists</li>
</ol>

<p><strong><em>For example:</em></strong></p>

<ul>
  <li>
    <p><strong>assume</strong> that such an oracle exists, then we have a decider and a table</p>
  </li>
  <li>
    <p>To prove $A_{TM}$ is not recognizable, we first constructed a table</p>

    <ul>
      <li>where instead of putting $w$, we used $\lang M\rang$</li>
    </ul>
  </li>
  <li>
    <p>Then we flipped it, and verify it is not in the table</p>

    <p><img src="\lectures\images\typora-user-images\image-20201113001720011.png" alt="image-20201113001720011" style="zoom: 50%;" /></p>
  </li>
  <li>
    <p>We show that the <strong>new program exists</strong>, by constructing it</p>

    <p><img src="\lectures\images\typora-user-images\image-20201113011316669.png" alt="image-20201113011316669" style="zoom:50%;" /></p>
  </li>
</ul>

<h2 id="tips-on-constructing-mapping-reduction">Tips on Constructing Mapping Reduction</h2>

<p>Think in the reverse. If we have $L_1 \le_M L_2$:</p>

<ol>
  <li>We need to construct a $f$ that:
    <ul>
      <li>$input \in L_1$ $\implies$ $output \in L_2$</li>
      <li>$input \notin L_1$ $\implies$ $output \notin L_2$</li>
    </ul>
  </li>
</ol>

<h1 id="appendix">Appendix</h1>

<h2 id="list-of-known-tm-languages">List of Known TM Languages</h2>

<p>So far, we have encountered the following:</p>

<p><strong>TM recognizable</strong></p>

<ul>
  <li>$A_{TM} = { \langle M,w\rangle \vert  \text{$M$is a TM, and$M$accepts$w$} }$</li>
  <li>$NE_{TM}$</li>
</ul>

<p><strong>TM decidable</strong></p>

<ul>
  <li>$A_{DFA}$</li>
  <li>$A_{NFA}$</li>
  <li>$E_{DFA}$</li>
  <li>$EQ_{DFA}$</li>
  <li>$A_{CFG}$</li>
  <li>$A_{regular}$</li>
</ul>

<p><strong>TM not recognizable</strong></p>

<ul>
  <li>$\overline{A_{TM}}$</li>
  <li>$E_{TM}$</li>
  <li>$ALL_{TM}$</li>
  <li>$\overline{ALL_{TM}}$</li>
</ul>

<p><strong>TM not decidable</strong></p>

<ul>
  <li>$A_{TM}$</li>
  <li>$Halt_{TM} = {\lang M,w\rang\vert  M \text{ halts on input$w$} }$</li>
  <li>$E_{TM}$</li>
  <li>$EQ_{TM}$</li>
  <li>$REG_{TM}$</li>
  <li>$EQ_{CFG}$</li>
  <li>Language that depends on the <strong>non-trivial property</strong> of a $TM$ (recognizable) machine</li>
</ul>

  </div><a class="u-url" href="/lectures/2020@columbia/COMS3261_CS_Theory.html/" hidden></a>
  <script src="/lectures/assets/js/my_navigation.js"></script>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/lectures/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Lecture Notes</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Lecture Notes</li><li><a class="u-email" href="mailto:jasonyux17@gmail.com">jasonyux17@gmail.com</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/jasonyux"><svg class="svg-icon"><use xlink:href="/lectures/assets/minima-social-icons.svg#github"></use></svg> <span class="username">jasonyux</span></a></li><li><a href="https://www.linkedin.com/in/xiao-yu2437"><svg class="svg-icon"><use xlink:href="/lectures/assets/minima-social-icons.svg#linkedin"></use></svg> <span class="username">xiao-yu2437</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>An inexhaustive collection of markdown/latex(PDF) notes that I took since college. </p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
