<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>CSOR4231 Analysis of Algorithms | Lecture Notes</title>
<meta name="generator" content="Jekyll v4.3.1" />
<meta property="og:title" content="CSOR4231 Analysis of Algorithms" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="*Picture credits from the Algorithms Illuminated book" />
<meta property="og:description" content="*Picture credits from the Algorithms Illuminated book" />
<link rel="canonical" href="/lectures/2023@columbia/CSOR4231_Analysis_of_Algorithms.html/" />
<meta property="og:url" content="/lectures/2023@columbia/CSOR4231_Analysis_of_Algorithms.html/" />
<meta property="og:site_name" content="Lecture Notes" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-01-20T00:00:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="CSOR4231 Analysis of Algorithms" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2024-01-20T00:00:00+00:00","datePublished":"2024-01-20T00:00:00+00:00","description":"*Picture credits from the Algorithms Illuminated book","headline":"CSOR4231 Analysis of Algorithms","mainEntityOfPage":{"@type":"WebPage","@id":"/lectures/2023@columbia/CSOR4231_Analysis_of_Algorithms.html/"},"url":"/lectures/2023@columbia/CSOR4231_Analysis_of_Algorithms.html/"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/lectures/assets/main.css"><link type="application/atom+xml" rel="alternate" href="/lectures/feed.xml" title="Lecture Notes" /></head>
<body><header class="site-header">

	<div class="wrapper"><a class="site-title" rel="author" href="/lectures/">Lecture Notes</a>

		<nav class="site-nav">
			<input type="checkbox" id="nav-trigger" class="nav-trigger" />
			<label for="nav-trigger">
			<span class="menu-icon">
				<svg viewBox="0 0 18 15" width="18px" height="15px">
				<path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
				</svg>
			</span>
			</label>
			<div class="trigger">
				<a class="page-link" href="/">home</a>
				<!-- <a class="page-link" href="/projects">Projects</a> -->
				<a class="page-link" href="/research">research</a>
				<span class="page-link" href="#">[education]</span>
				<!-- <a class="page-link" href="/learning">Blog</a> -->
			</div>
		</nav>
	</div>
  </header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">
  <head>
  <script>
    MathJax = {
      // 
      loader: {
        load: ['[tex]/ams', '[tex]/textmacros', '[tex]/boldsymbol']
      },
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']],
        packages: {'[+]': ['ams', 'textmacros', 'boldsymbol']}
      }
    };
  </script>
  <script id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
  </script>
  </head>
  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">CSOR4231 Analysis of Algorithms</h1>
    <p class="post-meta"><time class="dt-published" datetime="2024-01-20T00:00:00+00:00" itemprop="datePublished">
        Jan 20, 2024
      </time></p>
  </header>

  <div class="section-nav" id="toc-all">
    <button type="button" id="toc-close" class="toc_collapsible hidden" title="collapse">
      <span><strong>Table of Contents</strong></span>
    </button>
    <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" mirror-in-rtl="true" fill="#000000" style="width: 18px;" id="toc-reopen" class="toc_collapsible">
      <g id="SVGRepo_bgCarrier" stroke-width="0"></g><g id="SVGRepo_tracerCarrier" stroke-linecap="round" stroke-linejoin="round"></g><g id="SVGRepo_iconCarrier"> <circle fill="#494c4e" cx="2" cy="2" r="2"></circle> <circle fill="#494c4e" cx="2" cy="8" r="2"></circle> <circle fill="#494c4e" cx="2" cy="20" r="2"></circle> <circle fill="#494c4e" cx="2" cy="14" r="2"></circle> <path fill="#494c4e" d="M23.002 3H7.998C7.448 3 7 2.55 7 2.002v-.004c0-.55.45-.998.998-.998H23c.55 0 1 .45 1 .998V2c0 .55-.45 1-.998 1zM23.002 9H7.998C7.448 9 7 8.55 7 8.002v-.004c0-.55.45-.998.998-.998H23c.55 0 1 .45 1 .998V8c0 .55-.45 1-.998 1zM23.002 15H7.998c-.55 0-.998-.45-.998-.998V14c0-.55.45-1 .998-1H23c.55 0 1 .45 1 .998V14c0 .55-.45 1-.998 1zM23.002 21H7.998c-.55 0-.998-.45-.998-.998V20c0-.55.45-1 .998-1H23c.55 0 1 .45 1 .998V20c0 .55-.45 1-.998 1z"></path> </g>
    </svg>
    <ul id="toc" class="section-nav">
<li class="toc-entry toc-h1"><a href="#analysis-of-algorithms">Analysis of Algorithms</a>
<ul>
<li class="toc-entry toc-h2"><a href="#bellman-ford-algorithm-a-differential-version-that-converges-to-the-shortest-path">Bellman-Ford algorithm: a differential version that converges to the shortest path.</a></li>
<li class="toc-entry toc-h2"><a href="#compute-abcd-and-subtract-ac-and-bd-from-it-to-get-adbc">compute $(a+b)(c+d)$ and subtract $ac$ and $bd$ from it to get $ad+bc$</a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#introduction">Introduction</a>
<ul>
<li class="toc-entry toc-h2"><a href="#mergesort-the-algorithm">MergeSort: The Algorithm</a></li>
<li class="toc-entry toc-h2"><a href="#mergesort-the-analysis">MergeSort: The Analysis</a></li>
<li class="toc-entry toc-h2"><a href="#strassens-matrix-multiplication-algorithm">Strassen’s Matrix Multiplication Algorithm</a>
<ul>
<li class="toc-entry toc-h3"><a href="#details-of-strassens-algorithm">Details of Strassen’s Algorithm</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#asymptotic-notation">Asymptotic Notation</a>
<ul>
<li class="toc-entry toc-h2"><a href="#big-o-notation">Big-O Notation</a></li>
<li class="toc-entry toc-h2"><a href="#big-omega-and-big-theta-notation">Big-Omega and Big-Theta Notation</a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#the-master-method">The Master Method</a>
<ul>
<li class="toc-entry toc-h2"><a href="#formal-statement">Formal Statement</a></li>
<li class="toc-entry toc-h2"><a href="#proof-of-master-method">Proof of Master Method</a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#linear-time-selection">Linear-Time Selection</a>
<ul>
<li class="toc-entry toc-h2"><a href="#median-of-medians">Median of Medians</a></li>
<li class="toc-entry toc-h2"><a href="#runtime-of-select-algorithm">Runtime of Select Algorithm</a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#quicksort">QuickSort</a>
<ul>
<li class="toc-entry toc-h2"><a href="#in-place-partition">In-Place Partition</a></li>
<li class="toc-entry toc-h2"><a href="#randomized-quicksort">Randomized QuickSort</a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#graphs-the-basics">Graphs: The Basics</a>
<ul>
<li class="toc-entry toc-h2"><a href="#breadth-first-search-and-depth-first-search">Breadth-First Search and Depth-First Search</a></li>
<li class="toc-entry toc-h2"><a href="#generic-search">Generic Search</a></li>
<li class="toc-entry toc-h2"><a href="#computing-connected-components">Computing connected Components</a></li>
<li class="toc-entry toc-h2"><a href="#topological-sort">Topological Sort</a></li>
<li class="toc-entry toc-h2"><a href="#computing-strongly-connected-components">Computing Strongly Connected Components</a>
<ul>
<li class="toc-entry toc-h3"><a href="#correctness-and-runtime-of-kosarajus-algorithm">Correctness and Runtime of Kosaraju’s Algorithm</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#dijkstras-shortest-path-algorithm">Dijkstra’s Shortest Path Algorithm</a>
<ul>
<li class="toc-entry toc-h2"><a href="#dijkstras-algorithm">Dijkstra’s Algorithm</a></li>
<li class="toc-entry toc-h2"><a href="#correctness-of-dijkstras-algorithm">Correctness of Dijkstra’s Algorithm</a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#hash-tables-and-bloom-filters">Hash Tables and Bloom Filters</a>
<ul>
<li class="toc-entry toc-h2"><a href="#implementation-separate-chaining">Implementation: Separate Chaining</a></li>
<li class="toc-entry toc-h2"><a href="#implementation-open-addressing">Implementation: Open Addressing</a></li>
<li class="toc-entry toc-h2"><a href="#bloom-filters">Bloom Filters</a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#introduction-to-greedy-algorithms">Introduction to Greedy Algorithms</a>
<ul>
<li class="toc-entry toc-h2"><a href="#scheduling-problem">Scheduling Problem</a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#huffman-codes">Huffman Codes</a>
<ul>
<li class="toc-entry toc-h2"><a href="#prefix-free-codes">Prefix-Free Codes</a></li>
<li class="toc-entry toc-h2"><a href="#huffmans-greedy-algorithm">Huffman’s Greedy Algorithm</a></li>
<li class="toc-entry toc-h2"><a href="#correctness-of-huffmans-algorithm">Correctness of Huffman’s Algorithm</a></li>
<li class="toc-entry toc-h2"><a href="#inductive-step-we-need-to-show-that-pk-is-true-since-each-step-of-the-algorithm-we-are-merging-two-least-frequent-symbols-the-root-of-the-subtree-we-want-to-show-claim-1-and-claim-2-to-hold-in-order-to-prove-that-the-output-tree-at-this-stage-is-optimal">inductive step: we need to show that $P(k)$ is true. Since each step of the algorithm we are merging two least frequent “symbols” (the root of the subtree), we want to show claim 1 and claim 2 to hold in order to prove that the output tree at this stage is optimal.</a></li>
<li class="toc-entry toc-h2"><a href="#running-time-of-huffman-algorithm">Running Time of Huffman Algorithm</a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#minimum-spanning-trees">Minimum Spanning Trees</a>
<ul>
<li class="toc-entry toc-h2"><a href="#prims-algorithm">Prim’s Algorithm</a>
<ul>
<li class="toc-entry toc-h3"><a href="#correctness-of-prims-algorithm">Correctness of Prim’s Algorithm</a></li>
<li class="toc-entry toc-h3"><a href="#running-time-of-prims-algorithm">Running Time of Prim’s Algorithm</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#kruskals-algorithm">Kruskal’s Algorithm</a>
<ul>
<li class="toc-entry toc-h3"><a href="#correctness-of-kruskals-algorithm">Correctness of Kruskal’s Algorithm</a></li>
<li class="toc-entry toc-h3"><a href="#speeding-up-kruskal-with-union-find">Speeding up Kruskal with Union-Find</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#clustering">Clustering</a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#introduction-to-dynamic-programming">Introduction to Dynamic Programming</a>
<ul>
<li class="toc-entry toc-h2"><a href="#weighted-independent-set">Weighted Independent Set</a></li>
<li class="toc-entry toc-h2"><a href="#linear-time-algorithm-for-wis-in-path-graph">Linear-Time Algorithm for WIS in Path Graph</a></li>
<li class="toc-entry toc-h2"><a href="#reconstruction-algorithm-mis">Reconstruction Algorithm (MIS)</a></li>
<li class="toc-entry toc-h2"><a href="#principles-of-dynamic-programming">Principles of Dynamic Programming</a></li>
<li class="toc-entry toc-h2"><a href="#the-knapsack-problem">The Knapsack Problem</a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#advanced-dynamic-programming">Advanced Dynamic Programming</a>
<ul>
<li class="toc-entry toc-h2"><a href="#sequence-alignment">Sequence Alignment</a></li>
<li class="toc-entry toc-h2"><a href="#optimal-binary-search-trees">Optimal Binary Search Trees</a>
<ul>
<li class="toc-entry toc-h3"><a href="#average-search-time">Average Search Time</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#shortest-path-revisited">Shortest Path Revisited</a>
<ul>
<li class="toc-entry toc-h2"><a href="#shortest-path-with-negative-edge-length">Shortest Path with Negative Edge Length</a></li>
<li class="toc-entry toc-h2"><a href="#bellman-ford-algorithm">Bellman-Ford Algorithm</a></li>
<li class="toc-entry toc-h2"><a href="#floyd-warshall-algorithm">Floyd-Warshall Algorithm</a>
<ul>
<li class="toc-entry toc-h3"><a href="#detecting-negative-cycles">Detecting Negative Cycles</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#max-flows-and-min-cuts">Max Flows and Min Cuts</a>
<ul>
<li class="toc-entry toc-h2"><a href="#minimum-cut-problem">Minimum Cut Problem</a></li>
<li class="toc-entry toc-h2"><a href="#minimum-cut-application-image-segmentation">Minimum Cut Application: Image Segmentation</a></li>
<li class="toc-entry toc-h2"><a href="#maximum-flow-algorithm">Maximum Flow Algorithm</a>
<ul>
<li class="toc-entry toc-h3"><a href="#naive-greedy-maximum-flow-algorithm">Naive Greedy Maximum Flow Algorithm</a></li>
<li class="toc-entry toc-h3"><a href="#residual-graph-and-the-ford-fulkerson-algorithm">Residual Graph and the Ford-Fulkerson Algorithm</a></li>
<li class="toc-entry toc-h3"><a href="#correctness-of-ford-fulkerson-algorithm">Correctness of Ford-Fulkerson Algorithm</a></li>
<li class="toc-entry toc-h3"><a href="#reduction-to-min-cut">Reduction to Min Cut</a></li>
<li class="toc-entry toc-h3"><a href="#runtime-of-ford-fulkerson-algorithm">Runtime of Ford-Fulkerson Algorithm</a></li>
<li class="toc-entry toc-h3"><a href="#reduction-to-bipartite-matching">Reduction to Bipartite Matching</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#additional-proporties-of-flow-in-graphs">Additional Proporties of Flow in Graphs</a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#linear-programming">Linear Programming</a>
<ul>
<li class="toc-entry toc-h2"><a href="#ingredients-of-a-linear-program">Ingredients of a Linear Program</a></li>
<li class="toc-entry toc-h2"><a href="#example-applications-of-linear-programming">Example Applications of Linear Programming</a>
<ul>
<li class="toc-entry toc-h3"><a href="#linear-programming-for-maximum-flow">Linear Programming for Maximum Flow</a></li>
<li class="toc-entry toc-h3"><a href="#linear-programming-for-minimum-cost-flow">Linear Programming for Minimum-Cost Flow</a></li>
<li class="toc-entry toc-h3"><a href="#linear-programming-for-regression">Linear Programming for Regression</a></li>
<li class="toc-entry toc-h3"><a href="#linear-programming-for-linear-classifier">Linear Programming for Linear Classifier</a></li>
</ul>
</li>
</ul>
</li>
</ul>
  </div>

  <div class="post-content e-content" itemprop="articleBody">
    <p>*Picture credits from the Algorithms Illuminated book</p>

<h1 id="analysis-of-algorithms">Analysis of Algorithms</h1>

<p>Logistics: Mostly see Canvas, but just note that:</p>

<ul>
  <li>10 Psets, no late days, but 2 can be dropped. Each pset worth 10 points.</li>
  <li>3 non-cumulative exam,  each worth 60 points. Tentative dates Oct 3, Oct 31, Dec 7.
    <ul>
      <li>exams will have about 50% content verbatim from HW</li>
    </ul>
  </li>
  <li>textbook: the split version of Algorithms Illuminated will have the same content as the Algorithms Illuminated Omnibus version, except that problem numbering might be different</li>
  <li>skim the readings before/after class, as they are the content you are responsible for</li>
</ul>

<hr />

<p>Example demo algorithmic questions:</p>

<p><u>*For example*: Routing in Internet.</u> Let nodes/vertices be hosts, and edges be the physical/wireless connections. Let the connections be bidirectional. <strong>How do you figure out the shortest path (least number of hops) between two given hosts?</strong></p>

<ul>
  <li>
    <p>Dikstra algorithm: given a source host (e.g. node 0), we can find the shortest path to all other hosts. The key insight shortest path is composed of shortest path, <strong>assuming all edges are positive</strong>. This means that if you have a given shortest path from $v$ to $u$, and nodes $w,x,y,z$ are only connected to $u$, then any shortest path from $v$ to $w,x,y,z$ must go through $u$.</p>

    <p>The algorithm iteratively grows a “tree” of visited nodes. At each iteration, the node that has the smallest cost (e.g. node 1) will be marked as done. THen we add all the neighbors <em>of that marked node</em> (because of the insight above) to the tree of visited nodes, and update the cost of the neighbors.</p>

    <p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230905205050.png" style="zoom:100%;" /></p>

    <p>however, the issue is that it needs to remember information about the entire internet during computation (i.e. keep an adjacency matrix/is visited of all nodes), which is not scalable.</p>
  </li>
  <li>
    <h2 id="bellman-ford-algorithm-a-differential-version-that-converges-to-the-shortest-path">Bellman-Ford algorithm: a <strong>differential</strong> version that converges to the shortest path.</h2>
  </li>
</ul>

<p><u>*For example*: Sequence alignment.</u> Consider two strings composed of characters ${ A,C,G,T }$:</p>

\[AGGGCT, AGGCA\]

<p>How similar (smallest edit distance, or lowest NW score) are the two strings?</p>

<ul>
  <li>Brute force: try all possible alignments, and pick the one with the lowest score. Insanely expensive.</li>
  <li>Dynamic programming!</li>
</ul>

<hr />

<p><u>*For example:* Multiplying two numbers.</u> Given two $n$ digit number (e.g. $x=1234$, $y=5678$), find a way to find out their product.</p>

<ul>
  <li>
    <p>Grade school approach: multiply each digit by each, get partial product, and sum.</p>

    <p>Cost is $O(n^2)$ as for each digit need to do $n$ multiplication, and there are $n$ digits</p>
  </li>
  <li>
    <p>Recursive v1: We can break down multiplying numbers into <strong>multiplying parts of it</strong> and add back (<mark>divide and conquer</mark>). For instance, let $x=10^{n/2}a + b$ and $y=10^{n/2}c + d$ (e.g. $a=12, b=34$ for $x=1234$). Then realize that:</p>

\[\begin{align*}
  x\cdot y 
  &amp;= (10^{n/2}a + b) (10^{n/2}c + d) \\
  &amp;= 10^n ac + 10^{n/2} (ad + bc) + bd \\
\end{align*}\]

    <p>and then, for <strong>each of the 4 multiplication operation</strong>, we can further recurse into smaller components until we are at one digit.</p>

    <p>Is this necessarily faster than grade school? We will analyze this in the course.</p>
  </li>
  <li>
    <p>Recursive v2 (<strong>Karatsuba</strong> Algorithm): An improved version than above where we only do 3 multiplications instead of 4. Notice that we can rewrite:</p>

\[(a+b)(c+d) = ac + ad + bc + bd = ac + bd + (ad + bc)\]

    <p>therefore, to equivalently compute the 4 multiplications in v1, we can do:</p>
    <ol>
      <li>compute $ac$</li>
      <li>compute $bd$</li>
      <li>
        <h2 id="compute-abcd-and-subtract-ac-and-bd-from-it-to-get-adbc">compute $(a+b)(c+d)$ and subtract $ac$ and $bd$ from it to get $ad+bc$</h2>
      </li>
    </ol>
  </li>
</ul>

<h1 id="introduction">Introduction</h1>

<p>The basic idea is to break your problem into smaller subproblems, solve the subproblems (often recursively), and finally combine the solutions to the subproblems into one for the original problem.</p>

<h2 id="mergesort-the-algorithm">MergeSort: The Algorithm</h2>

<p><code class="language-plaintext highlighter-rouge">MergeSort</code> is a classical sorting algorithm using the divide and conquer paradigm. Recall that to sort an array, we could have done:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">SelectionSort</code>: scan the array, find the smallest element, put it in the first position, and repeat.</li>
  <li><code class="language-plaintext highlighter-rouge">InsertionSort</code>: keep two arrays, sorted and unsorted. Scan the unsorted array and place the smallest element there into the correct position of the sorted array.</li>
  <li><code class="language-plaintext highlighter-rouge">BubbleSort</code>: swap adjacent elements to make sure the smallest is in the first position, then repeat.</li>
</ul>

<p>the above three simple algorithms have a running time of $O(n^2)$, which is not great. We can do better with <code class="language-plaintext highlighter-rouge">MergeSort</code>. High level idea:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230907104943.png" style="zoom:70%;" /></p>

<p>where:</p>
<ul>
  <li>given two <strong>sorted</strong> subparts, we can combine them <strong>into a sorted array</strong> by <code class="language-plaintext highlighter-rouge">merging</code> them (use a pointer at each of the two subpart, and just move the smallest element of the two to the output array). You will see after the <a href="#the-master-method">Master Method</a> that the key to $O(n \log n)$ is that <mark>this merge only takes $O(n)$!</mark>.</li>
  <li>from the above you see the <strong>recursive</strong> nature: the base case of just one element is <strong>already sorted</strong>! So we can use this base case AND the above merging operation to sort the entire array.</li>
</ul>

<p>Specifically, the pseduocode is:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># input: array A of n distinct numbers
# output: return a sorted array from smallest to largest
</span><span class="k">def</span> <span class="nf">merge_sort</span><span class="p">(</span><span class="n">A</span><span class="p">):</span>
	<span class="c1"># base case
</span>	<span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">A</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
		<span class="k">return</span> <span class="n">A</span>
	<span class="n">c</span> <span class="o">=</span> <span class="n">merge_sort</span><span class="p">(</span><span class="n">A</span><span class="p">[:</span><span class="n">n</span><span class="o">//</span><span class="mi">2</span><span class="p">])</span>  <span class="c1"># recursively sort the first half of A
</span>	<span class="n">d</span> <span class="o">=</span> <span class="n">merge_sort</span><span class="p">(</span><span class="n">A</span><span class="p">[</span><span class="n">n</span><span class="o">//</span><span class="mi">2</span><span class="p">:])</span>  <span class="c1"># recursively sort the second half of A
</span>	<span class="k">return</span> <span class="n">merge</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span>
</code></pre></div></div>
<p>so basically all the work is to <code class="language-plaintext highlighter-rouge">merge</code> the two sorted subarrays into one sorted array. The pseudocode for <code class="language-plaintext highlighter-rouge">merge</code> is:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">merge</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">d</span><span class="p">):</span>
  <span class="n">i</span> <span class="o">=</span> <span class="mi">1</span>
  <span class="n">j</span> <span class="o">=</span> <span class="mi">1</span>
  <span class="n">e</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">d</span><span class="p">)):</span>
    <span class="c1"># there is a bit more code to deal with if one of the two arrays is exhausted
</span>    <span class="c1"># if the first unused element from c is smaller, then add it to e
</span>    <span class="k">if</span> <span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">d</span><span class="p">[</span><span class="n">j</span><span class="p">]:</span>
      <span class="n">e</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
      <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="c1"># otherwise, add the first unused element from d to e
</span>    <span class="k">else</span><span class="p">:</span>
      <span class="n">e</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>
      <span class="n">j</span> <span class="o">+=</span> <span class="mi">1</span>
  <span class="k">return</span> <span class="n">e</span>
</code></pre></div></div>

<p>So what is its runtime? How fast is this compared to $O(n^{2})$?</p>

<h2 id="mergesort-the-analysis">MergeSort: The Analysis</h2>

<p>On a high level, we can imagine the runtime as “the total number of lines of code/operation we need to execute to run the implementation”. How do we approach this? In general, we should <strong>first visualize what the algorithm does</strong>.</p>

<p>For recursive algorithms such as <code class="language-plaintext highlighter-rouge">MergeSort</code>, we can visualize it as a <strong>recursion tree</strong>:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230907220532.png" style="zoom:100%;" /></p>

<p>so basically, at each node THE REAL COST is <code class="language-plaintext highlighter-rouge">merge(C,D)</code>, assuming your code implementation can slice arrays in halves using $O(1)$ time. This means that the total runtime is:</p>

\[\sum_{n \in \text{all nodes}} \text{Cost of merge(C,D) at node $n$ }\]

<p>For a recursive algorithm, generally notice that <em>each level will receive similar input</em> (e.g. sizes). Therefore, we can instead consider:</p>

\[\sum_{j \in \text{all levels}} \text{(\# of nodes at level $j$)} \times \text{(Cost of merge(C,D) at level $j$)}\]

<p>Hence we get, for an input of length $n$ (assuming its a power of $2$)</p>
<ul>
  <li>in total there are $\log_{2} n + 1$ levels</li>
  <li>at each level, there are $2^{j}$ nodes (note that you can imagine growing a tree from top to bottom as an exponential operation, while collapsing it from bottom to top as a logarithmic operation)</li>
  <li>the input size at each node would therefore be $n/2^{j}$</li>
  <li>the cost of <code class="language-plaintext highlighter-rouge">merge</code> at a node (using the pseudocode above it is about $4m+2$, where we have $4$ operations during the loop and 2 initialization operations). For simplicity let it be $6m$.</li>
</ul>

<p>The total cost <strong>at each level</strong> is therefore:</p>

\[2^{j} \cdot 6 \left( \frac{n}{2^{j}} \right) = 6n\]

<p>and finally the <strong>total runtime cost</strong> is:</p>

\[\sum_{j \in \text{all levels}} 6n = \left( \log_{2} n + 1 \right) \cdot 6n = 6n \log_{2} n + 6n  = O(n \log n)\]

<blockquote>
  <p>Important notes:</p>
  <ul>
    <li>here we considered the <strong>worst case scenario</strong>. This would be appropriate for general purpose algorithms as we won’t know what the input is.
      <ul>
        <li>What about “average-case analysis”?	For example, in the sorting problem, we could assume that all input arrays are equally likely and then study the average running time of different sorting algorithms. A second alternative is to look only at the performance of an algorithm on a small collection of “benchmark instances” that are thought to be representative of “typical” or “real-world” inputs.</li>
      </ul>
    </li>
    <li>we are sloppy for constant factors/coefficients. This is because:
      <ul>
        <li>in real life these constants will be <em>heavily implementation dependent</em></li>
        <li>will see how the Big O notation will not care about these constants</li>
      </ul>
    </li>
    <li>related to above, we will <mark>focus on how runtime scales with input size $n$</mark>. Especially when $n$ become large.
      <ul>
        <li>yes, there are cases when a runtime of $0.5n^{2}$ is faster than $6n \log n$, for example when $n=2$. But smart algorithms doesn’t really matter if $n$ is small!</li>
        <li>the <mark>holy grail is a linear-time algorithm</mark> (seeing each input ~once). For some problems we will not find a linear time algorithm, and for some (e.g. binary search) we can by “cheating” (we are already given an sorted array)</li>
      </ul>
    </li>
  </ul>
</blockquote>

<h2 id="strassens-matrix-multiplication-algorithm">Strassen’s Matrix Multiplication Algorithm</h2>

<p>This section applies the divide-and-conquer algorithm design paradigm to the problem of multiplying matrices, culminating in Strassen’s amazing <strong>subcubic-time</strong> matrix multiplication algorithm.</p>

<p>Recall that matrix multiplication considers</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230914212838.png" style="zoom:100%;" /></p>

<p>Therefore the very basic algorithm would be:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">matrix_mut</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">):</span>
  <span class="c1"># X is n x n, Y is n x n
</span>  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
      <span class="n">Z</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
      <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">Z</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">+=</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">Y</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="n">j</span><span class="p">]</span>
  <span class="k">return</span> <span class="n">Z</span>
</code></pre></div></div>
<p>which is obviously $\Theta(n^{3})$</p>

<p>Since the input size is $O(n^{2})$, the best we can hope for would be $O(n^{2})$ runtime. So can we do better? Emboldened by the divide and conquer integer multiplication algorithm, we can try to divide the matrix into smaller submatrices and then recursively compute the product of these submatrices.</p>

<p>Consider breaking the matrix down to:
<img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230914214311.png" style="zoom:100%;" /></p>

<p>then we can write the product as:
<img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230914214322.png" style="zoom:100%;" /></p>

<p>where adding two matrices is just element-wise addition with cost $O(l^{2})$ for $l \times l$ matrices. Therefore, analogous to the integer multiplication algorithm, we can write the matrix multiplication algorithm 
<img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230914214431.png" style="zoom:80%;" /></p>

<p>which has basically eight recursive calls. The problem is that this is still $\Theta(n^{3})$!</p>

<p>The key insight from the <strong>Karatsuba algorithm</strong> was that we can <em>save one multiplication</em> by using some tricks, and <strong>that can help us get sub-cubic time!</strong></p>

<p>A high level description looks like:
<img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230914214653.png" style="zoom:80%;" /></p>

<h3 id="details-of-strassens-algorithm">Details of Strassen’s Algorithm</h3>

<p>The key detail is how to save the extra multiplication. The idea is to use the following 7 auxiliary matrices:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230914214913.png" style="zoom:80%;" /></p>

<p>which involves $O(n^{2})$ time doing additional matrix additions, but <em>just with these seven</em> we can compute the matrix product as:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230914215001.png" style="zoom:80%;" /></p>

<p>which works due to some crazy cancellation, for example in the upper left:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230914215042.png" style="zoom:80%;" /></p>

<p>the rest you can check yourself, but with it down to 7 recursive calls, we can compute the runtime (using the <a href="#The_Master_Method">The Master Method</a>): $O(n^{2.807})$!</p>

<h1 id="asymptotic-notation">Asymptotic Notation</h1>

<p>The high level idea of why to use Big O:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230907222732.png" style="zoom:80%;" /></p>

<p>where saving <em>one recursive call is a bigh win</em>, because that will get saved over and over again as the recursion goes deeper.</p>

<h2 id="big-o-notation">Big-O Notation</h2>

<p>Let $T(n)$ denote the worst-case running time of an algorithm we care about, where $n={1,2,3, …}$ being the size of the input. What does it mean to say something runs in $O(f(n))$ for some function $f(n)$?</p>

<blockquote>
  <p><strong>Big-O Notation</strong>: $T(n) = O(f(n))$ if and only if there exist positive constant $c$ and $n_0$ such that:</p>

\[T(n) \leq c \cdot f(n),\quad \text{ for all } n \geq n_0\]

  <p>i.e. eventually when input gets large enough, $T(n)$ is bounded by $c \cdot f(n)$. So all you need to show/prove is that you can <em>construct a $c$ and $n_0$</em> such that it holds.</p>
</blockquote>

<p>Pictorially, we can imagine:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230907223339.png" style="zoom:70%;" /></p>

<hr />
<p><em>For Example:</em> a degree-$k$ polynomials are $O(n^{k})$. Suppose:</p>

\[T(n) = a_{k} n^{k} + a_{k-1} n^{k-1} + ... + a_{1} n + a_{0}\]

<p>for $k \ge 0$ and $a_i$’s are real numbers. We can show that $T(n) = O(n^{k})$:</p>

\[\begin{align*}
	T(n)
	&amp;= a_{k} n^{k} + a_{k-1} n^{k-1} + ... + a_{1} n + a_{0} \\
	&amp;\le \left|a_k\right| n^{k} + \left|a_{k-1}\right| n^{k-1} + ... + \left|a_{1}\right| n + \left|a_{0}\right|\\
	&amp;\le \left|a_k\right| n^{k} + \left|a_{k-1}\right| n^{k} + ... + \left|a_{1}\right| n^k + \left|a_{0}\right| n^k\\
	&amp;= \left(\left|a_k\right| + \left|a_{k-1}\right| + ... + \left|a_{1}\right| + \left|a_{0}\right|\right) n^k\\
	&amp;\equiv c \cdot n^k

\end{align*}\]

<p>holds for all $n$, so $n_{0} = 1$ and $c = \left\vert a_k\right\vert  + \left\vert a_{k-1}\right\vert  + … + \left\vert a_{1}\right\vert  + \left\vert a_{0}\right\vert$.</p>

<hr />

<p><em>For Example:</em> a degree-$k$ polynomial is not $O(n^{k-1})$. Suppose for simplicity $T(n) = n^{k}$. Then <mark>proof by contradition</mark> that this means:</p>

\[n^{k} \le c \cdot n^{k-1}, \quad \text{ for all } n \ge n_0\]

<p>this means:</p>

\[n \le c, \quad \text{ for all } n \ge n_0\]

<p>which is a contradiction as $n$ can be arbitrarily large.</p>

<h2 id="big-omega-and-big-theta-notation">Big-Omega and Big-Theta Notation</h2>

<p>On a high level, if big-O is analogous to “less than or equal to ($\le$),” then big-omega and big-theta are analogous to “greater than or equal to ($\ge$),” and “equal to (=).”</p>

<blockquote>
  <p><strong>Big-Omega Notation</strong>: $T(n) = \Omega(f(n))$ if and only if there exist positive constant $c$ and $n_0$ such that:</p>

\[T(n) \geq c \cdot f(n),\quad \text{ for all } n \geq n_0\]

  <p>i.e. eventually when input gets large enough, $T(n)$ is <mark>bounded below</mark> by $c \cdot f(n)$.</p>
</blockquote>

<p>Pictorially, bounding from below means:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230907224630.png" style="zoom:70%;" /></p>

<p>and we would call $T(n) = \Omega(f(n))$.</p>

<blockquote>
  <p><strong>Big-Theta Notation</strong>: $T(n) = \Theta(f(n))$ if and only if there exist positive constant $c_1, c_2$ and $n_0$ such that:</p>

\[c_1 \cdot f(n) \leq T(n) \leq c_2 \cdot f(n),\quad \text{ for all } n \geq n_0\]

  <p>i.e. eventually when input gets large enough, $T(n)$ is <mark>sandwiched</mark> by $c_1 \cdot f(n)$ and $c_2 \cdot f(n)$. Notice that this is analogous to say that both $T(n) = \Theta(f(n))$ and $T(n) = O(f(n))$.</p>
</blockquote>

<p><em>For example</em>, if $T(n) = \frac{1}{2} n^{2} + 3n$, then $T(n) = \Theta(n^{2})$.</p>

<blockquote>
  <p><strong>Little-O Notation</strong>: $T(n) = o(f(n))$ if and only if <mark>for every positive constant $c&gt;0$</mark> there exists a constant $n_0$ such that:</p>

\[T(n) \le c \cdot f(n),\quad \text{ for all } n \geq n_0\]

  <p>i.e. eventually when input gets large enough, $T(n)$ is <mark>bounded above</mark> by $c \cdot f(n)$ for any $c$ you pick (note that you can pick $n_0$ based on $c$). Also note that this is much stronger than the Big O notation.</p>
</blockquote>

<p>Intuitively, this is like saying we want:</p>

\[\lim\limits_{n \to \infty} \frac{f(n)}{T(n)} = 0\]

<p>that $f(n)$ grows strictly faster than $T(n)$ (i.e. pick $c$ to be infinitesimally small in the above definition). Also note that the intutive way of converting between Big O and Little O is NOT just switching $\le$ to $&lt;$, as that would actually not change anything (see HW1 Problem 2.7)</p>

<p><em>For example</em>, $n^{k-1} = o(n^{k})$ is true for any $k \ge 1$.</p>

<h1 id="the-master-method">The Master Method</h1>

<p>This “master method” applies to analyzing most of the <em>divide-and-conquer algorithms</em> you’ll ever see, as their runtime typically follows a pattern of the form:</p>

\[T(n) = \underbrace{a \cdot T\left(\frac{n}{b}\right)}_{\text{word done by recursive calls}} + \underbrace{O(n^{d})}_{\text{clean up}}\]

<p>where $a$ would be the number of recursive calls you make, $b$ would be by how much you shrink the input size, and $O(n^{d})$ would be the time it takes to combine/clean up any of results of the recursive calls (e.g. the  cost for <code class="language-plaintext highlighter-rouge">merge</code> in <code class="language-plaintext highlighter-rouge">merge_sort</code>).</p>

<hr />

<p><em>For Example</em>, recall the multiplication problem. Grade-school algorithm would give us $O(n^{2})$. However,</p>
<ul>
  <li>
    <p>the recursive algorithm v1 (calculate $10^{n}ac + 10^{n / 2}(ad + bc) + bd$) would then give us:</p>

\[T(n) \le 4T(n / 2) + O(n)\]

    <p>where $4$ comes from doing 4 more multiplications to calculate $ac, ad, bc, bd$, and $n / 2$ because we are chopping each original interger into half $x = 10^{n / 2}a + b$ and $y = 10^{n / 2}c + d$.</p>
  </li>
  <li>
    <p>the recursive algorithm v2 (<strong>Karatsuba Algorithm</strong>) saves the computation of $ad + bc$ by computing only $(a+b)(c+d)$ and then minus $(ac + bd)$ which would be already computed. Given that addition is done in linear time:</p>

\[T(n) \le 3T(n / 2) + O(n)\]

    <p>where now you only have to do 3 more multiplications to calculate $ac, bd, (a+b)(c+d)$, with extra work in addition but that is already in $O(n)$ term.</p>
  </li>
</ul>

<p>and that for all the above cases, the base case is $T(1) = O(1)$.</p>

<hr />

<h2 id="formal-statement">Formal Statement</h2>

<p>We’ll discuss a version of the master method that handles what we’ll call <strong>“standard recurrences”</strong>, which have three free parameters and the following form:</p>

<blockquote>
  <p><strong>Standard Recurrence Format</strong>. Let $T(n) = \mathrm{constant}$ for some small enough $n$ (i.e. base case). Then for large values of $n$, we have the runtime being:</p>

\[T(n) \le a \cdot T\left(\frac{n}{b}\right) + O(n^{d})\]

  <p>where:</p>
  <ul>
    <li>$a$ is the number of recursive calls you make</li>
    <li>$b$ is by how much you shrink the input size</li>
    <li>$O(n^{d})$ is the time it takes to combine/clean up any of results of the recursive calls</li>
  </ul>
</blockquote>

<p>Then, we have the master method:</p>

<blockquote>
  <p><strong>Master Method</strong>. If $T(n)$ is defined by a standard recurrence of the form above with $a \ge 1, b &gt; 1$ and $d \ge 0$, then:</p>

\[T(n) = \begin{cases}
O(n^{d} \log n) &amp; \text{if } a = b^{d} \\
O(n^{d}) &amp; \text{if } a &lt; b^{d} \\
O(n^{\log_{b} a}) &amp; \text{if } a &gt; b^{d}
\end{cases}\]

  <p>note that</p>
  <ul>
    <li>intuitively, the second one indicates that your algorithm is “clean up step heavy”, and the third one indicates that your algorithm is “recursive call heavy”</li>
    <li>the last case <em>specifically specified a base $b$</em>, whereas the first case did not. This is because any two logarithm base differ by a constant multiple. This will be harmless in the first case because we are multiplying by a constant factor of $d$, but not in the last case because we are raising to a power of $n$.</li>
  </ul>
</blockquote>

<p>First for a sanity check, the merge sort algorithm takes the form of:</p>

\[T(n) = 2T\left(\frac{n}{2}\right) + O(n)\]

<p>hence we have $a = 2, b = 2, d = 1$, and so $a = b^{d}$, which means that the first case applies and we have $T(n) = O(n^{d} \log n) = O(n \log n)$.</p>

<p>Then we first answer the questions of runtime for KaraSuba algorithm and the recursive algo v1:</p>

<ul>
  <li>multiplication algo v1 has $a=4, b=2, d=1$ so $a &gt; b^{d}$, hence we have $T(n) = O(n^{\log_{b} a}) = O(n^{2})$, actually just as good as the grade-school algorithm.</li>
  <li>KaraSuba algo has $a=3, b=2, d=1$ so $a &gt; b^{d}$, but we have $T(n) = O(n^{\log_{b} a}) = O(n^{\log_{2} 3}) \approx O(n^{1.59})$, which is better than the grade-school algorithm.</li>
  <li>Matrix Multiplication v1 (splitting into 8 smaller matrix multiplications) have still $O(n^{3})$. To see this, there are two ways: 1) consider $T(n^{2})=8 T(n^{2} / 4) + O(n^{2})$, substitute $n^{2}=u$ we get runtime is $O(u^{\log_{a} b})$; 2) just consider the input $n^{2}$ as a function of $n$, hence runtime is $T(n) = 8T(n / 2) + O(n)$, which gives $O(n^{\log_{a} b})$.</li>
</ul>

<h2 id="proof-of-master-method">Proof of Master Method</h2>

<p>Next we prove the master’s method.</p>

<p><em>Proof</em>: Suppose that $T(1) = \text{constant}$ and we have the standard recurrence for $n &gt; 1$:</p>

\[T(n) \le a \cdot T\left(\frac{n}{b}\right) + c \cdot n^d\]

<p>where we replaced $O(n^{d})$ with $c \cdot n^{d}$ for some constant $c$.</p>

<p>We can try to write a few terms out and see if we can find a pattern, but alternatively we can also <strong>draw a recursion tree</strong> and see if we can <strong>directly find a closed-form equation</strong>:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230912225937.png" style="zoom:100%;" /></p>

<p>Our goal is to find the runtime of this entire tree. So we consider:</p>

\[T(n) = \sum_{j \in \mathrm{level}} \sum \mathrm{cost}(\text{each node})\]

<p>from which we know that:</p>
<ul>
  <li>there are <strong>$a^{j}$ subproblems/nodes</strong> at depth $j$</li>
  <li>each node at depth $j$ needs to solve problem with <strong>input size $n / b^{j}$</strong></li>
</ul>

<p>again, assuming splitting the input to $b$ subproblems takes constant time, we have the <mark>cost at each node being</mark>:</p>

\[\mathrm{cost}(\text{each node}) = c \cdot \left( \frac{n}{b^j} \right)^d\]

<p>since at each node it is just the clean up step $c \cdot n^{d}$. Then since there are $a^{j}$ nodes at level $j$, we have:</p>

\[\begin{align*}
  T(n) 
  &amp;= \sum_{j=0}^{\log_b a} a^j \cdot c \cdot \left( \frac{n}{b^j} \right)^d \\
  &amp;= c \cdot n^d \cdot \sum_{j=0}^{\log_b a} \underbrace{\left( \frac{a}{b^d} \right)^j}_{\text{this ratio!}} \\
\end{align*}\]

<p>where the ratio of $a / b^{d}$ was the ratio we had in the master method. This ratio also has a very important interpretation:</p>
<ul>
  <li>$a$ is the <mark>rate of growth/proliferation</mark></li>
  <li>$b^{d}$ is the <mark>rate of shrinkage of work</mark>. Since each of your subproblem shrink by a factor of $b$, but that goes into the term $O(n^{d})$, hence you shrink your work by a factor of $b^{d}$.</li>
</ul>

<p>Then we have the following cases:</p>
<ul>
  <li>
    <p>if $a = b^{d}$, then:</p>

\[T(n) = c \cdot n^d \cdot \sum_{j=0}^{\log_b a} \left( \frac{a}{b^d} \right)^j = c \cdot n^d \cdot \sum_{j=0}^{\log_b a} 1 = c \cdot n^d \cdot (\log_b a + 1) = O(n^d \log n)\]

    <p>note that we changed the base here.</p>
  </li>
  <li>
    <p>if $a / b^{d} = r \neq  1$, then we have a <strong>finite geometric series</strong> where:</p>

\[\sum\limits_{j=0}^{k} r^{j} = 1 + r + r^{2} + \cdots + r^{k} = \frac{r^{k+1} - 1}{r - 1}\]

    <p>which means that:</p>
    <ul>
      <li>
        <p>if $r &lt; 1$, then the first term $O(1)$ dominates. Hence we get</p>

\[T(n) = c \cdot n^d \cdot O(1) = O(n^d)\]

        <p>which is basically the <mark>work done by the root node</mark>!</p>
      </li>
      <li>
        <p>if $r &gt; 1$, then the last term $O(r^{k})$ dominates. Hence we get</p>

\[T(n) = c \cdot n^d \cdot O\left[ \left( \frac{a}{b^{d}} \right)^{\log_{b} n} \right]\]

        <p>note that since $b^{-d \log_{b} n} = (b^{\log_b n})^{-d} = n^{-d}$, we get:</p>

\[T(n) = O(a^{\log_{b} n}) = O(n^{\log_{b} a})\]

        <p>where $a^{\log_{b} n}$ is basically <mark>the number of leaves</mark>! However we still use the $n^{\log_{b} a}$ because it’s easier to apply.</p>
      </li>
    </ul>
  </li>
</ul>

<hr />

<h1 id="linear-time-selection">Linear-Time Selection</h1>

<p>This section discusses another divide-and-conquer algorithm, but won’t take the standard form of the master method (probably the only case in this course).</p>

<blockquote>
  <p><strong>Selection Problem</strong>. Given an array $A$ of $n$ distinct numbers and an index $i$, find the $i$th smallest element of $A$.</p>
</blockquote>

<p>The naive solution would be a sort + indexing, which takes $O(n \log n)$ time. However, we can do better by using the divide-and-conquer strategy. The intuition is that we can select a pivot and partition the array in such a way that we will only need to <em>recurse on one of the two partitions</em> = <strong>reduced input size</strong>!</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230914220414.png" style="zoom:100%;" /></p>

<p>one very important finding is that the <strong>pivot is at the “rightful” position</strong> which can tell us two things:</p>
<ol>
  <li><em>that pivot element</em> is in the right position as if it’s sorted, <mark>such that</mark>:</li>
  <li>if we are looking for, say, the $5$-th smallest element, the entire left partition (red) is <strong>irrelevant</strong></li>
</ol>

<p>Thus a high level sketch of the algorithm is as follows:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">select</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">i</span><span class="p">):</span>  <span class="c1"># n is the length, i is the i-th smallest
</span>  <span class="k">if</span> <span class="n">n</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">A</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="c1"># select a pivot and sort
</span>    <span class="n">p</span> <span class="o">=</span> <span class="n">pivot</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>

    <span class="c1"># recursively select
</span>    <span class="n">partition</span><span class="p">(</span><span class="n">A</span> <span class="n">around</span> <span class="n">p</span><span class="p">)</span>  <span class="c1"># O(n) to put smaller element on left, larger on right
</span>    <span class="n">j</span> <span class="o">=</span> <span class="s">"p's position "</span>  <span class="c1"># 1-indexed
</span>    <span class="k">if</span> <span class="n">j</span> <span class="o">==</span> <span class="n">i</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">p</span>
    <span class="k">elif</span> <span class="n">j</span> <span class="o">&gt;</span> <span class="n">i</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">select</span><span class="p">(</span><span class="n">A</span><span class="p">[:</span><span class="n">j</span><span class="p">],</span> <span class="n">j</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="c1"># note the new length of RHS search is n - j 
</span>      <span class="c1"># since RHS is all larger, the new i is i - j
</span>      <span class="k">return</span> <span class="n">select</span><span class="p">(</span><span class="n">A</span><span class="p">[</span><span class="n">j</span><span class="p">:],</span> <span class="n">n</span> <span class="o">-</span> <span class="n">j</span><span class="p">,</span> <span class="n">i</span> <span class="o">-</span> <span class="n">j</span><span class="p">)</span>
</code></pre></div></div>

<p>But what’s the running time? We have not yet discussed how to find a “good” pivot, but we know that:</p>
<ul>
  <li><strong>worst pivot</strong>: we always pick the minimum/maximum element, so that <strong>each recursive call can only throw away one element</strong>. This is bad, as it results in $\Theta(n^2)$.</li>
  <li><strong>best pivot</strong>: if we managed to pick the median (the $i= (n-1) / 2$-th smallest element, which we don’t know), then we can throw away half of the array each time. This is good, as it will result in $O(n)$ (try with the master method), but we don’t know how to find the median.</li>
</ul>

<p>(we will discuss how to find a “good enough” pivot, such that we can still get $O(n)$)</p>

<h2 id="median-of-medians">Median of Medians</h2>

<p>The trick to linear-time selection is to <strong>use the “median-of-medians” as a proxy</strong> for the true median. First we show the full <code class="language-plaintext highlighter-rouge">select</code> algorithm, and then we will discuss the intuition and runtime behind it.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">select</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">i</span><span class="p">):</span>  <span class="c1"># n is the length, i is the i-th smallest
</span>  <span class="k">if</span> <span class="n">n</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">A</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="c1">### select a pivot and sort
</span>    <span class="n">C</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="mi">5</span><span class="p">):</span>
      <span class="c1"># sort each 5-element subarray
</span>      <span class="n">B</span> <span class="o">=</span> <span class="n">sort</span><span class="p">(</span><span class="n">A</span><span class="p">[</span><span class="n">h</span><span class="p">:</span><span class="n">h</span><span class="o">+</span><span class="mi">5</span><span class="p">])</span>
      <span class="c1"># find/keep the median of each 5-element subarray
</span>      <span class="n">C</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">B</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>  <span class="c1">### first round winners
</span>    <span class="n">p</span> <span class="o">=</span> <span class="n">select</span><span class="p">(</span><span class="n">C</span><span class="p">,</span> <span class="n">n</span> <span class="o">/</span> <span class="mi">5</span><span class="p">,</span> <span class="n">n</span> <span class="o">/</span> <span class="mi">10</span><span class="p">)</span>  <span class="c1">### median of medians, recursively select 1
</span>
    <span class="n">partition</span><span class="p">(</span><span class="n">A</span> <span class="n">around</span> <span class="n">p</span><span class="p">)</span>  <span class="c1"># O(n) to put smaller element on left, larger on right
</span>    <span class="n">j</span> <span class="o">=</span> <span class="s">"p's position in the sorted array"</span>  <span class="c1"># 1-indexed
</span>    <span class="k">if</span> <span class="n">j</span> <span class="o">==</span> <span class="n">i</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">p</span>
    <span class="k">elif</span> <span class="n">j</span> <span class="o">&gt;</span> <span class="n">i</span><span class="p">:</span>  <span class="c1">### recursively select 2
</span>      <span class="k">return</span> <span class="n">select</span><span class="p">(</span><span class="n">A</span><span class="p">[:</span><span class="n">j</span><span class="p">],</span> <span class="n">j</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="c1"># note the new length of RHS search is n - j 
</span>      <span class="c1"># since RHS is all larger, the new i is i - j
</span>      <span class="k">return</span> <span class="n">select</span><span class="p">(</span><span class="n">A</span><span class="p">[</span><span class="n">j</span><span class="p">:],</span> <span class="n">n</span> <span class="o">-</span> <span class="n">j</span><span class="p">,</span> <span class="n">i</span> <span class="o">-</span> <span class="n">j</span><span class="p">)</span>
</code></pre></div></div>
<p>This warrants several “issues”:</p>

<ul>
  <li>Since there is a <code class="language-plaintext highlighter-rouge">sort</code>, how is this not $O(n \log n)$ runtime? This is because in this case we are sorting a <em>constant</em> number of elements , hence it becomes $O(5 \log 5) = O(1)$. But, since there will be $n / 5$ groups of 5 elements, the total runtime is $O(n)$!</li>
  <li>why 5 elements in particular? A short answer is that this is the <em>smallest odd number</em> that can give this algorithm a linear time. For exercise, try using $3$ and compute the runtime.</li>
  <li>how much smaller is the reduced input size <em>after this median of median pivot</em>? The answer is that this <strong>guarantees throwing at least 30% of the array away</strong>.</li>
</ul>

<blockquote>
  <p><strong>Lemma</strong>. The median of median pivot $p$ is at least the $30$th percentile of the array $A$. To see this, consider $k = n / 5$ is the number of groups you have spliited up, and $x_i$ is the $i$th smallest element <em>amongst the $k$ middle elements</em>. Then we can arrange the full array $A$ into the following way: 
<img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230914223004.png" style="zoom:20%;" />
where basically numbers are <strong>guaranteed to be bigger</strong> going from bottom to top, though not necessarily left to right. However, this still indicates that:</p>
  <ul>
    <li>the red highlighted bottom left corner is <strong>smaller than $x_{k / 2}$</strong></li>
    <li>the red highlighted top right corner is <strong>larger than $x_{k / 2}$</strong>
therefore, this means that the median of median, $x_{k / 2}$ is bigger than 3/5 of the rows and &gt;50% of the columns, hence it is at least the 30th percentile.</li>
  </ul>
</blockquote>

<h2 id="runtime-of-select-algorithm">Runtime of Select Algorithm</h2>

<p>Now given that the median is guaranteed to throw away at least 30% of the array, we can write the recurrence relation as follows:</p>

\[T(n) = \underbrace{T\left( \frac{n}{5} \right)}_{\text{recursive call by pivot()}} + \underbrace{T \left( \frac{7}{10}n \right)}_{\text{after pivot, search the other 70\%}} + \underbrace{O(n)}_{\text{sort the 5-element subarrays + partition}}\]

<p>note that we <em>cannot</em> use master’s method here, as now we have <em>two recursive calls</em>. In this case, we will need to show that with “guess the solution and check”: that <strong>this is $O(n)$ time</strong>.</p>

<hr />

<p><em>Proof</em>: We want to show tat $T(n) = c \cdot n$ for all $n \ge n_{0} = 1$ in this case. (Hindsight) let $c = 10a$, where $a$ is the constant in the $O(n)$ runtime of the <code class="language-plaintext highlighter-rouge">sort</code> function:</p>

\[T(n) \le T\left( \frac{n}{5} \right) + T \left( \frac{7}{10}n \right) + an\]

<p>is already given. We can prove $T(n) \le c \cdot n$ by induction on $n$:</p>

<ol>
  <li>base case: when $n=1$ this trivially holds as $T(1) = 1 \le c = 10a$ and $a&gt;1$.</li>
  <li>induction hypothesis: assume $T(k) \le c \cdot k$ for all $k &lt; n$ (e.g. holds for $k= n-1$)</li>
  <li>
    <p>induction step: we show that it holds for $n$:</p>

\[\begin{align*}
 T(n) 
 &amp;\le T\left( \frac{n}{5} \right) + T \left( \frac{7}{10}n \right) + an\\
 &amp;\le c \cdot \frac{n}{5} + c \cdot \frac{7}{10}n + an\\
 &amp;= \frac{9}{10}cn + an\\
 &amp;= n \cdot \left( \frac{9}{10}c + a \right)\\
 &amp;= n \cdot 10 a = c \cdot n
\end{align*}\]

    <p>where the second inequality comes from the induction step that we assumed $T(k)\le c \cdot k$ holds.</p>
  </li>
</ol>

<hr />

<h1 id="quicksort">QuickSort</h1>

<p>This is perhaps the most famous sorting algorithm, and it is also based on the idea of <strong>divide-and-conquer</strong>. Although it also operates with $O(n \log n)$, in practice there are differences compared to <code class="language-plaintext highlighter-rouge">merge_sort</code>:</p>
<ul>
  <li>The big win for QuickSort over MergeSort is that it CAN run in place. For this reason it needs to allocate only a minuscule amount of additional memory for intermediate computations. However <code class="language-plaintext highlighter-rouge">merge_sort</code> needs to allocate a whole new array for each merge step.</li>
  <li>On the aesthetic side, QuickSort is just a remarkably beautiful algorithm.</li>
</ul>

<p>The implementation follows directly from the <code class="language-plaintext highlighter-rouge">DSelect</code> and <code class="language-plaintext highlighter-rouge">partition</code> algorithm:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230919223127.png" style="zoom:80%;" /></p>

<p>how does this help <em>sort</em> the array?</p>

<ol>
  <li>the <strong>pivot element already winds up in its rightful position</strong>,</li>
  <li>partitioning has <strong>reduced the size of this problem</strong>: sorting the elements less than the pivot (which conveniently occupy their own subarray) and the elements greater than the pivot (also in their own subarray).</li>
</ol>

<p>After recursively sorting the elements in each of these two subarrays, the algorithm is done</p>

<p>Therefore the algorithm is simply:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">quick_sort</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">n</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">A</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">pivot</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
    <span class="n">A_1</span><span class="p">,</span> <span class="n">A_2</span> <span class="o">=</span> <span class="n">partition</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>
    <span class="n">A_1_sorted</span> <span class="o">=</span> <span class="n">quick_sort</span><span class="p">(</span><span class="n">A_1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">A_1</span><span class="p">))</span> 
    <span class="n">A_2_sorted</span> <span class="o">=</span> <span class="n">quick_sort</span><span class="p">(</span><span class="n">A_2</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">A_2</span><span class="p">))</span>
    <span class="c1"># if you can sort in place, you don't need this
</span>  <span class="k">return</span> <span class="n">A_1_sorted</span> <span class="o">+</span> <span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="o">+</span> <span class="n">A_2_sorted</span>
</code></pre></div></div>

<p>Even though the quick runtime analysis above gives the same result as <code class="language-plaintext highlighter-rouge">merge_sort</code>, the <code class="language-plaintext highlighter-rouge">quick_sort</code> algorithm feels a bit different. This is because the order of operations is different. In <code class="language-plaintext highlighter-rouge">merge_sort</code>, the recursive calls are performed first, followed by the combine step, <code class="language-plaintext highlighter-rouge">merge</code>. In <code class="language-plaintext highlighter-rouge">quick_sort</code>, the <strong>recursive calls occur after partitioning</strong>, and their results don’t need to be <code class="language-plaintext highlighter-rouge">merge</code>d at all!</p>

<p>But first of all, is this even correct? Here we prove it formally using induction, which is very suitable for recursive algorithms.</p>

<hr />

<p><em>Proof of Correctness</em>: We will prove by induction. Let $P(n)$ denote the statement “for any array $A$ of length $n$, <code class="language-plaintext highlighter-rouge">quick_sort(A, n)</code> returns a correctly sorted array”.</p>

<ol>
  <li>Base case: $P(1)$ is trivially true, as the array is already sorted.</li>
  <li>Inductive hypothesis: assume $P(k)$ is true for all $k &lt; n$, for any $n &gt; 1$.</li>
  <li>Induction step. Now we need to imagine an input of $P(n)$. First, we note that the pivot element $p$ is already in the right sorted position. Then, we note that since <code class="language-plaintext highlighter-rouge">A_1</code> and <code class="language-plaintext highlighter-rouge">A_2</code> are subarrays with size at most $n-1$, this means that <code class="language-plaintext highlighter-rouge">A_1_sorted</code> and <code class="language-plaintext highlighter-rouge">A_2_sorted</code> are correctly sorted by the induction hypothesis. Therefore, the concatenation of <code class="language-plaintext highlighter-rouge">A_1_sorted</code>, <code class="language-plaintext highlighter-rouge">p</code>, and <code class="language-plaintext highlighter-rouge">A_2_sorted</code> is also correctly sorted.</li>
</ol>

<h2 id="in-place-partition">In-Place Partition</h2>

<p>To sort the array in place using <code class="language-plaintext highlighter-rouge">quick_sort</code>, we just need a routine that can partition the array in place. This is a bit tricky, but it is possible to do this in <strong>a single scan</strong> over the array, <strong>while doing it in-place</strong>.</p>

<blockquote>
  <p><em>Key Idea</em>: while scanning through the array, we can urge to keep the following <strong>invariant</strong>:</p>

  <p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230919225947.png" style="zoom:100%;" /></p>

  <p>where to put the pivot element to the first position is just a swap in $O(1)$ during preprocessing. If we can check each new element in the unpartitioned part and <strong>swap it to the correct partition</strong>, then we can <mark>maintain this invariant = correctness</mark>!</p>
</blockquote>

<p>This is easiest to first go through an example. Consider an input:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230919230212.png" style="zoom:100%;" /></p>

<p>where we consider the invariant formally to be:</p>

<blockquote>
  <p><strong>Invariant</strong>: all elements between the pivot and $i$ are <em>less than</em> the pivot (the $&lt; p$ partition), and all elements between $i$ and $j$ are <em>greater than</em> the pivot (the $&gt; p$ partition). This means that:</p>
  <ul>
    <li>$i$ represent the boundary between the $&lt; p$ and $&gt; p$ partitions, and</li>
    <li>$j$ represent the boundary for yet unseen elements.</li>
  </ul>
</blockquote>

<ol>
  <li>We initialize $i,j$ to be right next to the pivot (first) element. As there is no element between $i$ and $j$ or between the pivot and $i$, the invariant is trivially satisfied.</li>
  <li>At each iteraction, we look at a new element and consider what to do to maintain the invariant:
<img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230919230632.png" style="zoom:100%;" />
in this case $8$ is larger than the pivot and invariant is maintained.</li>
  <li>If the new element is smaller than the pivot. To maintain invraiant, we can <em>swap it with the first element after $i$ and then increment $i$</em>:
<img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230919230757.png" style="zoom:90%;" /></li>
  <li>We continue increment $j$ to see the new element. If it is bigger than the pivot, we can just continue as the invariant is maintained.
<img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230919230942.png" style="zoom:100%;" /></li>
  <li>One last, example, now we see another element smaller than the pivot, so we need to swap and increment $i$:
<img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230919231113.png" style="zoom:100%;" /></li>
</ol>

<p>Hence the pseudocode is:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">partition_inplace</span><span class="p">(</span><span class="n">A</span><span class="p">):</span>
  <span class="n">p</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># assuming pivot is the first element
</span>  <span class="n">i</span> <span class="o">=</span> <span class="mi">1</span>
  <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">A</span><span class="p">)):</span>
    <span class="k">if</span> <span class="n">A</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">p</span><span class="p">:</span>
      <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">A</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
      <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
  <span class="n">A</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">A</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># swap pivot to the correct position
</span>  <span class="k">return</span> <span class="n">A</span>
</code></pre></div></div>

<h2 id="randomized-quicksort">Randomized QuickSort</h2>

<p>Now, what about runtime? Again, the key step is how we choose the pivot element. Similar to <code class="language-plaintext highlighter-rouge">DSelect</code>, this will have a huge impact:</p>
<ul>
  <li>if we choose min/max of the array, we get $\Omega(n^{2})$ runtime (technically also $O(n^{2})$, but just to emphasize the slowness).</li>
  <li>if we choose the median of the array, we get $T(n) = 2 T( n / 2) + O(n) = O(n \log n)$ where the $O(n)$ cost would be calling <code class="language-plaintext highlighter-rouge">DSelct</code> to find the median.</li>
</ul>

<p>While the median is the best choice, it is also the most expensive to compute. Therefore, we will use a <strong>randomized</strong> version of <code class="language-plaintext highlighter-rouge">quick_sort</code> that chooses a random pivot element. This is a very simple modification to the algorithm, and we will show that it has <strong>average case $O(n \log n)$!</strong></p>

<blockquote>
  <p>Why on earth would you want to inject randomness into your algorithm? Aren’t algorithms just about the most deterministic thing you can think of? As it turns out, there are hundreds of computational problems for which randomized algorithms are faster, more eﬀective, or easier to code than their deterministic counterparts.</p>
</blockquote>

<p>To prove the average case runtime, let’s define some notations:</p>

<ul>
  <li>sample space $\Omega$: the set of all possible outcomes of some random experiment</li>
  <li>random variable $X$: a (numerical) measurement of the outcome if a random process, so $X: \Omega \to \R$</li>
  <li>$P(\omega)$ is the probability of getting a particular outcome $\omega \in \Omega$.</li>
</ul>

<p>In the case of <code class="language-plaintext highlighter-rouge">quick_sort</code>, we have:</p>

<ul>
  <li>$\Omega$ being the set of all possible outcomes caused by some random (sequence of) choice of pivot element. (note that it is <em>not</em> defined on the length of the array)</li>
  <li>$X=RT$ that we care about is the runtime of this randomized <code class="language-plaintext highlighter-rouge">quick_sort</code> <em>given</em> a sequence of pivot choices. I.e. given $w \in \Omega$, we get a deterministic runtime $RT(\omega)$.</li>
</ul>

<p>So our goal is to find:</p>

\[\mathbb{E}[RT] = \sum_{\omega \in \Omega} P(\omega) RT(\omega)\]

<p>But this $RT(\omega)$ is hard to compute. Taking a look at the algorithm, we notice that we can simplify this random variable to:</p>

<blockquote>
  <p><strong>Lemma</strong>: For every input array $A$ of length $n \ge 2$ and every pivot sequence $\omega$:</p>

\[RT(\omega) \le a \cdot C(\omega)\]

  <p>for some constant $a &gt; 0$, and $C$ denote the random variable equal to the <strong>total number of comparisons made between pairs of input elements performed by <code class="language-plaintext highlighter-rouge">quick_sort</code></strong> with a given sequence of pivot choices.</p>
</blockquote>

<p>See the book chapter 5.5 for more details, but on a high level: the main operation in <code class="language-plaintext highlighter-rouge">quick_sort</code> is the <code class="language-plaintext highlighter-rouge">partition</code> call, and that is where the comparisons are made.</p>

<p>But $C$ is still a difficult random variable. The trick is that we can <mark>decompose it further</mark>. Let $X_{ij}$ denote the total number of times the elements $z_i$  and $z_j$ get compared in <code class="language-plaintext highlighter-rouge">quick_sort</code>:</p>

\[C(\omega) = \sum\limits_{i=1}^{n-1} \sum\limits_{j=i+1}^{n} X_{ij}(\omega)\]

<p>which literally represents the sum of all comparisons between pairs of elements in the array. Without loss of generality, let $z_i$, $z_j$ also be the $i$-th and $j$-th <em>smallest</em> elements in the array. Then, the question is how many times do we compare $z_i$ and $z_j$?</p>

\[X_{ij}(\omega) = \{0,1\}\]

<p>because comparisons only happen during <code class="language-plaintext highlighter-rouge">partition</code>:</p>
<ul>
  <li>if one of the elements is the pivot, then they can be compared at most once (and then they will be separated by the pivot and sent to different partitions)</li>
  <li>after they are separated, they will never be compared again.</li>
</ul>

<p>Now the real trick is to use the <strong>linearity of expectation</strong>:</p>

<blockquote>
  <p><strong>Linearity of Expectation</strong>: For any random variables $X_1, X_2, \dots, X_n$ and any constants $a_1, a_2, \dots, a_n$:</p>

\[\mathbb{E}[a_1 X_1 + a_2 X_2 + \dots + a_n X_n] = a_1 \mathbb{E}[X_1] + a_2 \mathbb{E}[X_2] + \dots + a_n \mathbb{E}[X_n]\]

  <p>In other words, the expectation of a sum of random variables is the sum of their expectations. Note that this is true even if the random variables are not independent.</p>
</blockquote>

<p>Then we compute the expectation of $C$:</p>

\[\begin{aligned}
\mathbb{E}[C] &amp;= \mathbb{E} \left[ \sum\limits_{i=1}^{n-1} \sum\limits_{j=i+1}^{n} X_{ij} \right] \\
&amp;= \sum\limits_{i=1}^{n-1} \sum\limits_{j=i+1}^{n} \mathbb{E}[X_{ij}] \\
&amp;= \sum\limits_{i=1}^{n-1} \sum\limits_{j=i+1}^{n} P(X_{ij} = 1) \\
&amp;= \sum\limits_{i=1}^{n-1} \sum\limits_{j=i+1}^{n} P(\text{did compare $z_i$ and $z_j$ in QuickSort})
\end{aligned}\]

<blockquote>
  <p><strong>Lemma</strong> If $z_i$ and $z_j$ denote the $i$-th and $j$-th smallest elements in the array, with $i &lt; j$, then the probability that they are compared in <code class="language-plaintext highlighter-rouge">quick_sort</code> is:</p>

\[P(\text{did compare $z_i$ and $z_j$ in QuickSort}) = \frac{2}{j-i+1}\]

</blockquote>

<p>Proof Sketch: Consider fixing $z_i$, $z_j$ with $i &lt; j$, and let some pivot element $z_k$ be chosen during the <em>first recursive call to <code class="language-plaintext highlighter-rouge">quick_sort</code></em>. What happens next?</p>
<ol>
  <li>if $z_k$ is smaller than $z_i$ or bigger than $z_j$, then $z_i, z_{i+1}, …, z_{j}$ will be in the same partition, and will be sent to the next recursive call. They <em>might</em> be compared against in the future, we don’t know yet.</li>
  <li>if $z_k$ happens to be between $z_i$ and $z_j$, then $z_i$ and $z_j$ will be separated by the pivot, and <strong>are not and will never</strong> be compared again.
<img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230919235354.png" style="zoom:100%;" /></li>
  <li>if $z_k$ happens to be $z_i$ or $z_j$, then they will be <strong>compared once</strong>, and then separated by the pivot, and <strong>are not and will never</strong> be compared again.</li>
</ol>

<p>Therefore, the first condition is just a “placeholder” that will eventually lead to the second or third conditions. So the probability of $z_i$ and $z_j$ being compared is equivalent to:</p>

\[P(\text{$z_i$ or $z_j$ is chosen as the pivot before any other element in $z_{i+1}, ..., z_{j-1}$}) = \frac{2}{j-i+1}\]

<p>Finally we can compute the expectation of $C$ (hence the average runtime):</p>

\[\begin{aligned}
\mathbb{E}[\cdot C]
&amp;= \sum\limits_{i=1}^{n-1} \sum\limits_{j=i+1}^{n} P(\text{did compare $z_i$ and $z_j$ in QuickSort}) \\
&amp;= \sum\limits_{i=1}^{n-1} \sum\limits_{j=i+1}^{n} \frac{2}{j-i+1} \\
&amp;\le \sum\limits_{i=1}^{n-1} \left( 2 \sum\limits_{k=2}^{n} \frac{1}{k} \right) \\
&amp;= 2n \sum\limits_{k=2}^{n} \frac{1}{k} \\
&amp;\le 2n \log n = O(n \log n) 
\end{aligned}\]

<p>where</p>
<ul>
  <li>
    <p>the third inequality comes from the fact that the largest sum we can get is when $i=1$:</p>

\[\sum\limits_{j=i+1}^{n} \frac{1}{j-i+1} = \frac{1}{2} + \frac{1}{3} + ... + \left( \frac{1}{n} \right)\]
  </li>
  <li>
    <p>the last inequality can be proven graphically:</p>

    <p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230920000352.png" style="zoom:80%;" /></p>

    <p>where the sum covers the green highlighted rectangles, and the intergral covers the entire area under the blue curve.</p>
  </li>
</ul>

<h1 id="graphs-the-basics">Graphs: The Basics</h1>

<p>Here we just go over some basics and notations, so that we are consistent for the rest of the course.</p>

<blockquote>
  <p><strong>Representing Graphs</strong>: Let $G=(V,E)$ consist of vertices and edges. Let $n$ be the number of <em>verticies</em> and $m$ be the number of <em>edges</em>.</p>
  <ul>
    <li>note that if $G$ is undirected, then you will have $m \le { n \choose 2 }$</li>
    <li>note that if $G$ is directed, then you will have $m \le 2 { n \choose 2 } = n(n-1)$</li>
  </ul>
</blockquote>

<p>Note that in either case, we have $m \le n^{2}$. Therefore in some proofs you will see, we might just swap $\log m$ with $\log n$ since:</p>

\[\log m \le \log n^{2} = 2 \log n \implies O(\log m) \le O(\log n)\]

<blockquote>
  <p><strong>Tree</strong> a connected graph that has no cycles = have $n$ vertices and $n-1$ edges. For example:
<img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230921225225.png" style="zoom:75%;" /></p>
</blockquote>

<blockquote>
  <p><strong>Ingredients for Adjacency List</strong>: the adjacency list <em>representation of graphs</em> is the dominant one we will use in this course. The main ingredients for representing such a list include:</p>
  <ul>
    <li>an array containing all the vertices</li>
    <li>an array containing all the edges</li>
    <li>for each edge, a pointer to each of its two endpoints</li>
    <li>for each vertex, a pointer to each of its incident edges
so visually, something like this:
<img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230921230015.png" style="zoom:100%;" />
where essentially we have $V_0$ having neighbor [2,3,4], and $V_2$ having neighbor [1,8], etc. Or alternatively, you can think of it as:
<img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230922215707.png" style="zoom:30%;" /></li>
  </ul>
</blockquote>

<p>But how much <em>memory</em> do we need to represent a adjaceny list? Well, we need:</p>
<ul>
  <li>$O(n)$ space for the array of vertices</li>
  <li>$O(m)$ space for the array of edges</li>
  <li>$2m = O(m)$ space for the pointers to the edges’ endpoints. This is because each edge has two endpoints, hence $2m$.</li>
  <li>$2m = O(m)$ space for the pointers to the vertices’ incident edges. If you think about this, this is the same as the previous point, as the pointers to the edges’ endpoints are the same as (reversing) the pointers to the vertices’ incident edges.</li>
</ul>

<p>Therefore we need <strong>in total $O(n+m)$ space to represent a graph using adjaceny list</strong>. Note that this is more efficient than adjaceny matrix, which need $O(n^2)$ space:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230921225855.png" style="zoom:70%;" /></p>

<h2 id="breadth-first-search-and-depth-first-search">Breadth-First Search and Depth-First Search</h2>

<p>Both BFS and DFS would work whether if the graph is directed or undirected. On a high level, recall that</p>

<blockquote>
  <p>BFS Idea: start a vertex $s$ (layer 0), we want to explore all neighbors (layer 1), and repeat this process (reaching layer 2, layer 3, etc.) until we have explored all vertices.</p>
</blockquote>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230921230806.png" style="zoom:70%;" /></p>

<p>So how do we implement it? The trick is to use a queue (FIFO) to keep track of the vertices still need to visit in the order of their discovery. The pseudocode is as follows:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">bfs</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">s</span><span class="p">):</span>
  <span class="c1"># let G be the adjaceny list representation of the graph
</span>  <span class="c1"># let s be the starting vertex
</span>  <span class="n">explored</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">=</span> <span class="bp">True</span>
  <span class="n">Q</span> <span class="o">=</span> <span class="n">Queue</span><span class="p">()</span>
  <span class="n">Q</span><span class="p">.</span><span class="n">enqueue</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>  <span class="c1"># initialize the queue with the starting vertex
</span>  <span class="k">while</span> <span class="n">Q</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">empty</span><span class="p">:</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">Q</span><span class="p">.</span><span class="n">dequeue</span><span class="p">()</span>  <span class="c1"># dequeue the first vertex in the queue
</span>    <span class="k">for</span> <span class="n">each</span> <span class="n">edge</span> <span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span> <span class="ow">in</span> <span class="n">G</span><span class="p">.</span><span class="n">adjacentEdges</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>  <span class="c1"># explore all neighbors of v
</span>      <span class="k">if</span> <span class="ow">not</span> <span class="n">explored</span><span class="p">[</span><span class="n">w</span><span class="p">]:</span>
        <span class="n">explored</span><span class="p">[</span><span class="n">w</span><span class="p">]</span> <span class="o">=</span> <span class="bp">True</span>
        <span class="n">Q</span><span class="p">.</span><span class="n">enqueue</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>  <span class="c1"># enqueue the neighbor at the end
</span></code></pre></div></div>

<blockquote>
  <p>DFS Idea: when you reach a vertex, immediately start exploring its (not yet visited) neighbors and backtracking only when necessary (i.e. when you have no more neighbors to explore).</p>
</blockquote>

<p>The most intuitive explanation is to talk about an example. Suppose we are given a graph, and the adjaceny list happened to give $s \to a$ before $s \to b$, then starting from $s$ we would go:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230921231717.png" style="zoom:80%;" /></p>

<p>where the “frontier” marks the “borderline” between the explored and unexplored vertices. To make things interesting, let’s say the adjacency list had $c \to d$ before $c\to e$. This would then give us:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230921231916.png" style="zoom:80%;" /></p>

<p>Now there is a problem: at vertex $e$ we have <strong>no unvisited neighbors</strong>. So DFS is forced to retreat to its previous vertex $d$: and now, it discovered one unexplored vertex $b$.</p>

<p>After this, DFS collapse quickly as each vertex has no unvisited neighbors, and DFS will eventually retreat all the way to $s$. <mark>If all neighbors of $s$ are visited</mark>, then DFS is done.</p>

<p>Therefore the pseudocode is as follows:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">dfs</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">s</span><span class="p">):</span>
  <span class="c1"># let G be the adjaceny list representation of the graph
</span>  <span class="c1"># let s be the starting vertex
</span>  <span class="n">explored</span> <span class="o">=</span> <span class="p">{}</span>  <span class="c1"># mark all vertices as unexplored
</span>  <span class="n">S</span> <span class="o">=</span> <span class="n">Stack</span><span class="p">()</span>
  <span class="n">S</span><span class="p">.</span><span class="n">push</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>  <span class="c1"># initialize the stack with the starting vertex
</span>  <span class="k">while</span> <span class="n">S</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">empty</span><span class="p">:</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">S</span><span class="p">.</span><span class="n">pop</span><span class="p">()</span>  <span class="c1"># pop the first vertex in the stack
</span>    <span class="k">if</span> <span class="ow">not</span> <span class="n">explored</span><span class="p">[</span><span class="n">v</span><span class="p">]:</span>
      <span class="n">explored</span><span class="p">[</span><span class="n">v</span><span class="p">]</span> <span class="o">=</span> <span class="bp">True</span>
      <span class="k">for</span> <span class="n">each</span> <span class="n">edge</span> <span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span> <span class="ow">in</span> <span class="n">G</span><span class="p">.</span><span class="n">adjacentEdges</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>  <span class="c1"># explore all neighbors of v
</span>        <span class="n">S</span><span class="p">.</span><span class="n">push</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>  <span class="c1"># push the neighbor at the top
</span></code></pre></div></div>

<p>Why stack? If you think about the more “natural” recursive implementation, you will realize that essentially you are using a call <em>stack</em>. So the iterative implementation is just a “translation” of the recursive implementation.</p>

<blockquote>
  <p><strong>Runtime of BFS/DFS</strong>: The running time for both algorithms is $O(n + m)$ being <mark>linear in the size of the graph</mark>. This is because both BFS/DFS will:</p>
  <ul>
    <li>examine each vertex at most once</li>
    <li>examine each edge at most twice (once for each endpoint)
therefore the total number of operations is $O(n + 2m) = O(n + m)$.</li>
  </ul>
</blockquote>

<h2 id="generic-search">Generic Search</h2>

<p>Is BFS and DFS correct? How do we prove that its runtime is $O(n+m)$? The answer is to realize that they both fall into the pattern of a generic search algorithm:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">generic_search</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">s</span><span class="p">):</span>
  <span class="c1"># let G=(V, E) be the adjaceny list representation of the graph
</span>  <span class="c1"># let s be the starting vertex
</span>  <span class="n">explored</span> <span class="o">=</span> <span class="p">{</span><span class="n">s</span><span class="p">}</span> <span class="c1"># mark s as explored, others as unexplored
</span>  <span class="k">while</span> <span class="n">there</span> <span class="ow">is</span> <span class="n">an</span> <span class="n">edge</span> <span class="p">(</span><span class="n">v</span><span class="p">,</span><span class="n">w</span><span class="p">)</span> <span class="ow">in</span> <span class="n">E</span> <span class="k">with</span> <span class="n">v</span> <span class="n">explored</span> <span class="ow">and</span> <span class="n">w</span> <span class="n">unexplored</span><span class="p">:</span>
    <span class="n">choose</span> <span class="n">some</span> <span class="n">such</span> <span class="n">edge</span> <span class="p">(</span><span class="n">v</span><span class="p">,</span><span class="n">w</span><span class="p">)</span>
    <span class="n">explored</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
</code></pre></div></div>

<p>To see why this could contain both BFS and DFS, consider the following example graph:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230923155032.png" style="zoom:100%;" /></p>

<ol>
  <li>initially only our home base $s$ is marked as explored.</li>
  <li>In the fist iteration of the while loop, two edges meet the loop condition: $( s, u )$ and $( s, v )$. The GenericSearch algorithm chooses one of these edges — $(s, u)$, say — and marks $u$ as explored.</li>
  <li>In the second iteration of the loop, there are again two choices: $( s, v )$ and $( u, w )$. The algorithm might choose $( u, w )$ being DFS-like or $( s, v )$ being BFS-like.</li>
</ol>

<blockquote>
  <p><strong>Correctness of Generic Graph Search</strong>: At the conclusion of the <code class="language-plaintext highlighter-rouge">generic_search</code>, a vertex is $v \in V$ is explored if and only if there is a path from $s$ to $v$ in $G$.</p>
  <ul>
    <li>this also means that every vertex $v$ is explored</li>
    <li>for BFS/DFS, it is then easy to see that each vertex is also explored <em>only once</em> (if reachable)</li>
  </ul>
</blockquote>

<p><em>Proof</em>: This is IFF proof, so we need to argue from both directions.</p>

\[\text{$v$ is explored in generic\_search} \implies \text{there is a path from $s$ to $v$ in $G$}\]

<p>this is trivially true, as the only way we can discover $v$ is by following paths from $s$.</p>

\[\text{there is a path from $s$ to $v$ in $G$} \implies \text{$v$ is explored in generic\_search}\]

<p>This basically says that the <code class="language-plaintext highlighter-rouge">generic_search</code> algorithm didn’t miss any vertex. We can prove this by contradiction: let there be a path from $s\leadsto v$, but <mark>`generic_search` halted and missed it</mark>. The intuition is that this cannot be, because we checked every edge given a vertex. More formally, let $S \subseteq V$ be the set of vertices just now marked as explored by the algorithm. Then vertex $s \in S$ and, by assumption, $v$ does not. But since there is a path from $s \leadsto v$, then there must exist a path from a vertex in $S$ going to one outside $S$ (reaching $v$). Then, our algorithm would have picked this during the <code class="language-plaintext highlighter-rouge">while</code> loop, and the algorithm would have at least explored one more vertex instead of halting, and would have eventually reached $v$. This is a contradiction, as we assumed that the algorithm halted and missed $v$.</p>

<h2 id="computing-connected-components">Computing connected Components</h2>

<p>This is one typical application of BFS/DFS. Let’s use BFS here.</p>

<p>Recall that</p>

<blockquote>
  <p><strong>Connected Component</strong> is a maximal set of vertices $S \subseteq V$ such that for every pair of vertices $u,v \in S$, there is a path from $u$ to $v$ in $G$. Visually:
<img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230921233123.png" style="zoom:70%;" /></p>
</blockquote>

<p>Consider $G=(V,E)$ being an undirected graph, and consider the task being to identify all connected components of $G$ (e.g. assign each vertex <code class="language-plaintext highlighter-rouge">v</code> a label <code class="language-plaintext highlighter-rouge">cc(v)</code> indicating which connected component it belongs to).</p>

<p>The idea is simple: we can use an outer loop to make a single pass over the vertices, and invoke BFS as a subroutine whenever we encounter an unexplored vertex. The pseudocode is as follows:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">ucc</span><span class="p">(</span><span class="n">G</span><span class="p">):</span>
  <span class="c1"># let G be the adjaceny list representation of the graph
</span>  <span class="n">cc</span> <span class="o">=</span> <span class="p">{}</span>  <span class="c1"># mark all vertices as unexplored
</span>  <span class="n">num_cc</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># number of connected components
</span>  <span class="k">for</span> <span class="n">each</span> <span class="n">vertex</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">G</span><span class="p">.</span><span class="n">vertices</span><span class="p">:</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">explored</span><span class="p">[</span><span class="n">v</span><span class="p">]:</span>
      <span class="n">cc</span><span class="p">[</span><span class="n">v</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>  <span class="c1"># label the connected component
</span>      <span class="n">num_cc</span> <span class="o">+=</span> <span class="mi">1</span>  <span class="c1"># increment the number of connected components
</span>
      <span class="c1">### BFS subroutine
</span>      <span class="n">Q</span> <span class="o">=</span> <span class="n">Queue</span><span class="p">()</span>
      <span class="n">Q</span><span class="p">.</span><span class="n">enqueue</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>  <span class="c1"># initialize the queue with the starting vertex
</span>      <span class="k">while</span> <span class="n">Q</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">empty</span><span class="p">:</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">Q</span><span class="p">.</span><span class="n">dequeue</span><span class="p">()</span>  <span class="c1"># dequeue the first vertex in the queue
</span>        <span class="k">for</span> <span class="n">each</span> <span class="n">edge</span> <span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> <span class="ow">in</span> <span class="n">G</span><span class="p">.</span><span class="n">adjacentEdges</span><span class="p">(</span><span class="n">w</span><span class="p">):</span>  <span class="c1"># explore all neighbors of w
</span>          <span class="k">if</span> <span class="ow">not</span> <span class="n">explored</span><span class="p">[</span><span class="n">x</span><span class="p">]:</span>
            <span class="n">explored</span><span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="o">=</span> <span class="bp">True</span>
            <span class="n">cc</span><span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>  <span class="c1"># assign the same connected component to x
</span>            <span class="n">Q</span><span class="p">.</span><span class="n">enqueue</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># enqueue the neighbor at the end
</span>  <span class="k">return</span> <span class="n">cc</span>
</code></pre></div></div>

<p>What’s the runtime? Although this <em>looks like</em> looping over $O(m+n)$ which is the cost of BFS, in fact we note that <mark>BFS/DFS$(G,s)$ is technically linear in the size of the connected component of $s$</mark>. Therefore the runtime is:</p>

\[\underbrace{O(n)}_{\text{looping over every vertex}} + O\left( \sum \text{connected component's size} \right) = O(n) + O(n + m) = O(n + m)\]

<h2 id="topological-sort">Topological Sort</h2>

<p>Here is another classic <em>application</em> of DFS. Imagine that you have a bunch of tasks to complete, and there are <strong>precedence constraints</strong>, meaning that you cannot start some of the tasks until you have completed others. ne application of topological orderings is to sequencing tasks so that all precedence constraints are respected. More formally</p>

<blockquote>
  <p><strong>Topological Orderings</strong>: let $G=(V,E)$ be a <mark>directed</mark> graph. A topological ordering of $G$ is an assignment $f(v)$  of every vertex $v \in V$ to a different number such that:</p>

\[\text{for every }v\to w \text{ edge}, f(v) &lt; f(w)\]

  <p>i.e. all of $G$’s directed edges should travel forward, with the arrow heading pointing to a vertex with a higher number.</p>
</blockquote>

<p>Visually, consider the following example:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230926223914.png" style="zoom:100%;" /></p>

<p>and there are two ways to topologically sort this graph:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230926223904.png" style="zoom:100%;" /></p>

<p>You can visualize a topological ordering by <strong>plotting</strong> the vertices in order of their f-values. In a topological ordering, <strong>all edges of the graph are directed from left to right</strong>.</p>

<blockquote>
  <p><strong>Note</strong> that this means, it is impossible to topologically order the vertices of a graph that contains a <mark>directed cycle</mark>. Therefore, in general a topological order exists only for a directed graph without any directed cycles - <mark>a directed acyclic graph</mark> (DAG).</p>
</blockquote>

<p>In fact</p>

<blockquote>
  <p><strong>Theorem 8.6</strong>: Every DAG has a topological ordering.</p>
</blockquote>

<p>To show this, first realize that</p>

<blockquote>
  <p><strong>Theorem 8.7</strong>: Every DAG has a source.</p>
  <ul>
    <li>proof: if you keep following incoming edges backward out of an arbitrary vertex of a directed acyclic graph, you’re bound to eventually reach a source vertex. Otherwise, there would be a directed cycle.</li>
    <li>i.e.: if you DFS and is stuck in a DFS, then there is a cycle in your graph.``</li>
  </ul>
</blockquote>

<p>where:</p>
<ul>
  <li>A <strong>source vertex</strong> of a directed graph is a vertex with no incoming edges.</li>
  <li>Analogously, a <strong>sink vertex</strong> is one with no outgoing edges.</li>
</ul>

<p>Then, we can prove Theorem 8.6 very easily. Let $G$ be a directed acyclic graph with $n$ vertices. The task is to assign $f$-values to vertices in an increasing order:</p>
<ol>
  <li>the source vertex will be assigned 1</li>
  <li>obtain $G’$ by removing the source vertex and all its outgoing edges. Note that this cannot produce a directed cycle, as deleting stuff can’t create new cycles</li>
  <li>repeat from step 1 on $G’$</li>
</ol>

<p>So how to do compute a topological sorting, i.e. output a <strong>topological ordering</strong> of the vertices of a DAG $G$?</p>

<ul>
  <li>the proof above naturally leads to an algorithm: a loop ($O(n)$) over each vertex where we find the source ($O(n)$), and then deleting it to repeat. This gives us $O(n^2)$.</li>
  <li>next up: a slicker solution via DFS resulting in $O(n+m)$.</li>
</ul>

<p>First we show the algorithm, the high level idea is simple: we use DFS to dive to the sink and assign the lowest ordering to it, but also <strong>assign things during backtracking!</strong>. We then mark it as explored (i.e. as if we removed the vertex from G) and repeat.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">curLabel</span> <span class="o">=</span> <span class="o">|</span><span class="n">V</span><span class="o">|</span>  <span class="c1"># tracks the ordering
</span><span class="n">f</span> <span class="o">=</span> <span class="p">{}</span>  <span class="c1"># topological ordering
</span>
<span class="k">def</span> <span class="nf">topo_sort</span><span class="p">(</span><span class="n">G</span><span class="p">):</span>
  <span class="c1"># let G = (V, E) be the adjaceny list representation of the graph
</span>  <span class="c1"># let s be the starting vertex
</span>  <span class="n">explored</span> <span class="o">=</span> <span class="p">{}</span>  <span class="c1"># mark all vertices as unexplored
</span>  <span class="k">for</span> <span class="n">each</span> <span class="n">vertex</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">G</span><span class="p">.</span><span class="n">vertices</span><span class="p">:</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">explored</span><span class="p">[</span><span class="n">v</span><span class="p">]:</span>
      <span class="n">dfs_topo</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">explored</span><span class="p">)</span>
  <span class="k">return</span>

<span class="k">def</span> <span class="nf">dfs_topo</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">explored</span><span class="p">):</span>
  <span class="k">global</span> <span class="n">curLabel</span><span class="p">,</span> <span class="n">f</span>

  <span class="n">explored</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">=</span> <span class="bp">True</span>
  <span class="k">for</span> <span class="n">each</span> <span class="n">edge</span> <span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span> <span class="ow">in</span> <span class="n">s</span> <span class="n">outgoing</span> <span class="n">adjaceny</span> <span class="nb">list</span><span class="p">:</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">explored</span><span class="p">[</span><span class="n">w</span><span class="p">]:</span>
      <span class="n">dfs_topo</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">explored</span><span class="p">)</span>
  <span class="n">f</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">=</span> <span class="n">curLabel</span>  <span class="c1"># assign the ordering
</span>  <span class="n">curLabel</span> <span class="o">-=</span> <span class="mi">1</span>  <span class="c1"># decrement the ordering
</span>  <span class="k">return</span>
</code></pre></div></div>
<p>note that <code class="language-plaintext highlighter-rouge">topo_sort</code> doesn’t need to us to start at a particular vertex. We can start at any vertex, and the algorithm will still work. (Basically the algorithm dives as deep as possible, and <strong>assign that deepest vertex</strong> (regardless which starting vertex you choose) <strong>with $f(\cdot) = \vert V\vert$</strong>.)</p>

<p>Correctness: first of all, it is obvious to see that:</p>
<ul>
  <li>every vertex $v$ is assigned a unique number $f(v)$, as each is called by <code class="language-plaintext highlighter-rouge">dfs_topo</code> only once.</li>
  <li>to argue why the returned <code class="language-plaintext highlighter-rouge">f</code> must be a topological order, we need to show <strong>for any arbitrary edge $(v,w)$ such that $v\to w$, we have $f(v) &lt; f(w)$</strong>.</li>
</ul>

<hr />

<p><em>Proof</em> if there is an edge $(v,w)$, then there are two cases in running <code class="language-plaintext highlighter-rouge">topo_sort</code>:</p>
<ol>
  <li>if $v$ is explored before $w$, i.e. we <code class="language-plaintext highlighter-rouge">dfs_topo</code> is invoked with vertex $v$ before $w$ is explored. Then as $v \to w$ is reachable, we will get a call stack of [<code class="language-plaintext highlighter-rouge">dfs_topo(v)</code> -&gt; <code class="language-plaintext highlighter-rouge">dfs_topo(w)</code>]. Since the nature of recursive call will mean <code class="language-plaintext highlighter-rouge">dfs_topo(w)</code> will terminate first, it will be assigned a higher ordering than <code class="language-plaintext highlighter-rouge">dfs_topo(v)</code>. Therefore $f(v) &lt; f(w)$.</li>
  <li>if $w$ is explored before $v$, then it means there <strong>cannot</strong> be a path from $w$ <strong>back</strong> to $v$ (because we already have $v \to w$ and we know the graph is a DAG). Therefore, the call <code class="language-plaintext highlighter-rouge">dfs_topo(w)</code> will terminate without calling <code class="language-plaintext highlighter-rouge">dfs_topo(v)</code>. Then, as <code class="language-plaintext highlighter-rouge">topo_sort</code> will eventually call <code class="language-plaintext highlighter-rouge">dfs_topo(v)</code> <strong>later</strong>, it means $v$ will get a lower ordering. Hence $f(v) &lt; f(w)$.</li>
</ol>

<hr />

<p>Runtime: runs in linear time $O(n+m)$, as it is just DFS with a little extra bookkeeping:</p>
<ul>
  <li>it explores each edge only once (from its tail), only performs a constant amount of work per edge/vertex</li>
  <li>therefore, the runtime is $O(n+m)$</li>
</ul>

<h2 id="computing-strongly-connected-components">Computing Strongly Connected Components</h2>

<p>In short, while it didn’t matter much for undirected graph, for directed graph having a <strong>connected component</strong> makes things more complicated. First, recall that a connected component for <em>undirected</em> graph is defined as maximal regions within which you can get from anywhere to anywhere else in the region. For directed graph, consider</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230926232541.png" style="zoom:80%;" /></p>

<p>Following the logic, the answer should be zero.</p>

<blockquote>
  <p><strong>Strongly Connected Component (SCC)</strong> a maximal set of vertices $S \subseteq V$ such that there is a directed path from any vertex in $S$ to any other vertex in $S$.</p>
</blockquote>

<p>For example</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230926232718.png" style="zoom:60%;" /></p>

<p>First of all, why would <code class="language-plaintext highlighter-rouge">ucc</code> not work? Consider evoking BFS on the following vertices</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230926233006.png" style="zoom:60%;" /></p>

<p>first, notice all the edges are organized to go mainly from left to right. In the case on the left, we would get a <em>wrong result</em>: BFS will discover every vertex and mark them as the same connected component. In the case on the right, we would get a <em>correct result</em>. This indicates that graph search can uncover strongly connected components, <mark>provided you start from the right place</mark>. But how? The key observation is that we want to first start from a <mark>sink SCC</mark>, i.e. the SCC with no outgoing edges to other SCCs. Then, we can go in a reverse topological order, plucking off sink SCCs one by one.</p>

<blockquote>
  <p><strong>Key Lemma</strong>: the SCC Meta-Graph is directed acyclic. Visually this is simple to see:
<img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230926235651.png" style="zoom:15%;" />
and the argument is also simple. If two meta SCC are not acyclic, then you would have collapsed them into one, i.e., the two meta SCC were not maximal at the first place.</p>
  <ul>
    <li>this lemma is actually very important. This means that all we need to do is to find <mark>one vertex</mark> in a <mark>sink SCC</mark>, run BFS/DFS to label all vertices it can reach (and mark them as explored), and repeat</li>
    <li>the above works because for a directed acyclic graph + using a sink SCC, you cannot get out of that sink SCC.</li>
  </ul>
</blockquote>

<p>On a high level, the arguments above in the lemma is pretty much what we will do, except you might be a bit confused by the graph reversing step</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># sktech of Kosaraju’s algorithm
</span><span class="k">def</span> <span class="nf">kosaraju_idea</span><span class="p">(</span><span class="n">G</span><span class="p">):</span>
  <span class="n">G_rev</span> <span class="o">=</span> <span class="n">reverse</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>  <span class="c1"># reverse the graph, i.e. reverse all edges
</span>  <span class="n">dfs_loop</span><span class="p">(</span><span class="n">G_rev</span><span class="p">),</span> <span class="n">let</span> <span class="n">f</span><span class="p">[</span><span class="n">v</span><span class="p">]</span> <span class="o">=</span> <span class="s">"finishing time"</span> <span class="n">of</span> <span class="n">DFS</span> <span class="n">on</span> <span class="n">a</span> <span class="n">vertex</span> <span class="n">v</span>
  <span class="n">dfs_loop</span><span class="p">(</span><span class="n">G</span><span class="p">),</span> <span class="n">using</span> <span class="n">f</span> <span class="n">to</span> <span class="n">process</span> <span class="n">vertices</span> <span class="ow">in</span> <span class="n">decreasing</span> <span class="n">order</span>  <span class="c1"># i.e. start from the sink vertex
</span>  <span class="k">return</span> <span class="n">vertices</span> <span class="k">with</span> <span class="n">their</span> <span class="n">labels</span>
</code></pre></div></div>

<p>while yes, the second relates to some kind of topological order, and third step relates to us wanting to get a reverse topological order before diving DFS to label the vertices. But there are a few caveat:</p>
<ul>
  <li>second step did something on a <strong>reversed</strong> graph. Why?</li>
  <li><strong>we thought about the <code class="language-plaintext highlighter-rouge">topo_sort</code> algorithm only in DAGs</strong>, and here we have a <strong>general directed graph</strong>.</li>
  <li>the second and third is <em>not equivalent</em> to <code class="language-plaintext highlighter-rouge">topo_sort</code> of a normal <code class="language-plaintext highlighter-rouge">G</code> and then start from the sink vertex.</li>
</ul>

<p>So what’s going on? First we show the full algorithm, and then we will illustrate how it works, and why it is correct.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">global</span> <span class="n">numSCC</span><span class="p">:</span> <span class="nb">int</span>

<span class="k">def</span> <span class="nf">Kosaraju</span><span class="p">(</span><span class="n">G</span><span class="p">):</span>
  <span class="c1"># let G = (V, E) be the adjaceny list representation of the graph
</span>  <span class="n">G_rev</span> <span class="o">=</span> <span class="n">reverse</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>  <span class="c1"># reverse the graph, i.e. reverse all edges
</span>  <span class="n">mark</span> <span class="nb">all</span> <span class="n">vertices</span> <span class="ow">in</span> <span class="n">G_rev</span> <span class="k">as</span> <span class="n">unexplored</span>

  <span class="c1"># first pass of DFS
</span>  <span class="c1"># computes f(v), the magical ordering
</span>  <span class="n">TopoSort</span><span class="p">(</span><span class="n">G_rev</span><span class="p">)</span>

  <span class="c1"># second pass of DFS
</span>  <span class="c1"># finds SCCs in reverse topological order
</span>  <span class="n">mark</span> <span class="nb">all</span> <span class="n">vertices</span> <span class="ow">in</span> <span class="n">G</span> <span class="k">as</span> <span class="n">unexplored</span>
  <span class="k">global</span> <span class="n">numSCC</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># number of SCCs, global variable
</span>  <span class="k">for</span> <span class="n">each</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">V</span><span class="p">,</span> <span class="ow">in</span> <span class="n">increasing</span> <span class="n">order</span> <span class="n">of</span> <span class="n">f</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">explored</span><span class="p">[</span><span class="n">v</span><span class="p">]:</span>
      <span class="n">numSCC</span> <span class="o">+=</span> <span class="mi">1</span>
      <span class="c1"># assign scc-values for all vertices in the SCC
</span>      <span class="n">dfs_scc</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">dfs_scc</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">s</span><span class="p">):</span>
  <span class="k">global</span> <span class="n">numSCC</span>
  <span class="n">explored</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">=</span> <span class="bp">True</span>
  <span class="n">scc</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">=</span> <span class="n">numSCC</span>
  <span class="k">for</span> <span class="n">each</span> <span class="n">edge</span> <span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span> <span class="ow">in</span> <span class="n">s</span> <span class="n">outgoing</span> <span class="n">adjaceny</span> <span class="nb">list</span><span class="p">:</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">explored</span><span class="p">[</span><span class="n">w</span><span class="p">]:</span>
      <span class="n">dfs_scc</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>
  <span class="k">return</span>
</code></pre></div></div>

<p>So, it turns out all the concern above will be addressed after thinking about this.</p>

<blockquote>
  <p><strong>Why reverse graph + topological sort?</strong></p>
</blockquote>

<p>What we want, in the end, is to <strong>find a vertex in a <em>sink SCC</em> of $G$</strong>. The hope with <code class="language-plaintext highlighter-rouge">topo_sort</code> is that, we recall, the vertex in the last position ($f(v)=\vert V\vert$) must be a sink vertex (hence inside sink SCC) of $G$. However, it was for DAGs. So are we lucky enough that this would hold for a general graph? The answer is sadly no. If we consider the following example where we started at vertex <code class="language-plaintext highlighter-rouge">1</code> (recall that <code class="language-plaintext highlighter-rouge">topo_sort</code> starts at random vertex):</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">correct source but wrong sink</th>
      <th style="text-align: center">correct source and correct sink</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230927012532.png" style="zoom:50%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230927012538.png" style="zoom:60%;" /></td>
    </tr>
  </tbody>
</table>

<p>where basically the left is made by trying to start at vertex 1 and wind up ending at vertex 4 during the first iteration, while the right is made by starting at vertex 1 and ends at vertex 8 during the first iteration of <code class="language-plaintext highlighter-rouge">topo_sort</code>. Although we couldn’t consistently find a vertex in a sink, it turns out we <strong>can consistently find a vertex in the source SCC</strong>. But in fact, the statement is even stronger: tThe topological order of the SCCs will <em>also be a topological ordering of the meta-graph</em>, if we label each SCC with the smallest $f$ of one of its vertices, i.e. formally</p>

<blockquote>
  <p><strong>Theorem 8.10</strong>: Topological Ordering of the SCCs. Let $G$ be a directed graph, with vertices ordered arbitrarily, and for each vertex $v \in V$ let $f(v)$ be the position of $v$ computed by <code class="language-plaintext highlighter-rouge">topo_sort</code>. Let $S_1, S_2$ denote two SCCs of $G$, and suppose $G$ has an edge $(v,w)$ with $v \in S_1$ and $w \in S_2$, then:</p>

\[\min_{x \in S_1} f(x) &lt; \min_{y \in S_2} f(y)\]

  <p>i.e. even if <code class="language-plaintext highlighter-rouge">topo_sort</code> is incorrect in this case globally for every vertex, it is still correct locally for the SCCs!.</p>
</blockquote>

<p>the proof is similar to the correctness of <code class="language-plaintext highlighter-rouge">topo_sort</code>. If we consider the following illustration:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230927014115.png" style="zoom:70%;" /></p>

<p>then there are two cases that can happen during <code class="language-plaintext highlighter-rouge">topo_sort</code> labeling all the vertices:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">topo_sort</code> explored and initialized a DFS from a vertex $s \in S_1$ before any vertex in $S_2$. But because we know vertices in a SCC can reach each other, then $s \leadsto v$, and since $v \to w$, then we can reach from $s$ to any vertex in $S_2$. Therefore, because <code class="language-plaintext highlighter-rouge">topo_sort</code> is a DFS/recursive call, the call <code class="language-plaintext highlighter-rouge">dfs_topo(s)</code> will not terminate until all the vertices in $S_2$ terminates. Therefore, $f(v)$ must also be smaller than $f(w)$.</li>
  <li><code class="language-plaintext highlighter-rouge">topo_sort</code> explored and initialized a DFS from a vertex $s \in S_2$ before any vertex in $S_1$. Then, <strong>because the meta-graph is directed acyclic</strong>, we are stuck in $S_2$, and $S_1$ will be unscathed. Since the counter for $f$ is a global variable, this means we will get a smaller $f$ for $S_1$ than $S_2$.</li>
</ul>

<p>The end result? We are sure that the <mark>first vertex resides in a source SCC</mark> if we do <code class="language-plaintext highlighter-rouge">topo_sort</code>. So to find a vertex in a sink SCC, all we need is to <mark>reverse the graph first</mark>.</p>

<hr />

<p>Finally, an example before going to the correctness and runtime discussion. We want to check that the magical reverse graph + <code class="language-plaintext highlighter-rouge">topo_sort</code> will indeed help us get vertices in a sink SCC, and so that the second pass of depth-first search discovers the SCCs in reverse topological order.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">$G_{rev}$ and compute $f(v)$</th>
      <th style="text-align: center">$G$ with computed $f(v)$</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230927015408.png" style="zoom:100%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230927015414.png" style="zoom:100%;" /></td>
    </tr>
  </tbody>
</table>

<p>Then, given the progress above (by reversing the graph and calling <code class="language-plaintext highlighter-rouge">topo_sort</code>), we continue to the second pass to DFS, which checks through vertices in increasing order:</p>

<ol>
  <li>first call to DFS-SCC is initiated at the vertex 1 with smallest $f$. (the vertex in a sink SCC!)</li>
  <li>then it will label all vertices $1,3,5$, and mark as done.</li>
  <li>the second smallest and third is with vertex 3, which is visited already.</li>
  <li>the third smallest is vertex 11, which is also (a vertex in) the second sink SCC.</li>
  <li>continues</li>
</ol>

<h3 id="correctness-and-runtime-of-kosarajus-algorithm">Correctness and Runtime of Kosaraju’s Algorithm</h3>

<p>The argument will be short as the proofs are mostly covered in the previous section.</p>

<p><strong>Correctness</strong>: each time we initiates a new call to <code class="language-plaintext highlighter-rouge">dsf_scc</code>, the algorithm discovers <em>exactly one new SCC</em> - the <em>sink SCC</em> relative to the not-yet-explored part of the graph.</p>

<p><strong>Runtime</strong>: each of the two passes of DFS does a constant number of operations per vertex or edge. Therefore, the runtime is $O(n+m)$.</p>

<h1 id="dijkstras-shortest-path-algorithm">Dijkstra’s Shortest Path Algorithm</h1>

<p>We’ve arrived at another one of computer science’s greatest hits: Dijkstra’s shortest-path algorithm.</p>

<blockquote>
  <p><strong>Assumptions with Dijkstra’s Algorithm</strong>: this algorithm works in any <em>directed graph with nonnegative edge length</em>.</p>
  <ul>
    <li>can we extend it to undirected graph? (Yes, by changing the ‘frontier’ condition)</li>
    <li>can we extend it to negative edge length? (No, but Bellman-Ford can)</li>
  </ul>
</blockquote>

<p><strong>Problem definition</strong>: consider a directed graph $G=(V,E)$, a starting vertex $s \in V$, and a nonnegative length $l_e$ for each edge $e \in E$. The goal is to compute the <strong>length of a shortest path $D(v)$ from $s$ to every other vertex $v$ in $G$</strong>.</p>

<blockquote>
  <p>Why can’t we use BFS? Remember that breadth-first search computes the minimum number of edges in a path from the starting vertex to every other vertex (i.e. we continue layer by layer). This is the special case of the single-source shortest path problem <strong>in which every edge has length 1</strong>.</p>
  <ul>
    <li>but then can’t we just think of an edge with a longer length $l&gt;1$ as a <em>path of edges</em> that each have length 1?
<img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230922003244.png" style="zoom:80%;" /></li>
    <li>Yes, in principle, you can solve the single-source shortest path problem by expanding + using BFS</li>
    <li>However, the problem with this is that it blows up the size of the graph</li>
  </ul>
</blockquote>

<h2 id="dijkstras-algorithm">Dijkstra’s Algorithm</h2>

<p>The idea of Dijkstra’s algorithm is to use a <strong>greedy</strong> approach: at each step, we will <strong>grow the frontier by one vertex</strong>. Overall it looks similar to BFS/DFS by iterating over the new vertices, but the clever part is <strong>how we choose which vertex to process next/is done</strong>.</p>

<p>Consider some example graph, where each edge $e$  has a length of $l_e$:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230922003934.png" style="zoom:80%;" /></p>

<p>Consider the pseudo-code</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">dijkstra</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">s</span><span class="p">):</span>
  <span class="c1"># let G = (V, E) be the adjaceny list representation of the graph
</span>  <span class="c1"># let s be the starting vertex
</span>  <span class="n">X</span> <span class="o">=</span> <span class="p">{</span><span class="n">s</span><span class="p">}</span>  <span class="c1"># list of vertices processed so far
</span>  <span class="n">dist</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span> <span class="c1"># tracks the cost of shortest path distance
</span>  <span class="n">path</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># tracks the shortest path, empty for s
</span>  
  <span class="k">while</span> <span class="n">there</span> <span class="ow">is</span> <span class="n">an</span> <span class="n">edge</span> <span class="p">(</span><span class="n">v</span><span class="p">,</span><span class="n">w</span><span class="p">)</span> <span class="k">with</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">X</span> <span class="ow">and</span> <span class="n">w</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">X</span><span class="p">:</span>  <span class="c1"># check edges that crossed the "frontier"
</span>    <span class="p">(</span><span class="n">v</span><span class="o">*</span><span class="p">,</span> <span class="n">w</span><span class="o">*</span><span class="p">)</span> <span class="o">=</span> <span class="n">edge</span> <span class="n">minimizing</span> <span class="n">dist</span><span class="p">[</span><span class="n">v</span><span class="p">]</span> <span class="o">+</span> <span class="n">l_vw</span>
    <span class="n">X</span><span class="p">[</span><span class="n">w</span><span class="o">*</span><span class="p">]</span> <span class="o">=</span> <span class="bp">True</span>  <span class="c1"># grow exactly one vertex
</span>    <span class="n">dist</span><span class="p">[</span><span class="n">w</span><span class="o">*</span><span class="p">]</span> <span class="o">=</span> <span class="n">dist</span><span class="p">[</span><span class="n">v</span><span class="o">*</span><span class="p">]</span> <span class="o">+</span> <span class="n">l_vw</span>
    <span class="n">path</span><span class="p">[</span><span class="n">w</span><span class="o">*</span><span class="p">]</span> <span class="o">=</span> <span class="n">path</span><span class="p">[</span><span class="n">v</span><span class="o">*</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">w</span><span class="o">*</span><span class="p">]</span>
  
  <span class="k">return</span> <span class="n">dist</span><span class="p">,</span> <span class="n">path</span>
</code></pre></div></div>

<p>Visually, this works like:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230922113037.png" style="zoom:100%;" /></p>

<p>Is this algorithm correct? If you think about it, this is what Dijkstra’s algorithm is trying to say. Consider an edge $(v,w)$ with $v \in X$ and $w \notin X$. Then <mark>the shortes path from $s$ to $w$ consists of the shortest path from $s$ to $v$ (or $s \leadsto v$) with edge $(v,w)$ tacked at the end</mark>. So is this correct?</p>

<h2 id="correctness-of-dijkstras-algorithm">Correctness of Dijkstra’s Algorithm</h2>

<p>Essentially Dijkstra’s algorithm iterates over the entire $V$ space, so we can consider induction on the number of vertices $n$.</p>

<p><em>Proof</em>: Let $P(n)$ denote that “the Dijkstra algorithm correctly computes the shortest-path distance of the $n$th vertex added to the processed set $X$”. We will prove this by induction on $n$:</p>
<ol>
  <li>Base case: $P(1)$ is trivially true, as the starting vertex $s$ is the first vertex in $X$ and the shortest path distance from $s$ to $s$ is indeed $0$.</li>
  <li>Inductive hypothesis: Let $P(k)$ be true for all $k=1,2,3…, n-1$. This means that we have $d(v)=\mathrm{shortest}(s,v)$ correctly computed for the first $n-1$ vertices added by Dijkstra to $X$.</li>
  <li>
    <p>Inductive step: now we need to show $P(n)$. Let $w^{<em>}$ be the $n$th vertex being added, and <strong>let Dijkstra to have selected the $(v^*, w^*)$ edge for that to happen</strong> (i.e. $v^{</em>}\to w^{*}$ is the shortest edge at the frontier). We need to show that:</p>

\[d(v^*) + l_{v^{*}w^{*}} = \mathrm{shortest}(s, w^*)\]

    <p>We can show this by:</p>
    <ul>
      <li>showing $d(v^<em>) + l_{v^{</em>}w^{<em>}} \ge \mathrm{shortest}(s, w^</em>)$, that the shortest path can only be less than or equal to the path from $s$ to $v^<em>$ plus the edge $(v^</em>, w^*)$. This is trivially true by definition of the shortest path.</li>
      <li>
        <p>showing $d(v^<em>) + l_{v^{</em>}w^{<em>}} \le \mathrm{shortest}(s, w^</em>)$, namely every competitor path $s \leadsto w^{<em>}$ must be at least  $d(v^</em>) + l_{v^{<em>}w^{</em>}}$. To show this, consider a “crazily short” path:</p>

        <p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230922011917.png" style="zoom:60%;" /></p>

        <p>where because we know that path has to start at $s$ and ends at $w^{*}$ which is <mark>outside $X$</mark>, then it must have crossed the frontier at some point. Let’s denote the <strong>first edge from that path crossing the frontier be $(y,z)$</strong>, such that $y\in X, z \notin X$. So in essence we can considering any competitor path $P’$ taking the form:</p>

\[P' = \underbrace{s \leadsto y}_{\text{inside X}} \to z \leadsto w^{*}\]

        <p>we note that this path must has at least:</p>

\[len(P') \ge \text{shortest}(s,y) + l_{yz} + 0 = d(y) + l_{yz}\]

        <p>where we used $+0$ <mark>because we assumed no edges can be negative</mark>, and that $d(y) = \text{shortest}(s,y)$ from the inductive hypothesis. But we notice that this $d(y) + l_{yz}$ exactly represents <mark>an edge that just crossed the frontier</mark>. This means that according to Dijkstra’s algorithm that since we picked $(v^{<em>}, w^{</em>})$ edge:</p>

\[d(y) + l_{yz} \ge d(v^{*}) + l_{v^{*}w^{*}}\]

        <p>Therefore every competitor path $P’$ must be at least $d(v^<em>) + l_{v^{</em>}w^{*}}$, and we are done. (Intuitively, this is saying that <mark>*any path $P'$* going outside of $X$ will need to use the shortest path inside $X$ + something outside $X$</mark>, and while Dijkstra is minimizing exactly this, it works.)</p>
      </li>
    </ul>
  </li>
</ol>

<p><strong>Q: What if we are dealing with a directed graph that has negative edges, but let’s say, <em>no negative cycles</em>?</strong></p>

<blockquote>
  <p>The main insight here is that the algorithm only looks at all directly connected edges and it takes the smallest of these edge. The algorithm <mark>does not look ahead</mark>.</p>
</blockquote>

<p>Therefore, you can consider the following example (from <a href="https://stackoverflow.com/questions/13159337/why-doesnt-dijkstras-algorithm-work-for-negative-weight-edges#:~:text=You%20can%20use%20dijkstra%27s%20algorithm,lose%20it%27s%20fast%20time%20complexity.">stackoverflow</a>)</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230923160616.png" style="zoom:100%;" /></p>

<p>where Dijkstra would return the shortest path from $A\leadsto D$ being at a cost of 2, but in reality it is $-4900$.</p>

<p><strong>Q: is there a case where Dijkstra algorithm is <em>still correct despite there are negative edges</em>?</strong></p>

<p>Yes. Consider a directed graph $G$ and a starting vertex $s$ with the following properties: <strong>no edges enter the starting vertex $s$; edges that leaves have arbitrary (possibly negative) lengths</strong>; and all other edge lengths are nonnegative. Dijkstra’s algorithm correctly solve the single-source shortest path problem. You can see this in two ways:</p>
<ul>
  <li>notice that adding the same positive constant $M$ to each of s’s outgoing edges preserves all shortest paths, as the lengths of all the $s \leadsto v$ path goes up by precisely $M$</li>
  <li>go back to the formal correctness proof of Dijkstra, and realize that the induction step would still work.</li>
</ul>

<h1 id="hash-tables-and-bloom-filters">Hash Tables and Bloom Filters</h1>

<p>The goal of a hash table is to facilitate <strong>super-fast searches</strong>, which are also called lookups in this context. Compared to other data structures we will discuss later (e.g. heaps and search trees), hash tables do not maintain any ordering information.</p>

<blockquote>
  <p>A hash table keep track of an evolving set of objects with keys while supporting fast lookups (by <strong>key</strong>).</p>
</blockquote>

<p>e.g. if you company manages an e-commerce site, you might use one hash table to keep track of employees (perhaps using names as keys).</p>

<blockquote>
  <p><strong>Hash Table Operations</strong>: a hash table needs to support the following operations:</p>
  <ul>
    <li>insert: given a new <strong>object</strong> $x$, add it to the hash table</li>
    <li>lookup: given a <strong>key</strong> $k$, return a pointer to an object in the hash table with key $k$ (or null if no such object exists)</li>
    <li>delete: given a key $k$, remove the object with key $k$ from the hash table, if it exists</li>
  </ul>

  <p>(for programming purposes you can just imagine the key a numerical representation of the object (e.g. memory address of the object), and a hash function $h$ operates on the key $h(k)$)</p>
</blockquote>

<p>and to really be a hash table:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Operation</th>
      <th style="text-align: center">Typical/Average Runtime</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">Lookup</td>
      <td style="text-align: center">O(1)*</td>
    </tr>
    <tr>
      <td style="text-align: center">Insert</td>
      <td style="text-align: center">O(1)</td>
    </tr>
    <tr>
      <td style="text-align: center">Delete</td>
      <td style="text-align: center">O(1)*</td>
    </tr>
  </tbody>
</table>

<p>where:</p>
<ul>
  <li>the asterisk (*) indicates that the running time bound <strong>holds if and only if</strong> the hash table is implemented properly (with a good hash function and an appropriate table size) and the data is non-pathological (see later).</li>
  <li>insert is technically always $O(1)$, not average runtime.</li>
</ul>

<p>Since this is really for fast lookups, example applications of hash tables include:</p>
<ul>
  <li>2-SUM problem: given a target $t$ and a list of integers $A$, find two distinct integers $x,y \in A$ such that $x+y=t$.
    <ul>
      <li>realize that given a $x$, there is only one possible $y$ that can achieve this = just look up $t-y$!</li>
    </ul>
  </li>
  <li>deduplication: given a list of $n$ items, remove all duplicates in $O(n)$ time
    <ul>
      <li>first check if the hash table already has the key, if not, insert the k and store the object</li>
    </ul>
  </li>
</ul>

<h2 id="implementation-separate-chaining">Implementation: Separate Chaining</h2>

<p>So how do we get a (near) constant lookup time? Here we discuss a very common implementation of hash tables, which is called <strong>separate chaining</strong> (and the other popular one is called <strong>open addressing</strong>). We will first discuss separate chaining.</p>

<p>Visually, this is very easy to understand:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230928225818.png" style="zoom:60%;" /></p>

<p>so that:&gt;</p>

<blockquote>
  <p><strong>Separate Chaining</strong>: Let there be an array $A$ of $n$ <strong>buckets</strong>, and for each bucket you have a linked list so that given a key $k$, <mark>lookup/insert/delete essentially all operate on the linked list $A[h(k)]$</mark>.</p>
  <ul>
    <li>note that this means your hash function needs to do $h: U \to {0,1,2,…,n-1}$ where $U$ is all possible objects/keys, which can be achieved by simply doing modulo n.</li>
  </ul>
</blockquote>

<p>But now we get some problems:</p>
<ul>
  <li>insert is surely constant time</li>
  <li>
    <p>but lookup and delete technically need:</p>

\[\text{Runtime(lookup/delete)} = O(\text{length of linked list})\]
  </li>
</ul>

<p>So our goal is to keep small linked list for each bucket. First of all, in what cases can we get bad performance?</p>
<ol>
  <li>Size of $n$ is too small, so that we have too many collisions.
    <ul>
      <li>This is easy to fix: just increase the size of $n$. But then you also need to rehash everything.</li>
    </ul>
  </li>
  <li>Using a bad hash function (e.g. $h(k) = 0$ a constant function).
    <ul>
      <li>So then what is a good hash function? One that <strong>Mimics a random function</strong> by spreading non-pathological datasets (see below) roughly evenly across the positions of the hash table</li>
    </ul>
  </li>
  <li>The data is pathological, i.e. it is <em>always</em> possible to adversarially come up with some kind of data such that they all hash to the same bucket. i.e. for every hash function $h: U \to {0,1,2,…,n-1}$, there exists a set $S$ of keys such that $h(k_1) = h(k_2)$ for every $k_{1}, k_{2} \in S$.
    <ul>
      <li>this is unfixable. The best we can do is to assume that the data is not pathological.</li>
    </ul>
  </li>
</ol>

<blockquote>
  <p><strong>Takeaway</strong>: while 1 and 2 are somewhat avoidable, condition 3 means that hash tables <mark>cannot guarantee $O(1)$ for lookup or delete</mark>.</p>
</blockquote>

<p>However, we <em>can</em> guarantee $O(1)$ is <em>average runtime</em> under some conditions (actually all the three will need to be addressed)</p>

<blockquote>
  <p><strong>Claim</strong>: let there be a dataset $S$. If our hash table has a reasonably big size $\vert S\vert =O(n)$ (condition 1), and $h(x)$ is like a random function (condition 2), and $S$ is not pathological (condition 3), then the average runtime of lookup and delete is $O(1)$.</p>
</blockquote>

<p><em>Proof</em>: since we are discussing average time, the procedure will be similar to quick sort analysis. We begin by figuring out the random variable we want to analyze, then decompose it to simpler random variables, and finally use linear expectation to get the result.</p>

<p>Suppose you have inserted all $s \in S$ into the hash table. 
Consider a lookup for a new random object $x$ with key $k$, which might or might not be in $S$. Then the runtime is:</p>

\[\mathrm{Runtime} = O(\text{list length of }A[h(k)]) = O(l)\]

<p>where $l$ is the random variable as it could be long or short. But notice that</p>

\[O(l) = O(\# \text{of collisions $x$ is making})\]

<p>This means that:</p>

\[\begin{align*}
  l \le 1 + \sum\limits_{y \in S, y \neq x} z_{y}  
\end{align*}\]

<p>where $z_y$ is (again) an indicator random variable indicating if there is a collision, and the one is there if there is a $y=x$ (i.e. essentially $x$ was an object $S$).</p>

\[z_{y} = 
\begin{cases}
1, &amp; \text{if $h(x)=h(y)$ } \\
0, &amp; \text{otherwise}
\end{cases}, \quad \forall y \in S\]

<p>Now decomposition is complete, we realize that:</p>

\[\begin{align*}
  \mathbb{E}[l]
  &amp;\le \mathbb{E}\left[1 + \sum\limits_{y \in S, y \neq x} z_{y}\right] \\
  &amp;= 1 + \sum\limits_{y \in S, y \neq x} \mathbb{E}[z_{y}] \\
  &amp;= 1 + \sum\limits_{y \in S, y \neq x} \Pr[h(x)=h(y)]
\end{align*}\]

<p>But we realize that if $h$ is a perfectly random hash function, then $\Pr[h(x)=h(y)]$ given an $x$ is like throwing the $y$ dart randomly at the $n$ buckets, and hoping that it lands on the same bucket as $x$. Therefore, the probability is $1/n$. Hence we get:</p>

\[\begin{align*}
  \mathbb{E}[l]
  &amp;\le 1 + \sum\limits_{y \in S, y \neq x} \Pr[h(x)=h(y)] \\
  &amp;= 1 + \sum\limits_{y \in S, y \neq x} \frac{1}{n} \\
  &amp;= 1 + \frac{|S|-1}{n} \\
  &amp;= O(1)
\end{align*}\]

<p>where the last equality is because we had said $\vert S\vert =O(n)$, i.e. our hash table is reasonably big.</p>

<h2 id="implementation-open-addressing">Implementation: Open Addressing</h2>

<p>Why did we have a linked list version before (i.e. separate chaining)? <mark>In the end it was to resolve collision</mark>, but letting them live in the same bucket. Note that such collision is inevitable, as we have fixed size of data structure but your dataset $S$ is huge.</p>

<p>The idea of open addressing is, instead of letting the collision live in the same bucket, we will <mark>try to find another bucket</mark> for the colliding object, assuming $n \ge \vert S\vert$. In this implementation, each bucket stores only 0 or 1 object.</p>

<blockquote>
  <p><strong>Open Addressing</strong>: given an object $x$ with key $k$ and its position to insert $h(k)$. We will use some <strong>probe sequence</strong> (i.e. a sequence of buckets to check) if $h(k)$ is occupied.</p>
  <ul>
    <li>so for insert, we continue this sequence until the first empty bucket, and insert the object there</li>
    <li>for lookup, we continue this sequence until we find the bucket storing $x$, or an empty bucket (return not found)</li>
    <li>we will <em>not</em> support delete.</li>
  </ul>
</blockquote>

<p>So the trick is this “probe sequence”. One simple sequence would be a <strong>linear probing</strong>: $h(k), h(k)+1, …, \text{wrap around}, h(k)-1$.</p>

<p>We skip other details here, but discuss its performance compared to separate chaining.</p>

<ul>
  <li>with chaining, the lookup time is affected by linked list length; with open addressing, its the <strong>number of probes required</strong> to either hit an empty slot or find the object.</li>
  <li>in both implementations, when the hash table gets increasingly full, performance degrades.</li>
  <li>however, with an appropriate hash table size and hash function, <strong>open addressing achieves the same running time bound</strong> as chaining.</li>
</ul>

<h2 id="bloom-filters">Bloom Filters</h2>

<p>Bloom filters have became a very popular data structure since its usage in internet routers. It has a very similar idea to hash tables, but:</p>

<ul>
  <li>it is more space efficient</li>
  <li>it can only return <code class="language-plaintext highlighter-rouge">true/false</code> for lookup (i.e. if the object is in the set or not)</li>
  <li>it <em>can</em> return false negatives (i.e. even if the object is not in the set, it might return <code class="language-plaintext highlighter-rouge">true</code>)</li>
  <li>it <em>guarantees</em> constant-time operations for every dataset.</li>
</ul>

<blockquote>
  <p><strong>Blook Filter Supported Operations</strong>: a bloom filter supports the following operations:</p>
  <ul>
    <li>lookup: given a key $k$, return <code class="language-plaintext highlighter-rouge">true</code> if $k$ is in the bloom filter, and <code class="language-plaintext highlighter-rouge">false</code> if $k$ is not in the bloom filter</li>
    <li>insert: add a new key $k$ to the bloom filter (since we are only returning <code class="language-plaintext highlighter-rouge">true/false</code> for lookup, we don’t need to store the key/object itself)</li>
  </ul>
</blockquote>

<p>The idea of Bloom filter is simple. Consider an array of $n$ bits all initially zero. Then the data structure uses $m$ hash functions $h_1, h_{2}, …, h_m$ each mapping $h_{i} : U \to { 0,1,2, … , n-1 }$.</p>
<ul>
  <li>you can create $m$ hash functions <em>*using one real hash function $h_{</em>}$<em>*, by doing $h_{1}(k) = m \cdot h_</em>(k), h_{2} = m \cdot h_*(k) + 1$, etc.</li>
  <li>typically $m$ is quite small, like $m=5$.</li>
</ul>

<p>Then the operations is simply:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">insertion</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
  <span class="c1"># flip all A[h_i(k)] = 1
</span>  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
    <span class="n">A</span><span class="p">[</span><span class="n">h_i</span><span class="p">(</span><span class="n">k</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">1</span>

<span class="k">def</span> <span class="nf">lookup</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
  <span class="c1"># check if all A[h_i(k)] == 1
</span>  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">A</span><span class="p">[</span><span class="n">h_i</span><span class="p">(</span><span class="n">k</span><span class="p">)]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
      <span class="k">return</span> <span class="bp">False</span>
  <span class="k">return</span> <span class="bp">True</span>
</code></pre></div></div>

<p>Visually:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230928235431.png" style="zoom:80%;" /></p>

<p>hence it is obvious that:</p>
<ul>
  <li>you cannot get false negative: if an object is in the set, then its bits must <em>have been flipped to 1</em> (as we are not supporting deletion).</li>
  <li>you can get false positive: if an object is not in the set, then its bits <em>might have been flipped to 1</em> by other objects.</li>
</ul>

<p>Now, error analysis: is this really worth it? How much error will this give? The goal is to get <strong>a $n$ not too large but still have a small false positive rate</strong>.</p>

<p>Suppose that we have inserted all elements $x \in S$ into the bloom filter. Consider a lookup for a new random object $x$ with key $k$, which is a false positive. For this to happen, we need:</p>

\[\Pr[\text{false positive}] = \Pr[\text{all $m$ bits are flipped for $x$}] = \Pr[ \text{one bit is flipped} ]^{m}\]

<p>What’s the probability that one bit is flipped?</p>

\[\Pr[ \text{one bit is flipped} ] = 1 - \Pr[ \text{all data missed that bit} ] = 1 - {\underbrace{\left( 1 - \frac{1}{n}\right)}_{\text{one hash function missed}}}^{m |S|}\]

<p>where its raised to the power of $m \vert S\vert$ since there are $\vert S\vert$ objects we inserted, and for each object we had $m$ “dart shots” (recall that we assume $h$ is a perfectly random function). This form approximates that of an exponential function:</p>

\[\Pr[ \text{one bit is flipped} ] =  1 - {\left( 1 - \frac{1}{n}\right)}^{m |S|} \approx 1 - e^{- m|S| / {n}}\]

<p>finally:</p>

\[\Pr[\text{false positive}] \approx \left( 1 - e^{- m|S| / {n}} \right)^{m}\]

<p>Notice that this is a function of $n,m, \vert S\vert$. Therefore, depending on the application, we can <mark>optimize for the error rate</mark> (using calculus), if we fix $n / \vert S\vert$ representing the number of bits per object:</p>

\[m^{*} = \frac{n}{|S|} \ln 2\]

<p>this means that if we are having an array for about <strong>8 bits per object</strong>, then we should use <strong>$m=5 \sim 6$ hash functions</strong> which gives an <strong>error rate of about 2%</strong>.</p>

<h1 id="introduction-to-greedy-algorithms">Introduction to Greedy Algorithms</h1>

<p>This is another <em>class</em> of algorithm, where compared to the divide and conquer algorithm:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Divide and Conquer</th>
      <th style="text-align: center">Greedy Algorithms</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231005214058.png" style="zoom:100%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231005214110.png" style="zoom:100%;" /></td>
    </tr>
    <tr>
      <td style="text-align: center">relatively easy to prove correct (e.g. induction)</td>
      <td style="text-align: center">usually hard correctness proof</td>
    </tr>
    <tr>
      <td style="text-align: center">harder to analyze runtime</td>
      <td style="text-align: center">usually straightforward sorting + single pass</td>
    </tr>
  </tbody>
</table>

<p>While it is myoptic and simple to implement, it is <strong>often hard to come up with a correct greedy algorithm</strong> (e.g. Dijkstra was one), and for many problems <strong>there might not exist a correct greedy algorithm</strong>. More specifically, you shall see that correctness proofs for greedy algorithms are more art than science, though there will be a useful trick, called the <strong>exchange argument</strong>, which we will show next.</p>

<h2 id="scheduling-problem">Scheduling Problem</h2>

<p>Consider the scheduling task in OS, where given some set of jobs $J$ with each job $j$ having known length $l_j$ (i.e. how long it takes to complete), and a weight $w_j$ (e.g. priority). We want to have a scheduling algorithm that can find the “best” sequence of jobs to complete $\sigma$. What is a “best” schedule?</p>

<ul>
  <li>
    <p>first of all, how many posisble schedules are there? $n!$.</p>
  </li>
  <li><strong>completion time</strong> $C_j(\sigma)$ of a job $j$ is the sum of lengths of the jobs preceding $j$ in $\sigma$, plus the length of $j$ itself. i.e. time elapsed when $j$ is completed.
    <ul>
      <li>e.g. consider three jobs with length $l_1=1, l_{2}=2, l_3=3$, weight $w_1=3, w_2=2, w_{3} = 1$. Suppose we scheduled them to be in the order of $j_1, j_2, j_3$. Then this means the completion time is $C_{1} = 1, C_{2} = 3, C_{3} = 6$. Visually</li>
    </ul>

    <p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231005220948.png" style="zoom:60%;" /></p>
  </li>
  <li>
    <p><strong>sum of weighted completion times</strong>. This is <mark>our objective function</mark>:</p>

\[\min_\sigma \sum\limits_{j =1}^{n} w_j C_j(\sigma)\]

    <p>i.e. we want shorter/more important jobs to be completed earlier.</p>
  </li>
</ul>

<blockquote>
  <p><strong>Scheduling Task</strong>: given a set of $n$ jobs with positive lengths $l_j$ and positive weights $w_j$, find a schedule $\sigma$ that minimizes the sum of weighted completion times.</p>
</blockquote>

<p>To solve this problem, let us <em>first posit that there actually is a correct greedy algorithm</em> for the problem. Then, we need to consider some <mark>intuitions by thinking about some "special cases"</mark>.</p>

<blockquote>
  <p><strong>Intuition</strong>:</p>
  <ul>
    <li>if all job lengths are equal, then we should schedule jobs with a <strong>higher weight</strong> first.</li>
    <li>if all job weights are equal, then we should schedule <strong>shorter jobs</strong> first. (Why? Realize that in general, the job scheduled first <em>contributes to the completion times of all the jobs</em>, as all jobs must wait for the first one to finish.)</li>
  </ul>
</blockquote>

<p>These two rules of thumbs make sense, but in reality we can have a job with high weight but long length, and vice versa. So how do we combine these two rules of thumbs? Consider a simple greedy idea where we 1) use a formula to compile each job’s length and weight into a single number, and 2) schedule the jobs greedily using that score. So what is the formula?</p>

<p>From our intuition above, we know that the formula <strong>must have two properties</strong>:</p>
<ol>
  <li>holding length constant, the score should increase with weight (assuming we want to schedule higher score first)</li>
  <li>holding weight constant, the score should decrease with length (longer length smaller score)</li>
</ol>

<p>So we can <em>guess</em> two candidates:</p>

<ul>
  <li>score 1: $w_{j} - l_{j}$. The <strong>GreedyDiff</strong> algorithm.</li>
  <li>score 2: $w_{j} / l_{j}$. The <strong>GreedyRatio</strong> algorithm.</li>
</ul>

<p>Obviously if they propose different schedules, then one of them must be wrong (or in general, both are wrong). In this case, we can rule out the first by considering the following example:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231005222454.png" style="zoom:80%;" /></p>

<p>where the first job would have a larger ratio, so GreedyRatio would schedule it first, but GreedyDiff would schedule the second job first. But we realize that the weighted completion time:</p>

<ul>
  <li>for GreedyRatio is $3 \cdot 5 + 1 \cdot 7 = 22$</li>
  <li>for GreedyDiff is $1 \cdot 2 + 3 \cdot 7 = 23$ is worse!</li>
</ul>

<p>So we can rule out GreedyDiff, and we are left with GreedyRatio. But is GreedyRatio correct? Luckily in this case it is!</p>

<blockquote>
  <p><strong>Theorem: Correctness of GreedyRatio</strong>. For every set of positive job weights $w_1, w_2, …, w_n$ and positive job length $l_1, l_2, … , l_n$, the GreedyRatio algorithm outputs a schedule with the minimum possible sum of weighted completion times.</p>
</blockquote>

<p><em>Proof</em>: we will use <mark>exchange arguments</mark>. The key idea is prove that every feasible/alternative solution can be improved by modifying it to look more like the output of the greedy algorithm $\implies$ the greedy algorithm is optimal.</p>

<p>Without loss of generality, let us compute the ratio for every job $j$ and renumber the jobs such that:</p>

\[\frac{w_1}{l_1} \ge \frac{w_2}{l_2} \ge ... \ge \frac{w_n}{l_n}\]

<p>so that $\sigma$ is the sequence $[1,2, … , n]$. Suppose by contradiction that we have some competitor $\sigma^{<em>}$ that is better, and $\sigma^{</em>} \neq \sigma$. For the greedy output we get essentially:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231005224435.png" style="zoom:80%;" /></p>

<p>but note that for any other schedule, we will have a <strong>consecutive inversion</strong>: a pair of job $i &gt; j$ (so $j$ has a higher score) such that job $i$ is processed immediately before job $j$. For instance $\sigma^{‘}$ has a consecutive inversion:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">$\sigma^{*}$</th>
      <th style="text-align: center">$\sigma^{‘}$</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231005225000.png" style="zoom:70%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231005225006.png" style="zoom:70%;" /></td>
    </tr>
  </tbody>
</table>

<blockquote>
  <p><strong>Lemma: Non-Greedy Schedules Have Inversions</strong>. Every schedule $\hat{\sigma}$ different from the greedy schedule $\sigma$ has at least one consecutive inversion.</p>
  <ul>
    <li>proof: if $\hat{\sigma}$ has no consecutive inversion, then the index of each job is at least 1 larger than the job that came before. Since there are only $n$ jobs and the maximum index is $n$, the jump between two consecutive job must be 1. Then $\hat{\sigma}$ must be the same as $\sigma$.</li>
  </ul>
</blockquote>

<p>Now, the key idea is to perform an exchange from $\sigma^{*}$ (to reach $\sigma^{‘}$) and realize it can only perform at least as good. After the swap above of job $i,j$, we realize that:</p>
<ul>
  <li>the objective does not change for the jobs before $i$ and after $j$</li>
  <li>for job $i$ in $\sigma^{*}$, it went up in $\sigma^{‘}$ so the cost increased by $l_{j} \cdot w_i$</li>
  <li>for job $j$ in $\sigma^{*}$, it went down in $\sigma^{‘}$ so the cost decreased by $l_{i} \cdot w_j$</li>
</ul>

<p>But since $i &gt; j$ by construction ($j$ had a higher score), it means:</p>

\[\frac{w_i}{l_i} \le \frac{w_j}{l_j} \implies l_{j} \cdot w_i \le l_{i} \cdot w_j\]

<p>So $\sigma^{‘}$ is at least as good as $\sigma^{<em>}$, with $\sigma^{‘}$ being more ordered = more similar to $\sigma$! More precisely, we can show that $\sigma^{‘}$ has <mark>exactly one less inversion</mark> than $\sigma^{</em>}$. To see this, define an inversion to be a pair $k,m$ of job such that $k &lt; m$ (so $k$ has a higher score) but $m$ is schedules before $k$, AND that they need not be consecutive. Then, realize that swapping one consecutive inversion does not change the relative order of $k,m$ relative to each other or $k,m$ relative to $i,j$:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231005231255.png" style="zoom:70%;" /></p>

<p>In other words, restoring consecutive inversion doesn’t affect any other inversions (if any). Therefore, this means:</p>

<ul>
  <li>having <strong>one less consecutive inversion produces a schedule at least as good</strong>!</li>
  <li>having <strong>one less consecutive inversion also decreases the total number of inversion by one</strong></li>
</ul>

<p>Therefore, we can repeatedly swap jobs to remove consecutive inversions until we get $\sigma$, which has no inversions. During the process, the objective function can not increase ($\le$). Hence $\sigma$ is at least as good as any $\sigma^{*}$ along the way. This means that $\sigma$ is optimal, and we are done.</p>

<h1 id="huffman-codes">Huffman Codes</h1>

<p>Huffman coding is a widely-used method for lossless compression. For example, every time you import or export an MP3 audio file, your computer uses Huffman codes. This section will cover the optimality of Huffman codes, and a fast algorithm for computing them.</p>

<blockquote>
  <p><strong>Compression Task</strong>: consider an input “string” that consists of symbols from an alphabet $\Sigma$ (e.g. a set of 64 symbols including all 26 letters plus punctuations and some special characters). Your goal is to represent this string to a <em>binary code</em>, i.e. a sequence of 0s and 1s, so that the code is as short as possible while still being able to recover the original string.</p>
</blockquote>

<p>Note that there are two different tasks here:</p>
<ol>
  <li><strong>encoding</strong>: find a mapping that maps each symbol to a binary code</li>
  <li><strong>decoding</strong>: given a binary code, can recover the original string without ambiguity</li>
</ol>

<p>For instance, consider the following alphabet to encode:</p>

\[\Sigma = \{ A,B,C,D \}\]

<p>and consider the following two encoding schemes:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">fixed-length code</th>
      <th style="text-align: center">variable-length code</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231010233843.png" style="zoom:80%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-                    .png" style="zoom:80%;" /></td>
    </tr>
  </tbody>
</table>

<p>While variable code in general can be shorter if designed correctly (so we will focus on this), but in this case what would the string “001” decode to? Note that this issue does not arise with fixed-length codes since we know where to start and end for each symbol. With variable-length codes, we must <strong>impose a constraint to prevent ambiguity</strong>.</p>

<h2 id="prefix-free-codes">Prefix-Free Codes</h2>

<p>We can eliminate all ambiguity by insisting that a code is <strong>prefix-free</strong>. This means that given any two pair of distinct symbols $a,b \in \Sigma$, the encoding of $a$ is not a prefix of that of $b$, and vice versa.</p>

<blockquote>
  <p>With a prefix-free code, encodings are unambiguous</p>
</blockquote>

<p>Why? If, say, the first 5 bits of a sequence match the encoding of a symbol $a$, then $a$ was definitely the first symbol encoded. Because the code is prefix-free, there’s no way these 5 bits could correspond to (a prefix of) the encoding of any other symbol.</p>

<p>An example of prefix-free code would be fixed length code, or the following variable-length code:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231011002350.png" style="zoom:100%;" /></p>

<p>But how do we find a variable-length code that is also prefix-free? Crucial to reasoning about the problem is a method of <strong>associating codes with labeled binary trees</strong>. This is most easy to see with examples:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Encoding</th>
      <th style="text-align: center">Tree</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-        .png" style="zoom:80%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-   .png" style="zoom:80%;" /></td>
    </tr>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231011002732.png" style="zoom:80%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-      .png" style="zoom:80%;" /></td>
    </tr>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231011002944.png" style="zoom:80%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231011002953.png" style="zoom:80%;" /></td>
    </tr>
  </tbody>
</table>

<p>where essentially edges are the encoding, and vertices are potential symbols. Notice that</p>
<ul>
  <li><strong>every binary code can be represented as a binary tree</strong> with left and right child edges labeled with “0” and “1,” respectively, and with each symbol of the alphabet used as the label for exactly one node</li>
  <li>the number of edges in a path/depth equals the number of bits used to encode the corresponding symbol</li>
</ul>

<p>But more importantly:</p>
<ul>
  <li>In general, the encoding of a symbol $a$ is a prefix of that of another symbol $b$ <strong>if and only if the node labeled $a$ is an ancestor of the node labeled $b$</strong>.</li>
  <li>therefore, because no leaf can be the ancestor of another, <mark>a tree with labels only at the leaves defines a prefix-free code</mark> (i.e., no label will be parent)</li>
</ul>

<p>Finally, we can visualize decoding as traversing the tree until we hit a leaf, and restarting from the root. For example, given the input string “010111” and the tree below, we would decode it as “ABD”:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231011003933.png" style="zoom:80%;" /></p>

<h2 id="huffmans-greedy-algorithm">Huffman’s Greedy Algorithm</h2>

<p>Now that we have a way to represent a prefix-free code as a binary tree, we can formulate the problem as follows:</p>

<blockquote>
  <p><strong>Task: Optimal prefix-free code</strong>. Given a string to encode, with each symbol $a \in \Sigma$ having a frequency $p_a$, our objective is to minimize:</p>

\[\min_T \sum\limits_{a \in \Sigma} p_a \cdot \text{depth}(a)\]

  <p>where $T$ is a binary tree with labels only at the leaves, which would define any prefix-free code.</p>
</blockquote>

<p>Now since we can have symbols of different frequency, it becomes apparent that variable length prefix-code is what we are looking for: associate the most frequent symbols with the shortest codes/number of bits.</p>

<p>The overall idea is to consider a bottom-up algorithm. We start with every symbol $a \in \Sigma$ as a leaf, and then we will repeatedly merge some symbols until we get a tree. But what do we choose which ones to merge in order to minimize the objective?</p>

<blockquote>
  <p><em>Intuition</em>: labels with high frequency are costly so they should be at the top of the tree. Hence, we should keep small frequency labels at the deeper levels.</p>

  <p>So, the idea for greediness is to consider merging ‘‘symbols’’ with the <strong>smallest frequencies</strong> first (bottom-up). i.e. every iteration of Huffman’s greedy algorithm myopically performs the merge that least increases this objective function.</p>
</blockquote>

<p>Why could it possibly be a good idea? Realize that each merge <strong>increments the depths of all the leaves in the two participating trees</strong> and, hence, the encoding lengths of the corresponding symbols:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Before Merge</th>
      <th style="text-align: center">After Merge</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-              .png" style="zoom:70%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-             .png" style="zoom:70%;" /></td>
    </tr>
  </tbody>
</table>

<p>where technically you are merging two trees (or two root nodes) each time, and specifically for every leaf/symbol in the two trees after merging, the depth increases by 1. This causes the <strong>objective function to increase by</strong>:</p>

\[\sum\limits_{a \in T_1} p_{a} +  \sum\limits_{a \in T_2} p_{a}\]

<p>because for symbol has increased one more bit, but as it appears $p_a$ times,the total cost increases $p_a$ for each leaf. <strong>Huffman’s greedy criterion thus dictates that we merge the pair of trees for which the sum above is as small as possible</strong>.</p>

<p>The pseudo code thus look like:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">huffman</span><span class="p">(</span><span class="n">S</span><span class="p">):</span>
  <span class="c1"># S is a set of symbols with frequencies p_a
</span>  <span class="c1"># initialize a forest of trees, one for each symbol
</span>  <span class="n">F</span> <span class="o">=</span> <span class="p">{</span> <span class="n">Tree</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">p_a</span><span class="p">)</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">S</span> <span class="p">}</span>

  <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">F</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">T_1</span><span class="p">,</span> <span class="n">T_2</span> <span class="o">=</span> <span class="n">two_trees_with_smallest_freq</span><span class="p">(</span><span class="n">F</span><span class="p">)</span>
    <span class="c1"># merge them into a new tree
</span>    <span class="n">T_3</span> <span class="o">=</span> <span class="n">merge</span><span class="p">(</span><span class="n">T_1</span><span class="p">,</span> <span class="n">T_2</span><span class="p">)</span>  <span class="c1"># root of T1, T2 become the children of a new internal node
</span>    <span class="n">T_3</span><span class="p">.</span><span class="n">p_a</span> <span class="o">=</span> <span class="n">T_1</span><span class="p">.</span><span class="n">p_a</span> <span class="o">+</span> <span class="n">T_2</span><span class="p">.</span><span class="n">p_a</span>  <span class="c1"># invariant: for every internal node, its p_a is the sum of its children
</span>
    <span class="n">F</span><span class="p">.</span><span class="n">remove</span><span class="p">(</span><span class="n">T_1</span><span class="p">)</span>
    <span class="n">F</span><span class="p">.</span><span class="n">remove</span><span class="p">(</span><span class="n">T_2</span><span class="p">)</span>
    <span class="n">F</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">T_3</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">the</span> <span class="n">only</span> <span class="n">tree</span> <span class="ow">in</span> <span class="n">F</span>
</code></pre></div></div>

<p>Before proof of correctness, consider a quick example. Given input of</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231011010013.png" style="zoom:100%;" /></p>

<p>and each iteration of the algorithm looks like:</p>

<ol>
  <li>initialize with 4 trees, each with a single symbol
<img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231011010135.png" style="zoom:100%;" /></li>
  <li>smallest is node C and D:
<img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231011010204.png" style="zoom:100%;" />
merge and obtain a new subtree with root CD at cost of $0.10+0.05=0.15$</li>
  <li>smallest two are $0.15$ and $0.25$, so merge the subtree CD with B:
   <img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231011010318.png" style="zoom:100%;" />
   and obtain a new subtree with cost $0.4$</li>
  <li>Finally<br />
<img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231011010443.png" style="zoom:100%;" />
where if we take the left edge to represent 0 and the right 1, this returns a variable length prefix-free code of A=0, B=10, C=110, D=111.</li>
</ol>

<h2 id="correctness-of-huffmans-algorithm">Correctness of Huffman’s Algorithm</h2>

<p>Now we want to show that the encoding returned by the above greedy algorithm is correct. In general greedy algorithm is not easy to prove, and here we will use induction + exchange argument to prove it.</p>

<p>Before the proof, we first notice that the algorithm is <strong>iteratively committing two smallest $p_a$ symbols $a,b$ to be siblings in the final tree</strong>. Therefore the plan is to show that:</p>

<ol>
  <li>Huffman’s tree is the best (minimizes the average leaf depth) amongst all possible trees in which $a$ and $b$ are siblings</li>
  <li>there is an optimal tree in which $a$ and $b$ are siblings</li>
</ol>

<p>Visually, each iteration of the algorithm is like:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231011094550.png" style="zoom:10%;" /></p>

<p>and to prove that the output tree is optimal (combining claim 1 and 2) we need to show that:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231011094612.png" style="zoom:10%;" /></p>

<p>If we can prove both of the above, then we are basically done (by induction).</p>

<hr />
<p><em>Proof</em> by induction. Let us denote $P(k)$ be the statement that Huffman’s tree output the best with an alphabet size at most $k$.</p>
<ol>
  <li>base case: when $k=2$, there is only a tree with one root and two leaves. So Huffman’s tree is optimal.</li>
  <li>inductive hypothesis: assume $P(k’)$ is true for $k’ &lt; k$.</li>
  <li>
    <h2 id="inductive-step-we-need-to-show-that-pk-is-true-since-each-step-of-the-algorithm-we-are-merging-two-least-frequent-symbols-the-root-of-the-subtree-we-want-to-show-claim-1-and-claim-2-to-hold-in-order-to-prove-that-the-output-tree-at-this-stage-is-optimal">inductive step: we need to show that $P(k)$ is true. Since each step of the algorithm we are merging two least frequent “symbols” (the root of the subtree), we want to show claim 1 and claim 2 to hold in order to prove that the <strong>output tree at this stage is optimal</strong>.</h2>
  </li>
</ol>

<p><em>Proof for claim 2</em>: we begin by first showing that there is an optimal tree in which $a$ and $b$ are siblings. To prove this, we will use the <em>exchange argument</em> again. Consider some arbitrary tree $T$, and without loss of generality, denote a sibling at the lowest level of the tree as $x,y$. Let $a,b$ the nodes with the smallest frequency $p_a$. We want to show that the objective function/cost is at least as good as the one with $a,b$ as siblings.</p>

<p>Consider changing the $a,b$ and $x,y$  pair:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231011095113.png" style="zoom:100%;" /></p>

<p>Then notice that the new tree $T’$ changed cost function by:</p>

\[\begin{align*}
  \Delta L
  &amp;= \underbrace{p_{a} (\mathrm{depth}(x) - \mathrm{depth}(a)) + p_{b} (\mathrm{depth}(y) - \mathrm{depth}(b))}_{\text{cost}} \\
  &amp;+ \underbrace{p_{x} (\mathrm{depth}(a) - \mathrm{depth}(x)) + p_{y} (\mathrm{depth}(b) - \mathrm{depth}(y))}_{\text{benefit}} \\
\end{align*}\]

<p>which we can simplify to</p>

\[\Delta L = (p_{a} - p_{x}) \cdot (\Delta(x,a)) + (p_{b} - p_{y}) \cdot (\Delta(y,b))\]

<p>where by definition of $x,y$ being the deepest we know that $\Delta(x,a) \ge 0$ and $\Delta(y,b) \ge 0$. Additionally, since by construction $p_a, p_{b} \le p_x, p_y$, we know that $\Delta L \le 0$ after the exchange, so the cost is at least as good $\implies$ there exists an optimal tree with $a,b$ being siblings.</p>

<hr />

<p><em>Proof of Claim 1</em>: We will use induction to show that Huffman’s tree is the best amongst the sibling trees $T_{ab}$ where $a,b$ being the least frequent symbol are siblings. The trick is that we can do induction proof on $\Sigma’$-tree, where each step of the algorithm we “rename” the symbols instead of denoting them as subtree (e.g. merging $a,b$ gives the new symbol $ab$). Then note that the tree constructed in this notation is essentially the same as tree constructed in the original notation with $\Sigma$:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231011102337.png" style="zoom:80%;" /></p>

<p>with the only difference being $p_{ab} = p_a + p_b$, and the average leaf depth is the same up to a constant that is independent of the choice of the tree:</p>

\[L(T) = L(T') + p_a + p_b\]

<p>because the expanded tree has node $a,b$ being one level deeper. Now, we can very easily show that running Huffman on $\Sigma’$ (replacing $a,b$ with $ab$ and $p_{ab} = p_{a} + p_{b}$) using the <strong>induction hypothesis</strong> we left off earlier. Since now $\vert \Sigma’\vert  &lt; \vert  \Sigma\vert  = k$, <strong>Huffman algorithm returns the optimal tree $T’_{ab}$ for $\Sigma’$-tree</strong>.</p>

<p>Then, because each $\Sigma’$-tree correspond to $\Sigma$-tree (with $a,b$ being siblings) and the average leaf depth is preserved (up to a constant), then knowing an optimal tree in $\Sigma’$-tree, is knowing an optimal in $\Sigma$-tree with $a,b$ being siblings.</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231011102843.png" style="zoom:80%;" /></p>

<p>where RHS is what we just proved, and LHS is claim 1.</p>

<hr />

<p>Combining claim 1 and claim 2, the induction step is complete because by claim 1, Huffman outputs the best-possible tree from the restricted $T_{ab}$ set and by claim 2, such a tree $T_{ab}$ must be optimal.</p>

<h2 id="running-time-of-huffman-algorithm">Running Time of Huffman Algorithm</h2>

<p>The simple implementation would run in $O(n^{2})$, because we will merge in total $n-1$ times for $n = \left\vert \Sigma\right\vert$ , and each iteration needs to identify the two smallest trees in the forest, which takes $O(2n)$ time by simple scan. There, however, is a small change we can make it run a bit faster:</p>

<blockquote>
  <p><strong>Heap</strong>: a special Tree-based data structure in which the tree is a <strong>complete binary tree</strong>.</p>
  <ul>
    <li>Min-Heap: the key present at the <strong>root node must be minimum</strong> among the keys present at all of it’s children. The same property must be recursively true for all sub-trees in that Binary Tree.</li>
    <li>Max-Heap: the key present at the <strong>root node must be maximum</strong> among the keys present at all of it’s children. The same property must be recursively true for all sub-trees in that Binary Tree.
<img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231011111524.png" style="zoom:30%;" /></li>
  </ul>

  <p>and the key usage is that deleting the top element of the heap or the highest priority element, and then <strong>re-balancing the tree only takes $O(\log N)$</strong>. (Actually it is $O(H)$ for $H$ being the height of the tree, which is $\log N$ if it is a complete binary tree). Therefore each find min/find max operation takes $O(\log N)$ time.</p>
</blockquote>

<p>Therefore, since we are repeatedly finding the minimum, we can use a min-heap to store the nodes/symbols, and then each iteration we can delete the top two elements and insert the new node, which takes $O(\log n)$ time. Therefore, the overall running time is $O(n \log n)$.</p>

<h1 id="minimum-spanning-trees">Minimum Spanning Trees</h1>

<p>The MST problem is a uniquely great playground for the study of greedy algorithms, in which <em>almost</em> any greedy algorithm that you can think of turns out to be correct. The goal is to find, in a given graph $G= (V,E)$ with weight $w$ on edges, what is the best subset of edges $T \subseteq E$ such that the resulting graph with $T$ will:</p>
<ol>
  <li>spanning: <strong>connect every vertex in $V$ (i.e. one connected component)</strong></li>
  <li>tree: it is a spanning <em>tree</em>: there are <strong>no cycles</strong>.</li>
  <li>minium: it has the <strong>minimum total weight</strong></li>
</ol>

<blockquote>
  <p><strong>Minimum Spanning Tree Problem</strong>. Input undirected graph $G=(V,E)$ in which each edge $e$ has a real-valued cost $c_e$, and the goal is to output a minimum spanning tree $T \subseteq E$  of $G$.</p>
  <ul>
    <li>note that it would only make sense if $G$ is a connected graph, otherwise there is no spanning tree.</li>
  </ul>
</blockquote>

<p>For example, the red highlighted is a MST with cost $7$:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231013004832.png" style="zoom:80%;" /></p>

<h2 id="prims-algorithm">Prim’s Algorithm</h2>

<p>The algorithm closely resembles Dijkstra’s shortest-path algorithm, except that we have no ‘‘source vertex’’ and we are trying to find a spanning tree rather than a shortest-path. The idea is to greedily pick the cheapest edge that cross the frontier until done (starting from any random vertex).</p>

<p>So an example before we going to the pseudo code:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">iteration 1</th>
      <th>iteration 2</th>
      <th>iteration 3</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-          .png" style="zoom:100%;" /></td>
      <td><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231013005456.png" style="zoom:100%;" /></td>
      <td><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231013005519.png" style="zoom:100%;" /></td>
    </tr>
  </tbody>
</table>

<p>where we started from vertex $b$, and at each iteration we checked the all edge that cross the  “frontier” and picked the cheapest one. The pseudo code is:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">prim</span><span class="p">(</span><span class="n">G</span><span class="p">):</span>
  <span class="c1"># G is a connected graph with edge weights w
</span>  <span class="c1"># initialization
</span>  <span class="n">X</span> <span class="o">=</span> <span class="p">{</span><span class="n">s</span><span class="p">}</span>  <span class="c1"># s is an arbitrary vertex
</span>  <span class="n">T</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># output and also an INVARIANT: edges that span X
</span>
  <span class="k">while</span> <span class="n">X</span> <span class="o">!=</span> <span class="n">V</span><span class="p">:</span>
    <span class="c1"># find the cheapest edge (u,v) with u in X, v not in X
</span>    <span class="n">e</span> <span class="o">=</span> <span class="p">(</span><span class="n">u</span><span class="p">,</span><span class="n">v</span><span class="p">)</span> <span class="o">=</span> <span class="n">cheapest</span> <span class="n">edge</span> <span class="k">with</span> <span class="n">u</span> <span class="ow">in</span> <span class="n">X</span><span class="p">,</span> <span class="n">v</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">X</span>
    <span class="n">T</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
    <span class="n">X</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">T</span>
</code></pre></div></div>

<p>where :</p>
<ul>
  <li>one obvious implementation could give $O (mn)$ since you are looping over all vertices once (n times) and finding the cheapest edge (m times) for loop.</li>
  <li>we will first show that this indeed outputs a MST</li>
  <li>and then we will also see that the algorithm is correct no matter which vertex it chooses to start from</li>
</ul>

<h3 id="correctness-of-prims-algorithm">Correctness of Prim’s Algorithm</h3>

<p>Proving the correctness of Prim’s algorithm is a bit easier when all the edge costs are distinct (this is to just make the proof easier, the algorithm is still correct without it), and let us take that as an <mark>assumption</mark> for now.</p>

<p>To prove this, we consider showing two things:</p>
<ol>
  <li>Prim outputs a <em>tree</em> (with no cycles)</li>
  <li>The tree is <em>spanning and minimal</em>.
    <ul>
      <li>first show that every edge picked by Prim satisfies the “minimum bottleneck property”</li>
      <li>then we show that a spanning tree with only MBP edges is a MST</li>
    </ul>
  </li>
</ol>

<hr />

<p>Proof for claim 1: consider a generic graph $G$ that can have multiple connected components. Then consider adding one edge $(u,v)$:</p>
<ul>
  <li>Type 1: if $u,v$ already in the same CC:
    <ul>
      <li>this <strong>will create a cycle</strong> (because there was already path from $u$ to $v$)</li>
      <li><strong>number of CC remains the same</strong></li>
    </ul>
  </li>
  <li>Type 2: if $u,v$ in different CC:
    <ul>
      <li>this <strong>will not create a cycle</strong></li>
      <li><strong>number of CC decreases by 1</strong></li>
    </ul>
  </li>
</ul>

<p>to visualize this:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231013234626.png" style="zoom:60%;" /></p>

<p>where having the red edge will create a cycle, and the blue will not. Now, notice that in Prim’s algorithm, we will 1) start with $n$ distinct CCs, 2) add $n-1$ edges to the graph, and 3) finish with one CC. Therefore, every edge added must be type 2, and hence the output is a tree (graph with no cycle).</p>

<blockquote>
  <p>Note that the above also proved the statement: <strong>if $T \subseteq E$ has only $n-1$ edges AND the resulting graph is connected, then $T$ must be a tree</strong>.</p>
</blockquote>

<hr />

<p>Proof for claim 2: we need to first define the MBP property, prove that Prim’s algorithm only picks MBP, and finally prove that a tree with only MBP edges is a MST.</p>

<blockquote>
  <p><strong>Minimum Bottleneck Property</strong>: an edge $(u,v) \in E$ with cost $c_{uv}$ satisfies the MBP if and only if there is no $u \overset{p}{\leadsto} v$ path that consists solely of edges with cost less than $c_{uv}$.</p>
  <ul>
    <li>i.e. for any other path you can think of, there is <em>at least one edge</em> that is more expensive than $(u,v)$</li>
  </ul>
</blockquote>

<p>For example, in the following graph, edge $(a,d)$ does not satisfy MBP, but edge $(a,c)$ does:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231013235651.png" style="zoom:80%;" /></p>

<p>Now, we prove that <strong>Prim’s algorithm only picks MBP edges</strong>. The trick is to realize that <strong>any path (see below) $v^{<em>} \leadsto w^{</em>}$ will have at least one edge that crosses the frontier</strong>. Since Prim picks the cheapest such edge, all other path must have at least one edge that is more expensive than the one picked by Prim.</p>

<p>To see this more concretely, consider the same argument as from Dijkstra’s proof. Consider an edge $(v^{<em>}, w^{</em>})$ chosen in an iteration of Prim’s algorithm, with $v^{<em>} \in X$ and $w \notin X$. Now, consider any arbitrary path $v^{</em>} \overset{p}{\leadsto} w^{*}$:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231013235845.png" style="zoom:70%;" /></p>

<p>Note that since $w^{*} \notin X$, at some point the path will go inside the frontier to the outside. Let that happen with edge $(x,y)$ crossing the frontier in that path. However, since Prim guaranteed:</p>

\[c_{v^{*}w^{*}} \le c_{xy}\]

<p>for every edge $(x,y)$ that crosses the frontier. Now, since this means there is at least one edge on any other path that will exceeded $c_{v^{<em>}w^{</em>}}$, we know that $(v^{<em>}, w^{</em>})$ satisfies the MBP.</p>

<p>Finally, we need to show that <strong>a tree with only MBP edges is a MST</strong>. To show this, we consider by contradiction that there is a MST $T^{*}$ that does not have the MBP property all the way but still has the minimum cost.(shown in solid lines):</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231014000728.png" style="zoom:70%;" /></p>

<p>Let Prim’s tree be $T$. Since $T \neq T^{<em>}$, there is at least one MBP edge, e.g. $e_1=(u,v)$, that is not in $T^{</em>}$. Since $T^{<em>}$ is a tree, there exists a path $u \overset{p}{\leadsto} v$. But since $e_1$ is an MBP edge, this means there exists an edge $e_2$ on $u \overset{p}{\leadsto} v$ that has cost *higher</em> than $e_1$. Now, consider an <mark>exchange argument</mark> that:</p>
<ol>
  <li>we add $e_1$ to $T^{*}$. This is a type 1 edge and will create a cycle and does not increase the number of CC (still one)</li>
  <li>Remove $e_2$ from $T^{*}$. Since you are removing an edge from the cycle, this is undoing type 1 edge and also does not increase the number of CC (still one)</li>
</ol>

<p>Now, we obtain $T’$:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231014001152.png" style="zoom:70%;" /></p>

<p>where by the above argument, $T’$ has also just $n-1$ edges and is connected $\implies$ $T’$ is a valid spanning tree. However, since $\mathrm{cost}(e_1) \le  \mathrm{cost}(e_2)$ by MBP, then cost of $T’$ is less than $T^{<em>}$, which is a contradiction. Therefore, every edge in $T^{</em>}$ must satisfy MBP to be MST, and hence Prim’s $T$ is a MST.</p>

<blockquote>
  <p><strong>Note</strong>: from HW 5, you can also show that the converse is true: every edge on a MST must satisfy MBP.</p>
  <ul>
    <li>this does <mark>not imply your MST will include every $(u,v)$ edge that is MBP</mark>, because having $u,v$ being connected in your MST may not even require having a $u\to v$ edge).</li>
  </ul>
</blockquote>

<h3 id="running-time-of-prims-algorithm">Running Time of Prim’s Algorithm</h3>

<p>The obvious runtime we discussed is $O(nm)$, but notice that it was <strong>repeatedly doing extract min</strong>. This hints at using a heap data structure.</p>

<blockquote>
  <p><strong>Recall: (min-)Heap</strong>: a special Tree-based data structure in which the tree is a <strong>complete binary tree</strong>, such that you can <code class="language-plaintext highlighter-rouge">insert</code> a new node with (key, value) pair into the tree, <code class="language-plaintext highlighter-rouge">extract_min</code> to get the node with the smallest key and rebalance the tree, and <code class="language-plaintext highlighter-rouge">delete</code> to remove a node from the tree and rebalance the tree. The tree <code class="language-plaintext highlighter-rouge">orders</code> nodes by the keys, and <strong>all of these operations take $O(\log n)$ time</strong>.</p>
  <ul>
    <li>how? a short peek into the implementation is that you either percolate up or percolate down the tree to rebalance it</li>
    <li>e.g. fo insert, you add the new node at the bottom, and then percolate up (swap with parent if this is smaller until done). Since the height of the tree is $O(\log n)$, this takes $O(\log n)$ time.</li>
  </ul>
</blockquote>

<p>To use <code class="language-plaintext highlighter-rouge">heap</code> for Prim, since we are repeatedly picking the minimum cost edge that <em>crossed the frontier</em>, we want the heap to:</p>
<ul>
  <li>Invariant 1: only store edges that cross the frontier</li>
  <li>Invariant 2: for each $v \notin X$, we will always keep $\mathrm{key}(v)=$ cheapest edge $(u,v)$ that crosses the frontier with $u \in X$. If no such edge exist for a node, store $\infty$.</li>
</ul>

<p>For example, invariant 2 would look like:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231014003326.png" style="zoom:70%;" /></p>

<p><em>If the above two invariant hold</em> for every iteration of our implementation, then it is obvious that taking the minimum from such heap $\implies$ cheapest edge amongst the cheapest for each nod $\notin X$  $\implies$ the cheapest edge that crosses the frontier.</p>

<p>How to we keep the two invariants? Invariant 1 hold easily because after we <code class="language-plaintext highlighter-rouge">extract_min</code> we removed the $(u,v)$ from the heap $\iff$ that $v$ was outside $X$ is now inside the frontier. So it is automatically satisfied. But after <code class="language-plaintext highlighter-rouge">extract_min</code>, e.g. we took vertex $x$ from the above image to $X$, some of the $\mathrm{key}(v)$ might need to be updated (e.g. that of vertex $z$). But note that since <strong>our frontier only changed by that newly added vertex</strong>, we only need to <strong>update keys related to that vertex!</strong> Specifically, we need to:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># w* is just extracted
</span>
<span class="c1"># for every edge from w* that crossed the frontier
</span><span class="k">for</span> <span class="n">every</span> <span class="n">edge</span> <span class="p">(</span><span class="n">w</span><span class="o">*</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="k">with</span> <span class="n">y</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">X</span><span class="p">:</span>
    <span class="c1"># update the new min cost for y = key(y)
</span>    <span class="k">if</span> <span class="n">c_w</span><span class="o">*</span><span class="n">y</span> <span class="o">&lt;</span> <span class="n">key</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
      <span class="n">delete</span> <span class="n">y</span> <span class="k">from</span> <span class="n">heap</span>
      <span class="n">key</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="n">c_w</span><span class="o">*</span><span class="n">y</span>
      <span class="n">best_edge</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="p">(</span><span class="n">w</span><span class="o">*</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
      <span class="n">insert</span> <span class="n">y</span> <span class="n">into</span> <span class="n">heap</span>
</code></pre></div></div>

<p>Now, the full algorithm looks like:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="k">def</span> <span class="nf">prim_w_heap</span><span class="p">(</span><span class="n">G</span><span class="p">):</span>
  <span class="n">X</span> <span class="o">=</span> <span class="p">{</span><span class="n">s</span><span class="p">}</span>  <span class="c1"># s is an arbitrary vertex
</span>  <span class="n">T</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># output and also an INVARIANT: edges that span X
</span>  <span class="n">H</span> <span class="o">=</span> <span class="n">heap</span><span class="p">()</span>  <span class="c1"># heap of edges that cross the frontier
</span>
  <span class="c1"># initialization
</span>  <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">V</span> <span class="ow">and</span> <span class="n">v</span> <span class="o">!=</span> <span class="n">s</span><span class="p">:</span>
    <span class="c1"># for every edge that crosses the frontier s
</span>    <span class="k">if</span> <span class="p">(</span><span class="n">s</span><span class="p">,</span><span class="n">v</span><span class="p">)</span> <span class="ow">in</span> <span class="n">E</span><span class="p">:</span>
      <span class="n">key</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="o">=</span> <span class="n">c_s</span><span class="o">*</span><span class="n">v</span>
      <span class="n">best_edge</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="o">=</span> <span class="p">(</span><span class="n">s</span><span class="p">,</span><span class="n">v</span><span class="p">)</span>
      <span class="n">insert</span> <span class="n">v</span> <span class="n">into</span> <span class="n">H</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">key</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="o">=</span> <span class="n">inf</span>
      <span class="n">best_edge</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="o">=</span> <span class="bp">None</span>
  
  <span class="c1"># main loop
</span>  <span class="c1"># if H is empty, then there is no vertex NOT in X = we are done!
</span>  <span class="k">while</span> <span class="n">H</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">empty</span><span class="p">:</span>
    <span class="c1"># extract the cheapest edge that crosses the frontier
</span>    <span class="n">w</span><span class="o">*</span> <span class="o">=</span> <span class="n">extract_min</span><span class="p">(</span><span class="n">H</span><span class="p">)</span>
    <span class="n">T</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">best_edge</span><span class="p">(</span><span class="n">w</span><span class="o">*</span><span class="p">))</span>  <span class="c1">##### greedy choice
</span>    <span class="n">X</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">w</span><span class="o">*</span><span class="p">)</span>

    <span class="c1"># update the keys for every edge from w* that crossed the frontier
</span>    <span class="k">for</span> <span class="n">every</span> <span class="n">edge</span> <span class="p">(</span><span class="n">w</span><span class="o">*</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="k">with</span> <span class="n">y</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">X</span><span class="p">:</span>
      <span class="c1"># update the new min cost for y = key(y)
</span>      <span class="k">if</span> <span class="n">c_w</span><span class="o">*</span><span class="n">y</span> <span class="o">&lt;</span> <span class="n">key</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
        <span class="n">delete</span> <span class="n">y</span> <span class="k">from</span> <span class="n">heap</span>
        <span class="n">key</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="n">c_w</span><span class="o">*</span><span class="n">y</span>
        <span class="n">best_edge</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="p">(</span><span class="n">w</span><span class="o">*</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">insert</span> <span class="n">y</span> <span class="n">into</span> <span class="n">heap</span>
  <span class="k">return</span> <span class="n">T</span>
</code></pre></div></div>

<p>So what is the runtime of this?</p>

<ul>
  <li>initialization phase performs does $n-1$ heap insert (i.e. once for every vertex not $s$), and $O(m)$ additional work as it checks the edges. So this takes $O(n \log n + m)$ time.</li>
  <li>the main while loop goes for $n-1$ iterations, and inside it at least does extract mins. This is already $O(n \log n)$. But additionally, notice there is also a for loop. However, realize that each edge of $G$ will enter this for loop exactly once, at the time when first of its endpoints get sucked into $X$. Therefore, since there are $m$ edges, this will give in total for the entire algrithm $O(m \log n)$.</li>
</ul>

<p>Hence adding up we get:</p>

\[O((n+m) \log n) = O(m \log n)\]

<p>since for a connected graph $G$, the least number of edges is $m \ge n-1$. Therefore, you can simplify the above to $O(m \log n)$.</p>

<h2 id="kruskals-algorithm">Kruskal’s Algorithm</h2>

<p>Why this in addition to Prim?</p>
<ul>
  <li>provides an opportunity to study a new and useful data structure, the disjoint-set or <strong>union-find</strong> data structure.</li>
  <li>there are some very cool connections between Kruskal’s algorithm and widely-used <strong>clustering</strong> algorithms</li>
</ul>

<p>Similar to Prim, this algorithm is greedy. Different from Prim’s algorithm which grows a single tree from a starting vertex, <strong>Kruskal can grow multiple trees in parallel</strong>, and coalesce into a single tree only at the end of the algorithm.</p>

<blockquote>
  <p><strong>Idea</strong>: repeatedly (greedily) pick the cheapest edge that does not create a cycle, until done.</p>
</blockquote>

<p>For example:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">iteration 1</th>
      <th style="text-align: center">iteration 2</th>
      <th style="text-align: center">iteration 3</th>
      <th style="text-align: center">iteration 4</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231018005153.png" style="zoom:100%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231018005200.png" style="zoom:100%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231018005216.png" style="zoom:100%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231018005224.png" style="zoom:100%;" /></td>
    </tr>
  </tbody>
</table>

<p>where we started with $T$ being empty, and at each iteration we picked the cheapest edge that does not create a cycle. The pseudo code is:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">kruskal</span><span class="p">(</span><span class="n">G</span><span class="p">):</span>
  <span class="c1"># G=(V,E) with costs c_e for each e in E
</span>  <span class="n">T</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># output
</span>  <span class="n">sorted_edges</span> <span class="o">=</span> <span class="n">sort</span><span class="p">(</span><span class="n">E</span><span class="p">)</span>  <span class="c1"># sort edges by increasing cost
</span>  <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">sorted_edges</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">adding</span> <span class="n">e</span> <span class="n">to</span> <span class="n">T</span> <span class="n">does</span> <span class="ow">not</span> <span class="n">create</span> <span class="n">a</span> <span class="n">cycle</span><span class="p">:</span>
      <span class="n">T</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">T</span>
</code></pre></div></div>

<p>note that similar to Prim, it requires a connected undirected graph $G=(V,E)$ with edge weights $c_e$ for each $e \in E$.</p>

<p>A straight-forward runtime for this algorithm is:</p>

\[O(m \log m) + O(m n) = \log(m \log n) + O(mn) = O(mn)\]

<p>where:</p>
<ul>
  <li>$O(m \log m) = O(m \log n)$ because we know $m \le n^{2}$, hence $O(\log m) = O(2 \log n)$. This equality will be used later as well</li>
  <li>$O(mn)$ because you can search for cycles in $O(m)$ time using DFS/BFS (this is equivalent to <mark>checking if the new edge $e=(u,v)$ are already reachable</mark>).</li>
</ul>

<p>Before we discuss how to make this faster using union-find, we need to first prove that this algorithm is correct. Without prior context, it is hard to see why this produces a tree that <em>spans all vertices</em>.</p>

<h3 id="correctness-of-kruskals-algorithm">Correctness of Kruskal’s Algorithm</h3>

<p>This section proves Kruskal’s algorithm is correct, under the simlar assumption that all edge costs are distinct (this is to just make the proof easier, and does not affect the algorithm’s correctness).</p>

<p>It is obvious that Kruskal produces <em>no cycles</em>, but we need to show that:</p>
<ol>
  <li>the output is <em>connected</em></li>
  <li>the output is a <em>spanning tree</em></li>
  <li>the output is <em>minimal</em> (by achieving MBP)</li>
</ol>

<hr />

<p><em>Proof for Claim 1</em>: Consider $T$ be the set of edges chosen by Kruskal so far, and that in this iteration Kruskal just finished examining an edge $e = (v,w)$. Then in the algorithm:</p>

<ul>
  <li>if $v,w$ are already in the same CC, then adding $e$ will create a cycle, so this is skipped</li>
  <li>otherwise, $(v,w)$ is added to $T$, fusing their CCs into one</li>
</ul>

<p>Therefore, just after this $(v,w)$ will be <strong>in the same CC</strong>. Since this is true for every iteration, we know that at the end of the algorithm, all vertices (since it will check all edges and the input graph is connected) will be in the same CC, and hence the output is connected.</p>

<hr />

<p><em>Proof for Claim 2</em>: since the algorithm explicitly ensures that the output is acyclic, and we just showed that all its vertices belong to the same CC, then it is a tree.</p>

<hr />

<p><em>Proof for Claim 3</em>: We prove by contrapositive, that Kruskal never includes an edge that is NOT MBP. To show this, consier an edge not being a MBP, and we want to show that Kruskal’s algorithm will never include it.</p>

<p>Let $e=(v,w)$ be not a MBP. Then there exists a path $v \overset{p}{\leadsto} w$ that consists <strong>solely of edges with cost less than $c_{vw}$</strong>. Because Kruskal scans through (greedily) the edges in non-decreasing cost, all edge of $P$ will be checked before $e$. From claim 1, we know that once an edge $e’=(x,y)$ is checked, both $x,y$ are in the same CC. Therefore, when we reached $e=(v,w)$, we know that $v,w$ are already in the same CC, and hence adding $e$ will create a cycle. Therefore, Kruskal will never include $e$.</p>

<p>Visually, by the time we are checking the black $e$ edge, we would have checked all the blue edges:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231018012523.png" style="zoom:50%;" /></p>

<hr />

<h3 id="speeding-up-kruskal-with-union-find">Speeding up Kruskal with Union-Find</h3>

<p>Prim’s algorithm is sped up using a genric data structure called heap, and Kruskal can also be sped up using a data structure called <strong>union-find</strong>.</p>

<blockquote>
  <p><strong>Union-Find Data Structure</strong>: the goal is to maintain a partition of a static set of objects. This is often used to efficiently track and manipulate connected components or disjoint sets. It supports the following operations:</p>
  <ul>
    <li><code class="language-plaintext highlighter-rouge">Initialization</code>: create a new union-find data structure with $n$ objects ($O(n)$)</li>
    <li><code class="language-plaintext highlighter-rouge">Union</code>: given two objects form a (different) union, merge the two sets into a single set</li>
    <li><code class="language-plaintext highlighter-rouge">Find</code>: determine which set a given object belongs to</li>
  </ul>
</blockquote>

<p>note that (though not used by Kruskal), with a good implementation the <code class="language-plaintext highlighter-rouge">Union</code> and <code class="language-plaintext highlighter-rouge">Find</code> operations both take time logarithmic in the number of objects. Since Kruskal itreatively <strong>checks connected components (if there is a cycle) and grow them</strong>, we can visualize the process as:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231018013613.png" style="zoom:100%;" /></p>

<p>such that finding if two vertices are in the same CC is just checking if they have the same root in a <code class="language-plaintext highlighter-rouge">union</code>. So instead of a DFS/BFS, we could just have done it in $O(1)$ by comparing if the two vertices have the same root! But how does union-find work?</p>

<hr />

<p><em>Quick-and-Dirty Implementation of Union-Find</em>.</p>

<p>The datastructure can be implemented by an array, where each index position represent a vertex $v \in V$, and stores the <strong>parent</strong> vertex (e.g., a root vertex representing the CC).</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Implementation</th>
      <th style="text-align: center">Visualization</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231018105402.png" style="zoom:100%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231018105314.png" style="zoom:15%;" /></td>
    </tr>
  </tbody>
</table>

<p>where in the drawing, the green vertices and edges are the original graph. The black circle highlights the ‘‘leader’’ representing this CC, and the red edges represent which vertex is the parent of which. This red graph is sometimes also called <mark>the parent graph</mark>.</p>

<p>With the notion that it stores the parent graph, the rest is easy:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">initialize</code>: for each $i=1,2,3, … , n$, initialize $parent[i] = i$ (i.e. each vertex is its own parent)
    <ul>
      <li>therefore, this takes $O(n)$ cost</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">find</code>: given a vertex $v$, repeatedly check $parent[v]$, until $parent[v] = v$ (i.e. $v$ is its own parent).
    <ul>
      <li>therefore, this takes $O(\mathrm{depth})$ of the parent tree</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">union</code> pick the union $x$ that has a larger size (with the parent keep a field <code class="language-plaintext highlighter-rouge">size</code>), and let the other union be $y$. Find the root of both unions, let them be $i,j$. Then set $parent[j] = i$ and update the <code class="language-plaintext highlighter-rouge">size</code>.
    <ul>
      <li>if we don’t merge the smaller one with the larger one so that our size <em>at least doubles</em>, we cannot get the logarithmic runtime</li>
      <li>if we don’t merge with the root node, then the depth of vertices in $y$ will increase by <em>more than one</em>, impacting runtime. Visually for <code class="language-plaintext highlighter-rouge">union</code> if done o non-root node:
<img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231018110926.png" style="zoom:80%;" /></li>
    </ul>
  </li>
</ul>

<hr />

<p>Now, we can implement Kruskal’s algorithm in $O((m+n) \log n)$ time. The idea is to:</p>

<ul>
  <li><strong>the parent pointer <em>all</em> point to the root of a CC</strong>, so that finding the root is $O(1)$. This means checking if two vertices are in the same CC is $O(1)$.</li>
  <li>to maintain the above invariant, when an edge $e=(u,v)$ is picked, <strong>merge all members of the smaller union into the larger union</strong>. Note that this is <em>not $O(n)$</em> for each merge:
    <ul>
      <li>each vertex can only be called to be merged/updated $\log_{2}$ times since each merge at least double the size.</li>
      <li>since there are in total $n$ vertices, the total cost in the entire algorithm is $n \log n$.</li>
    </ul>
  </li>
</ul>

<p>So finally we get preprocessing $O(m \log n)$, cycle check $O(m)$, and union update $O(n \log n)$, which gives $O((m+n) \log n)$.</p>

<h2 id="clustering">Clustering</h2>

<p>We will show that one <strong>application</strong> of Kruskal’s algorithm is to solve a problem called <strong>clustering</strong>. The goal is to partition a set of objects into a collection of clusters, such that given $n$ data points, they are classified into a coherent group:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231018111845.png" style="zoom:100%;" /></p>

<p>to do this, we assume that we are given:</p>

<ol>
  <li>a distance measure $d(p,q)$ between each pair of data points</li>
  <li>a distance measure being symmetric</li>
  <li>we’ve decided to get to $k$ clusters</li>
</ol>

<p>There are many ways to do this (e.g. bottom-up, top-down, k-means). Here we discuss <strong>bottom-up</strong> or <strong>agglomerative</strong> clustering is to begin with every data point in its own cluster, and then successively merge pairs of clusters until exactly $k$ remain.</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231018112326.png" style="zoom:100%;" /></p>

<blockquote>
  <p><strong>so the key part</strong> is how to decide which two clusters to merge at each step.</p>
</blockquote>

<p>Here we discuss one way to do it: <strong>single-link clusering</strong>, where we are optimistic such that we consider two clusters to be similar if their <strong>closest points are close</strong>. Formally, let the similarity measure between <em>two clusters</em> being $F$, then:</p>

\[F(S_1, S_2) = \min_{p \in S_1, q \in S_2} d(p,q)\]

<p>Therefore our single-link bottom up clustering algorithm is:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">bottom_up</span><span class="p">():</span>
  <span class="k">while</span> <span class="n">C</span> <span class="n">contains</span> <span class="n">more</span> <span class="n">than</span> <span class="n">k</span> <span class="n">clusters</span><span class="p">:</span>
    <span class="n">C1</span><span class="p">,</span> <span class="n">C2</span> <span class="o">=</span> <span class="n">closest</span> <span class="n">pair</span> <span class="n">of</span> <span class="n">clusters</span> <span class="ow">in</span> <span class="n">C</span>
    <span class="n">remove</span> <span class="n">C1</span> <span class="ow">and</span> <span class="n">C2</span> <span class="k">from</span> <span class="n">C</span>
    <span class="n">add</span> <span class="n">C1</span> <span class="n">union</span> <span class="n">C2</span> <span class="n">to</span> <span class="n">C</span>
  <span class="k">return</span> <span class="n">C</span>
</code></pre></div></div>

<p>note that one advantage of bottom-up algorithm is that during the process of running this, you <mark>also get the result for all $k' &lt; k$</mark>!</p>

<blockquote>
  <p><strong>Connection to Kruskal’s Algorithm</strong>: recall that in kruskal we “merge” two vertices if they are the <em>smallest edge</em> and <em>are in different CC</em>. This has great similarilty to merging two clusters if the simialrlity function checks the best pair of points from each cluster. In fact, the two are exactly the same except that in Kruskal does not stop at $k$</p>
  <ul>
    <li>define a complete undirected graph $G=(X,E)$ from the dataset $X$, such that $E$ represent every pair of points in $X$, and the edge costs are $d(p,q)$</li>
    <li>run kruskal on $G$ until $k$ connected components, return the tree $(X,T)$</li>
    <li>compute the connected components of $(X,T)$, which is the clustering result</li>
  </ul>
</blockquote>

<h1 id="introduction-to-dynamic-programming">Introduction to Dynamic Programming</h1>

<p>Most people initially find dynamic programming difficult and counterintuitive. However, this is relatively formulaic hence can be learned with practice. In this section, we are getting warmed up with some simple examples.</p>

<h2 id="weighted-independent-set">Weighted Independent Set</h2>

<p>First, some terminologies</p>

<blockquote>
  <p><strong>Independent Set</strong>: a subset of vertices $S \subseteq V$ such that no two vertices in $S$ are adjacent. More formally, every $v,w \in S$ has $(v,w)\notin E$.</p>
</blockquote>

<p>For example, in the two graphs below</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Graph 1</th>
      <th style="text-align: center">Graph 2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231019225023.png" style="zoom:80%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231019225032.png" style="zoom:80%;" /></td>
    </tr>
  </tbody>
</table>

<ul>
  <li>the first graph has six independent sets: $\emptyset$ and five singletons</li>
  <li>the second has the same six independent sets that the complete graph does, plus some (five) independent sets of size two. In total eleven.</li>
</ul>

<blockquote>
  <p><strong>Weighted Independent Set Problem</strong>: given an undirected grpah $G=(V,E)$ and a non-negative weight $w_v$ for each <em>vertex</em> $v \in V$, find an independent set $S \subseteq V$ of maximum total weight (of the vertices).</p>
  <ul>
    <li>the solution is also called a <strong>maximum-weight independent set (MWIS)</strong></li>
    <li>e.g., if vertices represent courses, vertex weights represent units, and edges represent conflicts between courses, the MWIS corresponds to the feasible course schedule with the heaviest load (in units)</li>
  </ul>
</blockquote>

<p>This is quite a difficult problem <mark>even if we just consider path graphs to be $G$</mark></p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231019225607.png" style="zoom:100%;" /></p>

<p>where by looking at it we can see the solution is $8$.</p>
<ul>
  <li>if we do <strong>exhaustive</strong> search, notice that there are <strong>8 independent sets</strong>. This will grow exponentially (consider adding one more vertex to the path graph, and think about how many more independent sets you will have).</li>
  <li>if we do <strong>greedy</strong>, maybe consider simply start picking from the largest vertex (i.e., with weight 5). Immediately you got the wrong answer.</li>
  <li>if we do <strong>divide-and-conquer</strong> is natural if we can break this into smaller subproblems. So we can consider maybe recursively computing MIS of the left half, the right half, and merge? But the problem is how do we merge to keep the independence?</li>
</ul>

<h2 id="linear-time-algorithm-for-wis-in-path-graph">Linear-Time Algorithm for WIS in Path Graph</h2>

<blockquote>
  <p>Insight: the trick for DP is to consider how an optimal solution must be <strong>constructed in a prescribed way from optimal solutions to smaller subproblems</strong>, and vice versa</p>
</blockquote>

<p>This feels very similar to divide-and-conquer, so here I hightlight the difference (from stackoverflow):</p>
<ul>
  <li>DnC:
    <ul>
      <li>dividing the problem into sub-problems, <strong>conquer each sub-problem independently</strong> and combine these solutions.</li>
      <li>Most of the canonical applications of the divide-and-conquer paradigm replace a straightforward polynomial-time algorithm</li>
    </ul>
  </li>
  <li>DP:
    <ul>
      <li>solving problems with <strong><mark>overlapping</mark> subproblems</strong>. Each sub-problem is solved only once and the result of each sub-problem is usually stored in a table (generally implemented as an array or a hash table) for future references.</li>
      <li>The killer applications of dynamic programming are polynomial-time algorithms for optimization problems for which straightforward solutions (like exhaustive search) require an exponential amount of time.</li>
    </ul>
  </li>
</ul>

<blockquote>
  <p><strong>WIS in Path Graph Problem</strong>. Consider $G=(V,E)$ being a $n$-vertex path graph with edges $(v_1, v_2), (v_2, v_3), …, (v_{n-1}, v_n)$ and a non-negative weight $w_i$ for each vertex $v_{i} \in V$.  Find an independent set $S \subseteq V$ of maximum total weight (of the vertices).</p>
</blockquote>

<p>Suppose we are given an optimal solution MWIS $S \subseteq V$ with total weight $W$. <mark>What can we say about $S$? What can we say about the solution to a smaller subproblem given $S$?</mark></p>

<p>The trick to this problem is that $S$ either contains the last vertex $v_n$ or doesn’t. We have two cases:</p>

<ol>
  <li>$v_n \notin S$. Then let $G’ = G$ without $v_n$. This would mean that:
    <ul>
      <li>the set $S$ is also an independent set in $G’$, and since $S$ is the MWIS in $G$, then <em>$S$ is also the MWIS in $G’$</em>.</li>
      <li>we can show the above (MWIS for $G’$) by contradiction: if there is $S^{<em>}$ that is MWIS for $G’$ with weight larger than $S$, then this means $S^{</em>}$ would also be an independent set with larger weight than $S$ in $G$, which is a contradiction.</li>
    </ul>

    <p>in other words, <em>if you know MWIS for $G’$</em> and <em>you know $v_n \notin S$</em>, then you can just use the MWIS for $G’$ as the MWIS for $G$.</p>
  </li>
  <li>$v_{n} \in S$. Then since $S$ is an indepednt set, we know that the penultimate vertex is not there.
<img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231019232103.png" style="zoom:70%;" />
Therefore, we can consider $G’’$ to be $G$ without $v_n$ and $v_{n-1}$. Then we can show that:
    <ul>
      <li>$S - {v_n}$ is an independent set for $G’’$, and since $S$ is the MWIS in $G$, then <em>$S - {v_n}$ is also the MWIS in $G’’$</em>.</li>
      <li>again can be proven by contradiction using a simlar logic as above.</li>
    </ul>
  </li>
</ol>

<p>in other words, <em>if you know MWIS for $G’’$</em> and <em>you know $v_n \in S$</em>, then you can just use the MWIS for $G’’$ as the MWIS for $G$.</p>

<blockquote>
  <p>The upshot of the above analysis is that <mark>now you have a recipe for building UP a solution</mark> from subproblems:
Let $S$ be an MWIS for $G$ with at least two vertices, and the nwe can find $S$ must be either</p>
  <ol>
    <li>an MWIS for $G’=G_{n-1}$ (i.e. without $v_n$)</li>
    <li>an MWIS for $G’‘=G_{n-2}$ plus $v_n$</li>
  </ol>

  <p>where $G_i$ denote the subgraph comprising its first $i$ vertices.</p>
</blockquote>

<p>So all we need to do is to solve small problem, and then build up. Now how do we implement this?</p>

<hr />

<p><em>Naive Recursive Approach</em> from divide-and-conquer. Since the best solution is either of the two, we can just try both and return the max!</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">recursive_mwis</span><span class="p">(</span><span class="n">G</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">G</span> <span class="n">has</span> <span class="n">no</span> <span class="n">vertices</span><span class="p">:</span>
    <span class="k">return</span> <span class="mi">0</span>
  <span class="k">elif</span> <span class="n">G</span> <span class="n">has</span> <span class="n">one</span> <span class="n">vertex</span><span class="p">:</span>
    <span class="k">return</span> <span class="p">{</span><span class="n">v1</span><span class="p">}</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="c1"># case 1: MWIS for G' without v_n
</span>    <span class="n">mwis1</span> <span class="o">=</span> <span class="n">recursive_mwis</span><span class="p">(</span><span class="n">G</span> <span class="n">without</span> <span class="n">v_n</span><span class="p">)</span>
    <span class="c1"># case 2: MWIS for G'' without v_n and v_{n-1}
</span>    <span class="n">mwis2</span> <span class="o">=</span> <span class="n">recursive_mwis</span><span class="p">(</span><span class="n">G</span> <span class="n">without</span> <span class="n">v_n</span> <span class="ow">and</span> <span class="n">v_</span><span class="p">{</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">})</span> <span class="o">+</span> <span class="n">v_n</span>
    <span class="k">return</span> <span class="n">max_weight</span><span class="p">(</span><span class="n">mwis1</span><span class="p">,</span> <span class="n">mwis2</span><span class="p">)</span>
</code></pre></div></div>

<p>This is guaranteed to be correct using proof by induction and the property of $S$ we just proved. But what is the runtime? <strong>Exponential!</strong></p>

<ul>
  <li>each recursive call only throws away one or two vertices, so there are $O(n)$ height in the recursion tree (compared to the ‘correct’ DnC ones, there were only logarithmic height)</li>
  <li>since the branching factor is 2, this gives $O(2^{n})$ number of leaves!</li>
</ul>

<p>The key difference now, between DP and DnC is that DP could <em>avoid a lot of computation</em> by <strong>memoizing</strong> the results of subproblems. Why is this related in this context? Consider <mark>how many distinct subproblem did the recursive algorithm solve</mark>?</p>
<ul>
  <li>since each subproblem is defined by the input graph, this is equivalent to how many distinct graphs we are solving</li>
  <li>the answer is $n+1$ since each time we are removing graphs from the tail! (empty graph, $G_1$, …, $G_n$).</li>
</ul>

<p>Therefore, we could cache the results of each subproblem, and then we can just look it up when we need it. This is called <strong>memoization</strong>. Implementation-wise, we can just use an array, where $A[i]$ represent the MWIS of $G_i$. However to <em>really see the runtime speed up</em>, the more direct way is to <mark>build from bottom up</mark>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">wis</span><span class="p">(</span><span class="n">G</span><span class="p">):</span>
  <span class="n">A</span> <span class="o">=</span> <span class="p">[]</span> <span class="o">*</span> <span class="p">(</span><span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># solutions for n+1 subproblems
</span>  <span class="n">A</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">A</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">w1</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="n">wi</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">A</span><span class="p">[</span><span class="n">n</span><span class="p">]</span>
</code></pre></div></div>

<p>note that now:</p>
<ul>
  <li>this is DP</li>
  <li>this is clearly linear time</li>
  <li>but it only returns the maximum weight, not the vertices themselves. Therefore a <mark>common step after DP is a postprocessing *reconstruction algorithm*</mark>
    <ul>
      <li>though you can hack this <code class="language-plaintext highlighter-rouge">wis</code> to also let $A$ store the vertices of an MWIS of $G_i$, the reconstruction algorithm is more genreally memory and time efficient</li>
    </ul>
  </li>
</ul>

<h2 id="reconstruction-algorithm-mis">Reconstruction Algorithm (MIS)</h2>

<p>Typically when you have a DP, you would have a reconstruction algorithm easily defined based on the same principle as the algorithm you came up with.</p>

<p>Consider back to the question: is $v_{n}$ included in the solution? Since we know $A$, we can actually answer this question immediately by looking at $A[n-1]$ and $A[n-2]$:</p>

<ul>
  <li>if $A[n-1] \ge A[n-2] + w_n$, then $v_n$ is not in the solution. Continue the process with thinking about $v_{n-1}$</li>
  <li>otherwise, $v_n$ is in the solution. Continue the process with thinking about $v_{n-2}$</li>
</ul>

<p>therefore the reconstruction algorithm is:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">wis_reconstruction</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">A</span><span class="p">):</span>
  <span class="c1"># A is the array we computed from `wis`
</span>  <span class="n">S</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># the solution
</span>  <span class="n">i</span> <span class="o">=</span> <span class="n">n</span>
  <span class="k">while</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="mi">2</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="n">wi</span><span class="p">:</span>
      <span class="n">i</span> <span class="o">-=</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">S</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">v_i</span><span class="p">)</span>
      <span class="n">i</span> <span class="o">-=</span> <span class="mi">2</span>
  <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">S</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">v_1</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">S</span>
</code></pre></div></div>

<p>wich is like doing a <mark>single backward pass</mark>, which runs in $O(n)$ to get us the real solution.</p>

<blockquote>
  <p>Note: <strong>the full MWIS problem on arbitrary graph is NP-complete</strong>. Even though we know that from HW 6, the following relation hold for arbirary graph:</p>

\[W_{G} = \max\{W_H, W_K + w_v\}\]

  <p>where $G$ is the <code class="language-plaintext highlighter-rouge">'original</code> graph, $H$ is the graph without $v$, $K$ is the graph without $v$ and $v$’s neighbor, and $w_v$ is the weight of $v$. So why does not NOT lead to linear time algorithm? The number of times you will need to lookup a subproblem’s solution is NOT constant!</p>
</blockquote>

<h2 id="principles-of-dynamic-programming">Principles of Dynamic Programming</h2>

<p>The above example showcase a paradigm in DP:</p>

<blockquote>
  <p><strong>DP Paradigm</strong>: we begin by thinking about the <em>optimal solution if we are given the optimal solution of smaller problems (and vice versa)</em>. Then:</p>
  <ol>
    <li>identify a relatively small number of subproblems (otherwise the runtime will be exponential)</li>
    <li>show how to quickly and correctly solve a larger problem using the solutions to a small number of subproblems</li>
    <li>quickly and correctly infer the final solution from the computed subproblem solutions (e.g. reconstruction algorithm)</li>
  </ol>
</blockquote>

<p>More specifcally, DP under this paradigm would be <em>fast</em> if we consider the runtimes:</p>

\[\underbrace{f(n)}_{\text{\# subproblems}} \times \underbrace{g(n)}_{\text{time/subproblem}} + \underbrace{h(n)}_{\text{postprocessing}}\]

<p>where $f(n),g(n), h(n)$ would come from point 1,2,3 mentioned above, respectively. In the case of WIS, we have:</p>
<ul>
  <li>$f(n) = n$ since there are $n+1$ subproblems</li>
  <li>$g(n) = O(1)$ since each subproblem is just a constant time comparison</li>
  <li>$h(n)=O(n)$ is the backward reconstruction cost</li>
</ul>

<p>so the total runtime is $O(n)$ for our WIS example.</p>

<h2 id="the-knapsack-problem">The Knapsack Problem</h2>

<p>The next example is the Knapsack problem, which follows closely to the paradigm we just discussed.</p>

<blockquote>
  <p><strong>Knapsack Problem</strong>: consider $n$ items with value $v_1, …, v_n$ and sizes $s_1, …, s_n$, all being positive integers. Consider you have a knapsack with capacity $C$, and you want to maximize the total value of items you can put in the knapsack.</p>
</blockquote>

<p>For example, given the following configuration, the maximum value you can stuff in is 8 for a capacity of 6:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231020004340.png" style="zoom:80%;" /></p>

<p>Now we can kind of just copy over the idea for WIS we had. Again, suppose someone gave you the optimal solution $S \subset {1,2,3 ,…,n }$ telling you the best items to put in the knapsack. <strong>We can we say about $S$ and problems of smaller size?</strong> Either $S$ includes the last item $n$ or it doesn’t.</p>

<ol>
  <li>$n \notin S$. Since the the optimal solution $S$ excluded it, the solution $S$ must also be feasible and optimal for the knapsack of size $C$ and items $1,2,3,…,n-1$.</li>
  <li>$n \in S$. First of all, this only happens if $s_{n} \le C$. Then what happens if we remove $n$? The solution $S - { n}$ is an optimal solution for the knapsack of size $C - s_n$ and items $1,2,3,…,n-1$. Notice the difference with <code class="language-plaintext highlighter-rouge">wis</code>:
    <ul>
      <li>both case in <code class="language-plaintext highlighter-rouge">wis</code> consider both subproblems by knocking out vertices.</li>
      <li>here, we need to change <em>both size and items</em></li>
    </ul>
  </li>
</ol>

<p>But regardless, this gives us a recipe of how to build up a solution from subproblems. Again writing down the recurrence: let $V_{i,x}$ denote the maximum total value for a subset of the first $i$ items with total size at most $c$.  Then:</p>

\[V_{i,c} = \max \begin{cases}
  V_{i-1, c} \\
  V_{i-1, c-s_i} + v_i, &amp; \text{only if } c \ge s_i. \text{ otherwise it will be $V_{i-1, c}$}
\end{cases}\]

<p>So what are the subproblems we need to solve in this case? $V_{i,c}$ for all $i \in {0,1,2, …, n}$ and $c \in { 0,1,2, …, C }$. Another way to see this is that now we have <strong>two parameters to specify input for each subproblem</strong>. Therefore it is natural that now we are filling up a 2D array</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">knapsack</span><span class="p">(</span><span class="n">V</span><span class="p">,</span><span class="n">S</span><span class="p">,</span><span class="n">C</span><span class="p">):</span>
  <span class="n">A</span> <span class="o">=</span> <span class="p">(</span><span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">C</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="n">array</span>  <span class="c1"># 2D array for solutions to subproblems
</span>  <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">C</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">A</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># base case
</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">C</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
      <span class="k">if</span> <span class="n">c</span> <span class="o">&gt;=</span> <span class="n">s_i</span><span class="p">:</span>
        <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">c</span><span class="p">],</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">c</span><span class="o">-</span><span class="n">s_i</span><span class="p">]</span> <span class="o">+</span> <span class="n">v_i</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">c</span><span class="p">]</span>

  <span class="k">return</span> <span class="n">A</span><span class="p">[</span><span class="n">n</span><span class="p">,</span><span class="n">C</span><span class="p">]</span>
</code></pre></div></div>

<p>Runtime? Obviously $O(nC)$ since we are filling up a 2D array.</p>

<p>Reconstruction? Again, a backward pass to figure out from $A[n][C]$ which case (whether $n$-th item is included) it is:</p>
<ul>
  <li>if $A[n-1][C] = A[n][C]$, then obviously $n$ is not included and we continue to $A[n-1][C]$</li>
  <li>otherwise, then $n$ is included and we continue to $A[n-1][C-s_n]$</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">knapsack_reconstruct</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">C</span><span class="p">):</span>
  <span class="n">S</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># the solution
</span>  <span class="n">c</span> <span class="o">=</span> <span class="n">C</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="n">c</span><span class="p">]</span> <span class="o">!=</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">c</span><span class="p">]:</span>
      <span class="n">S</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
      <span class="n">c</span> <span class="o">-=</span> <span class="n">s_i</span>
    <span class="c1"># else we are skipping i, capactiy is the same
</span>  <span class="k">return</span> <span class="n">S</span>
</code></pre></div></div>

<p>which runs in $O(n)$. Visually it is doing this:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231020011132.png" style="zoom:100%;" /></p>

<p>Finally, correctness. In general this will be proven by <strong>induction + the property we used to come up with the DP algorithm/recurrence itself</strong>. Hence, we omit the proof here.</p>

<h1 id="advanced-dynamic-programming">Advanced Dynamic Programming</h1>

<p>In this section we will discuss some more advanced DP problems, where the structure of optimal solution is more complex than that of the last section.</p>

<h2 id="sequence-alignment">Sequence Alignment</h2>

<p>This problem is both used in computational genomics and in NLP (e.g. to compute the edit distance). Consider the input consist of strings (e.g. representing portions of genomes) over some alphabet:</p>

\[\text{Input: AGGGCT},\qquad \text{Output: AGGCA}\]

<p>and the goal is to say “how similar the two strings are”. How do we measure similarity?</p>

<blockquote>
  <p><strong>Alignment</strong>: a way of inserting gaps such that the two strings have the same length. For example:
<img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231025012521.png" style="zoom:80%;" /></p>
</blockquote>

<p>so that then we can define the similarity of the two strings as the quality of the best alignment, for example</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231025012620.png" style="zoom:80%;" /></p>

<blockquote>
  <p><strong>Finding Optimal Sequence Alignment</strong> then is used to answer the question “how similar the two strings are”. Formally, consider two strings $X,Y$ over the alphabet $\Sigma$. And let there be a penalty $\alpha_{xy}$ for swapping $x$ with $y$, and $\alpha_{\mathrm{gap}}$ be the cost of inserting a gap. The goal is to find an optimal alignment of $X,Y$ that <strong>minimizes the total penalty</strong>.</p>
  <ul>
    <li>intuitively, is saying “how similar are the two strings” = “most plausible explanation” of how one of the strings might have evolved into the other.</li>
    <li>the minimum penalty of an aligmment is famous enough as a concept that it has a name: <strong>Needleman-Wunsch or NW score</strong>.</li>
  </ul>
</blockquote>

<p>So how do we solve it? Consider some alternative, e.g. greedy algorithm. If you give enough thought, you will realize that it is impossible because you <em>really need to think ahead to avoid bad choices</em> early on, which is the opposite of greedy.</p>

<p>The savior is again dynamic programming. Similar to prior approaches, we begin by reasoning about how <strong>optimal solution relates to optimal solutions of subproblems, and vice versa</strong>. Consider we are already given the optimal solution, and similar to previous problems, consider the <mark>subproblem is having one less character to align</mark>:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231025013516.png" style="zoom:90%;" /></p>

<p>This naturally becomes similar to WIS and Knapsack, but here we could have more cases. Let the optimal alignment for $X= x_1, x_2, …, x_m$ and $Y= y_1, y_2, …, y_n$ be given above. Denote $X’ = x_1, x_2, …, x_{m-1}$ and $Y’ = y_1, y_2, …, y_{n-1}$ both with last one removed:</p>

<ol>
  <li>
    <p>Case 1: $x_m$ is aligned with $y_n$, two actual characters (may or may not be the same). Then you can peel them off and the rest of the alignment should also be optimal:
<img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231025103754.png" style="zoom:80%;" />
note that this alignment between $X’$ and $Y’$ will also be the <em>optimal aligmnent</em>. (Proof by contradiction: suppose that the penalty for this induced alignment of $X’, Y’$ is $P$, but there is another better competitor $P’ &lt; P$. Then appending $x_m, y_n$ to the competitor alignment gives back $X,Y$, with new cost:</p>

\[P' + \alpha_{x_m y_n} &lt; P + \alpha_{x_m y_n}\]

    <p>which is a contradiction that $P + \alpha_{x_m y_n}$ was the optimal alignment.) Note that $\alpha_{x_m y_n}$ could be zero.</p>
  </li>
  <li>Case 2: $x_m$ is aligned with a gap. Then the induced alignment of $X’,Y$ is optimal.
<img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231025104438.png" style="zoom:80%;" /></li>
  <li>Case 3: $y_n$ is aligned with a gap. Then the induced alignment of $X,Y’$ is optimal.</li>
  <li>Case 4: a gap with a gap. Note that this is <strong>not a scenario</strong>, as we could have removed both gaps. Therefore, in general, <em>any column/pairing in an alignment will be either of the three cases above</em>.</li>
</ol>

<p>Now we can build a recurrence relation: since the optimal solution must be either one of the three cases, and each case either removes a character from $X$ or $Y$, we can write the recurrence as:</p>

\[P_{m,n} = \min \begin{cases}
  P_{m-1, n-1} + \alpha_{x_m y_n} \\
  P_{m-1, n} + \alpha_{\mathrm{gap}} \\
  P_{m, n-1} + \alpha_{\mathrm{gap}}
\end{cases}\]

<p>since this must be true for every $n=1,2, …$ and $m=1,2, …$  we get more generally from bottom-up:</p>

\[P_{i,j} = \min \begin{cases}
  P_{i-1, j-1} + \alpha_{x_i y_j} \\
  P_{i-1, j} + \alpha_{\mathrm{gap}} \\
  P_{i, j-1} + \alpha_{\mathrm{gap}}
\end{cases}\]

<p>for every $i=1,2, …$ and $j=1,2, …$ representing the <strong>subproblem of aligning first $i$ symbols in $X$ with first $i$ symbols in $Y$</strong>. Finally, what if one of $i,j$ is zero? This is the <strong>base case</strong>: imagine $X$ of the $X,Y$ is empty, then the alignment cost will be $\alpha_{\mathrm{gap}} \vert  X \vert$. So we obtained:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231025105309.png" style="zoom:70%;" /></p>

<p>which means our algorithm would be progresively filling in a 2D array:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231025105502.png" style="zoom:75%;" /></p>

<p>which obviously has a runtime of $O(nm)$.</p>

<p><strong>Proof of correctness?</strong> Induction on $i+j$ (the subproblem size), with the recurrence relationship justifying the inductive step.</p>

<p><strong>How do we reconstruct it?</strong> Start from the top $A[m][n]$ and figure out which of the three cases it went into. This can be done by checking A[i-1][j-1], A[i-1][j], A[i][j-1] and see which one it is. Then we can continue to that case and repeat. Details omitted here but this will be $O(n+m)$ since each time you are decreasing at least one of the two numbers $i,j$ by one.</p>

<h2 id="optimal-binary-search-trees">Optimal Binary Search Trees</h2>

<p>Goal: compute the best-on-average search tree given stastistics about the frequencies of different searches. Recall that the defining property of search tree is</p>

<blockquote>
  <p><strong>Search Tree Property</strong>: for every object $x$</p>
  <ol>
    <li>object in $x$’s left subtree must have keys smaller than $x$</li>
    <li>object in $x$’s right subtree must have keys larger than $x$
(assuming no duplicate keys for simplicity)</li>
  </ol>
</blockquote>

<p>This means that visually we are dealing with a fast search datastructure that looks like:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231025110413.png" style="zoom:70%;" /></p>

<p><strong>for every subtree</strong> in the search tree. An example would be:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231025110504.png" style="zoom:80%;" /></p>

<h3 id="average-search-time">Average Search Time</h3>

<p>Normally, when we consider a binary search tree, we measure the <strong>search time</strong> for a key $k$ to be the nunmber o nodes it need to visit while searching for $k$ (including $k$ itself). For exmaple in the following tree:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231025110917.png" style="zoom:80%;" /></p>

<p>key “1” wold have a search time 5. Therefore, without weights, the ideal search tree would be a balanced one</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231025111023.png" style="zoom:100%;" /></p>

<p>because this would minimize the length of the longest root-leaf path, or equivalently, the maximum search time. Minimzing the maximum search time <strong>makes sense since you don’t have knowledge about which searches are more likely than others</strong>.</p>

<p>However, here we consider the problem</p>

<blockquote>
  <p><strong>Optimal Binary Search Trees</strong>: A sorted list of keys $k_{1} &lt; k_{2} &lt; … &lt; k_n$ and nonnegative frequency $p_i$ for each key $k_i$. We want to minimize the <strong>weighted search time</strong>:</p>

\[\sum_{i=1}^n p_i \times \text{search time for } k_i = \sum_{i=1}^n p_i \times (1 + \mathrm{depth}_T(k_i) )\]

  <p>where $\mathrm{depth}_T(k_i)$ represent the depth of $k_i$ in the tree $T$. (The root will be considered as depth zero.)</p>
</blockquote>

<p>This looks <strong>very similar to the optimal prefix-tree code problem</strong>, where the goal is to also related to find a tree to minimize the average (weighted) depth. However, the challenge here is that, in the prefix-free code problem, the only restriction is that symbols appear at leaves, but here we have the <strong>search tree property</strong>. This makes greedy algorithm not work in this problem. Similarly divide-and-conquer algorithm would also struggle (imagining recursively choosing a root node to be the median, and continue). Fundamentally this is because <strong>the choice of root has unpredictable repercussions further down the tree</strong> if you chose too early.</p>

<p>So how do we do it? Different from other previous problems, there is no <em>clear notion of the rightmost/last object to pluck off and obtain optimal thing for subproblem</em>. But the intuition is that we can imagine building the tree from bottom up, and imagine the <strong>last decision we have to make = determing the root node!</strong>. Consider, if we know the optimal solution is the following</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231025130312.png" style="zoom:80%;" /></p>

<p>Then we (intuitively) also</p>
<ul>
  <li><mark>know the optimal solution for keys $1, ..., r-1$ and $r+1,. .., n$ will be $T_1, T_2$</mark>. (see proof below)</li>
  <li>the key is IF we know <mark>"what $r$ is"</mark>
    <ul>
      <li>recall that in WIS, we know the rest of the solution if we know “whether the last vertex is included or not”</li>
      <li>recall that in Knapsack, we know the rest of the solution if we know “whether last item is included or not”</li>
    </ul>
  </li>
  <li>therefore, the smaller subproblem is the trees $T_1, T_2$, and the case analysis will be <em>all the possible roots</em>.</li>
</ul>

<hr />

<p><em>Proof</em>: Let the root of $T$ have key $r$ (same as figure above). We want to show that the residents of $T_1$ with $p_1, …, p_{r-1}$ is optimal, and similarly for $T_2$ with $p_{r+1}, …, p_n$.</p>

<p>Suppose by contradiction that one of the subtrees, e.g. $T_1$ is NOT an optimal solution, so that we have a search tree $T_1^*$ that achieves a better search time with the same keys:</p>

\[\sum\limits_{k=1}^{r-1} p_{k} \cdot  (k\text{'s search time in $T_1^{*}$}) &lt; \sum\limits_{k=1}^{r-1} p_{k} \cdot (k\text{'s search time in $T_1$})\]

<p>Then intuitively, we want to show that we can cut and paste this tree into $T$ and the obtain a cost better than $T$:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231025162139.png" style="zoom:80%;" /></p>

<p>where RHS is the one we cut and pasted. The weighted search time of the original tree $T$ is:</p>

\[\begin{align*}
  &amp; p_{r} + \sum\limits_{i=1}^{r-1} (1 + 1 + \mathrm{depth}_{T_1}(k_i) ) + \sum\limits_{j=r+1}^{n} (1 + 1 + \mathrm{depth}_{T_2}(k_j) ) \\
  &amp;=  \sum\limits_{i=1}^{n} p_i + \sum\limits_{i=1}^{r-1} (1 + \mathrm{depth}_{T_1}(k_i) ) + \sum\limits_{j=r+1}^{n} (1 + \mathrm{depth}_{T_2}(k_j) ) \\
  &amp;= \sum\limits_{i=1}^{n} p_i + \text{weighted search time of $T_1$} + \text{weighted search time of $T_2$}
\end{align*}\]

<p>since the first and third term is the same for the weight time in $T^{<em>}$, and we know that $T_1^{</em>}$  is better than $T_1$, this is a contradiction to the statement that $T$ was optimal.</p>

<hr />

<p>From the above observation, we obtain the recurrence relationship that, llet $W_{i,j}$ denote the weighted search time for keys ${i, i+1, …, j}$, then:</p>

\[W_{1,n} = \sum\limits_{k=1}^{n} p_{k} + \min\limits_{r \in \{1,2, ..., n\}} \left( W_{1,r-1} + W_{r+1,n} \right)\]

<p>where $W_{1,n}$ is the full problem, and  $W_{1,r-1}, W_{r+1,n}$ are the subproblems. Notice that this also implies solving the subproblems (recursively) <strong>must be a dealing with a contiguous chunk of keys</strong> = a subtree. Since for the search tree property to hold, the above <strong>must be true for every subtree</strong>:</p>

\[W_{i,j} = \sum\limits_{k=i}^{j} p_{k} + \min\limits_{r \in \{i,i+1, ..., j\}} \left( W_{i,r-1} + W_{r+1,j} \right)\]

<p>where intutively, $W_{i, i}$ would representing you building a search tree with just the root node $r=i$. Then, the algorithm would just iteratively grow this tree like this:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231025125708.png" style="zoom:80%;" /></p>

<p>Alternatively you can also just start with the purple diagonal as base case in your algorithm, and go to the top left. And you will fill each new diagional from bottmo left to top right (think about why by looking at the recurrence relation).</p>

<p>and the detailed algorithm would be:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231025164341.png" style="zoom:70%;" /></p>

<p>where the runtime would be:</p>

<ul>
  <li>there are $O(n^2)$ subproblems</li>
  <li>each subproblem does a min over $O(n)$ choices</li>
</ul>

<p>so the total runtime is $O(n^3)$ (though with some optimization, you can get to $O(n^{2})$)</p>

<h1 id="shortest-path-revisited">Shortest Path Revisited</h1>

<p>This chapter considers a DP approach for computing the shortest path in a graph. Both are slower than Dijkstra or Prim’s algorithm, but:</p>

<ul>
  <li>Bellman-Ford can deal with negative edge weights and can be done in a <em>distributed</em> manner</li>
  <li>Floyd-Warshall can also deal with negative edge weights and can compute shortest-path distance between <em>any pair</em> of vertices</li>
</ul>

<h2 id="shortest-path-with-negative-edge-length">Shortest Path with Negative Edge Length</h2>

<p>As mentioned before, Dijkstra algorithm ca nfail with graphs that has negative edges (but not negative cycles). The reason is the greedy decision it makes now doesn’t work. Consider:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231026233920.png" style="zoom:70%;" /></p>

<p>where the shortest path from $s \leadsto t$  will be $s \to t$ in the first iteration of Dijkstra, which is wrong.</p>

<p>In general (for any graph that may have negative edges or cycles):</p>
<ul>
  <li>if you have a negative cycle, then any shortest distance doesn’t make sense as its $- \infty$</li>
  <li>What if in the presence of a negative cycle you forbidden that option for your optimal path? This version where <em>no repeat vertices is allowed</em> of the single-source shortest path problem is actually a NP-hard problem.</li>
</ul>

<p>Therefore, in this section we will consider the revised problem</p>

<blockquote>
  <p><strong>Shortest Path Revised</strong>: given a directed graph $G=(V,E)$ with edge lengths $l_e$ for each edge $e \in E$, and a source vertex $s \in V$, either:</p>
  <ul>
    <li>If there is a negative cycle, then the algorithm should report it and done.</li>
    <li>Otherwise, compute the shortest path distance $d_v$ from $s$ to every other vertex $v \in V$.</li>
  </ul>
</blockquote>

<p>However, if there is no negative cycle, then there are a few properties we can exploit to help us reach a solution quickly:</p>

<blockquote>
  <p>If a graph has no negative cycle, the optimal path $s \leadsto v$  must <mark>contain at most $n-1$ edges/cannot contain repeated vertices</mark>.</p>
</blockquote>

<p>Proof: consider an optimal path $P’$ that has at least $n$ edges. This means it visits at least $n+1$ vertices, meaning some vertex $w$ is visited twice. This means we can splice the repeated part out from $P’$ while keeping thee same endpoints <strong>but with fewer edges now</strong>:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231026235102.png" style="zoom:75%;" /></p>

<p>But because there is no negative cycle, this spliced out (path) cycle must have nonnegative length. Therefore, the new path $P’’$ is shorter than $P’$, which is a contradiction.</p>

<h2 id="bellman-ford-algorithm">Bellman-Ford Algorithm</h2>

<p>Again, the most important step is to reason about the optimal solution: <strong>what are the different ways that an optimal solution might be built up from optimal solutions to smaller subproblems</strong>?</p>

<p>Naively, you may think of subproblems being something based on a subset of the $G$ we need to solve (e.g., similar to how we solve WIS, where input graph is a path graph and we just pluck the last vertex out). However, the problem now is that <em>where is the “last vertex” in a generic graph</em>? Bellman-Ford thus considers a different approach. Although there is no sequentiality in input graph, <em>there is sequentialality in output graph, i.e., the optimal path</em>:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231027112721.png" style="zoom:80%;" /></p>

<p>which we will show that $P’$ must also be shortest (even if $w \to v$ can ve negative). This is great, but <mark>what is the subproblem</mark>?</p>

<blockquote>
  <p><strong>Bellman-Ford Subproblem</strong>: we only consider (optimal) paths that use <em>less than $i$ edges</em> each time. More formally, let the input graph be $G=(V,E)$ with a given source vertex $s \in V$. Consider finding the optimal $P$ bewteen $(s,v)$ that includes <em>at most $i$ edges</em>.</p>
  <ul>
    <li>note that different from previous DP, each subproblem here <em>still work on the full input</em></li>
  </ul>
</blockquote>

<p>How does this help construct an optimal solution to a larger problem? Consider the following:</p>

<ol>
  <li>that optimal $P$ for $s \leadsto v$ has <strong>at most $i-1$ edges</strong> (already a pretty good path using a budget $i-1$). Then $P$ must also be the <strong>optimal solution with edge budget $i-1$ for $s \leadsto v$</strong>. (Proof by contradiction: if not, then that shorter path would also be shorter for the original subproblem of at most $i$ edges.)</li>
  <li>that optimal $P$ uses <strong>exactly $i$ edges</strong>. Consider visually that optimal path and $P’$ being the last edge plucked (say $(w,v)$):
<img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231027113744.png" style="zoom:80%;" />
then that $P’$ is <strong>an $s \leadsto w$ optimal path with at most $i-1$ edges</strong> (<mark>a smaller subproblem BUT with different destination</mark>). This can be easily shown by contradiction as well, because if there exists a better path with at most $i-1$ edges from $s \leadsto w$, then we can swap that out and obtain a better $P$ to the original problem.</li>
</ol>

<p>Therefore:</p>
<ul>
  <li>we can construct an optimal $P$ for the budget of $i$ using the “two” cases above</li>
  <li>but how many subsoluions will the original subproblem need to look at? Consider computing the optimal path $s \leadsto v$ with cost $i$. Then “case 1” is one candidate, and “case 2” would have $\text{in-degree}(v)$ candidates. So in total it will scan through $1+\text{in-degree}(v)$ candidates.</li>
</ul>

<p>Anyway, this gives use the recurrence relationship. Let $L_{i,v}$ denote the minimum length of an $s\leadsto v$ path with at most $i$ edges, <em>cycles allowed</em> (since we have an edge budget, even negative cycles could be fine in this definition for now). Then for every $i \ge 1, v \in V$:</p>

\[L_{i,v} = \min \begin{cases}
  L_{i-1, v} \\
  \min\limits_{(w,v) \in E} \left( L_{i-1, w} + l_{wv} \right)
\end{cases}\]

<p>if no such path exist, then $L_{i,v} = \infty$. But when should we stop $i$?</p>

<blockquote>
  <p><strong>Bellman-Ford Convergence</strong>: interestingly, we can show that $L_{i,v}$ will converge if for some $k \ge 0$:</p>

\[L_{k+1,v} = L_{k,v}  \qquad \forall v \in V\]

  <p>then this would mean:</p>
  <ol>
    <li>$L_{k’,v} = L_{k,v}$ for every $k’ \ge k$ and any destination $v$</li>
    <li>for every destination $v$, then $L_{k,v}$ must be the $\mathrm{shortest}(s,v)$ in $G$</li>
  </ol>
</blockquote>

<p><em>Proof for statement 1:</em> Because $L_{k+1,v} = L_{k,v}$, then this means the subproblem of $L_{k+2}$ is doing</p>

\[L_{k+2,v} = \min \begin{cases}
  L_{k+1, v} \\
  \min\limits_{(w,v) \in E} \left( L_{k+1, w} + l_{wv} \right)
\end{cases} = \min \begin{cases}
  L_{k, v} \\
  \min\limits_{(w,v) \in E} \left( L_{k, w} + l_{wv} \right)
\end{cases}
= L_{k+1,v}\]

<p>Thus, any future subproblem will be the same as $L_{k+1,v}$, which is the same as $L_{k,v}$ by assumption.</p>

<p><em>Proof for statement 2:</em> if $L_{k,v}$ is NOT the shortest path for subproblem with at most $k$ edges. Then the shortest path must be beyond $k$ edges. This is a contradiction since we know that $L_{k’,v} = L_{k,v}$ for any $k’ \ge k$ if the assumption holds.</p>

<blockquote>
  <p><strong>Bellman-Ford Stops with No Negative Cycles</strong>: if there ARE negatiev cycles in the graph, then the condition $L_{k+1,v} = L_{k,v}, \forall v \in V$ in general will not even happen. But if there are <strong>no negative cycles</strong>, then it will converge exactly when reached $n-1$ edge budget (i.e., every vertex used in the path):</p>

\[L_{n,v} = L_{n-1,v}  \qquad \forall v \in V\]

  <p>the contrapositive statement of this is also powerful:</p>

\[\text{no neg cycle means convergence} \implies \text{not converging means has neg cycle}\]

  <p>so this algorithm can also detect negative cycles.</p>
</blockquote>

<p>Why? Remeber we showed that in Section <a href="#Shortest_Path_with_Negative_Edge_Length">Shortest Path with Negative Edge Length</a>, the optimal $s \leadsto v$ path in a graph with no negative cycle must at most visited every vertex once (otherwise we could remove the cycle and get a shorter path). Therefore, this is <mark>the only place where we need the no-negative cycle condition</mark>, such that Bellman-Ford’s algorithm will stop/converge at $n-1$ iterations. <strong>If not, then there is a negative cycle</strong>:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231027121122.png" style="zoom:80%;" /></p>

<p>where again, we needed to fill up a 2D array because we have two parameters, $i,v$ for the subproblem.</p>

<p><strong>Proof of Correctness</strong>: induction on $i$, with our recurrence relationship justifying the inductive step.</p>

<p><strong>Runtime</strong>: Superficially it looks like $O(n^{2})$ loops with $O(n)$ to compute the recurrence relation in the inner most loop. However, realize that during the “for $v\in V$” loop we actually just did:</p>

\[\sum_{v \in V} \text{in-degree}(v) = m\]

<p>abd in the outer for loop over $n$ iterations, we thus only need $O(nm)$ time! (if the graph is <em>dense</em>, then $m=O(n^{2})$ so we get the same solution as our naive analysis).</p>

<h2 id="floyd-warshall-algorithm">Floyd-Warshall Algorithm</h2>

<p>Now we can deal with all-pairs shortest path:</p>

<blockquote>
  <p><strong>All-Pairs Shortest Path Problem</strong>: consider a directed graph $G=(V,E)$ with a real-valued length $l_e$ for each edge. The goal is to:</p>
  <ul>
    <li>find the shortest path distance $\mathrm{shortest}(u,v)$ from <em>every</em> vertex $u$ to every other vertex $v$.</li>
    <li>if there is a negative cycle, then the algorithm should report it and done.</li>
  </ul>
</blockquote>

<p>Technically, we could solve this using Bellman-Ford by treating every vertex as source vertex. This will give us $O(n^{2}m)$ runtime, with potentially $m=O(n^{2})$. We show that we can do better than this by finishing in $O(n^{3})$.</p>

<p>The trick here is to still look at the output paths, and also puts some contraint on length. However, we further restrict the <em>identity of the vertices that can go into the solution</em>.</p>

<blockquote>
  <p><strong>Floyd-Warshall Subproblem</strong>: First we label each vertex $v\in V$ with names ${1,2,3, …, n}$. Then, consider the shortest path from $v$ to $w$ that only uses vertices in ${1,2, …, k}$ as intermediate vertices. i.e. this minimum path</p>
  <ul>
    <li>begins at $v$ and ends at $w$</li>
    <li>the path (excluding $v,w$) only includes vertices in ${1,2, …, k}$</li>
    <li>does not contain a directed cycle (by <mark>assuming there is no negative cycle</mark> so that we can splice out any cycle out of a path and end up with a lower cost.)
      <ul>
        <li>We shall also see how negative cycles can be detected later</li>
      </ul>
    </li>
  </ul>

  <p>Let $L_{k, u, v}$ denote the length of this path. If no such path exists, then $L_{k, u, v} = \infty$. Note that you can therefore <strong>imaging subproblem size defined by $k$</strong>: for a fixed origin-destination pair $v,w$, the set of allowable path will grow by $k$ and the minimum cost will only decrease.</p>
</blockquote>

<p>For example:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231027123349.png" style="zoom:80%;" /></p>

<p>In this graph, if we had source and vertex being $1,5$, then if $k=0,1,2$ there is no feasible path so $L_{k,1,5}=\infty$. However, when $k=3$, then the path $1 \to 2 \to 3 \to 5$ is eligible (and being the only one) with cost $L_{3,1,5} = 3$.</p>

<p>This we will soon see will make the optimal solution naturally break down into only two smaller subproblems. Suppose $P$ is a $v \leadsto w$ with no cycles and only uses vertices in ${1,2, …, k}$ as intermediate vertices. Then realize that that $P$ can  <em>either use the lastly added vertex $k$ or not</em>:</p>

<ol>
  <li>Case 1: <strong>optimal $P$ for $v \leadsto w$ did NOT use $k$</strong> as an intermediate vertex. Then $P$ must be an optimal path with at most $k-1$ intermediate vertices as well. (Proof by contradiction)</li>
  <li>
    <p>Case 2: <strong>optimal $P$ for $v \leadsto w$ did use $k$</strong>. Then we can split the path into two by <em>removing $k$ to be uneligible</em>:
<img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231027124934.png" style="zoom:80%;" /></p>

    <p>because $k$ could have only appeared in $P$ once (by assumption of cycle-free optimal path), then $P_1$ is optimal with origin $v$ and destination $k$, and $P_2$ is optimal with origin $k$ and destination $w$, <strong>both with a smaller subproblem using only ${1,2, …, k-1}$ vertices</strong>.</p>
    <ul>
      <li>to prove that $P_1, P_2$ is also optimal is slightly tricky here. Suppose there is a better $P_1^{<em>}$ for $v \leadsto k$. To concatenate $P_1</em>$ with $P_2$ we want to have a lower cost than $P$ to get a contradiiction.
        <ul>
          <li>If $P_1^{*}$ with $P_2$ will have no cycle, proof done.</li>
          <li>If $P_1^{<em>}$ with $P_2$, denote $P^{</em>}$, now has a cycle, we need to invoke the assumption that there is no negative cycle in $G$. Therefore we can splice up the cycle in $P^{<em>}$ such that we still hhave the same origin $u$ and destination $v$ in now a cycle free path $\hat{P}$, which can only be shorter than $P^{</em>}$.</li>
        </ul>
      </li>
    </ul>
  </li>
</ol>

<blockquote>
  <p>In sum, we broke the large problem into “two” subproblems: <strong>case 1 is reducing the problem size by one</strong>, and case 2 is <strong>reducing the problem size by one AND changing the source/destination pairs</strong>.</p>
</blockquote>

<p>Therefore, <mark>suppose (for now) $G$ has no negative cycles</mark>. Then the <strong>recurrence relation</strong> is deinfed by letting $L_{k,v,w}$ be the minimum length of a cycle-free path from $v$ to $w$ that only uses vertices in ${1,2, …, k}$ as intermediate vertices. Then:</p>

\[L_{k,v,w} = \min \begin{cases}
  L_{k-1, v, w} \\
  L_{k-1, v, k} + L_{k-1, k, w}
\end{cases}\]

<p>which has to be true for every $k \in {1,2, …, n}$ and every $v,w \in V$.</p>

<p>Finally this gives the algorithm:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231027130119.png" style="zoom:75%;" /></p>

<p>where note that:</p>
<ul>
  <li>since we are viewing subproblems defined by size $k$, the base cases are $L_{0,v,w}$. This can result in three cases:
    <ul>
      <li>if $v=w$, then $L_{0,v,w}=0$</li>
      <li>if $(v,w) \in E$, then $L_{0,v,w}=l_{vw}$</li>
      <li>otherwise $L_{0,v,w}=\infty$</li>
    </ul>
  </li>
  <li>since the subproblems grows by $k$, the outermost loop will start with $k$</li>
  <li>this algorithm <mark>can detect negatiev cycles as well</mark> (see below why)</li>
</ul>

<p><strong>Proof of Correctness</strong>: induction on $k$, with our recurrence relationship justifying the inductive step.</p>

<p><strong>Runtime</strong>: $O(n^{3})$ since we are filling in a 3D array, and each subproblem takes $O(1)$ time to compute.</p>

<h3 id="detecting-negative-cycles">Detecting Negative Cycles</h3>

<p>What if the input graph has a negative cycle?</p>

<blockquote>
  <p><strong>Lemma 18.8</strong>: the graph $G$ has a negative cycle if and only if, at the conclusion of the algorithm, there is a vertex $v$ such that $L_{n,v,v} &lt; 0$.</p>
</blockquote>

<p><em>Proof</em>: if there is no negative cycle, then obviously $L_{n,v,v} = 0$ for every $v$ since every shortest path will also be cycle free. But if there is a negative cycle, then this means $G$ has a negative cycle with no repeated vertices other than its start and end (e.g. $v$). The trick is to think about two paths to form such a cycle, and argue how a repeated vertex can be spliced out.</p>

<p>Let $C$ denote such a cycle, and let $k$ be the largest labeled vertex of $C$ with $k \neq v$:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231027132431.png" style="zoom:80%;" /></p>

<p>then we know:</p>
<ul>
  <li>$P_1, P_2$ are cycle-free $v \leadsto k$ and $k \leadsto v$ paths respectively (since this cycle has no repeated vertex other than source) with vertices restricted to ${1,2, …, k-1}$</li>
  <li>then Floyd-Warshall would found $L_{k-1, v, k}$ and $L_{k-1, k, v}$ to be at least smaller or equal to the actual length of $P_1, P_2$ (being cycle-free)</li>
  <li>therefore, $L_{k,v,v}$, which is at most the length $L_{k-1, v, k} + L_{k-1, k, v}$, <strong>will also be smaller or equal $C$</strong>, which is negative.</li>
</ul>

<p>Therefore, if there is a negative cycle, $L_{k,v,v}$ will at least once become negative. This means $L_{n,v,v}$ will be negative since for each iteration $k’ &gt; k$ the minimum length only decreases.</p>

<h1 id="max-flows-and-min-cuts">Max Flows and Min Cuts</h1>

<p>Before we dive into the algorithms, its sometimes enlightening to see how those seemingly “unrelated/unpractical” algorithms can be very useful in practice. Here we will see two examples.</p>

<h2 id="minimum-cut-problem">Minimum Cut Problem</h2>

<blockquote>
  <p><em>Minimum Cut Problem</em>: consider a flow nertwork consisting of a directed graph $G=(V,E)$ with <strong>a source vertex $s$ and a sink vertex $t$</strong>. Each edge $e \in E$ has a capacity $c_e$. The goal is to find a $(s,t)$ cut into two sets $A,B$ such that it minimizes the total capacity of edges sticking out from set $A$ into $B$.</p>

\[\min \sum_{e =(u,v); u \in A, v \in B} c_e\]

  <ul>
    <li>basically think of those source and sink as water flows, and the capacity is the pipe</li>
    <li>the cut is basically coming up with two groups of vertices but one needs to include $s$ and the other needs to include $t$.</li>
  </ul>
</blockquote>

<p>Visually, a cut below would be optimal with a total capcity of 3:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231102231406.png" style="zoom:30%;" /></p>

<p>where:</p>
<ul>
  <li>the purple edge would not count as it is <em>not flowing from $A$ to $B$</em></li>
  <li>the green edge will count</li>
  <li>the blue edge would not count as it is <em>flowing from $B$ to $A$</em></li>
</ul>

<p>Notice that since this is just choosing which vertex goes where, there are $2^{n-2}$ possible cuts (excluding source and sink). We will not see an algorithm here, but we will see how this can be solved in linear time in the next section.</p>

<h2 id="minimum-cut-application-image-segmentation">Minimum Cut Application: Image Segmentation</h2>

<p>We will see how this minimum cut problem relates to how we can do image segmentation. First we formalize the “version” of image segmentation we are considering:</p>

<blockquote>
  <p><em>Image Segmentation with Fore/background</em>: Consider the task of classifying pixels of an image to be either foreground or background. Let us be given some prior (e.g. heuristics, non-negative) that each pixel could be in foreground with $a_v$ and background with $b_v$. Additionally, we are given non-negative $p_e$ for each undirected edge between each pixel, which represents the fact that we want neighboring pixels to be close together, i.e. smooth.</p>

  <p>Then, we can define the segmentation as an <em>undirected graph</em> with all those costs/rewards assigned to the vertices and edges:
<img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231102232526.png" style="zoom:30%;" /></p>

  <p>where the first value of the nertex denotes $a_v$ and second denotes $b_v$ in this example. We <strong>want to maximize the objective</strong>:</p>

\[\max_{(X,Y)}\quad \sum_{v \in X} a_v + \sum_{v \in Y} b_v - \sum_{e \in \delta(X)} p_e\]

  <p>which represents an “MLE” objective of wanting all the foreground-likely pixels in $A$, and all the background-likely pixels in $B$, while also wanting to minimize the cost of the “incongruity” between $A$ and $B$. $\delta(X)$ denotes the cut edges between $A$ and $B$.</p>
</blockquote>

<p>The claim is that this problem reduces to the minimum cut problem. First we note a few similarlities and differences to motivate the reduction:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Similarities</th>
      <th style="text-align: center">Differences</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">both problem needs a partition</td>
      <td style="text-align: center">here we consider <em>undirected edges</em></td>
    </tr>
    <tr>
      <td style="text-align: center">both want to minimize the cut across partitions</td>
      <td style="text-align: center">missing a <em>source and sink vertex</em></td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: center">additional $a_v, b_v,p_e$ costs</td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: center">maximization instead of minimization</td>
    </tr>
  </tbody>
</table>

<blockquote>
  <p>Our overall reduction approach will be intuitive for this class:</p>
  <ol>
    <li>transform the problem into the problem that can be solved by (e.g. min cut algorithm)</li>
    <li>transform the solution of that problem back to the original problem</li>
    <li>finally show that the transformed solution is optimal to the original problem</li>
  </ol>
</blockquote>

<p>So how do we convert from the two different graph problems? A few are easy fixes. Let the original segmentation graph be $G$, we consider building a new graph $G’$:</p>

<ul>
  <li>
    <p><strong>max problem to a min problem?</strong> Multiply by negative one:</p>

\[\max_{(X,Y)} \sum_{v \in X} a_v + \sum_{v \in Y} b_v - \sum_{e \in \delta(X)} p_e \implies \min_{(X,Y)} -\sum_{v \in X} a_v - \sum_{v \in Y} b_v + \sum_{e \in \delta(X)} p_e\]

    <p>and we can “remove the negative sign” by adding the constant $\sum\limits_{v \in V}a_{v} + \sum\limits_{v \in V}b_{v}$ to <em>every</em> edge, which gives:</p>

\[\implies \min_{(X,Y)} +\sum_{v \in X} b_v +\sum_{v \in Y} a_v + \sum_{e \in \delta(X)} p_e\]

    <p>which (unlike the case of shortest path problem) does <em>not</em> change the optimal solution.</p>
  </li>
  <li>
    <p><strong>undirected edges to directed?</strong> add both and give both a penalty of $p_e$ to mimic $c_e$:</p>

    <p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231102234327.png" style="zoom:35%;" /></p>
  </li>
  <li>
    <p><strong>missing source and sink?</strong> Add them to the new graph $G’$ so that $V’ = V \cup {s,t}$</p>

    <p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231102234446.png" style="zoom:30%;" /></p>

    <p>where we can make $s$ the source by adding a directed edge from $s$ to <em>every edge in $V$ but not $t$</em>, and similarlity make $t$ the sink by adding a directed edge from <em>every edge in $V$ but not $s$</em> to $t$:</p>
  </li>
  <li>
    <p><strong>additional $a_v, b_v$ costs?</strong> Since now we have an edge from $s$ to every vertex $v \in V$, we can just assign $a_v$ to the capacity of that edge, and similarly for $b_v$.</p>

    <p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231102234841.png" style="zoom:25%;" /></p>
  </li>
</ul>

<p>Now, compare the two graphs we get $G$ and $G’$:</p>

<ul>
  <li>
    <p>there is a bijection where every parition $X,Y$ of $V$ will correspond to a cut $A,B$ in $G’$. This is basically because we can just have $A \iff X \cup {s}$ and $B \iff Y \cup {t}$.</p>

    <p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231102235254.png" style="zoom:15%;" /></p>
  </li>
  <li>
    <p>then we argue that <strong>computing the capacity $\sum_{e =(u,v); u \in A, v \in B} c_e$ of such cut in $G’$</strong> is the same as <strong>computing the objective function of $\sum_{v \in X} b_v +\sum_{v \in Y} a_v + \sum_{e \in \delta(X)} p_e$</strong>. How?</p>

    <p>Consider computing the capacity of the cut $A,B$ in $G’$. You see that the edges that going across $A,B$ would be:</p>
    <ul>
      <li>for every $v \in Y$, we pay $a_v$ for edges $(s,v)$ which crosses the boundary (left to right)</li>
      <li>for every $v \in X$, we pay $b_v$ for edges $(v,t)$ which crosses the boundary (left to right)</li>
      <li>finally we pay $p_e$ for all the edge that starst in $A$ and ends in $B$ (which is exactly $\sum_{e \in \delta(X)} p_e$)</li>
    </ul>

    <p>adding all the above up we get exactly $\sum_{v \in X} b_v +\sum_{v \in Y} a_v + \sum_{e \in \delta(X)} p_e$ for $G$.</p>
  </li>
  <li>
    <p>since we can minimize the capacity in $G’$, we can minimze $\sum_{v \in X} b_v +\sum_{v \in Y} a_v + \sum_{e \in \delta(X)} p_e$, which maximizes the original objective function.</p>
  </li>
  <li>
    <p>finally to reconstruct the partition $X,Y$ from the cut $A,B$, we just remove $s$ from $A$ and $t$ from $B$.</p>
  </li>
</ul>

<h2 id="maximum-flow-algorithm">Maximum Flow Algorithm</h2>

<p>Similar to minimum flow, we start with a flow graph $G=(V,E)$  wth <strong>directed edges</strong>, a source vertex $s$ and a sink $t$. Each edge $e \in E$ has a capacity $c_e$. The goal is to find a “flow” $f$ that maximizes the total flow from $s$ to $t$.</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231109222028.png" style="zoom:80%;" /></p>

<p>where in the right flow, we made “three streams of water flow”:</p>
<ul>
  <li>path $s \to v \to t$ with flow 2, because the $v\to t$ bottlenecks at 2</li>
  <li>path $s \to w \to t$ with flow 2, because the $s\to w$ bottlenecks at 2</li>
  <li>path $s \to v \to w \to t$ with flow 1, because the $s \to v$ only has 1 capacity left</li>
</ul>

<p>But how do we formalize this into a problem (and find an algorithm to solve it)? First, we need to redefine what it means to be a valid flow:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">View 1</th>
      <th style="text-align: center">View 2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231109222428.png" style="zoom:70%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231109222415.png" style="zoom:70%;" /></td>
    </tr>
  </tbody>
</table>

<p>and notice that <mark>these two are equivalent</mark>: specifying a configuation of <mark>valid flow is the same as obeying the conservation principle</mark>. If each edge is spending $\le$ its full capacity and for each vertex (except for $s,t$) the <mark>total outflow equals total inflow</mark>, then it is a valid flow. (Note that this understanding is critical to figure out why the algorithm works.)</p>

<p>Therefore, this gives us the formal definition:</p>

<blockquote>
  <p><strong>Maximum Flow Problem</strong>: given a flow graph, assign a flow amount $f_e \ge 0$ to every edge such that:</p>
  <ul>
    <li>for every edge $e \in E$, $f_e \le c_e$ (i.e. you cannot exceed the capacity)</li>
    <li>for every vertex $v \in V \setminus {s,t}$, the total inflow equals total outflow</li>
  </ul>

  <p>the goal is to <strong>maximize</strong> the total flow from $s$ to $t$ = total flow out of $s$ = total flow into $t$.</p>
</blockquote>

<p>The intuition of solving this is to first try a intuitive greedy approach, figure out what went wrong, and attempt to fix that (magically reach the correct algorithm in this case).</p>

<h3 id="naive-greedy-maximum-flow-algorithm">Naive Greedy Maximum Flow Algorithm</h3>

<p>Idea:  start with the all-zero flow (i.e. all edges assigned $f_e = 0$) and greedily produce ﬂows with ever-higher value:</p>

<ol>
  <li>find a viable path $s \overset{P}{\leadsto} t$ in the graph (i.e. can send flow through) using BFS/DFS while checking $f_{e} \le u_e$ does not exceed capacity</li>
  <li>if none exist, then we are done</li>
  <li>if found, find how much we can send through on that path $\Delta = \min_{e \in P} (u_e - f_e)$ where $f_e$ represents the current flow we assigned on that edge</li>
</ol>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231109223809.png" style="zoom:70%;" /></p>

<p>Technically this is already greedy, to make it “greedier” consider step 1 to always pick the path that has highest $\Delta$. Either way, we show that this algorithm is incorrect:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Greedy Output</th>
      <th style="text-align: center">Optimal Output</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231109224100.png" style="zoom:70%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231109224111.png" style="zoom:70%;" /></td>
    </tr>
  </tbody>
</table>

<p>where the greedy algorithm can be “unlucky” in that if it picked the zig-zag path in the first iteration, then it has to terminate with flow 3. But the optimal solution is flow 5.</p>

<h3 id="residual-graph-and-the-ford-fulkerson-algorithm">Residual Graph and the Ford-Fulkerson Algorithm</h3>

<p>The key idea is to imagine to be able to send flow <strong>backward</strong> along the edge. How does this work? Essentially it relies on the equivalent view that <mark>all we need is conservation of flow at each vertex</mark>. For example considering the blue path:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Sending Flow Backward</th>
      <th style="text-align: center">Optimal Solution</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231109224747.png" style="zoom:70%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231109224800.png" style="zoom:70%;" /></td>
    </tr>
  </tbody>
</table>

<p>Now notice that <strong>these are the same</strong>! Because we are sending flow in the opposite direction, we can just subtract that from the existing flow we assigned (alike thinking about Kirchoff’s law in circuits). This is the idea of the <strong>residual graph</strong>:</p>

<blockquote>
  <p><em>Residual Graph</em>: given a flow graph $G=(V,E)$ with a flow $f$ assigned to each edge, the residual graph $G_f$ is defined as:</p>
  <ul>
    <li>the same set of vertics</li>
    <li>but with two directed edges for each edge in $G$
an edge $e = (v,w)$ that carries flow $f_e$ spawns into a forward edge of $G_f$ with capacity $u_e - f_e$, and a backward edge with capacity $f_e$.</li>
  </ul>

  <p>Visually:</p>

  <p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231109225642.png" style="zoom:70%;" /></p>

  <p>and as a result, <strong>any feasible flow in $G$ must still be feasible in $G_f$</strong>, because the remaining flow is kept by the forward edge. But since we now also have backward edges, the “search space” for possible flows is now larger. Though how is this useful?</p>
</blockquote>

<p>First a concrete example of what a redidual graph looks like:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Given a flow $f$ graph</th>
      <th style="text-align: center">Resdiual $G_f$ verbose</th>
      <th style="text-align: center">Residual $G_f$ simplified</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231109224100.png" style="zoom:70%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231109225311.png" style="zoom:70%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231109225318.png" style="zoom:70%;" /></td>
    </tr>
  </tbody>
</table>

<p>where essentially now:</p>
<ul>
  <li>the forward edge in residual graph means how much flow can you <em>still send out</em></li>
  <li>the backward edge is how much you can undo, i.e. from the flow you <em>already sent out</em></li>
</ul>

<p>We now show that the Ford-Fulkerson algorithm <strong>just needs to use that residual graph to be correct</strong>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">ford_fulkerson</span><span class="p">():</span>
  <span class="n">initialize</span> <span class="p">{</span><span class="n">f_e</span><span class="p">}</span> <span class="n">to</span> <span class="n">be</span> <span class="nb">all</span> <span class="n">zero</span>
  <span class="n">G_f</span> <span class="o">=</span> <span class="n">residual_graph</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="p">{</span><span class="n">f_e</span><span class="p">})</span>  <span class="c1"># a residual graph is defined with a flow
</span>  <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
    <span class="c1"># simple modified DFS/BFS can do this in O(m)
</span>    <span class="n">P</span> <span class="o">=</span> <span class="n">find_path</span><span class="p">(</span><span class="n">G_f</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>  <span class="c1"># find a path in RESIDUAL graph s.t. every edge has positive capacity
</span>    <span class="k">if</span> <span class="n">P</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
      <span class="k">return</span> <span class="p">{</span><span class="n">f_e</span><span class="p">}</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">Delta</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">capacity</span> <span class="n">of</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">G_f</span> <span class="ow">in</span> <span class="n">that</span> <span class="n">path</span> <span class="n">P</span><span class="p">)</span>  <span class="c1"># find the bottleneck capacity
</span>
      <span class="c1"># increase the flow from what we found
</span>      <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">P</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">e</span> <span class="ow">is</span> <span class="n">forward</span> <span class="n">edge</span> <span class="ow">in</span> <span class="n">G</span><span class="p">:</span>  <span class="c1"># flow in the real graph
</span>          <span class="n">f_e</span> <span class="o">+=</span> <span class="n">Delta</span>
        <span class="k">else</span><span class="p">:</span>
          <span class="n">f_e</span> <span class="o">-=</span> <span class="n">Delta</span>
    <span class="n">G_f</span> <span class="o">=</span> <span class="n">residual_graph</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="p">{</span><span class="n">f_e</span><span class="p">})</span>  <span class="c1"># update the residual graph
</span></code></pre></div></div>

<p>where the only difference is that now we are <strong>searching for path in the residua graph</strong> (which has more options). But why it this correct?</p>

<h3 id="correctness-of-ford-fulkerson-algorithm">Correctness of Ford-Fulkerson Algorithm</h3>

<p>The plan is similar to proving <a href="#prims-algorithm">Prim’s Algorithm</a> where we show correctness by:</p>
<ol>
  <li>FF algorithm outputs a viable flow</li>
  <li>There is some property that gives rises to the maximum flow</li>
  <li>FF output satisfies that property</li>
</ol>

<hr />

<p><em>Proof of Claim 1</em>: The intuition is that every iteration of the algorithm we are maintainining the invariance that ${f_e}_{e \in E}$ is a flow. This is essentially because</p>
<ul>
  <li>we chose $\Delta$ such that no $f_e$ in the real graph $G$ to become negative or exceeds $u_e$</li>
  <li>every edge still preserves “flow in equals flow out”. Why? Consider a vertex $v \in P$ for a $P$ in $G_f$ we picked at the current iteration of the algorithm. Then there is an edge $(x,v)$ and $(v,w)$ with some flow we assigned. Since this flow assigned is in the residual graph:
    <ul>
      <li>if $(x,v)$ corresponded to the forward edge in $G$, vertex $v$ <em>increased incoming flow by $\Delta$</em>. If $(v,w)$ corresponds also to forward edge, then it <em>increased outgoing flow by $\Delta$</em>. Therefore, the net flow in/out $v$ stayed the same.</li>
      <li>if $(x,v)$ corresponded to the forward edge in $G$, vertex $v$ <em>increased incoming flow by $\Delta$</em>. If $(v,w)$ corresponds also to backward edge, then it <em>decreased incoming flow by $\Delta$</em>. Therefore, the net flow in/out $v$ stayed the same.</li>
      <li>… in total four cases, and all of them preserve the flow in/out $v$.</li>
    </ul>
  </li>
</ul>

<p>Therefore, if the algorithm halted, the flow ${f_e}_{e \in E}$ <strong>is a viable flow</strong>. Finally, since every iteration of the algorithm increases the value of the current flow by $\Delta &gt; 0$, and since there is only a finite amount of flow that can come out of $s$ source, the algorithm <strong>will terminate</strong> eventually.</p>

<hr />

<p><em>Proof of Claim 2</em>: Recall that in a directed graph $G$ with a source $s$ and sink $t$, an $s-t$ cut is a partition of $V$ into $A,B$ such that $s \in A$ and $t \in B$. The capacity of the cut is the sum of the capacities of edges <strong>crossing from $A$ to $B$</strong>. We claim that</p>

<blockquote>
  <p><strong>Optimality Condition for Max Flow</strong>: let $f$ be a valid flow in graph $G$, then:</p>
  <ul>
    <li>$f$ is a maixmum flow</li>
    <li>$\iff$ there is an $s-t$ cut with capacity equal to the value of $f$</li>
    <li>$\iff$ there is no $s \leadsto t$ path with positive capacity in the residual graph $G_f$</li>
  </ul>

  <p>where condition 3 is basically when FF algorithm terminates, so if we can prove this then we are done.</p>
</blockquote>

<p>(note that condition 3 is quite “strong”, it means <strong>all you need to do is to somehow come up with a flow $f$ such that the residual network has no more viable $s \leadsto t$ path</strong>.)</p>

<blockquote>
  <p>First we show that condition (2) implies condition (1)</p>
</blockquote>

<p>The intuition is that for ean $s-t$ cut we do, that cost will include all the edge costs that flows out of $A$. Therefore, for any flow configuration $f$, it will consist of path that goes out from $A$ to $B$. Since the maximum/best case scenraio is the flow configuration exhausts all out-flowing capacity, therefore:</p>

\[\text{value of any }f \le \text{capacity of any }s-t \text{ cut}\]

<p>To prove this inequality a bit more formally, the value $f$ of any flow can be considered as</p>

\[\text{value of }f = \sum\limits_{e \in \delta^{+}(s)} f_{e} = \sum\limits_{e \in \delta^{+}(s)} f_{e} - \underbrace{\sum\limits_{e \in \delta^{-}(s)} f_{e}}_{\mathrm{zero}}\]

<p>since $\delta^{-}(s) = \empty$ as source has no incoming edges. Then, consider any $A,B$ cut in residual graph $G_f$. Since the conservation property hold, all other vertices will have the two terms zero:</p>

\[\text{value of }f = \sum\limits_{v \in A} \left( \sum\limits_{e \in \delta^{+}(v)} f_{e} - \sum\limits_{e \in \delta^{-}(v)} f_{e} \right)\]

<p>which is essentially to count every edge’s contribution in $A$. But then that is <strong>essentially treating $A$ as a giant “source” vertex</strong>, so that:</p>

\[\text{value of }f = \sum\limits_{e \in \delta^{+}(A)} f_{e} - \sum\limits_{e \in \delta^{-}(A)} f_{e}\]

<p>Then the rest is obvious: all the flow coming out of $A$ cannot be larger than the capacity $u_e$, and all $f_e$ back into $A$ are non-negative, so:</p>

\[\begin{align*}
  \text{value of }f 
  &amp;= \sum\limits_{e \in \delta^{+}(A)} f_{e} - \sum\limits_{e \in \delta^{-}(A)} f_{e} \\
  &amp;\le \sum\limits_{e \in \delta^{+}(A)} u_e - \sum\limits_{e \in \delta^{-}(A)} 0 \\
  &amp;= \sum\limits_{e \in \delta^{+}(A)} u_e \\
\end{align*}\]

<p>therefore, visually this inequality means:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231109234433.png" style="zoom:80%;" /></p>

<p>so if value of <strong>one of $s-t$ cut overlapped with the cross in the figuer above</strong> (condition 2), then that cross has to be the maximum $f$ you can have due to the inequality above $\implies$ condition (1).</p>

<blockquote>
  <p>Next we show that (1) implies (3)</p>
</blockquote>

<p>This is obvious. If by contrapositive that we still find a s-t path in $G_f$, then we can just increase the flow by $\Delta$ and still have a viable flow. But this contradicts the fact that (1) is a maximum flow.</p>

<blockquote>
  <p>Finally we show (3) implies (2).</p>
</blockquote>

<p>If (3) is true (no $s \leadsto t$ path possible in $G_f$), then we can obtain a partition $A$ by just doing a BFS/DFS from $s$ until we get stuck:</p>

\[A = \{ v \in V: \text{ther is an $s \leadsto v$ path in $G_f$} \}\]

<p>then the other partition $V-A$ will contain $t$. Additionally, such a cut must look like this:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231110000720.png" style="zoom:80%;" /></p>

<p>where no (positive) edges would be sticking out of $A$, as otherwise we would have expanded $A$. But what does this cut mean <strong>for the original graph $G$</strong>?</p>

<ul>
  <li>
    <p>Every edge sticking <em>out</em> of $A$ in $G$ must had assigned $f_e = u_e$ saturated the capacity. If not, then the residual graph $G_f$ would have a positive capacity edge forward edge (representing how much capacity you can still send) sticking out of $A$.</p>
  </li>
  <li>
    <p>Every edge going <em>into</em> $A$ in $G$ must have an assigned $f_{e} = 0$. This corresponds to the residual graph $G_f$ having an edge of $0$ sticking <em>out of</em> $A$ to $B$ (recall that the corresponding backward edge in $G_f$ represents the flow you have already sent out).</p>
  </li>
</ul>

<p>Now recall that we had the inequality before, it now becomes equality</p>

\[\begin{align*}
  \text{value of }f 
  &amp;= \sum\limits_{e \in \delta^{+}(A)} f_{e} - \sum\limits_{e \in \delta^{-}(A)} f_{e} \\
  &amp;= \sum\limits_{e \in \delta^{+}(A)} u_e - \sum\limits_{e \in \delta^{-}(A)} 0 \\
  &amp;= \sum\limits_{e \in \delta^{+}(A)} u_e \\
  &amp;= \text{capcity of }(A, V-A)
\end{align*}\]

<p>this completes the proof.</p>

<h3 id="reduction-to-min-cut">Reduction to Min Cut</h3>

<p>This now becomes trivial, as you recall this figure</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231109234433.png" style="zoom:80%;" /></p>

<p>The recall that in the third part of <a href="#correctness-of-ford-fulkerson-algorithm">Correctness of Ford-Fulkerson Algorithm</a> proof we said</p>

\[\text{value of }f = \text{capcity of }(A, V-A), \quad \text{for $f$ is a max flow}\]

<p>therefore the correspdong $(A, V-A)$ parition must be a minimum cut (based on Figure 7 above, corresponding to an overlap of cross and circle).</p>

<h3 id="runtime-of-ford-fulkerson-algorithm">Runtime of Ford-Fulkerson Algorithm</h3>

<p>So what about the runtime? The worst case is $f$ many iterations, where $f$ is the value of the maximum flow in the graph (because we are increasing the flow by $\Delta$ each time). But note that:</p>

<blockquote>
  <p>Ford-Fulkerson Algorithm always terminates for networks whose edge capacities are integral (or, equivalently, rational). On the other hand, it might <em>fail to terminate if networks have an edge with an irrational capacity</em>.</p>
</blockquote>

<p>However, we can make it polynomial time by using BFS to find an augmentation path, which is called Edmonds-Karp algorithm, which we will not cover here.</p>

<h3 id="reduction-to-bipartite-matching">Reduction to Bipartite Matching</h3>

<blockquote>
  <p><em>Bipartite Matching Problem</em>: consdier an undirected bipartite graph $G=(V \cup W \cup E)$ (see image below), with every edge of $E$ having one endpoint in each of $V$ and $W$. That is, no edges internal to $V$ or $W$ are allowed. The feasible solutions are the matchings of the graph, meaning we can only <strong>pick $S \subset E$ of edges that share no endpoints</strong>. <strong>The goal is to pair up as many vertices as possible (using edges of $S$)</strong></p>
</blockquote>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231103000933.png" style="zoom:30%;" /></p>

<p>For example, in the following graph, the maximum matching is 1 (pair of vertex):</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231103001131.png" style="zoom:40%;" /></p>

<blockquote>
  <p><em>Claim</em>: maximum-cardinality matching reduces in linear time to <strong>maximum flow</strong>.</p>
</blockquote>

<p>The trick is to consider transformation of the bipartite graph $G$ to the following:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231110012430.png" style="zoom:80%;" /></p>

<p>where given a bipartite graph $G=(V \cup W \cup E)$, we construct a flow graph $G’$ with:</p>

<ul>
  <li>add $s$ source with edges to all vertices in $V$ with <strong>outgoing capacity exactly 1</strong></li>
  <li>add $t$ sink with edges from all vertices in $W$ with <strong>incoming capacity exactly 1</strong></li>
  <li>all other edges from a vertex in $V$ to $W$ can have <strong>any capacity greater than 1</strong>. Here we use infinity to illustrate this.</li>
</ul>

<p>Notice that this construction gives <em>any flow in $G’$</em> to</p>

<ul>
  <li>use each vertex in $x \in V$ at most once, since there is only one edge that can flow to $x$ and has the bottleneck capacity of 1</li>
  <li>use each vertex in $y \in W$ at most once, since there is only one edge that can flow from $y$ and has the bottleneck capacity of 1</li>
</ul>

<p>Therefore:</p>

<ul>
  <li>$\implies$ a bijection between a bipartite matching in $G$ with an integer-valued flow in $G’$</li>
  <li>$\implies$ the bijection also gives the same cost: the size of flow you assigned is th same as the cardinality of the matching</li>
  <li>$\implies$ the maximum flow in $G’$ is the same as the maximum cardinality matching in $G$</li>
</ul>

<h2 id="additional-proporties-of-flow-in-graphs">Additional Proporties of Flow in Graphs</h2>

<p>This section all considers a flow graph $G$ being a directed graph with a source $s$ and sink $t$, and each edge $e \in E$ has a positive, interger capacity $c_e$.</p>

<blockquote>
  <p><strong>Acyclic Flow</strong>: a flow is acyclic if, for <strong>every</strong> cycle in the flow graph $C \subset G$:</p>

\[C = \{ x_1 \to x_2, x_2 \to x_3, ... , x_n \to x_1 \}\]

  <p>have at least one edge $e = (x_i, x_{i+1}) \in C$ having a flow of zero $f(e) = 0$. (otherwise we have a cycle flow)</p>
</blockquote>

<blockquote>
  <p><strong>Partitionable Flow</strong>: a flow is partitionable if there is a collection of $s,t$ paths flows $P_1, P_2, …, P_{\vert f\vert }$ with paths can be duplicates, $\vert f\vert$ is the value of the flow (i.e. total out of source $s$), and every path just consumes flow of $1$, so that:</p>

\[f(e) = \mathrm{size}( \{ i | e \in P_i \} ), \quad \forall e \in E\]

  <p>i.e. the flow on an edge $e$ is the number of paths that use that edge.</p>
</blockquote>

<p>Then some properties of flow include:</p>

<ol>
  <li>For every flow, there exists an acyclic flow with the same value.</li>
  <li>every acyclic flow is partitionable</li>
</ol>

<hr />

<p>Proof sketch for 1: realize that edges from a source vertex or the sink cannot be involved in any cycle. Therefore, for every cycle in the graph, we can decrement the flow on every edge until one of the edges hit zero. This will result in:</p>

<ul>
  <li>no change in flow value (since source/sink aren’t affected)</li>
  <li>still a valid flow since for every vertex, the total inflow equals total outflow (since we decremented the same amount into each vertex and out of each vertex)</li>
</ul>

<hr />

<p>Proof sketch for 2: We can decompose the flow in the network as follows:</p>

<ol>
  <li>Identify a path from the source to the sink that carries a positive flow. This can be done by starting at the source and following edges with positive flow until the sink is reached.</li>
  <li>The minimum flow in an edge along this path is the bottleneck of the path. We can consider this as a single unit of flow and subtract this flow value from every edge along this path.
    <ul>
      <li>This process <strong>does not violate</strong> the flow conservation principle at any node since that path will also be acyclic = i.e. every vertex on the graph is <strong>entered and exited exactly once.</strong></li>
      <li>if the original path is cyclic, then this does not work: we may find a cyclic path where a vertex is exited, entered (a cycle), and exited again = net flow in/out is not conserved on that path.</li>
      <li>this will decrease the original flow value of the network by the bottleneck value of the path</li>
    </ul>
  </li>
  <li>Because the conservation principle holds, the remaining flow is still valid. This means that by definition, if the remaining flow $&gt; 0$, then there must still exists flow paths from the source to the sink with positive flow (i.e. the water is still running).</li>
</ol>

<p>Repeat the above step until <strong>no more paths with positive flow from the source to the sink can be found in the residual network</strong>. Each time a path is found, it is distinct and non-overlapping with previously found paths because:</p>

<ol>
  <li>The flow in an edge cannot be counted more than once since each path uses the minimum flow on its route (the bottleneck), which is then subtracted from the network.</li>
  <li>Once the flow on an edge is reduced to zero, <strong>that edge cannot be used</strong> in subsequent paths.</li>
</ol>

<h1 id="linear-programming">Linear Programming</h1>

<p>Linear programming is a method to solve optimization problems where the objective function and constraints are linear. It is special in that:</p>

<ul>
  <li>Linear programming is a remarkable sweet spot between <em>generality and
computational efficiency</em> (too general a problem becomes NP-Hard)</li>
  <li>exists many commercial solvers (i.e. algorithm implementations) that can solve those problems within <em>polynomial time</em></li>
  <li>many problems we have seen in the later part of this course <em>can be formulated as linear programming problems</em></li>
</ul>

<p>We will mostly focus on how to reduce problems into a linear programming problem, and not so much on the algorithmic details of solving it.</p>

<h2 id="ingredients-of-a-linear-program">Ingredients of a Linear Program</h2>

<p>So <strong>what kind of problems can linear programming solve</strong>? The answer is to formulate questions in the following form:</p>

<blockquote>
  <p><strong>Ingredients of a Linear Program</strong>: basically you can specify what variables to solve/be returned, what constraints you have, and what is the objective.</p>
  <ol>
    <li><em>Decision Variables</em>: the variables you want to solve for, denoted as $x_1, x_2, …, x_{n} \in \R$.</li>
    <li>
      <p><em>Linear Constraints</em>: you can have as many as you want, but each needs to be in the form of:</p>

\[\sum_{j=1}^n a_j x_j \{* \} b_i\]

      <p>where $*$ can be $\le, \ge, =$. (Really all you need is $\le$, because to get $\ge$ you can multiply by $-1$ and to get $=$ you can do both $\le$ and $\ge$.)</p>
    </li>
    <li>
      <p><em>Linear Objective Function</em>: one objective function to maximize or minimize, in the form of:</p>

\[\max \sum_{j=1}^n c_j x_j\]

      <p>or the minimum (again, you can just multiply by $-1$ to get the other one).</p>
    </li>
  </ol>

  <p>note that <strong>you can specify the $a_j,b_i,c_j$</strong>, and the algorithm will solve for the $x_j$.</p>
</blockquote>

<p>A starter example is to consider finding the solution to:</p>

\[\max x_1 + x_2\]

<p>subject to the following (four) linear constraints:</p>

\[\begin{align*}
  x_1 \ge 0 \\
  x_{2} \ge 0 \\
  2x_1 + x_2 \le 4 \\
  x_1 + 2 x_2 \le 1
\end{align*}\]

<p>then obviously this fits directly with the linear programming formulation, where $x_1, x_2$ are the decision variables. Visually, this linear problem does:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231115010146.png" style="zoom:80%;" /></p>

<p>where the</p>
<ul>
  <li><strong>dimension of space</strong> we are working with is specified by the number of decision variables</li>
  <li><strong>constraints</strong> specify the feasible region (the shaded area)</li>
  <li><strong>objective</strong> specifies the direction of optimization (the green arrow)</li>
</ul>

<p>To be more general:</p>

<blockquote>
  <p><strong>Geometric Interpretation of Linear Programs</strong>:</p>
  <ol>
    <li>A linear <strong>constraint</strong> in $n$ dimensions corresponds to a halfspace in $\R^{n}$. Thus a feasible region is an intersection of halfspaces (i.e. many constraints), the higher-dimensional analog of a polygon.</li>
    <li>The <strong>objective function</strong> specifies parallel $(n-1)$ dimensional hyperplans, with a direction vector specified by the vector $\vec{c} = [c_1, …, c_n]$. (in the previous example, $\vec{c} = [1,1]$)</li>
    <li>The <strong>optimal solution</strong> is the point in the feasible region that is furthest in the direction of $\vec{c}$.</li>
    <li>When there is a <em>unique</em> optimal solution, it is vertex (i.e. a corner) of the feasible region.</li>
  </ol>
</blockquote>

<p>besides the above, also note that for any given linear programming problem:</p>
<ul>
  <li>There might be <em>no feasible solutions</em> at all</li>
  <li>optimal objective function value might be <em>unbounded</em>, which the linear programming algorithms should detect if this is the case</li>
  <li>there might be <em>multiple optimal solutions</em>. Whenever the feasible region is bounded, however, there always exists an optimal solution</li>
</ul>

<h2 id="example-applications-of-linear-programming">Example Applications of Linear Programming</h2>

<p>Zillions of problems reduce to linear programming. Here we cover a few interesting ones.</p>

<h3 id="linear-programming-for-maximum-flow">Linear Programming for Maximum Flow</h3>

<p>The problem of maximum literally translates directly to a linear program (though Ford-Fulkerson algorithm is more efficient).</p>

<p>Proof: in maximum flow we wanted to find a flow for each edge $f_e$, such that the sum of flow is maximum, subjective to conservation constraints. This sounds exactly like linear programming:</p>

<ol>
  <li><em>Decision Variables</em>: the flows for each edge ${ f_e }_{e \in E}$</li>
  <li>
    <p><em>Constraints</em>: We needed the conservation contraints, and the capacity constraints</p>

\[\sum\limits_{e  \in \delta^{+}(v)} f_e - \sum\limits_{e \in \delta^{-}(v)} f_e = 0, \quad \forall v \in V \setminus \{s,t\}\]

    <p>which gives $n-2$ constraint equations, where $e  \in \delta^{+}(v)$ means edges going out of $v$ and $e \in \delta^{-}(v)$ means edges going into $v$. Then we additionally have for each edge:</p>

\[f_{e} \le u_e\]

    <p>and finally</p>

\[f_e \ge 0\]

    <p>So in total this is $n-2+2m$ contraints. <mark>Note that these are all linear (each decision variable $f_e$ only appears by itself with some constant)!</mark></p>
  </li>
  <li><em>Objective Function</em>: simply:</li>
</ol>

\[\max \sum\limits_{e \in \delta^{+}(s)} f_e\]

<p>which you can do by specifing a weight $c_j$ to be one only for edges from the source and zero otherwise.</p>

<h3 id="linear-programming-for-minimum-cost-flow">Linear Programming for Minimum-Cost Flow</h3>

<blockquote>
  <p>Problem: in addition to maximum flow, consider two changes:</p>
  <ul>
    <li>there is a cost $c_e$ associated with each unit of flow spent</li>
    <li>
      <p>the flow is required to be exactly $d$</p>

\[\sum_{e \in \delta^{+}(s)} f_e = d\]
    </li>
  </ul>

  <p>so the objective function is to minimize routing over “expensive pipes”:</p>

\[\min \sum_{e \in E} c_e f_e\]

</blockquote>

<p>Notice that this can be reduced to the <em>same linear program</em> in the previous section, but with:</p>

<ul>
  <li>an additional constraint: $\sum_{e \in \delta^{+}(s)} f_e = d$</li>
  <li>objective function changed to $\min \sum_{e \in E} c_e f_e$ (which is linear since $c_e$ are constants)</li>
</ul>

<h3 id="linear-programming-for-regression">Linear Programming for Regression</h3>

<p>We now consider two less obvious applications of linear programming, to basic problems in
machine learning.</p>

<blockquote>
  <p><strong>Regression</strong>: consider inputs of labeled data ${ \vec{p}^{1}, \vec{p}^{2}, …, \vec{p}^{m} }$ consisting of $m$ data points in $\R^{d}$, and their corresponding labels ${ y^{1}, y^{2}, …, y^{m} }$, where $y^{i} \in \R$.</p>
  <ul>
    <li>for example, a dataset of features of $m$ undergraduate students, and $y^{i}$ are their GPAs.</li>
  </ul>

  <p>The goal is to find a linear function $h(\vec{z}) = \vec{w} \cdot \vec{z} + b= \sum_{i=1}^{d} w_i z_i + b$ that fits this data as well as possible.</p>
</blockquote>

<p>We now show that computing the best line under the definition of <strong>minimizing absolute error</strong> can be formulated as a linear program (for the more common one, mean squared error, check the ML notes).</p>

<p>First recall that for a $d$-dimensional space, a linear function $h  : \R^{d} \to \R$ has the form:</p>

\[h(\vec{z}) = \vec{w} \cdot \vec{z} + b = \sum_{i=1}^{d} w_i z_i + b\]

<p>where the <strong>coefficients $w_i$’s and $b$ are unknown</strong>. The absolute error for one data point is defined as:</p>

\[E_i ( \vec{w} ,b) = \left| \underbrace{\left( \sum\limits_{j=1}^{d} w_j p_j^{i} +b\right)}_{\text{prediction}} - y^{i} \right|\]

<p>and so the total loss over the entire dataset is:</p>

\[\min_{\vec{w} ,b} \sum\limits_{i=1}^{m} E_i(\vec{w} ,b)\]

<p>note that up to this point, this problem had:</p>

<ul>
  <li>$d+1$ decision variables: $\vec{w} ,b$</li>
  <li>no constraints for the weights and bias</li>
  <li>a nonlinear objective function (because it used absolute value)</li>
</ul>

<p>So how is this linear programmable? The trick is we can <strong>convert the absolute value in objective function to become constraints</strong>. Consider introducing $m$ new decision variables $e_1, e_2, … , e_m$ which would represent  $E_i ( \vec{w} ,b)$. We make it look like it can choose $e_i$, but in fact not because we know:</p>

\[| x| = \max \{ x, -x \}\]

<p>so we can get inequalities to represent absolute values:</p>

\[e_{i} \ge \left( \sum\limits_{j=1}^{d} w_j p_j^{i} +b \right) - y^{i} \\
e_{i} \ge - \left( \sum\limits_{j=1}^{d} w_j p_j^{i} +b \right) + y^{i}\]

<p>and the objective function is:</p>

\[\min \sum\limits_{i=1}^{m} e_i\]

<p>so that now we consider</p>

<ul>
  <li>$d+1+m$ decision variables: $\vec{w} ,b, e_1, e_2, … , e_m$</li>
  <li>$2m$ constraints for the weights and bias</li>
  <li>a linear objective function where obtaining the best $e_i$’s becomes obtaining the best absolute error (think about obtaining a better $e_i$ subject to this contraint is the same as obtaining $\vec{w},b$ with a lower loss )</li>
</ul>

<p>note that the $e_i$ under the hood <mark>aren't ''free'' variables</mark>:</p>
<ul>
  <li>After the program found out about $w_j$ and $b$, the $e_i$’s are determined by picking to be <strong>as close as possible to the inequality (i.e. represents the absolute error)</strong> because of the objective function being a minimizer</li>
  <li>then, the objective function also correctly represents the total absolute error</li>
</ul>

<h3 id="linear-programming-for-linear-classifier">Linear Programming for Linear Classifier</h3>

<blockquote>
  <p><strong>Linear Classifier</strong>: consider inputs of binary classification, where you get $m$ positive data points $\vec{p}^{1}, …, \vec{p}^{m} \in \R^{d}$ and $m’$ negative data points $\vec{q}^{1}, …, \vec{q}^{m’} \in \R^{d}$.</p>

  <p>The goal is to compute a linear function $h(\vec{z}) = \vec{w} \cdot \vec{z} + b= \sum_{i=1}^{d} w_i z_i + b$ that separates the positive and negative data points as well as possible. In other words:</p>

\[h(\vec{p}^{i}) &gt; 0, \quad \forall i \in [m] \\\]

  <p>and for negative points:</p>

\[h(\vec{p}^{i}) &lt; 0, \quad \forall i \in [m'] \\\]

</blockquote>

<p>Visually, it looks likes:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231115015439.png" style="zoom:80%;" /></p>

<p>Assuming there exists such a classifier, the problem almost looks exactly like a linear program, except that we have strict inequalities here. Again, the simple trick of adding an extra decision variable solves the problem.</p>

<p>To encode this strict inequality, we introduce a new decision variable $\delta$ representing the <mark>margin</mark> by which the nearest data point is on the correct side of the decision boundary. Then we have a new constraint with <strong>inequality</strong>:</p>

\[\sum\limits_{j=1}^{d} w_j p_j^{i} +b \ge \delta, \quad \forall i \in [m] \\
\sum\limits_{j=1}^{d} w_j q_j^{i} +b \le -\delta, \quad \forall i \in [m']\]

<p>with the objective of maximzing the margin $\delta$:</p>

\[\max \delta\]

<p>so that we have a linear program with:</p>
<ul>
  <li>$d+2$ decision variables: $\vec{w} ,b, \delta$</li>
  <li>$m + m’$ constraints for the weights and bias</li>
  <li>a linear objective function</li>
</ul>

<p>(note that this looks awfully like SVM)</p>

<hr />

<p><strong>However, what if the points <em>aren’t</em> perfectly separable?</strong> In SVM we had slack varittlables, but here we can consider another extension: allow for errors, but penalize them.</p>

<p>More specifically, let’s say that in a perfect world, we would like a linear function $h$ such that:</p>

\[h(\vec{p}^{i}) &gt; 1, \quad \forall i \in [m] \\\]

<p>and</p>

\[h(\vec{q}^{i}) &lt; -1, \quad \forall i \in [m'] \\\]

<p>where the constant $1$ is a bit arbitrary here. Though the goal is to consider a <strong>hinge loss</strong> such that it penalizes on incorrect classifications, but gives zero loss as long as you have a correct classification with a margin of at least $1$:</p>

\[\mathrm{loss} = \begin{cases}
  \max \{1 - h(\vec{p}^{i}), 0 \}, \quad \text{for positive points}\\
  \max \{1 + h(\vec{q}^{i}), 0 \}, \quad \text{for negative points}
\end{cases}\]

<p>so then our task is to find a linear function that <strong>minimizes total hinge loss</strong>. While hinge loss looks non-linear, it really is just the maximum of two linear functions. We claim that this can be formulated as a linear program with constraints:</p>

\[\begin{align*}
  e_i &amp;\ge 1 - \left( \sum\limits_{j=1}^{d} w_{j} p_j^{i} +b \right), \quad \text{for every positive point $\vec{p}^i$ }\\
  e_i &amp;\ge 1 + \left( \sum\limits_{j=1}^{d} w_{j} q_j^{i} +b \right), \quad \text{for every negative point $\vec{q}^i$ }\\
  e_i &amp;\ge 0, \quad \text{for every point}
\end{align*}\]

<p>which is basically the hinge-loss, and then the objective is:</p>

\[\min \sum\limits_{i=1}^{m} e_i\]

<p>so again, we introduced $m$ new decision variables $e_i$ <mark>which aren't real ''free'' variables</mark>:</p>
<ul>
  <li>After the program found out about $w_j$ and $b$, the $e_i$’s under the hood are determined by picking to be as close as possible to the inequality (i.e. represents the hinge loss) because of the objective function being a minimizer</li>
  <li>then, the objective function also correctly represents the total hinge lossa</li>
</ul>

  </div><a class="u-url" href="/lectures/2023@columbia/CSOR4231_Analysis_of_Algorithms.html/" hidden></a>
  <script src="/lectures/assets/js/my_navigation.js"></script>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/lectures/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Lecture Notes</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Lecture Notes</li><li><a class="u-email" href="mailto:jasonyux17@gmail.com">jasonyux17@gmail.com</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/jasonyux"><svg class="svg-icon"><use xlink:href="/lectures/assets/minima-social-icons.svg#github"></use></svg> <span class="username">jasonyux</span></a></li><li><a href="https://www.linkedin.com/in/xiao-yu2437"><svg class="svg-icon"><use xlink:href="/lectures/assets/minima-social-icons.svg#linkedin"></use></svg> <span class="username">xiao-yu2437</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>An inexhaustive collection of markdown/latex(PDF) notes that I took since college. </p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
