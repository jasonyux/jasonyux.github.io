<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>CSEE4119 Computer Networks | Lecture Notes</title>
<meta name="generator" content="Jekyll v4.3.1" />
<meta property="og:title" content="CSEE4119 Computer Networks" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="An inexhaustive collection of markdown/latex(PDF) notes that I took since college." />
<meta property="og:description" content="An inexhaustive collection of markdown/latex(PDF) notes that I took since college." />
<link rel="canonical" href="/lectures/2021@columbia/CSEE4119_Computer_Networks.html/" />
<meta property="og:url" content="/lectures/2021@columbia/CSEE4119_Computer_Networks.html/" />
<meta property="og:site_name" content="Lecture Notes" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-12-16T00:00:00-05:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="CSEE4119 Computer Networks" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2021-12-16T00:00:00-05:00","datePublished":"2021-12-16T00:00:00-05:00","description":"An inexhaustive collection of markdown/latex(PDF) notes that I took since college.","headline":"CSEE4119 Computer Networks","mainEntityOfPage":{"@type":"WebPage","@id":"/lectures/2021@columbia/CSEE4119_Computer_Networks.html/"},"url":"/lectures/2021@columbia/CSEE4119_Computer_Networks.html/"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/lectures/assets/main.css"><link type="application/atom+xml" rel="alternate" href="/lectures/feed.xml" title="Lecture Notes" /></head>
<body><header class="site-header">

	<div class="wrapper"><a class="site-title" rel="author" href="/lectures/">Lecture Notes</a>

		<nav class="site-nav">
			<input type="checkbox" id="nav-trigger" class="nav-trigger" />
			<label for="nav-trigger">
			<span class="menu-icon">
				<svg viewBox="0 0 18 15" width="18px" height="15px">
				<path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
				</svg>
			</span>
			</label>

			<div class="trigger">
				<a class="page-link" href="/">Home</a>
				<a class="page-link" href="/projects">Projects</a>
				<a class="page-link" href="/research">Research</a>
				<span class="page-link" href="#">[Education]</span>
				<a class="page-link" href="/learning">Blog</a>
			</div>
		</nav>
	</div>
  </header><main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">
  <head>
  <script>
    MathJax = {
      // 
      loader: {
        load: ['[tex]/ams', '[tex]/textmacros', '[tex]/boldsymbol']
      },
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']],
        packages: {'[+]': ['ams', 'textmacros', 'boldsymbol']}
      }
    };
  </script>
  <script id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
  </script>
  </head>
  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">CSEE4119 Computer Networks</h1>
    <p class="post-meta"><time class="dt-published" datetime="2021-12-16T00:00:00-05:00" itemprop="datePublished">
        Dec 16, 2021
      </time></p>
  </header>

  <div class="section-nav" id="toc-all">
    <button type="button" id="toc-close" class="toc_collapsible" title="collapse">
      <span><strong>Table of Contents</strong></span>
    </button>
    <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" mirror-in-rtl="true" fill="#000000" style="width: 18px;" id="toc-reopen" class="toc_collapsible hidden">
      <g id="SVGRepo_bgCarrier" stroke-width="0"></g><g id="SVGRepo_tracerCarrier" stroke-linecap="round" stroke-linejoin="round"></g><g id="SVGRepo_iconCarrier"> <circle fill="#494c4e" cx="2" cy="2" r="2"></circle> <circle fill="#494c4e" cx="2" cy="8" r="2"></circle> <circle fill="#494c4e" cx="2" cy="20" r="2"></circle> <circle fill="#494c4e" cx="2" cy="14" r="2"></circle> <path fill="#494c4e" d="M23.002 3H7.998C7.448 3 7 2.55 7 2.002v-.004c0-.55.45-.998.998-.998H23c.55 0 1 .45 1 .998V2c0 .55-.45 1-.998 1zM23.002 9H7.998C7.448 9 7 8.55 7 8.002v-.004c0-.55.45-.998.998-.998H23c.55 0 1 .45 1 .998V8c0 .55-.45 1-.998 1zM23.002 15H7.998c-.55 0-.998-.45-.998-.998V14c0-.55.45-1 .998-1H23c.55 0 1 .45 1 .998V14c0 .55-.45 1-.998 1zM23.002 21H7.998c-.55 0-.998-.45-.998-.998V20c0-.55.45-1 .998-1H23c.55 0 1 .45 1 .998V20c0 .55-.45 1-.998 1z"></path> </g>
    </svg>
    <ul id="toc" class="section-nav">
<li class="toc-entry toc-h1"><a href="#chapter-1-basics">Chapter 1 Basics</a>
<ul>
<li class="toc-entry toc-h2"><a href="#the-network-edge">The Network Edge</a>
<ul>
<li class="toc-entry toc-h3"><a href="#access-networks">Access Networks</a>
<ul>
<li class="toc-entry toc-h4"><a href="#digital-subscriber-line">Digital Subscriber Line</a></li>
<li class="toc-entry toc-h4"><a href="#cable-internet-access">Cable Internet Access</a></li>
<li class="toc-entry toc-h4"><a href="#fiber-to-home">Fiber to Home</a></li>
<li class="toc-entry toc-h4"><a href="#ethernet-and-wifi">Ethernet and WiFi</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#network-core">Network Core</a></li>
<li class="toc-entry toc-h2"><a href="#performance-delay-loss-throughput">Performance (Delay, Loss, Throughput)</a>
<ul>
<li class="toc-entry toc-h3"><a href="#traceroute">Traceroute</a></li>
<li class="toc-entry toc-h3"><a href="#queuing-delay-and-packet-loss">Queuing Delay and Packet Loss</a></li>
<li class="toc-entry toc-h3"><a href="#throughput">Throughput</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#protocol-layers-and-their-service-models">Protocol Layers and Their Service Models</a>
<ul>
<li class="toc-entry toc-h3"><a href="#protocol-layering">Protocol Layering</a>
<ul>
<li class="toc-entry toc-h4"><a href="#application-layer">Application Layer</a></li>
<li class="toc-entry toc-h4"><a href="#transport-layer">Transport Layer</a></li>
<li class="toc-entry toc-h4"><a href="#network-layer">Network Layer</a></li>
<li class="toc-entry toc-h4"><a href="#link-layer">Link Layer</a></li>
<li class="toc-entry toc-h4"><a href="#physical-layer">Physical Layer</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#encapsulation">Encapsulation</a></li>
<li class="toc-entry toc-h3"><a href="#protocol-stack-variants">Protocol Stack Variants</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#chapter-2-application-layer">Chapter 2 Application Layer</a>
<ul>
<li class="toc-entry toc-h2"><a href="#principles-of-network-applications">Principles of Network Applications</a>
<ul>
<li class="toc-entry toc-h3"><a href="#application-architecture">Application Architecture</a>
<ul>
<li class="toc-entry toc-h4"><a href="#client-server-architecture">Client-Server Architecture</a></li>
<li class="toc-entry toc-h4"><a href="#p2p-architecture">P2P Architecture</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#processes-communicating">Processes Communicating</a>
<ul>
<li class="toc-entry toc-h4"><a href="#interface-between-process-and-computer-network">Interface between Process and Computer Network</a></li>
<li class="toc-entry toc-h4"><a href="#addressing-processes">Addressing Processes</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#transport-services-available-to-applications">Transport Services Available to Applications</a>
<ul>
<li class="toc-entry toc-h4"><a href="#transport-services-provided-by-the-internet">Transport Services Provided by the Internet</a>
<ul>
<li class="toc-entry toc-h5"><a href="#tcp-services">TCP Services</a></li>
<li class="toc-entry toc-h5"><a href="#udp-services">UDP Services</a></li>
<li class="toc-entry toc-h5"><a href="#tcp-vs-udp">TCP vs UDP</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#securing-tcp">Securing TCP</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#socket-programming">Socket Programming</a></li>
<li class="toc-entry toc-h2"><a href="#web-and-http">Web and HTTP</a>
<ul>
<li class="toc-entry toc-h3"><a href="#http-overview">HTTP Overview</a></li>
<li class="toc-entry toc-h3"><a href="#http-connections">HTTP Connections</a>
<ul>
<li class="toc-entry toc-h4"><a href="#non-persistent-http-example">Non-persistent HTTP: example</a></li>
<li class="toc-entry toc-h4"><a href="#persistent-http">Persistent HTTP</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#http-message-format">HTTP Message Format</a>
<ul>
<li class="toc-entry toc-h4"><a href="#http-request-message">HTTP Request Message</a>
<ul>
<li class="toc-entry toc-h5"><a href="#conditional-get">Conditional GET</a></li>
</ul>
</li>
<li class="toc-entry toc-h4"><a href="#http-response-message">HTTP Response Message</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#maintaining-state-cookies">Maintaining State: Cookies</a></li>
<li class="toc-entry toc-h3"><a href="#http2">HTTP/2</a></li>
<li class="toc-entry toc-h3"><a href="#http3">HTTP/3</a></li>
<li class="toc-entry toc-h3"><a href="#web-caching">Web Caching</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#dns-domain-name-system">DNS: Domain Name System</a>
<ul>
<li class="toc-entry toc-h3"><a href="#dns-services">DNS Services</a></li>
<li class="toc-entry toc-h3"><a href="#overview-of-how-dns-works">Overview of How DNS Works</a>
<ul>
<li class="toc-entry toc-h4"><a href="#root-name-server">Root Name Server</a></li>
<li class="toc-entry toc-h4"><a href="#top-level-domain-server">Top Level Domain Server</a></li>
<li class="toc-entry toc-h4"><a href="#local-name-server">Local Name Server</a></li>
<li class="toc-entry toc-h4"><a href="#iterative-query">Iterative Query</a></li>
<li class="toc-entry toc-h4"><a href="#recursive-query">Recursive Query</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#dns-records-and-messages">DNS Records and Messages</a>
<ul>
<li class="toc-entry toc-h4"><a href="#dns-messages">DNS Messages</a></li>
<li class="toc-entry toc-h4"><a href="#inserting-records-into-dns-database">Inserting Records into DNS Database</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#dns-security">DNS Security</a></li>
<li class="toc-entry toc-h3"><a href="#facebook-dns-outrage">Facebook DNS Outrage</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#video-streaming-and-content-distribution-networks">Video Streaming and Content Distribution Networks</a>
<ul>
<li class="toc-entry toc-h3"><a href="#internet-video">Internet Video.</a></li>
<li class="toc-entry toc-h3"><a href="#http-streaming-and-dash">HTTP Streaming and DASH</a>
<ul>
<li class="toc-entry toc-h4"><a href="#dash---dynamic-adaptative-streaming-over-http">DASH - Dynamic Adaptative Streaming over HTTP</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#cdn---content-distribution-networks">CDN - Content Distribution Networks</a>
<ul>
<li class="toc-entry toc-h4"><a href="#cdn-operation">CDN Operation</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#peer-to-peer-file-distribution">Peer-to-Peer File Distribution</a>
<ul>
<li class="toc-entry toc-h3"><a href="#scalability-of-p2p-architecture">Scalability of P2P Architecture</a></li>
<li class="toc-entry toc-h3"><a href="#p2p-file-distribution">P2P File Distribution</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#chapter-3-transport-layer">Chapter 3 Transport Layer</a>
<ul>
<li class="toc-entry toc-h2"><a href="#transport-services-and-protocol">Transport Services and Protocol</a></li>
<li class="toc-entry toc-h2"><a href="#multiplexing-and-demultiplexing">Multiplexing and Demultiplexing</a>
<ul>
<li class="toc-entry toc-h3"><a href="#udp-demultiplexing">UDP (De)Multiplexing</a></li>
<li class="toc-entry toc-h3"><a href="#tcp-demultiplexing">TCP (De)Multiplexing</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#user-datagram-protocol">User Datagram Protocol</a>
<ul>
<li class="toc-entry toc-h3"><a href="#udp-action">UDP Action</a></li>
<li class="toc-entry toc-h3"><a href="#udp-segment-structure">UDP Segment Structure</a></li>
<li class="toc-entry toc-h3"><a href="#udp-checksum">UDP Checksum</a></li>
<li class="toc-entry toc-h3"><a href="#udp-summary">UDP Summary</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#principle-of-reliable-data-transfer">Principle of Reliable Data Transfer</a>
<ul>
<li class="toc-entry toc-h3"><a href="#building-a-reliable-data-transfer-protocol">Building a Reliable Data Transfer Protocol</a>
<ul>
<li class="toc-entry toc-h4"><a href="#simplest-case-rdt10">Simplest Case: RDT1.0</a></li>
<li class="toc-entry toc-h4"><a href="#bit-error-rdt20">Bit Error: RDT2.0</a></li>
<li class="toc-entry toc-h4"><a href="#feedback-corrupted-rdt21">Feedback Corrupted: RDT2.1</a></li>
<li class="toc-entry toc-h4"><a href="#nak-free-rdt22">NAK-Free: RDT2.2</a></li>
<li class="toc-entry toc-h4"><a href="#error-and-loss-rdt30">Error and Loss: RDT3.0</a></li>
<li class="toc-entry toc-h4"><a href="#rdt30-timeline">RDT3.0: Timeline</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#stop-and-wait-vs-pipelining">Stop-and-Wait vs Pipelining</a></li>
<li class="toc-entry toc-h3"><a href="#go-back-n-gbn">Go-Back-N (GBN)</a></li>
<li class="toc-entry toc-h3"><a href="#selective-repeat-sr">Selective Repeat (SR)</a>
<ul>
<li class="toc-entry toc-h4"><a href="#dilemma-with-selective-repeat">Dilemma with Selective Repeat</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#gbn-vs-sr-model">GBN vs SR Model</a></li>
<li class="toc-entry toc-h3"><a href="#summary">Summary</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#tcp">TCP</a>
<ul>
<li class="toc-entry toc-h3"><a href="#the-tcp-connection">The TCP Connection</a></li>
<li class="toc-entry toc-h3"><a href="#tcp-segment-structure">TCP Segment Structure</a>
<ul>
<li class="toc-entry toc-h4"><a href="#sequence-and-acknowledgement-number">Sequence and Acknowledgement Number</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#round-trip-time-estimation-and-timeout">Round-Trip Time Estimation and Timeout</a>
<ul>
<li class="toc-entry toc-h4"><a href="#estimating-rtt">Estimating RTT</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#tcp-reliable-data-transfer">TCP Reliable Data Transfer</a>
<ul>
<li class="toc-entry toc-h4"><a href="#tcp-sender">TCP Sender</a></li>
<li class="toc-entry toc-h4"><a href="#tcp-receiver">TCP Receiver</a></li>
<li class="toc-entry toc-h4"><a href="#tcp-retransmissions">TCP Retransmissions</a>
<ul>
<li class="toc-entry toc-h5"><a href="#fast-retransmit">Fast Retransmit</a></li>
<li class="toc-entry toc-h5"><a href="#doubling-timeout-interval">Doubling Timeout Interval</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#tcp-flow-control">TCP Flow Control</a></li>
<li class="toc-entry toc-h3"><a href="#tcp-connection-management">TCP Connection Management</a>
<ul>
<li class="toc-entry toc-h4"><a href="#2-way-handshake">2 Way Handshake</a></li>
<li class="toc-entry toc-h4"><a href="#3-way-handshake">3 Way Handshake</a></li>
<li class="toc-entry toc-h4"><a href="#closing-tcp-connection">Closing TCP Connection</a></li>
<li class="toc-entry toc-h4"><a href="#tcp-states">TCP States</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#principles-of-congestion-control">Principles of Congestion Control</a>
<ul>
<li class="toc-entry toc-h4"><a href="#causes-and-the-costs-of-congestion">Causes and the Costs of Congestion</a>
<ul>
<li class="toc-entry toc-h5"><a href="#summary-of-congestion-situations">Summary of Congestion Situations</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#tcp-congestion-control">TCP Congestion Control</a>
<ul>
<li class="toc-entry toc-h4"><a href="#classic-tcp-congestion-control">Classic TCP Congestion Control</a></li>
<li class="toc-entry toc-h4"><a href="#tcp-congestion-control-algorithms">TCP Congestion-Control Algorithms</a>
<ul>
<li class="toc-entry toc-h5"><a href="#component-slow-start">Component: Slow Start</a></li>
<li class="toc-entry toc-h5"><a href="#component-congestion-avoidance">Component: Congestion Avoidance</a></li>
<li class="toc-entry toc-h5"><a href="#component-fast-recovery">Component: Fast Recovery</a></li>
<li class="toc-entry toc-h5"><a href="#summary-aimd">Summary: AIMD</a></li>
<li class="toc-entry toc-h5"><a href="#tcp-cubic">TCP CUBIC</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#network-assisted-and-delay-based-algorithm">Network Assisted and Delay-Based Algorithm</a>
<ul>
<li class="toc-entry toc-h3"><a href="#explicit-congestion-notification">Explicit Congestion Notification</a></li>
<li class="toc-entry toc-h3"><a href="#delay-based-congestion-control">Delay-Based Congestion Control</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#fairness">Fairness</a>
<ul>
<li class="toc-entry toc-h3"><a href="#fairness-and-udp">Fairness and UDP</a></li>
<li class="toc-entry toc-h3"><a href="#fairness-and-parallel-tcp">Fairness and Parallel TCP</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#evolving-transport-layer-functionality">Evolving Transport Layer Functionality</a>
<ul>
<li class="toc-entry toc-h3"><a href="#quic-quick-udp-internet-connections">QUIC: Quick UDP Internet Connections</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#chapter-4-network-layer-data-plane">Chapter 4 Network Layer: Data Plane</a>
<ul>
<li class="toc-entry toc-h2"><a href="#overview">Overview</a>
<ul>
<li class="toc-entry toc-h3"><a href="#quick-overview-of-control-plane">Quick Overview of Control Plane</a></li>
<li class="toc-entry toc-h3"><a href="#overview-of-services">Overview of Services</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#inside-a-router">Inside A Router</a>
<ul>
<li class="toc-entry toc-h3"><a href="#input-port-processing">Input Port Processing</a></li>
<li class="toc-entry toc-h3"><a href="#switching-fabric">Switching Fabric</a>
<ul>
<li class="toc-entry toc-h4"><a href="#switching-via-memory">Switching via Memory</a></li>
<li class="toc-entry toc-h4"><a href="#switching-via-bus">Switching via Bus</a></li>
<li class="toc-entry toc-h4"><a href="#switching-via-interconnection-network">Switching via Interconnection Network</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#output-port-processing">Output Port Processing</a></li>
<li class="toc-entry toc-h3"><a href="#queueing-in-router">Queueing in Router</a>
<ul>
<li class="toc-entry toc-h4"><a href="#input-port-queueing">Input Port Queueing</a></li>
<li class="toc-entry toc-h4"><a href="#output-port-queueing">Output Port Queueing</a></li>
<li class="toc-entry toc-h4"><a href="#buffer-length">Buffer Length</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#packet-scheduling">Packet Scheduling</a>
<ul>
<li class="toc-entry toc-h4"><a href="#scheduling-fifo">Scheduling: FIFO</a></li>
<li class="toc-entry toc-h4"><a href="#scheduling-priority">Scheduling: Priority</a></li>
<li class="toc-entry toc-h4"><a href="#scheduling-rr">Scheduling: RR</a></li>
<li class="toc-entry toc-h4"><a href="#scheduling-wfq">Scheduling: WFQ</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#the-ip-protocol-ipv4-ipv6-and-more">The IP Protocol: IPv4, IPv6 and more</a>
<ul>
<li class="toc-entry toc-h3"><a href="#ipv4-datagram-format">IPv4 Datagram Format</a></li>
<li class="toc-entry toc-h3"><a href="#ipv4-addressing">IPv4 Addressing</a>
<ul>
<li class="toc-entry toc-h4"><a href="#obtaining-host-address-dhcp">Obtaining Host Address: DHCP</a></li>
<li class="toc-entry toc-h4"><a href="#obtaining-network-address-address-aggregation">Obtaining Network Address: Address Aggregation</a></li>
<li class="toc-entry toc-h4"><a href="#network-address-translation-nat">Network Address Translation: NAT</a></li>
<li class="toc-entry toc-h4"><a href="#obtaining-block-of-address">Obtaining Block of Address</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#ipv6">IPv6</a>
<ul>
<li class="toc-entry toc-h4"><a href="#tunning-from-ipv4-to-ipv6">Tunning from IPv4 to IPv6</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#generalized-forwarding-and-sdn">Generalized Forwarding and SDN</a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#chapter-5-network-layer-control-plane">Chapter 5 Network Layer: Control Plane</a>
<ul>
<li class="toc-entry toc-h2"><a href="#routing-algorithms">Routing Algorithms</a>
<ul>
<li class="toc-entry toc-h3"><a href="#link-state-routing-algorithm">Link-State Routing Algorithm</a>
<ul>
<li class="toc-entry toc-h4"><a href="#oscillations-of-dijkstras-algorithm">Oscillations of Dijkstra’s Algorithm</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#distance-vector-routing-algorithm">Distance-Vector Routing Algorithm</a>
<ul>
<li class="toc-entry toc-h4"><a href="#link-cost-changes-and-link-failure">Link Cost Changes and Link Failure</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#comparison-between-ls-and-dv">Comparison between LS and DV</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#intra-as-routing-in-the-internet-ospf">Intra-AS Routing in the Internet: OSPF</a>
<ul>
<li class="toc-entry toc-h3"><a href="#ospf">OSPF</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#inter-as-routing-bgp">Inter-AS Routing: BGP</a>
<ul>
<li class="toc-entry toc-h3"><a href="#advertising-bgp-route-information">Advertising BGP Route Information</a></li>
<li class="toc-entry toc-h3"><a href="#determining-the-best-routes">Determining the Best Routes</a>
<ul>
<li class="toc-entry toc-h4"><a href="#hot-potato-routing">Hot Potato Routing</a></li>
<li class="toc-entry toc-h4"><a href="#route-selection-algorithm">Route-Selection Algorithm</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#routing-policy">Routing Policy</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#software-defined-network">Software Defined Network</a>
<ul>
<li class="toc-entry toc-h3"><a href="#sdn-controller-architecture">SDN Controller Architecture</a></li>
<li class="toc-entry toc-h3"><a href="#openflow-protocol">OpenFlow Protocol</a></li>
<li class="toc-entry toc-h3"><a href="#interaction-with-network-application-layer">Interaction with Network Application Layer</a></li>
<li class="toc-entry toc-h3"><a href="#sdn-challenges">SDN Challenges</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#icmp-internet-control-message-protocol">ICMP: Internet Control Message Protocol</a>
<ul>
<li class="toc-entry toc-h3"><a href="#icmp-messages">ICMP Messages</a></li>
<li class="toc-entry toc-h3"><a href="#examples-of-icmp-usages">Examples of ICMP Usages</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#network-management-snmp-and-netconfyang">Network Management, SNMP, and NETCONF/YANG</a>
<ul>
<li class="toc-entry toc-h3"><a href="#network-management-framework">Network Management Framework</a></li>
<li class="toc-entry toc-h3"><a href="#snmp-and-mib">SNMP and MIB</a></li>
<li class="toc-entry toc-h3"><a href="#netconf-and-yang">NETCONF and YANG</a>
<ul>
<li class="toc-entry toc-h4"><a href="#yang">YANG</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#chapter-6-link-layer">Chapter 6 Link Layer</a>
<ul>
<li class="toc-entry toc-h2"><a href="#introduction-to-the-link-layer">Introduction to the Link Layer</a>
<ul>
<li class="toc-entry toc-h3"><a href="#link-layer-services">Link Layer Services</a></li>
<li class="toc-entry toc-h3"><a href="#where-is-the-link-layer-implemented">Where Is the Link Layer Implemented</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#error-detection-and-correction">Error Detection and Correction</a>
<ul>
<li class="toc-entry toc-h3"><a href="#parity-checks">Parity Checks</a></li>
<li class="toc-entry toc-h3"><a href="#checksumming-methods">Checksumming Methods</a></li>
<li class="toc-entry toc-h3"><a href="#cyclic-redundancy-check-crc">Cyclic Redundancy Check (CRC)</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#multiple-access-links-and-protocols">Multiple Access Links and Protocols</a>
<ul>
<li class="toc-entry toc-h3"><a href="#channel-partitioning">Channel Partitioning</a></li>
<li class="toc-entry toc-h3"><a href="#random-access-protocol">Random Access Protocol</a>
<ul>
<li class="toc-entry toc-h4"><a href="#slotted-aloha">Slotted ALOHA</a></li>
<li class="toc-entry toc-h4"><a href="#pure-aloha">Pure ALOHA</a></li>
<li class="toc-entry toc-h4"><a href="#csma">CSMA</a></li>
<li class="toc-entry toc-h4"><a href="#csmacd">CSMA/CD</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#taking-turns-protocols">Taking-Turns Protocols</a></li>
<li class="toc-entry toc-h3"><a href="#docsis-protocol-for-cable-access">DOCSIS: Protocol for Cable Access</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#switched-local-area-network">Switched Local Area Network</a>
<ul>
<li class="toc-entry toc-h3"><a href="#link-layer-addressing-and-arp">Link-Layer Addressing and ARP</a>
<ul>
<li class="toc-entry toc-h4"><a href="#mac-addresses">MAC Addresses</a></li>
<li class="toc-entry toc-h4"><a href="#arp-address-resolution">ARP: Address Resolution</a></li>
<li class="toc-entry toc-h4"><a href="#routing-to-another-subnet">Routing to Another Subnet</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#ethernet">Ethernet</a>
<ul>
<li class="toc-entry toc-h4"><a href="#link-layer-switches">Link-Layer Switches</a>
<ul>
<li class="toc-entry toc-h5"><a href="#forwarding-and-filtering">Forwarding and Filtering</a></li>
<li class="toc-entry toc-h5"><a href="#self-learning">Self-Learning</a></li>
<li class="toc-entry toc-h5"><a href="#properties-of-switches">Properties of Switches</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#switched-network-example">Switched Network Example</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#vlans">VLANS</a></li>
<li class="toc-entry toc-h2"><a href="#data-center-networking">Data Center Networking</a>
<ul>
<li class="toc-entry toc-h3"><a href="#data-center-architectures">Data Center Architectures</a>
<ul>
<li class="toc-entry toc-h4"><a href="#load-balancing-in-data-centers">Load Balancing in Data Centers</a></li>
<li class="toc-entry toc-h4"><a href="#hierarchical-structure-in-real-life">Hierarchical structure in Real life</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#datacenter-networks-protocol-innovations">Datacenter Networks: Protocol Innovations</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#a-day-in-life-of-web-page-request">A Day in Life of Web Page Request</a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#miscellaneous">Miscellaneous</a>
<ul>
<li class="toc-entry toc-h2"><a href="#wireshark">Wireshark</a>
<ul>
<li class="toc-entry toc-h3"><a href="#intro-to-wireshark">Intro to Wireshark</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#distributed-hash-tables">Distributed Hash Tables</a>
<ul>
<li class="toc-entry toc-h3"><a href="#dht-step-1-the-hash">DHT Step 1: The Hash</a></li>
<li class="toc-entry toc-h3"><a href="#dht-step-2-routing">DHT Step 2: Routing</a></li>
<li class="toc-entry toc-h3"><a href="#case-studies">Case Studies</a>
<ul>
<li class="toc-entry toc-h4"><a href="#can">CAN</a>
<ul>
<li class="toc-entry toc-h5"><a href="#can-routing">CAN Routing</a></li>
<li class="toc-entry toc-h5"><a href="#can-node-insertion">CAN Node Insertion</a></li>
<li class="toc-entry toc-h5"><a href="#can-removal-process">CAN Removal Process</a></li>
</ul>
</li>
<li class="toc-entry toc-h4"><a href="#chord">Chord</a>
<ul>
<li class="toc-entry toc-h5"><a href="#chord-routing">Chord Routing</a></li>
<li class="toc-entry toc-h5"><a href="#chord-node-insertion">Chord Node Insertion</a></li>
<li class="toc-entry toc-h5"><a href="#chord-node-deletion">Chord Node Deletion</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#using-newudpl">Using newudpl</a>
<ul>
<li class="toc-entry toc-h3"><a href="#errors-encounted">Errors Encounted</a></li>
</ul>
</li>
</ul>
</li>
</ul>
  </div>

  <div class="post-content e-content" itemprop="articleBody">
    <style type="text/css">@page { margin-left: 2in; margin-right: -0.25in; } img{ width: 60%; }</style>

<h1 id="chapter-1-basics">Chapter 1 Basics</h1>

<p>The internet/networking system now evolves into including lots of applications.</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20210920082800394.png" alt="image-20210920082800394" /></p>

<p>Additionally:</p>

<ul>
  <li>End systems are connected together by a network of <strong>communication links</strong> (e.g. copper wire) and <strong>packet switches</strong></li>
</ul>

<blockquote>
  <p><strong>Packet Switch</strong>:</p>

  <p>A packet switch takes a packet arriving on one of its incoming communication links and forwards that <em>packet</em> on one of its outgoing communication links. e.g. routers and link-layer switches</p>
</blockquote>

<p>It might be important to know the difference between a switch and a router.</p>

<blockquote>
  <p><strong>Router</strong>:</p>

  <p>Routers are computer networking devices that serve two primary functions:</p>

  <ol>
    <li>create and maintain a local area network</li>
    <li>manage the data entering and leaving the network as well as data moving inside of the network.</li>
    <li>has one connection to the Internet and one connection to your private local network.</li>
  </ol>

  <p>Additionally,</p>

  <ul>
    <li>Routers operate at Layer 3 (Network)</li>
    <li>Router store IP address in the routing table</li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Link-Layer Switch</strong>:</p>

  <p>A network switch is a computer networking device which connects various devices together <em>on a single computer network</em>. It may also be used to route information in the form of electronic data sent over networks.</p>

  <p>So its functions are:</p>

  <ol>
    <li>store MAC address in a lookup table</li>
    <li>decide and forward data to the right destination, i.e. which computer</li>
  </ol>

  <p>Additionally,</p>

  <ul>
    <li>Network switches operate at Layer 2 (Data Link Layer)</li>
    <li>Switches store MAC address in a lookup table</li>
  </ul>
</blockquote>

<p>Last but not least:</p>

<blockquote>
  <p><strong>ISP</strong></p>

  <p>End systems access the Internet through Internet Service Providers (ISPs), including residential ISPs such as local cable or telephone companies.</p>

  <p>To be more detailed, it does:</p>

  <ol>
    <li>Provide a physical network connection <strong>to your device</strong> (e.g. wireless to your smart phone, or wired to your home router), supporting some basic data communication protocols (e.g. 4G, DSL, DOCSIS, Ethernet, …).</li>
    <li>Providing Internet Protocol (IP) connectivity, i.e. provide your device with an IP address, receive IP traffic from your device and <strong>route (send) it</strong> onto the Internet, and <strong>receive IP traffic from the Internet and route it</strong> to your device.</li>
  </ol>
</blockquote>

<h2 id="the-network-edge">The Network Edge</h2>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20210920143433724.png" alt="image-20210920143433724" style="zoom:80%;" /></p>

<blockquote>
  <p><strong>End-system</strong>:</p>

  <p>Devices sitting at the edge of the Internet. End systems are also referred to as <em>hosts</em> because they host (that is, run) application programs such as a Web browser program, a Web server program, an e-mail client program, or an e-mail server program.</p>

  <ul>
    <li>Hosts are sometimes further divided into <em>two categories: clients and servers</em>. Today, most of the servers from which we receive search results, e-mail, Web pages, videos and mobile app content reside in large data centers.</li>
  </ul>
</blockquote>

<h3 id="access-networks">Access Networks</h3>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20210920143826965.png" alt="image-20210920143826965" style="zoom:80%;" /></p>

<blockquote>
  <p><strong>Access Network</strong></p>

  <p>The network that physically connects an end system to the first router (also known as the “edge router”)</p>
</blockquote>

<h4 id="digital-subscriber-line">Digital Subscriber Line</h4>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20210920152827246.png" alt="image-20210920152827246" style="zoom:80%;" /></p>

<p>A residence typically obtains DSL Internet access from the <strong>same local telephone company</strong> (telco) that provides its
wired local phone access. Thus, when DSL is used, a customer’s telco is also its ISP.</p>

<p>Some components used here are:</p>

<blockquote>
  <p><strong>DSL Modem</strong></p>

  <p>DSL modem uses the <em>existing telephone line</em> exchange data with a digital subscriber line access multiplexer (DSLAM). The home DSL modem takes digital data and <em>translates it to high-frequency tones</em> for transmission over telephone wires to the CO (central office).</p>
</blockquote>

<p>This means that the residential telephone line <strong>carries both data and traditional telephone signals</strong> simultaneously, which are encoded at <strong>different frequencies</strong>:</p>

<ul>
  <li>A high-speed downstream channel, in the 50 kHz to 1 MHz band</li>
  <li>A medium-speed upstream channel, in the 4 kHz to 50 kHz band</li>
  <li>An ordinary two-way telephone channel, in the 0 to 4 kHz band</li>
</ul>

<blockquote>
  <p><strong>Splitter</strong></p>

  <p>Splitter <em>separates the data and telephone signals arriving</em> to the home and forwards the data signal to the DSL modem</p>
</blockquote>

<blockquote>
  <p><strong>DSLAM</strong></p>

  <p>DSLAM <em>separates the data and phone signals from home</em> and sends the data into the Internet.</p>
</blockquote>

<p>Last but not least:</p>

<ul>
  <li>this is installed particularly per user (if they have an <strong>existing telephone line</strong>).</li>
  <li>the DSL standards define multiple transmission rates, including downstream transmission rates of 24 Mbs and 52 Mbs, and upstream rates of 3.5 Mbps and 16 Mbps</li>
</ul>

<blockquote>
  <p><strong>Voice Encoding</strong></p>

  <p>Since essentially you want to convert a wave (your speech wave -&gt; wave in voltage) to digital bits, you need:</p>

  <ul>
    <li>sample frequency</li>
    <li>number of samples</li>
  </ul>

  <p>To decide the quality of your recorded voice. For example, if It captures <em>speech</em> in a range of 300 to 3.4 kHz, samples at 8000 samples/second with 8 bits per sample, then we have it <strong>resulting</strong> in <em>64 kbps</em> of voice encoding.</p>
</blockquote>

<h4 id="cable-internet-access">Cable Internet Access</h4>

<p>Cable Internet access makes use of the <strong>cable television company’s existing cable</strong> television infrastructure. Therefore, A residence obtains cable Internet access from the same company that provides its cable television.</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20210920153727811.png" alt="image-20210920153727811" style="zoom:80%;" /></p>

<p>some important components here are defined below</p>

<blockquote>
  <p><strong>HFS</strong></p>

  <p>Because both fiber and coaxial cable are employed in this <em>system</em>, it is often referred to as <em>hybrid fiber coax</em> (HFC).</p>
</blockquote>

<blockquote>
  <p><strong>Cable Modems</strong></p>

  <p>Cable internet access requires special modems, called cable modems. As with a DSL modem, the cable modem is typically an external device and connects to the home PC through an Ethernet port.</p>
</blockquote>

<blockquote>
  <p><strong>CMTS</strong></p>

  <p>At the cable head end, the cable modem termination system (CMTS) serves a similar function as the DSL network’s DSLAM—turning the <em>analog signal sent from the cable modems in many downstream homes back into digital format</em>.</p>
</blockquote>

<p>However, the larger difference here is that:</p>

<ul>
  <li>it is a <strong>shared broadcast medium</strong>. In particular, every packet sent by the head end travels downstream on every link to every home and every packet sent by a home travels on the upstream channel to the head end. For this reason, download and upload speed are sometimes slowed due to <strong>simultaneous uses.</strong></li>
</ul>

<h4 id="fiber-to-home">Fiber to Home</h4>

<p>Fiber to the home (FTTH). As the name suggests, provides an <strong>optical fiber</strong> path from the CO <strong>directly to the home</strong>.</p>

<ul>
  <li>in the DSL case, telephone line was used</li>
  <li>in the cable internet access case, coaxial cables were shared</li>
</ul>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20210920154447611.png" alt="image-20210920154447611" /></p>

<p>where we see that</p>

<ul>
  <li>it is split into individual customer-specific fibers until the fiber gets relatively close to the homes, but they are <strong>all fiber optics</strong></li>
</ul>

<p>There are two competing optical-distribution network architectures: <strong>active optical networks (AONs)</strong> and <strong>passive optical networks (PONs)</strong>. AON is essentially switched Ethernet, which is discussed in Chapter 6.</p>

<p>PON, which is used in Verizon’s FiOS service. Figure 1.7 shows FTTH using the PON distribution architecture.</p>

<blockquote>
  <p><strong>Optical Splitter</strong></p>

  <p>The splitter combines a number of homes (typically less than 100, as compared to the cable internet access, which typically has thousands) onto a single, shared optical fiber, which connects to an optical line terminator (OLT) in the telco’s CO</p>
</blockquote>

<blockquote>
  <p><strong>Optical Line Terminator</strong></p>

  <p>OLT, providing conversion between optical and electrical signals, connects to the Internet via a telco router.</p>
</blockquote>

<blockquote>
  <p><strong>Optical Network Terminator</strong></p>

  <p>At home, users connect a home <em>router (typically a wireless router) to the ONT</em> and access the Internet via this home router. This basically substitutes the role of modems in previous examples.</p>
</blockquote>

<h4 id="ethernet-and-wifi">Ethernet and WiFi</h4>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20210920155239301.png" alt="image-20210920155239301" /></p>

<blockquote>
  <p><strong>Ethernet Switch</strong></p>

  <p>Ethernet users use twisted-pair copper wire to <em>connect to an Ethernet switch</em>, and the Ethernet switch, or a network of such interconnected switches, is then in turn <em>connected into the larger Internet</em>.</p>
</blockquote>

<p>In a <strong>wireless LAN</strong> setting, wireless users transmit/receive packets to/from an <strong>access point</strong> that is connected into the enterprise’s network (most likely using wired Ethernet), which in turn is connected to the <strong>wired Internet</strong>.</p>

<blockquote>
  <p><strong>Access Point</strong></p>

  <p>A networking hardware device that allows <em>other Wi-Fi devices</em> to connect to an <strong>existing wired network</strong>. Essentially access point (base station) is just a sub-device within the LAN <strong>providing another location for devices to connect on the network</strong>.</p>

  <ul>
    <li>therefore, access point can <em>create WLANs</em> (Wireless Local Area Networks) while being <em>connected to routers/switches</em> and its functionality is limited to this only. This can be done by routers as well, e.g. embedded in a <em>wireless router</em>, hence you don’t require a separate AP.</li>
  </ul>
</blockquote>

<p>Many homes <strong>combine broadband residential access</strong> (that is, cable modems or DSL) <strong>with these inexpensive wireless LAN</strong> technologies. In Figure 1.9 shows a typical home network.</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20210920155624985.png" alt="image-20210920155624985" /></p>

<p>where here:</p>

<ul>
  <li>base station (the wireless access point), which <strong>communicates with the wireless PC and other wireless devices in the home</strong></li>
  <li>home <strong>router</strong> that connects the wireless access point, and any other wired home devices, <strong>to the Internet</strong></li>
</ul>

<h2 id="network-core">Network Core</h2>

<p>We have covered the edges used in our network. Figure 1.10 highlights the network core with thick, shaded lines.</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20210920161036673.png" alt="image-20210920161036673" style="zoom:80%;" /></p>

<h2 id="performance-delay-loss-throughput">Performance (Delay, Loss, Throughput)</h2>

<p>The idea is to get good performance out of switches without guarantee (of delivery). As a packet travels from one node (host or router) to the subsequent node (host or router) along this path, the packet suffers from several types of delays at each node along the path.</p>

<p>First, we need to know how packet loss and delay occurs.</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20210922090255882.png" alt="image-20210922090255882" /></p>

<p>So we get:</p>

<ol>
  <li>when the packet arrives at router A from the upstream node, router A <strong>examines the packet’s header</strong> to <strong>determine</strong> the appropriate outbound link for the packet.</li>
  <li>Then the packet is <strong>directed to the queue</strong> that precedes the link to router B</li>
  <li>then the packet has to wait <em>on a link</em> <strong>until</strong> there is no other packet currently being transmitted <em>on the link</em></li>
  <li>then, it needs to <strong>push the bits</strong> of the packet onto the link</li>
  <li>finally, the electricity (voltage representing those bits) needs to <strong>travel</strong> towards B</li>
  <li>at B, we repeat the same step from 1-6</li>
</ol>

<p>Therefore, the ==most important delays== are</p>

\[d_{\text{total}}=d_{\text{proc}}+d_{\text{queue}}+d_{\text{trans}}+d_{\text{prop}}\]

<p>where:</p>

<ul>
  <li>
    <p>$d_{\text{proc}}$ is process delay, required to examine the packet’s header and determine where to direct.</p>

    <ul>
      <li>other usage include time need to check bit errors, etc.</li>
    </ul>
  </li>
  <li>
    <p>$d_{\text{queue}}$ waits to be transmitted onto the link.</p>

    <ul>
      <li><strong>Packet Queue</strong>: in general, a switch/router will have a packet queue/buffer, since it could ==only send one packet at a time==.</li>
    </ul>
  </li>
  <li>
    <p>$d_{\text{trans}}$ the amount of time required to push (that is, transmit) all of the packet’s bits into the link. Therefore, it depends on the size of information and the bandwidth</p>

    <ul>
      <li>
        <p>this can be computed by:</p>

\[\text{transmission delay} = \frac{L}{R}\]

        <p>where the length/size of the packet is $L$ bits, and the bandwidth/transmission rate of the route is $R$ bits/sec.</p>
      </li>
    </ul>
  </li>
  <li>
    <p>$d_{\text{prop}}$ time taken to transmit the data over the medium. This then depends on the distance, medium etc.</p>

    <ul>
      <li>e.g. under sea cable would have a larger $d_{\text{prop}}$, but for data centers, this would be small.</li>
    </ul>
  </li>
</ul>

<blockquote>
  <p><strong>Note</strong></p>

  <ul>
    <li>in reality, the routers keep a list of other connected router’s destination. However, the possibility of being <strong>congested</strong> in some of the router <em>might not be recorded</em>.
      <ul>
        <li>One possible solution would be to <em>measure latency yourself</em> and then decide which route to send to (if you have control of it).</li>
      </ul>
    </li>
    <li>Though there might be some fine changes of routes <strong>within a network</strong>, the link/route (i.e. weak tie) <strong>across networks</strong> will usually be stable.</li>
  </ul>
</blockquote>

<p>An analogy of the above process would be:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20210922095002446.png" alt="image-20210922095002446" /></p>

<p>we know that:</p>

<ul>
  <li>cars (=packet of 1 bit) contain some information</li>
  <li>highway segments between tollbooths (=links)</li>
  <li>tollbooth (=router)</li>
</ul>

<p>Then, given that cars (=packet) propagates at speed of 100km/hour and each toll booth takes 12 seconds to service car ($d_{\text{trans}}$), we know that, for the <em>last car (bit)</em> to reach the destination</p>

<ol>
  <li>each car needs to be processed/examined</li>
  <li>each car needs to wait for previous cars</li>
  <li>each car then is <em>pushed on to the highway</em> after 12 seconds of service ($d_{\text{trans}}$)</li>
  <li>each car then travels to the next tollbooth in 1 hour. $(d_{\text{prop}})$</li>
</ol>

<hr />

<h3 id="traceroute">Traceroute</h3>

<p><code class="language-plaintext highlighter-rouge">traceroute</code> in Linux:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>➜ traceroute nytimes.com
traceroute to nytimes.com <span class="o">(</span>151.101.1.164<span class="o">)</span>, 30 hops max, 60 byte packets
1  JASONXYU-NB1.mshome.net <span class="o">(</span>172.27.144.1<span class="o">)</span>  0.347 ms  0.326 ms  0.270 ms
2  cc-wlan-1-vlan3572-1.net.columbia.edu <span class="o">(</span>209.2.216.2<span class="o">)</span>  3.706 ms  3.696 ms  3.681 ms
3  cc-core-1-x-cc-wlan-1.net.columbia.edu <span class="o">(</span>128.59.255.77<span class="o">)</span>  3.673 ms  3.670 ms  3.627 ms
4  nyser32-gw-1-x-cc-core-1.net.columbia.edu <span class="o">(</span>128.59.255.6<span class="o">)</span>  3.658 ms  3.646 ms  3.640 ms
5  199.109.104.13 <span class="o">(</span>199.109.104.13<span class="o">)</span>  5.095 ms  5.087 ms  5.070 ms
6  nyc32-55a1-nyc32-9208.cdn.nysernet.net <span class="o">(</span>199.109.107.202<span class="o">)</span>  5.159 ms  3.572 ms  3.559 ms
...
</code></pre></div></div>

<p>where basically this is delay in a ==roundtrip== (forth and back).</p>

<ul>
  <li>the number in the front <code class="language-plaintext highlighter-rouge">1,2,3,4...</code> means the number of <strong>TTL</strong> defined. In the above, 6 samples are tried, each with TTL 1 up to 6 respectively.</li>
  <li>basically this shows you the <strong>hops</strong> that is needed from your end point to the destination end point, as well as the total latency.</li>
  <li>sometimes there are <code class="language-plaintext highlighter-rouge">*</code>, which indicates that the router did not respond (e.g. configured not to respond to you)</li>
  <li><code class="language-plaintext highlighter-rouge">cc-wlan-1-vlan3572-1.net.columbia.edu</code> would be the resolved DNS/host name</li>
</ul>

<p>Note that:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">traceroute</code> in this case would have measured <strong>all the four delays for each hop</strong>.</li>
</ul>

<blockquote>
  <p><strong>TTL</strong> (time to live): the number of hops in which the message should reach the destination. This is to prevent the case that your packets will go in a cycle and never reaches the destination. If the TTL gets to zero, then an error message will be <em>sent back to the source</em></p>

  <ul>
    <li>For example, if the packet doesn’t reach the destination in 20 hops, just give up the packet.</li>
    <li>this is also added in the <strong>network layer</strong>.
      <ul>
        <li>detailed implementation of <code class="language-plaintext highlighter-rouge">traceroute</code> can be found in <a href="#Examples of ICMP Usages">Examples of ICMP Usages</a></li>
      </ul>
    </li>
    <li>all packets will have this field (defined by the protocol)</li>
  </ul>
</blockquote>

<hr />

<p><em>For Example</em></p>

<p>Consider the case when you want to debug the latency from Orlando to Seattle <strong>and vice versa</strong>.</p>

<p>Suppose you are at <em>Orlando</em>. Upon using traceroute, you see:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20210922142323659.png" style="zoom: 50%;" /></p>

<p>so that we have <em>wasted some routes</em> by going back to Florida.</p>

<p>Now, the problem is that routes on the internet are often ==asymmetric==. So that going from Seattle to Orlando, we might have the path in purple:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20210922144459861.png" alt="image-20210922144459861" style="zoom:50%;" /></p>

<blockquote>
  <p>Therefore, due to the <strong>asymmetry</strong>:</p>

  <ul>
    <li><code class="language-plaintext highlighter-rouge">traceroute</code> from a reversed direction might have a different result.</li>
  </ul>
</blockquote>

<hr />

<h3 id="queuing-delay-and-packet-loss">Queuing Delay and Packet Loss</h3>

<p>Queuing delay is more complicated than others. Unlike the other delays, this <strong>varies from packet to packet</strong>.</p>

<p>Therefore, when characterizing queuing delay, one typically uses statistical measures, such as</p>

<ul>
  <li>average queuing delay</li>
  <li>variance of queuing delay</li>
  <li>probability that the queuing delay exceeds some specified value</li>
</ul>

<p>Suppose, for simplicity, that all packets consist of $L$ bits, and that on <em>average</em> you get $a$ packets per second. Suppose your transmission rate is $R$ (being pushed off the queue to the link):</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20210922100545698.png" alt="image-20210922100545698" /></p>

<p>Here we notice that:</p>

<ul>
  <li>
    <p>==due to variations== in packet arrival rate, when the traffic intensity is close to $1$, there will be intervals of time when the arrival rate <strong><em>exceeds</em></strong> the transmission capacity.</p>

    <ul>
      <li>on the other hand, if packets arrive <em>exactly</em> periodically - that is, one packet arrives every $L/R$ seconds - then every packet will arrive at an empty queue and there will be no queuing delay.</li>
    </ul>
  </li>
  <li>
    <p>$La/R$ is also called the <strong>traffic intensity</strong>.</p>
  </li>
  <li>
    <p>this is assuming there is some <em><strong>distribution</strong> of incoming intensity instead of a <strong>uniform</strong> one</em>, e.g. the Poisson distribution of incoming intensity. As a result, there will be bursts of influxes at times and the queue would build up. The resulting formula would be:</p>

\[d \propto \frac{\rho}{1-\rho}\]

    <p>where:</p>

    <ul>
      <li>$\rho \equiv La/R$ is the traffic incoming intensity.</li>
    </ul>
  </li>
</ul>

<p>However, no loss occurs if we assumes that our router can hold <em>infinitely</em> number of bits. Yet this is often not true.</p>

<blockquote>
  <p><strong>Packet Loss</strong></p>

  <ul>
    <li>When a packet can arrive to find a full queue, so that there is <em>no place to store</em> such a packet, a router will <strong>drop</strong> that packet; that is, the packet will be lost.</li>
    <li>In general, the fraction of lost packets increases as the traffic intensity increases</li>
  </ul>
</blockquote>

<h3 id="throughput">Throughput</h3>

<p>Throughput is different against transmission rate/bandwidth, because it is <strong>macroscopic</strong>.</p>

<blockquote>
  <p><strong>Throughput</strong></p>

  <p>Number of bits per second that a <strong>client receives</strong> data from a host.</p>

  <ul>
    <li>therefore, it is ==not able between links==. It is more like end-to-end measurement.</li>
  </ul>
</blockquote>

<p>Consider the following two cases:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211004200340352.png" alt="image-20211004200340352" style="zoom:67%;" /></p>

<p><strong>For case a)</strong>, suppose we have $R_c$ for the bandwidth between router and client, and $R_s$ for the server. Then:</p>

\[\text{Throughput} = \min\{R_c,R_s\}\]

<p>due to bottlenecks.</p>

<p><strong>For case b)</strong>, let all 10 serves have the same $R_s = 2$ Mbps, and all clients have $R_c=1$ Mbps. Assume the shared link is fair to every server, and it has $R=5$ Mbps. Then we have:</p>

\[\text{Throughput} = \min{\{R_s, R/10, R\}} = 5/10 = 500 \text{ Kbps}\]

<h2 id="protocol-layers-and-their-service-models">Protocol Layers and Their Service Models</h2>

<p>The entire core system of internet is very complex, since we need to organize numerous applications and protocols, various end systems and etc. To manage the complex system, <strong>we split them into manageable components (layers) and build them up</strong>.</p>

<h3 id="protocol-layering">Protocol Layering</h3>

<p>The idea is to separating a big task into smaller tasks, and a combination of those small stacks become the protocol stack. This is needed since it needs to go though mediums such as routers, ISP, etc.</p>

<p>Consider the example of sending text massages from me to mom, then <strong>some challenges</strong> we need to overcome would be:</p>

<ul>
  <li>security</li>
  <li>data integrity</li>
  <li>routing</li>
  <li>etc.</li>
</ul>

<p>network designers organize <strong>protocols</strong> (tasks) - and the network hardware and software that implement the protocols - <strong>in layers</strong>. When taken together, the protocols of the various layers are called the <strong>protocol stack</strong>.</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20210920164306438.png" alt="image-20210920164306438" /></p>

<p>where:</p>

<ul>
  <li>Application Layer: sending data to correct <strong>application</strong>/software</li>
  <li>Transport: Recovery of lost packets, congestion control, rate control</li>
  <li>Network: Sending packets in the right <strong>destination</strong>/direction</li>
  <li>Link/MAC: Getting information correctly between <strong>2 physically connected points</strong></li>
  <li>Physical: physical/science needed to send info between <strong>2 physically connected points</strong> (i.e. how to physically transmit bit information)</li>
</ul>

<blockquote>
  <p><strong>Note</strong></p>

  <ul>
    <li>in each layer, there is some <em>protocols</em> defining what each information received means, and what it should do next.</li>
    <li>in each layer, it assumes the other layer is doing their stuff correctly</li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Advantage</strong></p>

  <ul>
    <li>Modularity = easier to maintain and update</li>
  </ul>

  <p><strong>Disadvantage</strong></p>

  <ul>
    <li>One layer may duplicate lower-layer functionality. For example, many protocol stacks provide error recovery on both a per-link basis and an end-to-end basis</li>
  </ul>
</blockquote>

<hr />

<p><em>Analogy: Post Office</em></p>

<p>Consider the example you trying to send a recorded TV show to your friend.</p>

<p>Application: received the recorded disk, knows to use the TV/laptop to <strong>play it</strong>.</p>

<p>Transport: (e.g. error control) your friend telling <strong>you</strong> that something went wrong. e.g. you sent me the wrong episode.</p>

<p>Other stuff are all dealt by the post office.</p>

<hr />

<h4 id="application-layer">Application Layer</h4>

<p>Parsing/forming the packet in the application. So this is application specific, and only implemented in the <strong>end points</strong> as well.</p>

<p>Some example protocols at this level are:</p>

<ul>
  <li>HTTP protocol (which provides for Web document request and transfer)</li>
  <li>SMTP (which provides for the transfer of e-mail messages)</li>
  <li>FTP (which provides for the transfer of files between two end systems).</li>
</ul>

<p>Packets of information on this level will be referred to as a <strong>message</strong>.</p>

<h4 id="transport-layer">Transport Layer</h4>

<p>This is only implemented <strong>at end points</strong>, and <strong>adds information</strong> such as your device tells the source to <em>repeat the information</em> if you didn’t “hear it” clearly.</p>

<p>In the Internet, there are two transport protocols:</p>

<ul>
  <li>TCP (guaranteed delivery of application-layer messages)</li>
  <li>UDP</li>
</ul>

<p>Some functionalities here include:</p>

<ul>
  <li>congestion control by having source throttles its transmission rate when the network is congested (TCP).</li>
  <li>breaks long messages into shorter segments</li>
</ul>

<p>Packets of information on this level will be referred to as a <strong>segment</strong>.</p>

<h4 id="network-layer">Network Layer</h4>

<p>Built upon link layer, assuming we can get a frame across two end points (via lower layers), we need to now consider <strong>where</strong> to send it. So this layer receives a frame and <strong>figures out the next hop</strong>.</p>

<ul>
  <li><strong>moving</strong> network-layer packets known as <strong>datagrams</strong> <em>from one host to another.</em></li>
</ul>

<p>The upper level Transport layer passes ==a segment (packet of information) and a destination address== to the network layer (this), so we have the:</p>

<ul>
  <li>IP protocol (which defines the fields in the datagram as well as how the end systems and routers act on these fields)</li>
  <li>or other routing protocols that determine the routes that datagrams take between sources and destinations</li>
</ul>

<p>At this level, we say that data sent are <strong>datagram/packets</strong>.</p>

<h4 id="link-layer">Link Layer</h4>

<p>Sending a <strong>frame</strong>, i.e. a collection of bits, over the physical layer.</p>

<p>Examples of link-layer protocols include:</p>

<ul>
  <li>Ethernet</li>
  <li>WiFi</li>
  <li>cable access network DOCSIS protocol</li>
</ul>

<p>As datagrams typically need to traverse several links to travel from source to destination, a datagram may be <strong>handled by different link-layer protocols</strong> at different links along its route.</p>

<p>Some link-layer protocols <strong>provide reliable delivery, from transmitting node, over one link</strong>, to receiving node, which has ==nothing to do with the reliability of TCP==, for example, which guarantees at the application level.</p>

<p>Therefore, this also have additional information added to the packet.</p>

<h4 id="physical-layer">Physical Layer</h4>

<p>Having a medium, e.g. a copper wire, to transmit bit information across 2 physically connected points. This is the ==only and final place where transmission of data happened==. All the above protocols are just <strong>parsing information and deciding what to do next</strong>.</p>

<p>Protocols at this level deal with how <strong>bits are moved</strong> between the two connected points:</p>

<ul>
  <li>Ethernet has many physical-layer protocols: one for twisted-pair copper wire, another for coaxial cable, another for fiber, and so on.</li>
</ul>

<blockquote>
  <p><strong>Network Interface Card</strong></p>

  <p>Physical layer and data link layers are responsible for <em>handling communication over a specific link</em>, they are typically implemented in a network interface card (for example, Ethernet or WiFi interface cards) associated with a given link.</p>
</blockquote>

<h3 id="encapsulation">Encapsulation</h3>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20210920091643011.png" alt="image-20210920091643011" /></p>

<p>where:</p>

<ul>
  <li>
    <p>Figure 1.24 shows the physical path that data takes</p>
  </li>
  <li>we knew that some layers, e.g. Transport and Application, are only implemented at the end points</li>
  <li>what physically connects the two is the <strong>edge across physical layers</strong>. So in the end, this is the <em>only place</em> where data is actually <em>transmitted</em>.</li>
</ul>

<blockquote>
  <p><strong>Note</strong></p>

  <ul>
    <li>that hosts implement all five layers, and must be <em>identical</em>. As otherwise a message from application of user $A$ cannot be understood by the architecture in the computer of $B$.</li>
  </ul>
</blockquote>

<p>What actually happens when you send (origin being $A$), e.g. an email would be:</p>

<ol>
  <li>Email application start with ==Application Layer== forming the message, and ask the <strong>Transport Layer</strong> to deal with it</li>
  <li>==Transport layer== then takes the big package and split them into <strong>packets</strong> (if needed due to large data), and add <strong>appends additional information</strong> (so-called transport-layer header information) will be ==used== by the ==receiver-side transport layer==
    <ul>
      <li>e.g. ensuring there is destination/source IP, destination/source MAC, packet sequence id, etc. Then, those packets are passed to Network Layer.</li>
      <li>The transport-layer segment thus <strong>encapsulates</strong> the application-layer message, and pass down to <strong>Network Layer</strong></li>
    </ul>
  </li>
  <li>==Network Layer== then <strong>appends</strong> network-layer header information to the segment, such as source and destination end system addresses, creating a <strong>network-layer datagram</strong>
    <ul>
      <li>figures out where is the <strong>next hop</strong>, e.g. in the figure, <strong>which router/link-layer switch</strong> to send to.</li>
      <li>then pass to Link Layer</li>
    </ul>
  </li>
  <li>==Link Layer== will add its own link-layer header information and create a link-layer <strong>frame</strong>, and pass to physical layer</li>
  <li>==Physical layer== sends the bits to the next hop, a switch in the figure</li>
</ol>

<p>Now, at the switch:</p>

<ol>
  <li>receives data from the ==Physical Layer==, parse the data and move up</li>
  <li>parse the data in the ==Link Layer==, recognize the Ethernet addresses and what to send to the <strong>next router</strong>, so pass down again to physical layer</li>
  <li>==Physical Layer== then send the frame by bits.</li>
</ol>

<blockquote>
  <p><strong>Note</strong></p>

  <ul>
    <li>notice the need to go <strong>up and down</strong> the stack, if we need to “forward” the data to the next device.</li>
  </ul>
</blockquote>

<p>Eventually, repeating the process will let the data reach the destination.</p>

<h3 id="protocol-stack-variants">Protocol Stack Variants</h3>

<p>Sometimes additional layers could be added in reality, such as:</p>

<p><img src="https://www.researchgate.net/profile/Wazen-Shbair/publication/321347130/figure/fig3/AS:631648328613936@1527608105482/The-security-related-protocols-associated-with-the-TCP-IP-protocol-stack.png" alt="2: The security-related protocols associated with the TCP/IP protocol... |  Download Scientific Diagram" style="zoom: 50%;" /></p>

<p>where here we added a <strong>security layer</strong> basically.</p>

<blockquote>
  <p><strong>Note</strong></p>

  <ul>
    <li>This only works if both <strong>end-points</strong> have the same added layer. Otherwise, it would not be able to process the information correctly.</li>
  </ul>
</blockquote>

<p>The more popular ones now is the <strong>OSI model</strong>:</p>

<p><img src="https://www.researchgate.net/profile/Jay-Johnson-11/publication/322568288/figure/fig6/AS:631584889778238@1527592980914/OSI-model-seven-layer-protocol-stack-28.png" alt="OSI model, seven layer protocol stack. 28 | Download Scientific Diagram" style="zoom:50%;" /></p>

<p>where:</p>

<ul>
  <li>this is the most <strong>common implemented model now</strong></li>
</ul>

<h1 id="chapter-2-application-layer">Chapter 2 Application Layer</h1>

<p>In this chapter, we study the <strong>conceptual</strong> and <strong>implementation</strong> aspects of network applications.</p>

<ul>
  <li>for example, we will learn how to create network applications via socket API</li>
</ul>

<p>Recall that some common network apps include:</p>

<ul>
  <li>e-mail</li>
  <li>web</li>
  <li>P2P file sharing</li>
  <li>streaming stored video (<em>occupies the highest internet volume</em>)</li>
  <li>etc.</li>
</ul>

<blockquote>
  <p>==Aim for Application Layer==:</p>

  <ul>
    <li>network applications allows you to communicate between end points of <strong>different OS</strong>! So that you don’t need to write software for network-core devices (abstracted away), for example, a switch.
      <ul>
        <li>i.e. you don’t need to know anything about the network layer when writing code in the application layer</li>
      </ul>
    </li>
  </ul>
</blockquote>

<h2 id="principles-of-network-applications">Principles of Network Applications</h2>

<p>At the core of network application development is writing <strong>programs</strong> that run on <strong>different end systems</strong> and ==communicate== with each other ==over the network==.</p>

<ul>
  <li>For example, web application there are two distinct programs that communicate with each other: the browser program running in the user’s host (desktop, laptop, tablet, smartphone, and so on); and the Web server program running in the Web server host.</li>
</ul>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20210927140904107.png" alt="image-20210927140904107" style="zoom:80%;" /></p>

<p>The key idea here is that your ==don’t== write and don’t need to write application programs on <strong>network-core devices</strong> (e.g. switches), as they <em>never include application layer stuff</em> and are already “taken care” of.</p>

<ul>
  <li>This basic design- namely, confining application software to the end systems - as shown in Figure 2.1, has facilitated the
rapid development and deployment of a vast array of network applications</li>
</ul>

<h3 id="application-architecture">Application Architecture</h3>

<p>Again, the key idea is that, from the <strong>application developer’s</strong> perspective, the network architecture is fixed and ==provides a specific set of services to applications== (i.e. API’s for them to work). The <strong>application architecture</strong>, on the other hand, is <strong>designed by the application developer</strong> and dictates how the application is structured over the various end systems.</p>

<p>Therefore, at this level, we just need to know how <strong>end-to-end</strong> devices should communicate to each other <em>without worrying about what happens in between</em>.</p>

<p>In modern application architecture (i.e. how end devices talk to other end devices), there are two predominant architecture paradigms:</p>

<ul>
  <li>client-server architecture</li>
  <li>peer-to-peer (P2P) architecture.</li>
</ul>

<h4 id="client-server-architecture">Client-Server Architecture</h4>

<p>A common example of network application would be a <strong>web browser</strong> which uses the following architecture</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20210927091606049.png" alt="image-20210927091606049" /></p>

<p>where basically you have:</p>

<ul>
  <li>a server
    <ul>
      <li><strong>associated with some address</strong> (IP address), (e.g. whatever IP resolved from www.columbia.edu)</li>
      <li><strong>always-on</strong> host</li>
      <li>data centers for scaling</li>
    </ul>
  </li>
  <li>clients
    <ul>
      <li>communicate with <strong>server</strong>. (the ==client initiates a connection in this case==)
        <ul>
          <li>but clients do not directly communicate with each other</li>
        </ul>
      </li>
      <li>may have dynamic IP addresses
        <ul>
          <li>essentially we move and connects to different routers, cell towers, etc.</li>
          <li>therefore, packets need to include the <em>client’s IP</em> so that the server can find it</li>
        </ul>
      </li>
      <li>may be intermittently connected</li>
    </ul>
  </li>
</ul>

<h4 id="p2p-architecture">P2P Architecture</h4>

<p>Now, there is minimal (or no) reliance on dedicated servers in data centers. Instead, we have application exploits direct communication between pairs of intermittently connected hosts, called <strong>peers</strong>.</p>

<ul>
  <li>Basically a client, when joined this kind of network, would be that <em>clients could be a server</em> as well.</li>
</ul>

<p>the motivation is so that</p>

<ul>
  <li><strong>resources are distributed between peers/nodes</strong>, instead of having a central server holding all the data</li>
  <li>so a peer connects <strong>directly with another peer</strong></li>
</ul>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20210927092217951.png" alt="image-20210927092217951" /></p>

<p>where each node/device here is:</p>

<ul>
  <li>no always-on server, since it could be clients</li>
  <li>arbitrary end systems directly communicate</li>
  <li>both servers and clients
    <ul>
      <li>peers request service from other peers, provide service <strong>in return to</strong> other peers</li>
    </ul>
  </li>
  <li>self scalability – new peers bring new service capacity, as well as new service demands
    <ul>
      <li>peers are intermittently connected and change IP addresses</li>
    </ul>
  </li>
  <li>complex management</li>
</ul>

<p>One example of popular P2P application is the file-sharing application BitTorrent.</p>

<hr />

<p><em>For Example</em></p>

<p>You can think of the following: In a P2P file-sharing system, a file is transferred from a process in one peer to a process in another peer.</p>

<p>Then, this is equivalent of having:</p>

<ul>
  <li>With P2P file sharing, the peer that is downloading the file is labeled as the client</li>
  <li>the peer that is uploading the file is labeled as the server.</li>
</ul>

<hr />

<blockquote>
  <p><strong>Client vs Server</strong></p>

  <ul>
    <li>In the context of a communication session between a pair of processes, the process that ==initiates== the communication (that is, initially contacts the other process at the beginning of the session) is labeled as the ==client==. The process that waits to be contacted to begin the session is the server.</li>
  </ul>
</blockquote>

<h3 id="processes-communicating">Processes Communicating</h3>

<p>In any application architecture talked about above, we basically have <strong>processes</strong> on different end points <strong>communicating over the network</strong>.</p>

<ul>
  <li>when two processes are on the same device, <em>inter-process communication</em> calls (defined by OS) are used.</li>
  <li>when two processes are on different devices, e.g. a client and a server, then they communicate by exchanging network ==messages==.</li>
</ul>

<h4 id="interface-between-process-and-computer-network">Interface between Process and Computer Network</h4>

<p>So what is the ==abstraction== of the Transport Layer when you are <strong>programming an application</strong>?</p>

<p>A process sends messages into, and receives messages from, the network through a software interface called a <strong>socket</strong>.</p>

<ul>
  <li>A socket is also referred to the Application Programming Interface (API) between the <em>application and the network</em></li>
</ul>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20210927093148602.png" alt="image-20210927093148602" /></p>

<p>where:</p>

<ul>
  <li>the Internet in between is the network-core devices, including routes and switches, which is abstracted away from you</li>
</ul>

<p>The only control that the application developer has on the <strong>transport layer</strong> is (quite small)</p>

<ol>
  <li>the choice of transport protocol</li>
  <li>perhaps the ability to fix a few transport-layer parameters such as maximum buffer and maximum segment sizes</li>
</ol>

<h4 id="addressing-processes">Addressing Processes</h4>

<p>To receive messages, application processes must have some identifier</p>

<p>To identify the receiving process, <strong>two</strong> pieces of information need to be specified:</p>

<ol>
  <li>==an IP address==: the address of the host</li>
  <li>==a port number==: an identifier that specifies the receiving process in the destination host.</li>
</ol>

<ul>
  <li>identifier includes both IP address and port numbers associated with process on host.
    <ul>
      <li>example port numbers HTTP server: 80 (being also a kind of <strong>permanent address</strong>)</li>
      <li>in reality, it is common that many <em>different applications</em> ends using <code class="language-plaintext highlighter-rouge">80</code>, which is somewhat now like a <em>directory management server</em>, that tells the application which port to go</li>
    </ul>
  </li>
</ul>

<h3 id="transport-services-available-to-applications">Transport Services Available to Applications</h3>

<p>On the <strong>application layer</strong>, we might define <em>each message’s</em>:</p>

<ul>
  <li>types of messages exchanged, e.g., request, response</li>
  <li>message syntax: what fields in messages &amp; how fields are delineated</li>
  <li>
    <p>message semantics: parsing a received message</p>
  </li>
  <li>
    <p>rules for when and how processes send &amp; respond to messages</p>
  </li>
  <li>open protocols:
    <ul>
      <li>defined in RFCs</li>
      <li>allows for interoperability and <em>discussion/emendation</em></li>
      <li>e.g., HTTP, SMTP</li>
    </ul>
  </li>
</ul>

<p>Recall that the socket is our current interface for <strong>Transport-Layer</strong> protocol. Since it is an API, we choose the:</p>

<ol>
  <li>which transport protocol to use</li>
  <li>some parameters available for that protocol</li>
</ol>

<p>To <strong>decide which protocol</strong> to use, we can classify each protocol along four dimesions:</p>

<ol>
  <li><strong>reliable data transfer</strong>:
    <ul>
      <li>if a protocol can ==guarantee== that the data sent by one end of the application is delivered correctly and completely to the other end of the application</li>
      <li>so that the sending process can just pass its data into the socket and know with complete confidence that the data will arrive without errors at the receiving process</li>
      <li>on the other hand, you might need to have loss-tolerant applications</li>
    </ul>
  </li>
  <li><strong>throughput</strong>: the <em>rate</em> at which the sending process can deliver bits to the receiving process
    <ul>
      <li>because network bandwidth is shared, available throughput can fluctuate with time</li>
      <li>natural service that a transport-layer protocol could provide, namely, ==guaranteed== available throughput at some specified rate. So that the application could request a guaranteed throughput of $r$ bits/sec</li>
      <li>Applications that have throughput requirements are said to be <em>bandwidth-sensitive applications</em>. Many current multimedia applications are bandwidth sensitive due to <strong>encoding</strong>.</li>
    </ul>
  </li>
  <li><strong>timing</strong>
    <ul>
      <li>timing ==guarantees== can come in many shapes and forms. For example, every bit that the sender pumps into the socket arrives at the receiver’s socket no more than $100$ msec later (i.e. delay)</li>
      <li>for real-time applications, such as interactive games, this is very important</li>
    </ul>
  </li>
  <li><strong>security</strong>
    <ul>
      <li>a transport <em>protocol</em> can ==encrypt== all data transmitted by the sending process, and in the receiving host, the transport-layer protocol can ==decrypt== the data before delivering the data to the receiving process</li>
    </ul>
  </li>
</ol>

<blockquote>
  <p><strong>Recall that</strong></p>

  <ul>
    <li>The <strong>instantaneous throughput</strong> at any instant of time is the rate (in bits/sec) at which Host B is receiving the file.
      <ul>
        <li>instantaneous throughput during downloads = download speed</li>
      </ul>
    </li>
    <li>If the file consists of $F$ bits and the transfer takes $T$ seconds for Host B to receive all F bits, then the <strong>average throughput</strong> of the file transfer is $F/T$ bits/sec</li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Note</strong></p>

  <ul>
    <li>in general, the Applications themselves will calculate the delay and throughput of the current network by <em>actively observing it</em>. And in reality, the network usually does not <strong>guarantee anything</strong>. Therefore, applications needs to have some flexibility in those.</li>
  </ul>
</blockquote>

<hr />

<p><em>For Example</em></p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20210927095247397.png" alt="image-20210927095247397" style="zoom:80%;" /></p>

<hr />

<h4 id="transport-services-provided-by-the-internet">Transport Services Provided by the Internet</h4>

<p>Up until this point, we have been considering transport services that a computer network <strong>could</strong> provide in general. Let’s now get more specific and examine the <strong>type of transport services provided</strong> by the Internet.</p>

<p>Some common Transport Layer Protocols would be:</p>

<ul>
  <li><strong>TCP</strong>: a connection-oriented service and a reliable data transfer service.</li>
  <li><strong>UDP</strong>: simple and straight forward implementation</li>
</ul>

<h5 id="tcp-services">TCP Services</h5>

<p>When an application invokes TCP as its transport protocol, you get (for free):</p>

<ul>
  <li><strong>Connection-oriented service</strong>: TCP has the client and server exchange transport layer control information with each other ==before== the application-level messages begin to flow (i.e. the handshaking procedure)
    <ul>
      <li>Then the connection is <em>established</em>, the connection is a full-duplex connection in that the two processes can send messages to each other over the connection at the same time.</li>
      <li>When the application <em>finishes</em> sending messages, it must tear down the connection</li>
      <li>this provides the basis for flow control and congestion control</li>
    </ul>
  </li>
  <li><strong>Reliable Data Transfer service</strong>: rely on TCP to deliver all data sent without error and in the proper order.</li>
</ul>

<p>(Additionally, TCP also includes a congestion-control mechanism, a service for the general welfare of the <em>Internet</em> rather than for the direct benefit of the communicating <em>processes</em>.)</p>

<ul>
  <li>throttles a sending process (client or server) when the network is congested between sender and receiver</li>
</ul>

<h5 id="udp-services">UDP Services</h5>

<p>UDP is a no-frills, lightweight transport protocol, providing minimal services. UDP is connectionless, so there is no handshaking before the two processes start to communicate. Therefore:</p>

<ul>
  <li>unreliable data transfer service, so messages that do arrive at the receiving process may arrive out of order</li>
</ul>

<h5 id="tcp-vs-udp">TCP vs UDP</h5>

<p>Below summarizes features of the two protocols.</p>

<table>
  <thead>
    <tr>
      <th>TCP</th>
      <th>UDP</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>reliable</strong> transport between sending and receiving process</td>
      <td>Nothing, but <strong>low</strong> overhead.</td>
    </tr>
    <tr>
      <td><strong>flow control</strong>: sender won’t overwhelm receiver</td>
      <td> </td>
    </tr>
    <tr>
      <td><strong>congestion control</strong>: throttle sender when network overloaded</td>
      <td> </td>
    </tr>
    <tr>
      <td><strong>connection-oriented</strong>: setup required between client and server processes (this is <em>required</em> for flow control or congestion control)</td>
      <td> </td>
    </tr>
    <tr>
      <td>==does not provide==: timing, minimum throughput guarantee, security</td>
      <td>==does not provide==: reliable or in order delivery, flow control, congestion control, timing, throughput guarantee, security, or connection setup</td>
    </tr>
  </tbody>
</table>

<blockquote>
  <p><strong>Note</strong></p>

  <ul>
    <li>TCP itself does not provide security. In reality, it is usually the TLS = Transport Layer Security that provides encryption.</li>
    <li>In UDP, though packets might arrive out of order, <strong>you</strong> (application layer) can check and request the sender to sending again the missing packet.</li>
  </ul>
</blockquote>

<p>So UDP might be advantageous when the data to transfer is small (e.g. DNS), or when you really need a small overhead for transfer:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20210929085258953.png" alt="image-20210929085258953" style="zoom: 80%;" /></p>

<h3 id="securing-tcp">Securing TCP</h3>

<p>SSL/TLS</p>

<ul>
  <li>provides <strong>encrypted</strong> TCP connection</li>
  <li>data integrity</li>
  <li>end-point authentication</li>
  <li>SSL is older, deprecated</li>
</ul>

<p>TLS is at app layer</p>

<ul>
  <li>apps use SSL libraries, that “talk” to TCP</li>
  <li>Client/server negotiate use of TLS</li>
</ul>

<p><strong>TLS socket</strong> API</p>

<ul>
  <li>if you send a cleartext password into socket, it traverses Internet encrypted</li>
</ul>

<h2 id="socket-programming">Socket Programming</h2>

<p>The goal is to learn how to build client/server applications that communicate using sockets.</p>

<p>Recall that there are two socket types for two transport services:</p>

<ul>
  <li>UDP: unreliable datagram but low overhead</li>
  <li>TCP: reliable, byte stream-oriented</li>
</ul>

<hr />

<p><em>For Example</em></p>

<p>Application Example:</p>

<ol>
  <li>client reads a line of characters (data) from its keyboard and sends data to server</li>
  <li>server receives the data and converts characters to uppercase</li>
  <li>server sends modified data to client</li>
  <li>client receives modified data and displays line on its screen</li>
</ol>

<p><strong>For UDP:</strong></p>

<ul>
  <li>recall that this is connectionless. Therefore, ==every packet== needs to know its destination. As compared to TCP. which just needs to dump the packet in the <em>established connection</em> and you are done
    <ul>
      <li>no handshaking before sending data</li>
      <li>sender explicitly attaches IP and port destination address for every packet</li>
    </ul>
  </li>
  <li>transmitted data may be lost or received out-of-order
    <ul>
      <li>(e.g. packet 1 sent on 10 MBPS link and packet 2 on 100MBPS, different routes)</li>
      <li>therefore, the application layer might need to anticipate and check this</li>
    </ul>
  </li>
</ul>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20210929091850365.png" alt="image-20210929091850365" style="zoom:80%;" /></p>

<p>In Python, you then get for the <strong>client</strong>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">socket</span> <span class="kn">import</span> <span class="o">*</span>
<span class="n">serverName</span> <span class="o">=</span> <span class="err">‘</span><span class="n">hostname</span><span class="err">’</span>
<span class="n">serverPort</span> <span class="o">=</span> <span class="mi">12000</span>

<span class="c1"># creates socket
</span><span class="n">clientSocket</span> <span class="o">=</span> <span class="n">socket</span><span class="p">(</span><span class="n">AF_INET</span><span class="p">,</span> <span class="n">SOCK_DGRAM</span><span class="p">)</span>
<span class="n">message</span> <span class="o">=</span> <span class="nb">raw_input</span><span class="p">(</span><span class="err">’</span><span class="n">Input</span> <span class="n">lowercase</span> <span class="n">sentence</span><span class="p">:</span><span class="err">’</span><span class="p">)</span>
<span class="n">clientSocket</span><span class="p">.</span><span class="n">sendto</span><span class="p">(</span><span class="n">message</span><span class="p">.</span><span class="n">encode</span><span class="p">(),</span> <span class="p">(</span><span class="n">serverName</span><span class="p">,</span> <span class="n">serverPort</span><span class="p">))</span> <span class="c1"># sends to a queue
</span>
<span class="c1"># receive a message
</span><span class="n">modifiedMessage</span><span class="p">,</span> <span class="n">serverAddress</span> <span class="o">=</span> <span class="n">clientSocket</span><span class="p">.</span><span class="n">recvfrom</span><span class="p">(</span><span class="mi">2048</span><span class="p">)</span>
<span class="k">print</span> <span class="n">modifiedMessage</span><span class="p">.</span><span class="n">decode</span><span class="p">()</span>
<span class="n">clientSocket</span><span class="p">.</span><span class="n">close</span><span class="p">()</span>
</code></pre></div></div>

<ul>
  <li>notice that <code class="language-plaintext highlighter-rouge">clientSocket.sendto(message.encode(), (serverName, serverPort))</code> shows that we are ==specifying destination for every packet==</li>
</ul>

<p>Then for the <strong>server</strong>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">socket</span> <span class="kn">import</span> <span class="o">*</span>
<span class="n">serverPort</span> <span class="o">=</span> <span class="mi">12000</span>

<span class="c1"># create socket
</span><span class="n">serverSocket</span> <span class="o">=</span> <span class="n">socket</span><span class="p">(</span><span class="n">AF_INET</span><span class="p">,</span> <span class="n">SOCK_DGRAM</span><span class="p">)</span>
<span class="n">serverSocket</span><span class="p">.</span><span class="n">bind</span><span class="p">((</span><span class="s">''</span><span class="p">,</span> <span class="n">serverPort</span><span class="p">))</span>
<span class="k">print</span> <span class="p">(</span><span class="err">“</span><span class="n">The</span> <span class="n">server</span> <span class="ow">is</span> <span class="n">ready</span> <span class="n">to</span> <span class="n">receive</span><span class="err">”</span><span class="p">)</span>

<span class="c1"># listening and receiving
</span><span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
    <span class="n">message</span><span class="p">,</span> <span class="n">clientAddress</span> <span class="o">=</span> <span class="n">serverSocket</span><span class="p">.</span><span class="n">recvfrom</span><span class="p">(</span><span class="mi">2048</span><span class="p">)</span> <span class="c1"># reads from a queue
</span>    <span class="n">modifiedMessage</span> <span class="o">=</span> <span class="n">message</span><span class="p">.</span><span class="n">decode</span><span class="p">().</span><span class="n">upper</span><span class="p">()</span>
    <span class="n">serverSocket</span><span class="p">.</span><span class="n">sendto</span><span class="p">(</span><span class="n">modifiedMessage</span><span class="p">.</span><span class="n">encode</span><span class="p">(),</span> <span class="n">clientAddress</span><span class="p">)</span>
</code></pre></div></div>

<ul>
  <li>notice that there is only <em>one socket</em></li>
  <li>since it is UDP, it also means that if the server if <em>full in queue</em>, the client will have no idea and still sends the packets (TCP would have notified the client)</li>
</ul>

<blockquote>
  <p>==UDP Takeaway==</p>

  <ul>
    <li>the idea is that at every single time, there is only a <strong>one-way connection</strong></li>
  </ul>
</blockquote>

<hr />

<p>On the other hand, when we have a <strong>TCP</strong> protocol:</p>

<ul>
  <li>client needs to be creating TCP socket, specifying IP address, port number of server process ==at socket creation==</li>
  <li>when contacted by client, server TCP creates new socket for server process to communicate with that particular client
    <ul>
      <li>i.e. you <code class="language-plaintext highlighter-rouge">fork</code> that socket</li>
      <li>allows server to talk with multiple clients</li>
      <li>source port numbers used to distinguish clients (more in Chap 3)</li>
    </ul>
  </li>
</ul>

<p>Therefore, the abstraction is:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20210929093217927.png" alt="image-20210929093217927" style="zoom:80%;" /></p>

<p>where we notice that:</p>

<ul>
  <li>on the server, <em>when connection is established</em>, you will get a listening <code class="language-plaintext highlighter-rouge">serverSocket</code> and a <code class="language-plaintext highlighter-rouge">connectionSocket</code> which you would use for sending/receiving</li>
</ul>

<p>In the client side, you get:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">socket</span> <span class="kn">import</span> <span class="o">*</span>
<span class="n">serverName</span> <span class="o">=</span> <span class="err">’</span><span class="n">servername</span><span class="err">’</span>
<span class="n">serverPort</span> <span class="o">=</span> <span class="mi">12000</span>

<span class="c1"># creating socket
</span><span class="n">clientSocket</span> <span class="o">=</span> <span class="n">socket</span><span class="p">(</span><span class="n">AF_INET</span><span class="p">,</span> <span class="n">SOCK_STREAM</span><span class="p">)</span>
<span class="n">clientSocket</span><span class="p">.</span><span class="n">connect</span><span class="p">((</span><span class="n">serverName</span><span class="p">,</span><span class="n">serverPort</span><span class="p">))</span> <span class="c1"># server destination specified at CREATION time
</span>
<span class="c1"># sending/receiving message
</span><span class="n">sentence</span> <span class="o">=</span> <span class="nb">raw_input</span><span class="p">(</span><span class="err">‘</span><span class="n">Input</span> <span class="n">lowercase</span> <span class="n">sentence</span><span class="p">:</span><span class="err">’</span><span class="p">)</span>
<span class="n">clientSocket</span><span class="p">.</span><span class="n">send</span><span class="p">(</span><span class="n">sentence</span><span class="p">.</span><span class="n">encode</span><span class="p">())</span> <span class="c1"># convert to INTERNET BYTE ORDER (inet_aton)
</span><span class="n">modifiedSentence</span> <span class="o">=</span> <span class="n">clientSocket</span><span class="p">.</span><span class="n">recv</span><span class="p">(</span><span class="mi">1024</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="err">‘</span><span class="n">From</span> <span class="n">Server</span><span class="p">:</span><span class="err">’</span><span class="p">,</span> <span class="n">modifiedSentence</span><span class="p">.</span><span class="n">decode</span><span class="p">())</span> <span class="c1"># convert back to 
</span><span class="n">clientSocket</span><span class="p">.</span><span class="n">close</span><span class="p">()</span>
</code></pre></div></div>

<ul>
  <li>as compared to UDP, which has <code class="language-plaintext highlighter-rouge">clientSocket = socket(AF_INET, SOCK_DGRAM)</code></li>
</ul>

<p>The server then does:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">socket</span> <span class="kn">import</span> <span class="o">*</span>
<span class="n">serverPort</span> <span class="o">=</span> <span class="mi">12000</span>

<span class="c1"># create
</span><span class="n">serverSocket</span> <span class="o">=</span> <span class="n">socket</span><span class="p">(</span><span class="n">AF_INET</span><span class="p">,</span><span class="n">SOCK_STREAM</span><span class="p">)</span>

<span class="c1"># bind and listen
</span><span class="n">serverSocket</span><span class="p">.</span><span class="n">bind</span><span class="p">((</span><span class="err">‘’</span><span class="p">,</span><span class="n">serverPort</span><span class="p">))</span>
<span class="n">serverSocket</span><span class="p">.</span><span class="n">listen</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="k">print</span> <span class="err">‘</span><span class="n">The</span> <span class="n">server</span> <span class="ow">is</span> <span class="n">ready</span> <span class="n">to</span> <span class="n">receive</span><span class="err">’</span>

<span class="c1"># listenning/blocking
</span><span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
    <span class="n">connectionSocket</span><span class="p">,</span> <span class="n">addr</span> <span class="o">=</span> <span class="n">serverSocket</span><span class="p">.</span><span class="n">accept</span><span class="p">()</span> <span class="c1"># gets a new socket with fork
</span>    <span class="n">sentence</span> <span class="o">=</span> <span class="n">connectionSocket</span><span class="p">.</span><span class="n">recv</span><span class="p">(</span><span class="mi">1024</span><span class="p">).</span><span class="n">decode</span><span class="p">()</span> <span class="c1"># convert to OS endianness
</span>    <span class="n">capitalizedSentence</span> <span class="o">=</span> <span class="n">sentence</span><span class="p">.</span><span class="n">upper</span><span class="p">()</span>
    <span class="n">connectionSocket</span><span class="p">.</span><span class="n">send</span><span class="p">(</span><span class="n">capitalizedSentence</span><span class="p">.</span><span class="n">encode</span><span class="p">())</span>
    <span class="n">connectionSocket</span><span class="p">.</span><span class="n">close</span><span class="p">()</span> <span class="c1"># done
</span></code></pre></div></div>

<p>so the extra things we need to do is:</p>

<ol>
  <li>listen to the socket <em>after <code class="language-plaintext highlighter-rouge">bind</code></em>
    <ul>
      <li>the UDP does not need to <code class="language-plaintext highlighter-rouge">listen</code></li>
    </ul>
  </li>
  <li>accept connection (and fork) to get a connection
    <ul>
      <li>the UDP just needs to have a <code class="language-plaintext highlighter-rouge">serverSocket.recvfrom(2048)</code> from the same <code class="language-plaintext highlighter-rouge">bind</code> socket</li>
    </ul>
  </li>
</ol>

<hr />

<h2 id="web-and-http">Web and HTTP</h2>

<p>Here we discuss two protocols that is common in application layer.</p>

<p>We ==assume== that you know</p>

<ul>
  <li>
    <p>how <code class="language-plaintext highlighter-rouge">html</code> file (“a markup language”) works with browsers, including how the images/videos/scripts works</p>
  </li>
  <li>
    <p>as well as how path names work</p>

    <p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211004085524529.png" alt="image-20211004085524529" /></p>
  </li>
</ul>

<h3 id="http-overview">HTTP Overview</h3>

<p>Because we need the browser to render the page correctly, so we need <em>reliable data transfer</em>. Hence, HTTP protocols <strong>chooses to use TCP</strong>, with port <code class="language-plaintext highlighter-rouge">80</code></p>

<blockquote>
  <p><em>Recall:</em> <em>how we implemented the TCP for sockets:</em></p>

  <ol>
    <li>client <strong>initiates</strong> TCP connection (creates socket) to server, port 80</li>
    <li>server <strong>accepts</strong> TCP connection from client</li>
    <li>HTTP <strong>messages</strong> (application-layer protocol messages) <strong>exchanged</strong> between browser (HTTP client) and Web server (HTTP server)</li>
    <li>TCP connection <strong>closed</strong></li>
  </ol>
</blockquote>

<p>Additionally, ==by DEFAULT==, the protocol of HTTP is “stateless”</p>

<ul>
  <li>yet <strong>we MADE IT</strong> stateful by using other tools such as Cookies</li>
</ul>

<blockquote>
  <p><strong>Disadvantage of Stateful Connections</strong></p>

  <ul>
    <li>past history (state) must be maintained</li>
    <li>if server/client crashes, their views of “state” may be inconsistent, must be reconciled</li>
    <li>security issues!</li>
  </ul>
</blockquote>

<h3 id="http-connections">HTTP Connections</h3>

<p>In generally we had two types:</p>

<ol>
  <li><strong>Non-persistent HTTP</strong>: sending only ONE object (e.g. an image) over one connection
    <ul>
      <li>then if your html has 3 images, 3 <code class="language-plaintext highlighter-rouge">css</code>, 1 html, then it needs <em>7 connections</em></li>
      <li>connection terminates over each single message exchanges</li>
    </ul>
  </li>
  <li><strong>Persistent HTTP</strong>: multiple objects can be sent over a single TCP connection
    <ul>
      <li>less overhead, better performances</li>
      <li>connection terminates after multiple exchanges</li>
    </ul>
  </li>
</ol>

<h4 id="non-persistent-http-example">Non-persistent HTTP: example</h4>

<p>Consider the case when you entered <code class="language-plaintext highlighter-rouge">www.someSchool.edu/someDepartment/home.index</code></p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211004090817833.png" alt="image-20211004090817833" /></p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211004090926457.png" alt="image-20211004090926457" /></p>

<p>So basically this is very wasteful.</p>

<blockquote>
  <p><strong>RTT (definition)</strong></p>

  <ul>
    <li>time for a small packet to travel from client to server and back</li>
  </ul>
</blockquote>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211004091258299.png" alt="image-20211004091258299" /></p>

<h4 id="persistent-http">Persistent HTTP</h4>

<p>In this case:</p>

<ol>
  <li>server leaves connection open after sending response
    <ul>
      <li>the <strong>connection</strong> to the <strong>host</strong>, has <em>nothing</em> to do with your path such as <code class="language-plaintext highlighter-rouge">/index.html</code> (remember it is just a <code class="language-plaintext highlighter-rouge">socket</code>)</li>
    </ul>
  </li>
  <li>subsequent HTTP messages between same client/server sent over open connection
    <ul>
      <li>here we have the request, i.e. <code class="language-plaintext highlighter-rouge">GET /index.html blablabla</code></li>
    </ul>
  </li>
  <li>client sends requests as soon as it encounters a referenced object</li>
  <li>as little as one RTT for all the <em>referenced</em> objects (cutting response time in half)
    <ul>
      <li>the initial connection for (e.g.) <code class="language-plaintext highlighter-rouge">index.html</code> will still take 2 RTT, but for all other (e.g.) 10 objects on that <code class="language-plaintext highlighter-rouge">index.html</code> page, we just need $10 \times 1$ RTT.</li>
    </ul>
  </li>
</ol>

<h3 id="http-message-format">HTTP Message Format</h3>

<h4 id="http-request-message">HTTP Request Message</h4>

<p>We have two types: request and response.</p>

<p>Each <strong>request message looks like</strong></p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211004091730450.png" alt="image-20211004091730450" style="zoom: 33%;" /></p>

<p>notice that:</p>

<ul>
  <li>the connection goes to the <code class="language-plaintext highlighter-rouge">HOST</code> field</li>
  <li>in the connection, the <code class="language-plaintext highlighter-rouge">path</code> is queried</li>
  <li>content is in ASCII</li>
</ul>

<p>Moreover, remember that we can have user parameters specified with <code class="language-plaintext highlighter-rouge">login?a=b&amp;c=d</code> etc.</p>

<ul>
  <li>fundamentally this is agreed upon in the <strong>application</strong> side how to parse the stuff after <code class="language-plaintext highlighter-rouge">?</code></li>
</ul>

<h5 id="conditional-get">Conditional GET</h5>

<p><em>Goal:</em> don’t send object if cache has up-to-date cached version</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211004095110171.png" alt="image-20211004095110171" style="zoom: 50%;" /></p>

<p>where if you get <code class="language-plaintext highlighter-rouge">304</code>, then no data is actually sent over.</p>

<h4 id="http-response-message">HTTP Response Message</h4>

<p>An response message looks like:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211004093204431.png" alt="image-20211004093204431" style="zoom: 33%;" /></p>

<p>where:</p>

<ul>
  <li>notice the <code class="language-plaintext highlighter-rouge">Last-Modified</code> field. This is used later by the <strong>client browser</strong>, so that the next time it requests the <em>same resource</em>, it will send a “send if modified” version of a get request, with this date attached.</li>
  <li>notice that <code class="language-plaintext highlighter-rouge">200 OK</code> status code</li>
</ul>

<p>Additionally, some other status codes:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211004093719447.png" alt="image-20211004093719447" /></p>

<h3 id="maintaining-state-cookies">Maintaining State: Cookies</h3>

<p>Recall that HTTP protocol is stateless, which means <strong>each request is independent of each other</strong>.</p>

<p>Then, to ==emulate== a STATEFUL request, we use cookies.</p>

<p>Usually, we have <em>four components</em> interacting when using/managing cookies:</p>

<ol>
  <li>cookie received from header line of HTTP <em>response</em> message</li>
  <li>cookie sent (from user’s browser) header line in next HTTP <em>request</em> message</li>
  <li>cookie file kept on user’s host, managed by user’s browser</li>
  <li>back-end database at Web site (used for managing what to do with those cookies)</li>
</ol>

<p><em>For Example</em></p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211004094222058.png" alt="image-20211004094222058" /></p>

<p>where:</p>

<ul>
  <li>the server creates cookies and</li>
  <li><strong>subsequent</strong> HTTP requests to this site will contain the cookie ID value</li>
  <li>the above is an example of a persistent cookie</li>
</ul>

<blockquote>
  <p><strong>Note</strong></p>

  <ul>
    <li>we have <strong>session specific cookies</strong>, and <strong>persistent cookies</strong>
      <ul>
        <li>session specific cookies are <strong>erased</strong> after you close your session (e.g. browser window)</li>
        <li>persistent cookies has an <strong>expiration date</strong>, which expires after that but stays there after you close your session</li>
      </ul>
    </li>
    <li><strong>third party persistent cookies</strong> (tracking cookies) allow common identity (cookie value) to be tracked across multiple web sites
      <ul>
        <li>These are usually used for <em>online-advertising purposes</em> and placed on a website through a script or tag. A third-party cookie is accessible on any website that loads the third-party server’s code.</li>
        <li>e.g. once you shopped on Amazon for (e.g.) a pair of brown shoes, it might create some <em>third party cookie</em>. Then future other websites might look at that and provide you relevant ads.</li>
      </ul>
    </li>
  </ul>
</blockquote>

<h3 id="http2">HTTP/2</h3>

<p><em>Goal</em>: Solve the head of the line issue:</p>

<ul>
  <li>what if the first request is a huge file, and subsequent are small files? The first will block the other requests.</li>
</ul>

<p><strong>HTTP 1.1</strong>: introduced multiple, pipelined GETs over single TCP connection</p>

<ul>
  <li>server responds <em>in-order</em> (FCFS: first-come-first-served scheduling) to <code class="language-plaintext highlighter-rouge">GET</code> requests in a pipe
    <ul>
      <li>e.g. if you requested for 10 images, they are responded/served in a FIFO</li>
      <li>therefore, may developers tend to still open multiple <em>parallel connections</em> to resolve this</li>
    </ul>
  </li>
</ul>

<p>However, the ==problem== with that is:</p>

<ul>
  <li>
    <p>with FCFS, small object may have to wait for transmission (head-of-line (HOL) blocking) behind large object(s)</p>
  </li>
  <li>
    <p>loss recovery (retransmitting lost TCP segments) stalls object transmission</p>
  </li>
</ul>

<blockquote>
  <p><strong>Aim of HTTP/2</strong></p>

  <p>One of the primary goals of HTTP/2 is to get rid of (or at least reduce the number of) parallel TCP connections for transporting a single Web page (as a resolution to Head-Of-Line blocking problem)</p>

  <ul>
    <li>TCP congestion control can also operate as intended</li>
  </ul>

  <p>The HTTP/2 solution for HOL blocking is to ==break each message into small frames==, and interleave the request and response messages on the same TCP connection.</p>

  <ul>
    <li>of course we need to then reassemble them on the other end. So this protocol has to be made clear on that.</li>
  </ul>
</blockquote>

<p>Of course besides that, HTTP/2 also has the following features:</p>

<ol>
  <li><strong>Response Message Prioritization</strong>:
    <ul>
      <li>the client can give a weight to each request for its priority. Numbers range from $1\to 256$. Then the server cans send first the frames for the responses with the highest priority.</li>
      <li>You can also states each message’s dependency on other messages by specifying the ID of the message on which it depends.</li>
    </ul>
  </li>
  <li><strong>Server Pushing</strong>: a server to send <em>multiple responses</em> for a single client request.
    <ul>
      <li>for a single page, there is usually a lot of objects (e.g. images). Instead of waiting for the HTTP requests for these objects, the ==server can analyze the HTML page==, identify the objects that are needed, and ==send them to the client before receiving explicit requests== for these objects.</li>
    </ul>
  </li>
</ol>

<hr />

<p><em>For Example</em>:</p>

<p>In HTTP 1.1, this is the order of data sent:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211004095404224.png" alt="image-20211004095404224" /></p>

<p>For <strong>HTTP 2:</strong></p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211004095423396.png" alt="image-20211004095423396" /></p>

<p>where basically you do a Round-Robin.</p>

<hr />

<h3 id="http3">HTTP/3</h3>

<p>Thought <strong>HTTP/2</strong> is the most common now, it still has some ==problems==. HTTP/2 over single TCP connection means:</p>

<ul>
  <li>recovery from packet loss still stalls all object transmissions</li>
  <li>no security over vanilla TCP connection</li>
</ul>

<p>HTTP/3 is yet a new HTTP protocol that is designed to operate over <strong>QUIC</strong>. As of 2020, HTTP/3 is described in Internet drafts and has not yet been fully standardized.</p>

<ul>
  <li>QUIC (Quick UDP Internet Connections, pronounced quick) is an <strong>experimental transport layer network protocol designed by</strong> Google</li>
  <li>Think of QUIC as being similar to TCP+TLS+HTTP/2 implemented on UDP</li>
</ul>

<blockquote>
  <p><strong>HTTP/3</strong></p>

  <p>HTTP/3: adds security, per object error- and congestion-control (more pipelining) over ==QUIC== (which is UDP)</p>

  <ul>
    <li>QUIC was chosen because many of the HTTP/2 features (such as message interleaving) are subsumed by QUIC</li>
    <li>since it is on UDP, it would be faster as well</li>
  </ul>
</blockquote>

<p>More on HTTP/3 in transport layer chapter.</p>

<h3 id="web-caching">Web Caching</h3>

<p>There are two caches:</p>

<ul>
  <li>the caching of website made by <strong>your application</strong></li>
  <li>the caching of website <strong>in a Web Cache/proxy server</strong>. Here we talk about ==this one==.</li>
</ul>

<blockquote>
  <p><strong>Web Caching Server</strong></p>

  <p>A Web cache—also called a proxy server—is a network entity that satisfies HTTP requests on the <em>behalf of an origin Web server</em>.</p>

  <ul>
    <li>therefore, the Web cache has its own disk storage and keeps copies of recently requested objects in this storage</li>
  </ul>
</blockquote>

<p>The basic diagram looks as follows, and the flow is simple:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211006212559970.png" alt="image-20211006212559970" style="zoom:67%;" /></p>

<p>Suppose you want to get <code class="language-plaintext highlighter-rouge">www.someschool.edu/campus.gif</code>. (You need to configure your web browser so that all of the user’s HTTP requests are first directed to the Web cache first).</p>

<p>Then:</p>

<ol>
  <li>The browser establishes a TCP connection to the <strong>Web cache</strong> and sends an HTTP request for the object to the Web cache.</li>
  <li>The Web cache checks to see if it has a copy of the object stored locally.
    <ul>
      <li>If it <strong>does</strong>, the <strong>Web cache returns</strong> the object within an HTTP response message to the client browser.</li>
      <li>If the <strong>Web cache does not</strong> have the object, the <em>Web cache opens</em> a TCP connection to the origin server, that is, to www.someschool.edu. then sends an HTTP request</li>
    </ul>
    <ul>
      <li>When the Web cache receives the object, it <strong>stores a copy</strong> in its local storage and sends a copy to the client (over the existing TCP connection between the client browser and the Web cache).</li>
    </ul>
  </li>
</ol>

<p>So basically a cache is both a server and a client at the same time.</p>

<p>In reality:</p>

<ul>
  <li>Typically a Web cache is purchased and installed by an ISP. For example, a university might install a cache on its campus network and configure all of the campus browsers to point to the cache</li>
</ul>

<h2 id="dns-domain-name-system">DNS: Domain Name System</h2>

<p>The idea is that:</p>

<ul>
  <li>an internet host is identified by an <strong>IP address</strong>
    <ul>
      <li>an IP address assigned per <em>network interface</em>. So a device could have multiple IP addresses</li>
    </ul>
  </li>
  <li>but we use readable formats such as <code class="language-plaintext highlighter-rouge">cs.umass.edu</code>, we need to <strong>map them to IP addresses</strong></li>
</ul>

<blockquote>
  <p><strong>Domain Name System</strong></p>

  <ul>
    <li><em><strong>distributed</strong> database</em> implemented in hierarchy of many <em>name servers</em>
      <ul>
        <li>distributed database = each database contains partial information; synchronization issue is saved</li>
      </ul>
    </li>
    <li><em><strong>application-layer</strong> protocol</em>: hosts, DNS servers communicate to <em>resolve</em> names (address/name translation)</li>
  </ul>
</blockquote>

<p><em>Disadvantage of Centralized DNS</em></p>

<ul>
  <li>single point of failure</li>
  <li>traffic volume</li>
  <li>distant centralized database</li>
  <li>maintenance</li>
</ul>

<h3 id="dns-services">DNS Services</h3>

<p>Some services provided by the DNS server is:</p>

<ul>
  <li>hostname-to-IP-address translation</li>
  <li><strong>host aliasing</strong>
    <ul>
      <li>Basically you can have two or more domain names that take you to a single site.</li>
      <li>e.g. a hostname such as <code class="language-plaintext highlighter-rouge">relay1.west-coast.enterprise.com</code> could have, say, two aliases such as www.enterprise1.com and www.enterprise.com. In this case, the hostname <code class="language-plaintext highlighter-rouge">relay1.west-coast.enterprise.com</code> is said to be a <strong>canonical hostname</strong></li>
    </ul>
  </li>
  <li><strong>mail server aliasing</strong>
    <ul>
      <li>all organization has a dedicated mail server</li>
      <li>e.g. Bob has an account with Yahoo Mail, which might be as simple as bob@yahoo.com. However, the hostname of the Yahoo mail server is <strong>more complicated</strong> and much less mnemonic than simply <code class="language-plaintext highlighter-rouge">yahoo.com</code>. So internally there is some aliasing done.</li>
    </ul>
  </li>
  <li><strong>load distribution</strong>
    <ul>
      <li>there are some replicated Web Servers: many IP addresses correspond to one name</li>
      <li>load balancing: depending on <em>where the request comes from</em>, the service can respond <strong>different IP addresses</strong> so we can load balance</li>
    </ul>
  </li>
</ul>

<p><em>For Example</em>: Using <code class="language-plaintext highlighter-rouge">nslookup</code></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>➜ nslookup
<span class="o">&gt;</span> www.columbia.edu
Server:         172.18.48.1
Address:        172.18.48.1#53

Non-authoritative answer:
www.columbia.edu        canonical name <span class="o">=</span> www.a.columbia.edu.
www.a.columbia.edu      canonical name <span class="o">=</span> www.wwwr53.cc.columbia.edu.
Name:   www.wwwr53.cc.columbia.edu
Address: 128.59.105.24
</code></pre></div></div>

<p>In general, DNS are used:</p>

<ul>
  <li><em>trillions</em> of queries/day
    <ul>
      <li>so performance matters!</li>
    </ul>
  </li>
  <li>databases contains billion records</li>
  <li>decentralized databases
    <ul>
      <li>millions of different organizations responsible for their records</li>
    </ul>
  </li>
</ul>

<h3 id="overview-of-how-dns-works">Overview of How DNS Works</h3>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211006092034706.png" alt="image-20211006092034706" /></p>

<p>where:</p>

<ul>
  <li>
    <p>the <strong>root server</strong> stores IPs for the Top Level Domain servers (TLD)</p>

    <ul>
      <li>There are more than 1000 root servers instances scattered all over the world, as shown in Figure 2.18. These root servers are <em><strong>copies</strong> of 13 different root servers</em>, managed by 12 different organizations.</li>
    </ul>

    <p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211006214111135.png" alt="image-20211006214111135" style="zoom:50%;" /></p>
  </li>
  <li>
    <p>the top level domain servers knows about <em>lower level/authoritative DNS servers</em></p>

    <ul>
      <li>For each of the top-level domains—top-level domains such as com, org, net, edu, and gov, and all of the country top-level domains such as uk, fr, ca, and jp—there is TLD server (or server cluster).</li>
    </ul>
  </li>
  <li>
    <p>the <strong>authoritative DNS server</strong> basically keeps the actual mapping (so it is managed by the actual organization such as Amazon)</p>

    <ul>
      <li>Every organization with publicly accessible hosts (such as Web servers and mail servers) on the Internet must provide publicly accessible DNS records that map the names of those hosts to IP addresses</li>
    </ul>
  </li>
  <li>
    <p>basically each parent node ==knows IP address of their child node==</p>
  </li>
</ul>

<blockquote>
  <p><strong>Advantages</strong></p>

  <ul>
    <li>the benefit is that if some IP-DNS needs to be changed, only <em>one node</em> needs to be updated.</li>
  </ul>
</blockquote>

<p><em>For Example</em></p>

<p>Client wants IP address for www.amazon.com; 1st approximation:</p>

<ol>
  <li>client queries <em>local DNS server</em> first (covered in <a href="#Local Name Server">Local Name Server</a>)</li>
  <li>client queries <strong>root server</strong> to find <code class="language-plaintext highlighter-rouge">.com</code> DNS server</li>
  <li>client queries <strong><code class="language-plaintext highlighter-rouge">.com</code> DNS server</strong> to get <code class="language-plaintext highlighter-rouge">amazon.com</code> DNS server</li>
  <li>client queries <strong><code class="language-plaintext highlighter-rouge">amazon.com</code> DNS server</strong> to get IP address for www.amazon.com</li>
</ol>

<p>However, in reality:</p>

<ul>
  <li>once a name gets resolved, it will get cached <em>locally</em> (e.g. in your organization DNS server). This means that queries to the root DNS server is actually not a lot</li>
  <li>each cached name will have an <em>expiration time</em>. Before that name expires, you cannot load balance using CDN obviously.</li>
</ul>

<h4 id="root-name-server">Root Name Server</h4>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211006093248377.png" alt="image-20211006093248377" /></p>

<h4 id="top-level-domain-server">Top Level Domain Server</h4>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211006093355630.png" alt="image-20211006093355630" /></p>

<p>Knows about authoritative DNS servers, who stores the actual mapping you need.</p>

<blockquote>
  <p><strong>Authoritative DNS servers:</strong></p>

  <ul>
    <li>organization’s own DNS server(s), providing authoritative hostname to IP mappings for organization’s named hosts can be maintained by organization or service provider</li>
  </ul>
</blockquote>

<h4 id="local-name-server">Local Name Server</h4>

<p>This is where things get cached and can be reducing the number of requests to the root server.</p>

<p>So technically, when host makes DNS query, it is ==first sent to its <em>local</em> DNS server==</p>

<ul>
  <li>Local DNS server returns reply if it has been cached</li>
  <li>Forwarding request into DNS hierarchy for resolution if it doesn’t know</li>
</ul>

<p>local DNS server doesn’t strictly belong to hierarchy</p>

<blockquote>
  <p><code class="language-plaintext highlighter-rouge">ipconfig</code></p>

  <p>When you type that command in Windows, you get something like:</p>

  <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>DNS 服务器  <span class="nb">.</span> <span class="nb">.</span> <span class="nb">.</span> <span class="nb">.</span> <span class="nb">.</span> <span class="nb">.</span> <span class="nb">.</span> <span class="nb">.</span> <span class="nb">.</span> <span class="nb">.</span> <span class="nb">.</span> : 128.59.1.3
                                   128.59.1.4
</code></pre></div>  </div>

  <p>and those would be your local name server address</p>

  <ul>
    <li>those are configured <em>once you connect to the WiFi/network</em></li>
  </ul>
</blockquote>

<h4 id="iterative-query">Iterative Query</h4>

<p>Now we talk about how DNS actually works.</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211006094150411.png" alt="image-20211006094150411" /></p>

<p>the <strong>advantage of this</strong> is:</p>

<ul>
  <li>your local server can cache ==also Top Level DNS Server IP, Authoritative DNS Server IP==</li>
</ul>

<h4 id="recursive-query">Recursive Query</h4>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211006094401758.png" alt="image-20211006094401758" /></p>

<p>this is rarely used due to its <strong>problem of</strong></p>

<ul>
  <li>heavy load on root DNS server</li>
  <li>caching less stuff</li>
</ul>

<p>In reality, it is more often to see a combination of iterative and recursive approaches.</p>

<h3 id="dns-records-and-messages">DNS Records and Messages</h3>

<p>DNS distributed database store resource records (RRs), which contains mappings from Domain to IP.</p>

<blockquote>
  <p><strong>Resource Record</strong></p>

  <p>A single record is a four tuple</p>

  <p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211006214902859.png" alt="image-20211006214902859" /></p>

  <p>where:</p>

  <ul>
    <li>
      <p><strong>TTL</strong> is the time to live of the resource record; it determines when a resource should be removed from a cache.</p>

      <ul>
        <li>we ignore this field for examples below</li>
      </ul>
    </li>
    <li>
      <p><strong>Types</strong> assign meanings to Name and Value</p>

      <table>
        <thead>
          <tr>
            <th>Type</th>
            <th>Name</th>
            <th>Value</th>
            <th>Example</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>A</td>
            <td>Hostname</td>
            <td>IP Address</td>
            <td><code class="language-plaintext highlighter-rouge">(relay1.bar.foo.com, 145.37.93.126, A)</code></td>
          </tr>
          <tr>
            <td>NS</td>
            <td>Domain</td>
            <td>Hostname of an authoritative DNS server that knows the IP of this domain (used for build DNS route)</td>
            <td><code class="language-plaintext highlighter-rouge">(foo.com, dns.foo.com, NS)</code></td>
          </tr>
          <tr>
            <td>CNAME</td>
            <td>alias hostname</td>
            <td>canonical hostname</td>
            <td><code class="language-plaintext highlighter-rouge">(foo.com, relay1.bar.foo.com, CNAME)</code></td>
          </tr>
          <tr>
            <td>MX</td>
            <td>alias hostname</td>
            <td>canonical name of a mail server</td>
            <td><code class="language-plaintext highlighter-rouge">(foo.com, mail.bar.foo.com, MX)</code></td>
          </tr>
        </tbody>
      </table>
    </li>
  </ul>
</blockquote>

<h4 id="dns-messages">DNS Messages</h4>

<p>Therefore, each DNS <strong>reply message</strong> carries one or more <strong>resource records</strong>.</p>

<p>In general, we have two types:</p>

<ul>
  <li>DNS query messages</li>
  <li>DNS reply messages</li>
</ul>

<p>But both query and reply messages have the <strong>same format</strong></p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211006215624368.png" alt="image-20211006215624368" style="zoom:67%;" /></p>

<p>where:</p>

<ul>
  <li><strong>Identification</strong>: 16-bit number that identifies the query. This identifier is copied into the reply message to a query, allowing the client to match received replies with sent queries.</li>
  <li><strong>Flags</strong>: Basically a bitmap, with each bit:
    <ul>
      <li>1-bit query/reply flag indicates whether the message is a query (0) or a reply (1).</li>
      <li>1-bit authoritative flag is set in a reply message when a DNS server is an <em>authoritative server</em> for a queried name.</li>
      <li>1-bit recursion-desired flag is set when a client (host or DNS server) desires that the DNS server perform recursion</li>
      <li>1-bit recursion-available field is set in a reply if the DNS server supports recursion.</li>
    </ul>
  </li>
  <li><strong>Number of xxx</strong>: number of occurrences of the four types of data sections that follow the header</li>
  <li><strong>Questions</strong>: this section contains information about the query that is being made. This section includes
    <ul>
      <li>a name field that contains the name that is being queried</li>
      <li>type field that indicates the type of question (e.g. type <code class="language-plaintext highlighter-rouge">MX</code>)</li>
    </ul>
  </li>
  <li><strong>Answer</strong> : contains the <em>resource records</em> (i.e. four tuples) for the name that was originally queried</li>
  <li>The rest is labelled</li>
</ul>

<h4 id="inserting-records-into-dns-database">Inserting Records into DNS Database</h4>

<p>Suppose you have just created an exciting new startup <strong>company</strong> called Network Utopia. Then you might want to have your own <strong>authoritative DNS running</strong> so you can deliver content.</p>

<ol>
  <li>
    <p><strong>register</strong> the domain name networkutopia.com at a registrar (i.e. buy it from somewhere)</p>

    <ul>
      <li>A registrar is a commercial entity that verifies the uniqueness of the domain name, ==enters the domain name into its DNS database== (as discussed below), and collects a small fee from you for its services.</li>
    </ul>
  </li>
  <li>
    <p>provide the registrar with the names and IP addresses of your primary and secondary <strong>authoritative DNS servers</strong></p>

    <ul>
      <li>
        <p>e.g. <code class="language-plaintext highlighter-rouge">dns1.networkutopia.com</code>, <code class="language-plaintext highlighter-rouge">dns2.networkutopia.com</code>, <code class="language-plaintext highlighter-rouge">212.2.212.1</code>, and <code class="language-plaintext highlighter-rouge">212.212.212.2</code>.</p>
      </li>
      <li>
        <p>then the registrar would then make sure that a Type NS and a Type A record are ==entered into the TLD com server==</p>

        <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(networkutopia.com, dns1.networkutopia.com, NS)
(dns1.networkutopia.com, 212.212.212.1, A)
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
  <li>
    <p>Then, in <strong>your authoritative DNS server</strong>:</p>

    <ul>
      <li>Type A resource record for your Web server www.networkutopia.com and the Type MX resource record for your mail server <code class="language-plaintext highlighter-rouge">mail.networkutopia.com</code> are entered into your authoritative DNS servers.</li>
    </ul>
  </li>
  <li>
    <p>Once all of these steps are completed, people will be able to visit your Web site at www.networkutopia.com and send e-mail to the employees at your company</p>
  </li>
</ol>

<p>Then, one someone wanted to visit, the following would ==actually happen==:</p>

<ol>
  <li>host will first send a DNS query to her local DNS server.</li>
  <li>The local DNS server will then contact a TLD com server. (The local DNS server will also have to contact a root DNS server if the
address of a TLD com server is not cached.)</li>
  <li>The TLD com server sends a reply to Alice’s local DNS server, with the <strong>reply</strong> containing the two resource records of <strong>TYPE A and TYPE NS.</strong></li>
  <li>The local DNS server then sends a DNS <strong>query to <code class="language-plaintext highlighter-rouge">212.212.212.1</code></strong>, asking for the <strong>Type A record</strong> corresponding to www.networkutopia.com</li>
  <li>Then your authoritative DNS server needs to respond, say <code class="language-plaintext highlighter-rouge">212.212.71.4</code>, which is the IP of your webserver</li>
  <li>Alice’s browser can now initiate a TCP connection to the host 212.212.71.4 and send an HTTP request over the connection</li>
</ol>

<h3 id="dns-security">DNS Security</h3>

<p>In reality, there were two types of attacks on DNS servers.</p>

<ol>
  <li><strong>DDoS attacks</strong>
    <ul>
      <li>bombard root servers with traffic
        <ul>
          <li>not successful to date, since we can do traffic filtering</li>
        </ul>
      </li>
      <li>bombard TLD servers</li>
    </ul>
  </li>
  <li><strong>Spoofing attacks</strong>
    <ul>
      <li>intercept DNS queries, returning bogus replies</li>
      <li>DNS cache poisoning</li>
    </ul>
  </li>
</ol>

<h3 id="facebook-dns-outrage">Facebook DNS Outrage</h3>

<p>Recall that in the end, we will get an <code class="language-plaintext highlighter-rouge">IP</code> address. But we still needs to <strong>get to that IP address physically</strong>.</p>

<ul>
  <li>each router needs to ==tell other routers== which destination it can reach, by some announcement.</li>
</ul>

<blockquote>
  <p><strong>Facebook DNS Outrage</strong></p>

  <ul>
    <li>Some configuration were mistaken, so Facebook routers starts to <em>withdrawn</em> their connection to every ISP. As a result, physically <em>no routing exists</em> to reach a Facebook DNS Server</li>
    <li>Then, due to the absence of DNS requests, those DNS server thought there is an error so they shutted down</li>
    <li>In the end, now there is both NO ROUTES and NO ALIVE DNS. So nobody can actually reach Facebook’s servers.</li>
  </ul>
</blockquote>

<h2 id="video-streaming-and-content-distribution-networks">Video Streaming and Content Distribution Networks</h2>

<p>By many estimates, streaming video—including Netflix, YouTube and Amazon Prime—account for about 80% of Internet traffic in 2020. Things to take into account:</p>

<ul>
  <li>heterogeneity of uses (e.g. bandwidth available)</li>
  <li>need to scale to 1 billion + users</li>
</ul>

<p>This section discusses <strong>how popular video streaming services are implemented</strong> in today’s Internet.</p>

<ul>
  <li>a distributed, application-level infrastructure</li>
</ul>

<h3 id="internet-video">Internet Video.</h3>

<p>Basically, for <strong>pre-recorded videos</strong></p>

<ul>
  <li>servers have a copy of them</li>
  <li>users send requests to the servers to view the videos on <strong>demand</strong></li>
</ul>

<blockquote>
  <p><strong>Bit Rate</strong></p>

  <p>Bit rate is the number of bits that are conveyed or processed per unit of time.,</p>

  <ul>
    <li>each video is a <em>sequence of images</em> with certain <strong>FPS</strong> (frame per second)</li>
    <li>each frame/image has a number of <strong>pixels</strong></li>
    <li>each pixel is represented by some <strong>bits</strong></li>
  </ul>

  <p>Then some algorithm can <strong>compress those bits per second</strong> by utilizing redundancy within and between images (a like <code class="language-plaintext highlighter-rouge">zip</code> compression techniques). So we need less bits per image = less bits rate.</p>

  <ul>
    <li>spatial compression + temporal compression</li>
  </ul>
</blockquote>

<p>But obviously, the ==higher the bit rate, the better the quality== =  the higher the ==bandwidth requirement==.</p>

<p>In reality, we then have:</p>

<ul>
  <li><strong>CBR (constant bit rate)</strong>, such that video encoding rate is fized</li>
  <li><strong>VBR (variable bit rate)</strong>, video encoding rate changes depending on amount of spatial and temporal compression we have
    <ul>
      <li>i.e. when a scene changes to a new one, compression changes.</li>
      <li>so to preserve high quality, this is the way</li>
    </ul>
  </li>
</ul>

<h3 id="http-streaming-and-dash">HTTP Streaming and DASH</h3>

<p>Now, we know how video is “played”. Here we talked about how to <strong>store and deliver</strong> the video such that it can be played as mentioned before.</p>

<p>Consider for the simple case</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211011142509446.png" alt="image-20211011142509446" style="zoom:50%;" /></p>

<p>the main problem we are facing is therefore:</p>

<ul>
  <li>clients tend to have <strong>variable bandwidth</strong></li>
  <li>clients might have various <strong>packet loss, delay, congestion</strong></li>
</ul>

<p>Then, ==in this model==, we have:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211011143001997.png" alt="image-20211011143001997" style="zoom: 67%;" /></p>

<p>where:</p>

<ul>
  <li>we assumed some CBR</li>
  <li>due to some network delay, video plays at line 3</li>
  <li>at the time of play, we stored (about) 1 second of received video. So essentially we are <em>still receiving data</em> while playing.</li>
</ul>

<blockquote>
  <p><strong>Playback</strong></p>

  <p>Once the number of bytes (for the video) in client’s buffer buffer exceeds a predetermined threshold, the client application begins playback — specifically, <em>starts playing by grabbing images from the buffer.</em></p>
</blockquote>

<p>What happens yet in ==reality== is:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211011143250381.png" alt="image-20211011143250381" style="zoom: 50%;" /></p>

<p>where:</p>

<ul>
  <li>due to the variable network condition, we might need to ==buffer quite some== so that client won’t need to “re-buffer”/pause in the video</li>
  <li>if the ==black curve intersects with blue curve==, we need “re-buffering/pausing” on client side = bad experience</li>
</ul>

<blockquote>
  <p><strong>Need Variable Bit Rate</strong></p>

  <p>Therefore, when <strong>client detects</strong> <em>that the two curves are about to intersect</em>, it will ==lower the bit rate of requested video==, so that it can buffer = make sure smooth client experience.</p>

  <ul>
    <li>client experience include fast forward, rewind, etc.</li>
  </ul>

  <p>To realize this, this is done by DASH.</p>
</blockquote>

<p>Problem with HTTP:</p>

<ul>
  <li>All clients receive the same encoding of the video, despite the large variations in the amount of bandwidth available to a client, both across different clients and also over time for the same client</li>
</ul>

<h4 id="dash---dynamic-adaptative-streaming-over-http">DASH - Dynamic Adaptative Streaming over HTTP</h4>

<p>In DASH, the video is</p>

<ul>
  <li>divided in to multiple chunks</li>
  <li>each chunk is encoded into several different versions, with each version having a different bit rate</li>
</ul>

<p>Therefore, the idea is that:</p>

<p><strong>Server</strong></p>

<ul>
  <li>holds all those different chunks + versions</li>
  <li>holds a <code class="language-plaintext highlighter-rouge">manifest</code> file, with a mapping of <code class="language-plaintext highlighter-rouge">url</code> for each different chunk</li>
  <li>all those chunks=files are then replicated in CDN nodes</li>
</ul>

<p><strong>Client</strong></p>

<ol>
  <li>request the <code class="language-plaintext highlighter-rouge">manifest</code> file
    <ul>
      <li>note that this file is the same for all users for the same resource</li>
    </ul>
  </li>
  <li>periodically estimate the bandwidth</li>
  <li>decide to request for <em>which chunk of video</em> depending on observer bandwidth, and consults the <code class="language-plaintext highlighter-rouge">manifest</code> for actual request
    <ul>
      <li>so we can have different bit rates over time if needed</li>
      <li>so ==all the intelligence is at client==, decides <strong>when</strong> to request, <strong>what</strong> bit rate to request, and <strong>where</strong> to request (<code class="language-plaintext highlighter-rouge">manifest</code> + closest CDN node)</li>
    </ul>
  </li>
  <li>use the <code class="language-plaintext highlighter-rouge">url</code>  on the <code class="language-plaintext highlighter-rouge">manifest</code> and get the chunk from a CDN node
    <ul>
      <li>recall that <strong>DNS server</strong> is the one that decides which CDN node your data will be from, by look at the <code class="language-plaintext highlighter-rouge">source ip</code>.</li>
    </ul>
  </li>
</ol>

<blockquote>
  <p><strong>Note</strong>: when actually sending each chunk, it is done by HTTP <code class="language-plaintext highlighter-rouge">GET </code>request messages.</p>
</blockquote>

<h3 id="cdn---content-distribution-networks">CDN - Content Distribution Networks</h3>

<p>Now, the idea is that we prefer having receiving file from <strong>geographically close sites</strong>.</p>

<p>CDNs typically adopt one of two different server placement philosophies:</p>

<ul>
  <li><strong>Enter Deep</strong>. One philosophy, pioneered by Akamai, is to enter deep into the access networks of Internet Service Providers, by deploying server clusters in access ISPs all over the world
    <ul>
      <li>so we get really close to end users, which means there are clusters in <strong>thousands</strong> of locations</li>
      <li>smaller storage size</li>
    </ul>
  </li>
  <li><strong>Bring Home.</strong> A second design philosophy, taken by Limelight and many other CDN companies, is to bring the ISPs home by building large clusters at a smaller number (10s)
    <ul>
      <li>lower maintenance and management overhead, but a bit larger delay</li>
      <li>larger storage size</li>
    </ul>
  </li>
</ul>

<p>Then, once its clusters are <em>physically</em> in place, the CDN replicates content across its clusters.</p>

<blockquote>
  <p><strong>Pulling Contents</strong></p>

  <ul>
    <li>The CDN may not want to place a copy of <em>every</em> video in each cluster, since some videos are rarely viewed or are only popular in some countries. In fact, many CDNs do not push videos to their clusters but instead use a simple <strong>pull</strong> strategy: if request file is not stored in the CDN node, it will retrieve it and store the copy.</li>
    <li>When cluster’s storage is <strong>full</strong>, it removes the least frequently requested video</li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Note</strong>:</p>

  <ul>
    <li>Above are <strong>third-party CDNs</strong>, which distribute contents for other content providers.</li>
    <li>There is also <strong>private CDN</strong>, that is, owned by the content provider itself; for example, Google’s CDN distributes YouTube videos and other types of content.</li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Load Balancing with DNS</strong></p>

  <p>The trick to load balance between CDN nodes is that:</p>

  <ol>
    <li>each <code class="language-plaintext highlighter-rouge">url</code> to <code class="language-plaintext highlighter-rouge">ip</code> translation is essentially done by a DNS server. So we can store a <strong>short <code class="language-plaintext highlighter-rouge">expiration</code></strong> time such that it will frequently go to the authoritative DNS server</li>
    <li>then <strong>authoritative DNS server</strong> can then tell you which CDN <em>cluster</em> to use for load balancing purposes.
      <ul>
        <li>then even inside the CDN cluster, you could have some load balancing for which CDN node to use</li>
      </ul>
    </li>
  </ol>
</blockquote>

<h4 id="cdn-operation">CDN Operation</h4>

<p>Here we demonstrate how DNS + CDN cluster works.</p>

<p>Suppose that you wanted to watch the film Transformers 7, which on <code class="language-plaintext highlighter-rouge">NetCinema.com</code> has the <code class="language-plaintext highlighter-rouge">url</code> of http://video.netcinema.com/6Y7B23V. Then, the following would happen:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211011151705329.png" alt="image-20211011151705329" style="zoom: 67%;" /></p>

<ol>
  <li>The user visited the Web page at  <code class="language-plaintext highlighter-rouge">netcinema.com</code> and got http://video.netcinema.com/6Y7B23V</li>
  <li>The user clicked http://video.netcinema.com/6Y7B23V to watch the film, which then sends a DNS query for <code class="language-plaintext highlighter-rouge">video.netcinema.com</code></li>
  <li>First it goes to the Local DNS server (LDNS), which then handles the query to the authoritative DNS of NetCinema
    <ul>
      <li>now, instead of returning an IP address, the NetCinema authoritative DNS server <strong>returns to the LDNS a hostname in the KingCDN’s domain</strong>: <code class="language-plaintext highlighter-rouge">a1105.kingcdn.com</code></li>
    </ul>
  </li>
  <li>Then, the DNS query enters into <strong>KingCDN’s private DNS infrastructure</strong>. Now, for <code class="language-plaintext highlighter-rouge">a1105.kingcdn.com</code>.
    <ul>
      <li>here, it can decide which CDN node to use.</li>
    </ul>
  </li>
  <li>KingCDN’s DNS system eventually returns the <strong>IP addresses of a KingCDN content server node</strong> to the LDNS, and LDNS forwards the IP address of the content-serving CDN node to the user’s host</li>
  <li>The users received an <code class="language-plaintext highlighter-rouge">ip</code> from the KingCDN node, and will <strong>establish the TCP connection there</strong> and request for the data.
    <ul>
      <li>here, if DASH is used, the server will first respond with a <code class="language-plaintext highlighter-rouge">manifest</code> and etc.</li>
    </ul>
  </li>
</ol>

<h2 id="peer-to-peer-file-distribution">Peer-to-Peer File Distribution</h2>

<p>The applications described in this chapter thus far—including the Web, e-mail, and DNS—all employ client-server architectures with significant reliance on always-on infrastructure servers.</p>

<p>There is <strong>minimal (or no) reliance on always-on infrastructure servers</strong>. Instead, pairs of intermittently connected ==hosts==, called peers, ==communicate directly== with each other.</p>

<ul>
  <li>e.g. file distribution (BitTorrent): each torrent address will be a “directory” to the specific peer-to-peer network
    <ul>
      <li>you can download any part of the file first (e.g. the last part might comes first)</li>
    </ul>
  </li>
  <li>e.g. Streaming (KanKan): we need to download from the first part</li>
  <li>e.g. VoIP (Skype, originally)</li>
</ul>

<p>Basically the advantage is that your P2P will be <em>self-scaling</em> since each host is also an uploader/server</p>

<h3 id="scalability-of-p2p-architecture">Scalability of P2P Architecture</h3>

<p>We want to compare the ideal performance of <strong>client-server</strong> and <strong>p2p</strong>.</p>

<p>Consider the case when we need to <strong>deliver a large file to a larger number of hosts</strong>. You will see that:</p>

<ul>
  <li>In client-server file distribution, the ==server== must send ==a copy of the file to each of the peers==</li>
  <li>In p2p, each ==peer== can ==redistribute any portion of the file it has received== to any other peers.</li>
</ul>

<p>Let there be $F$ bits of a file to be send, and there are $N$ users. Let the upload speed be $u$, and download speed be $d$. We want to compare the ==distribution time== - the time it takes to get a copy of the file to all N peers:</p>

<ul>
  <li>(assumption that the Internet core has abundant bandwidth, implying that all of the bottlenecks are in access networks)</li>
</ul>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211013085615885.png" alt="image-20211013085615885" style="zoom: 50%;" /></p>

<p>Then, we can compute that</p>

<ul>
  <li>
    <p>Distribution time for <strong>client-server model</strong> $D_{cs}$:</p>

    <p>==The idea is that we either have server uploading the file into the client or client downloading from server.==</p>

    <ul>
      <li>
        <p>The server must transmit one copy of the file to each of the $N$ peers. Thus, the server must transmit $NF$ bits. Since the server’s upload rate is $u_s$, the <strong>time to distribute the file</strong> must be at least $NF/u_s$.</p>
      </li>
      <li>
        <p>the slowest client will have $d_{min}=\min{d_1,…,d_N}$. So if everyone downloads, we have $F/d_{min}$</p>
      </li>
    </ul>

    <p>so distribution time is:</p>
  </li>
</ul>

\[D_{cs} \ge \max \left\{  \frac{NF}{u_s}, \frac{F}{d_{min}} \right\}\]

<p>notice that $NF/u_s$ increases with $N$ linearly</p>

<ul>
  <li>
    <p>Distribution time for <strong>P2P</strong>.</p>

    <p>The main difference is that when a peer receives some file data, it can use its <em>own upload capacity to redistribute</em> the data to other peers. Therefore:</p>

    <ul>
      <li>If only server has the file, and we assume that each client <strong>starts redistributing immediately</strong> when they get a bit, then the minimum distribution time is at least $F/u_s$</li>
      <li>The worst case for downloading is that all bits goes to the same host with $d_{min}$. Then in that case, we have $F/d_{min}$.</li>
      <li>The last case is when each host has some share of the file, then to make sure <strong>everyone</strong> has all $F$ bits, we need to have uploaded $NF$ bits (to each other) with no faster than $u_{\text{total}} =u_s + \sum u_i$. Therefore, in this case, the distribution time is $NF/(u_s + \sum u_i)$.</li>
    </ul>

    <p>so performance is:</p>

\[D_{P2P} \ge \max \left\{  \frac{F}{u_s}, \frac{F}{d_{min}},\frac{NF}{u_s + \sum u_i}\right\}\]
  </li>
</ul>

<p>notice that the term $NF/(u_s + \sum u_i)$ means increasing $N$ increases both $NF$ and $\sum u_i$. So eventually, this term <strong>flattens out</strong> even when $N$ is large.</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211013090824850.png" alt="image-20211013090824850" style="zoom:67%;" /></p>

<h3 id="p2p-file-distribution">P2P File Distribution</h3>

<p>In reality, we would first divide the file into <strong>256Kb chunk</strong>, and each host will own some of the chunks.</p>

<ul>
  <li>$NF/(u_s + \sum u_i)$ in the P2P means we want the peer to become a server as soon as possible</li>
  <li>if you waited for the entire file to be a server, that will take quite a long time/wasted</li>
</ul>

<blockquote>
  <p><strong>Tracker</strong></p>

  <ul>
    <li>Each torrent has an infrastructure node called a tracker. When a peer joins a torrent, it registers itself with the tracker and periodically <strong>informs the tracker that it is still in the torrent</strong>.</li>
    <li>Therefore, the tracker keeps track of the peers that are participating in the torrent.</li>
  </ul>
</blockquote>

<p>Then, how P2P works is:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211013091214206.png" alt="image-20211013091214206" style="zoom: 67%;" /></p>

<p>where basically when Alice clicked the magnet link:</p>

<ol>
  <li>
    <p>obtains a list of peers from tracker, and ask the peers for a list of chunks of the file they have</p>

    <ul>
      <li>basically gives you the IP of the peers, then each peer gives you a list of what they have</li>
      <li>let there be $L$ neighbors. Then you get $L$ lists of chunks</li>
    </ul>
  </li>
  <li>
    <p>register <strong>yourself</strong> to tracker</p>
  </li>
  <li>
    <p>requests missing chunks from peers, ==rarest first==. (the chunks that are the ==rarest/fewest copies among her neighbors==)</p>

    <ul>
      <li>
        <p>compute from the $L$ list of chunks which one is the rarest</p>
      </li>
      <li>
        <p>the rarest first is the key, with the aim of maintaining high availability</p>
      </li>
    </ul>
  </li>
  <li>
    <p>==while== gathering chunks, Alice also <strong>sends chunks</strong> to some of other peers (==algorithm deciding who to send: Tit-for-Tat==)</p>

    <ul>
      <li><strong>unchoked</strong> peers - send to four peers who are sending Alice the data at the highest rate (reevaluate top 4 every 10 secs)</li>
      <li><strong>optimistically unchoked</strong> - in addition, randomly select a new peer and send chunks every 30 seconds (this randomly selected peer MAY become the top 4 later - optimistic)</li>
      <li><strong>chocked</strong> - all peers beside the above 5 are not sent data to.</li>
    </ul>

    <p>The upshot is that, the in total 5 peers you are sending to would be:</p>

    <ul>
      <li>peers capable of uploading at compatible rates tend to find each other</li>
      <li>random neighbor selection also allows new peers to get chunks, so that they can have something to trade</li>
    </ul>
  </li>
  <li>
    <p>When Alice is done, she will leave and no longer in the network anymore</p>
  </li>
</ol>

<h1 id="chapter-3-transport-layer">Chapter 3 Transport Layer</h1>

<p>Principles behind transport layer services:</p>

<ul>
  <li>multiplexing, demultiplexing</li>
  <li>reliable data transfer</li>
  <li>flow control</li>
  <li>congestion control</li>
</ul>

<p>Technically, reliability/flow control/congestion can also be implemented at <strong>other layers</strong> (e.g. Application, WIFI itself might cater to that by implementing in app layer), so the concept is more important in this case.</p>

<ul>
  <li>so the idea is that those concepts <strong>goes beyond the transport layer</strong></li>
</ul>

<p>Commonly, there are two protocols:</p>

<ul>
  <li>TCP, UDP</li>
</ul>

<h2 id="transport-services-and-protocol">Transport Services and Protocol</h2>

<p>A transport-layer protocol provide <strong>logical communication channel</strong> (a socket) between application</p>

<ul>
  <li>the physical one could include many links in a path</li>
</ul>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211013173039437.png" alt="image-20211013173039437" style="zoom: 67%;" /></p>

<p>where notice that:</p>

<ul>
  <li>transport-layer protocols are ==implemented in the end systems== but not in network routers. Makes sense since their job is to cater to application.</li>
</ul>

<p><strong>Sender in Network Layer</strong></p>

<ul>
  <li>breaks application messages into segments (i.e. packets), add transport-layer headers, and passes to <em>network</em> layer</li>
  <li>the <em>network</em> later will then have the segment encapsulated within a network-layer packet (a datagram) and sent to the destination
    <ul>
      <li>in the end network routers act only on the network-layer fields of the datagram</li>
    </ul>
  </li>
</ul>

<p><strong>Receiver in Network Layer</strong></p>

<ul>
  <li>
    <p>from below, the network layer extracts the transport-layer segment from the datagram and passes the segment up to the <em>transport</em> layer.</p>
  </li>
  <li>
    <p>the <em>transport</em> layer then processes/reassembles the segments into messages, passes to application layer</p>
  </li>
</ul>

<hr />

<p><em>Household Analogy</em></p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211013094508750.png" alt="image-20211013094508750" style="zoom:67%;" /></p>

<p>So the idea is that</p>

<ul>
  <li>network layer: logical communication between <em>hosts</em> (get into the right house)</li>
  <li>transport layer<em>:</em> logical communication between <em>processes</em> (when in the correct house, get to the right kid)
    <ul>
      <li>also note that the work of being in the house + give to the right kid means <strong>transport layer is not in the network core</strong></li>
    </ul>
  </li>
</ul>

<h2 id="multiplexing-and-demultiplexing">Multiplexing and Demultiplexing</h2>

<p>The idea is to extending the host-to-host delivery service provided by the <em>network layer</em> to a <strong>process-to-process delivery service for applications</strong> running on the hosts (which is what we need to do in transport layer)</p>

<ul>
  <li>for this purpose, each transport-layer segment has ==a set of fields== in the segment</li>
</ul>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211013194333151.png" alt="image-20211013194333151" style="zoom: 80%;" /></p>

<blockquote>
  <p><strong>Demultiplexing</strong></p>

  <p>At the ==receiving end==, the transport layer examines these fields to</p>

  <ol>
    <li>identify the receiving socket</li>
    <li>then <strong>directs</strong> the segment to that socket.</li>
  </ol>

  <p>This job of delivering the data in a transport-layer segment to the correct socket is called demultiplexing</p>
</blockquote>

<blockquote>
  <p><strong>Multiplexing</strong></p>

  <p>Then obviously this does the opposite, at the ==sending end==:</p>

  <ol>
    <li>Gathering data chunks at the source host <strong>from different sockets</strong></li>
    <li>encapsulating each data chunk with header information (that will later be used in demultiplexing) to create segments</li>
    <li>finally passing the segments to the network layer</li>
  </ol>
</blockquote>

<p>Note that:</p>

<ul>
  <li>It’s important to realize that they are concerns whenever <strong>a single protocol at one layer</strong> (at the transport layer or elsewhere) is used by <strong>multiple protocols at the next higher layer</strong></li>
</ul>

<p>From the discussion above, we know that transport-layer multiplexing requires</p>

<ol>
  <li>that ==sockets have unique identifiers==</li>
  <li>that each <strong>segment</strong> have special fields that <strong>indicate the socket</strong> to which the segment is to be delivered</li>
</ol>

<p>This is done by <strong>source port number</strong> and <strong>destination port number</strong>.</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211013194631888.png" alt="image-20211013194631888" style="zoom: 80%;" /></p>

<p>Then ==each socket in the host could be assigned a port number==, and when a segment arrives at the host, the transport layer examines the destination port number in the segment and directs the segment to the corresponding socket.</p>

<ul>
  <li>this is basically how UDP does it. What TCP does it is slightly different.</li>
</ul>

<h3 id="udp-demultiplexing">UDP (De)Multiplexing</h3>

<p>Recall that we had in programming:</p>

<p><strong>Host</strong>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">serverPort</span> <span class="o">=</span> <span class="mi">19157</span>
<span class="c1"># create socket
</span><span class="n">serverSocket</span> <span class="o">=</span> <span class="n">socket</span><span class="p">(</span><span class="n">AF_INET</span><span class="p">,</span> <span class="n">SOCK_DGRAM</span><span class="p">)</span>
<span class="n">serverSocket</span><span class="p">.</span><span class="n">bind</span><span class="p">((</span><span class="s">''</span><span class="p">,</span> <span class="n">serverPort</span><span class="p">))</span>
<span class="c1"># etc
</span></code></pre></div></div>

<p><strong>Client</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">serverPort</span> <span class="o">=</span> <span class="mi">19157</span>
<span class="c1"># creates socket
</span><span class="n">clientSocket</span> <span class="o">=</span> <span class="n">socket</span><span class="p">(</span><span class="n">AF_INET</span><span class="p">,</span> <span class="n">SOCK_DGRAM</span><span class="p">)</span> <span class="c1"># assigns a random port for client, e.g. 46428
</span><span class="n">message</span> <span class="o">=</span> <span class="s">"some message"</span>
<span class="n">clientSocket</span><span class="p">.</span><span class="n">sendto</span><span class="p">(</span><span class="n">message</span><span class="p">.</span><span class="n">encode</span><span class="p">(),</span> <span class="p">(</span><span class="s">'localhost'</span><span class="p">,</span> <span class="n">serverPort</span><span class="p">))</span> <span class="c1"># sends to a queue
</span></code></pre></div></div>

<p>Suppose a process in Host A, with UDP port <code class="language-plaintext highlighter-rouge">19157</code>, wants to <strong>send</strong> a chunk of application data to a process with UDP port <code class="language-plaintext highlighter-rouge">46428</code> in
Host B. Then</p>

<ol>
  <li>The <strong>transport layer</strong> in Host A creates a transport-layer segment that includes the application data, <strong>the source port number (<code class="language-plaintext highlighter-rouge">19157</code>), the destination port number (<code class="language-plaintext highlighter-rouge">46428</code>)</strong>, and two other values (discussed later)
    <ul>
      <li>the source port will be used by the UDP on the client to reply (in a new connection)</li>
    </ul>
  </li>
  <li>transport layer then passes the resulting segment to the network layer.</li>
  <li>The <strong>network layer</strong> encapsulates the segment in an IP datagram and makes a best-effort attempt to deliver the segment to the receiving host</li>
  <li>If the segment arrives at the receiving Host B, the <strong>transport layer</strong> at the receiving host <strong>examines the destination port number</strong> in the segment (<code class="language-plaintext highlighter-rouge">46428</code>) and <strong>delivers the segment</strong> to its socket identified by port <code class="language-plaintext highlighter-rouge">46428</code>.</li>
</ol>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211013200348313.png" alt="image-20211013200348313" style="zoom: 80%;" /></p>

<blockquote>
  <p><strong>To distinguish with Socket to Send</strong></p>

  <ul>
    <li>
      <p>UDP socket is ==fully identified by a two-tuple== consisting of</p>

\[(\text{destination IP}, \text{destination Port})\]

      <ul>
        <li>because we ==cannot send replies directly without starting a new connection!==</li>
      </ul>
    </li>
    <li>
      <p>if two UDP segments have different source IP addresses and/or source port numbers, but have the <strong>same destination IP address and destination port number</strong>, then the two segments will be <strong>directed to the same destination process</strong> via the same destination socket</p>
    </li>
  </ul>
</blockquote>

<p>Note:</p>

<ul>
  <li>though we only needed two tuples, all four including the IP addresses are there, it is just not used.</li>
</ul>

<h3 id="tcp-demultiplexing">TCP (De)Multiplexing</h3>

<p>Up on front, we show the difference</p>

<blockquote>
  <p><strong>To distinguish with Socket to Send</strong></p>

  <ul>
    <li>
      <p>TCP socket is ==fully identified by a four-tuple== consisting of</p>

\[(\text{source IP}, \text{source Port}, \text{destination IP}, \text{destination Port})\]

      <ul>
        <li>because ==each client has its own persistent socket!==</li>
        <li>the host uses all four values to direct (demultiplex)</li>
      </ul>
    </li>
    <li>
      <p>if two TCP segments have <strong>different source IP addresses and/or source port numbers</strong>, but have the same destination IP address and destination port number, then the two segments will be <strong>directed to the DIFFERENT destination process</strong>.</p>

      <ul>
        <li>with the exception of a TCP segment carrying the original connection-establishment request (i.e. when we first called the <code class="language-plaintext highlighter-rouge">server_socket.accept()</code>, multiple segments of different source goes into the same server port)</li>
      </ul>
    </li>
  </ul>
</blockquote>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211013200727856.png" alt="image-20211013200727856" style="zoom:80%;" /></p>

<ol>
  <li>
    <p>The TCP <strong>server</strong> application has a “welcoming socket,” that <strong>waits/listens</strong> for connection establishment requests from TCP clients (see Figure 2.29) on port number <code class="language-plaintext highlighter-rouge">12000</code></p>
  </li>
  <li>
    <p>The TCP <strong>client</strong> creates a socket and sends a connection establishment request segment</p>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">clientSocket</span> <span class="o">=</span> <span class="n">socket</span><span class="p">(</span><span class="n">AF_INET</span><span class="p">,</span> <span class="n">SOCK_STREAM</span><span class="p">)</span> <span class="c1"># some random port number assigned
</span><span class="n">clientSocket</span><span class="p">.</span><span class="n">connect</span><span class="p">((</span><span class="n">serverName</span><span class="p">,</span><span class="mi">12000</span><span class="p">)</span>
</code></pre></div>    </div>

    <ul>
      <li>A connection-establishment request is just a TCP segment with destination port number <code class="language-plaintext highlighter-rouge">12000 </code>+  source port number + a special connection-establishment bit set in the TCP header.</li>
    </ul>
  </li>
  <li>
    <p>The TCP <strong>server</strong> accept a connection on port number The server process then creates a new socket</p>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">connectionSocket</span><span class="p">,</span> <span class="n">addr</span> <span class="o">=</span> <span class="n">serverSocket</span><span class="p">.</span><span class="n">accept</span><span class="p">()</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p>The ==transport layer== at the TCP <strong>server</strong> notes the following four values in the connection-request segment:</p>

    <ol>
      <li><strong>source port number</strong> in the (connection-request) segment</li>
      <li>the **IP address of the source host **in the (connection-request) segment</li>
      <li>the new forked destination port number (<code class="language-plaintext highlighter-rouge">addr</code>)</li>
      <li>its own IP address.</li>
    </ol>

    <p>The newly created connection socket is identified by these four values.</p>
  </li>
</ol>

<h2 id="user-datagram-protocol">User Datagram Protocol</h2>

<p>A no-frills, bare-bones transport protocol. Aside from the multiplexing/demultiplexing function and some light error checking, it adds nothing to IP protocol.</p>

<p>UDP usages:</p>

<ul>
  <li>
    <p>streaming multimedia apps (loss tolerant, rate sensitive)</p>
  </li>
  <li>
    <p>DNS</p>
  </li>
  <li>
    <p>SNMP</p>
  </li>
  <li>
    <p>HTTP/3</p>
  </li>
</ul>

<p>if reliable transfer needed over UDP (e.g., HTTP/3):</p>

<ul>
  <li>
    <p>add needed reliability at application layer</p>
  </li>
  <li>
    <p>add congestion control at application layer</p>
  </li>
</ul>

<blockquote>
  <p><strong>Short Summary</strong></p>

  <p>In fact, if the application developer chooses UDP instead of TCP, then the application is almost directly talking with IP.</p>

  <p>UDP takes messages from the application process, <strong>attaches source and destination port number fields for the multiplexing/demultiplexing service</strong>, adds two other small fields, and passes the resulting segment to the network layer.</p>
</blockquote>

<h3 id="udp-action">UDP Action</h3>

<ol>
  <li>is passed an application-layer message to transport layer</li>
  <li><strong>transport layer uses UDP, so add a small fields of ports, length and checksum. This becomes a UDP segment now.</strong></li>
  <li>network layer encapsulates the transport-layer segment into an IP datagram and then makes a best-effort attempt to deliver the segment to the receiving host</li>
</ol>

<p>On the receiver side:</p>

<ol>
  <li>
    <p>network layer received an IP segment, extracts the UDP segment and pass it up to transport layer</p>
  </li>
  <li>
    <p><strong>transport layer, with UDP, which now has a UDP segment:</strong></p>

    <ul>
      <li>checks UDP checksum</li>
      <li>extract application message</li>
      <li>
        <p>uses the destination port number to deliver the segment’s data to the correct application process</p>
      </li>
      <li>pass it to application layer</li>
    </ul>
  </li>
  <li>
    <p>application layer receives the application message.</p>
  </li>
</ol>

<blockquote>
  <p><strong>Advantages of UDP</strong></p>

  <ol>
    <li>Finer application-level control over what data is sent, and when.
      <ul>
        <li>As compare to TCP, which might throttle your message with its congestion control protocol.</li>
      </ul>
    </li>
    <li>No connection establishment.
      <ul>
        <li>As we’ll discuss later, TCP uses a three-way handshake before it starts to transfer data</li>
      </ul>
    </li>
    <li>No connection state.
      <ul>
        <li>since once you sent the packet, you are done. There is no connection.</li>
      </ul>
    </li>
    <li>Small packet header overhead.</li>
  </ol>
</blockquote>

<h3 id="udp-segment-structure">UDP Segment Structure</h3>

<p>Therefore, following from the above discussion, the content looks like</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211018091229396.png" alt="image-20211018091229396" style="zoom:50%;" /></p>

<p>where:</p>

<ul>
  <li>the source IP and destination IP will then be in the <strong>IP protocol packet</strong></li>
  <li>the port numbers
allow the destination host to pass the application data to the correct process running
on the destination end system</li>
</ul>

<h3 id="udp-checksum">UDP Checksum</h3>

<blockquote>
  <p><strong>Goal</strong>: detect errors (i.e. flipped bits) in transmitted segment, by ==computing 1s complement== of the sum of all the 16-bit words in the segment</p>
</blockquote>

<p>Basically, the sender will:</p>

<ul>
  <li>send the data (in payload)</li>
  <li>send the checksum of the data</li>
</ul>

<p>The receiver will:</p>

<ul>
  <li>receive the data, <strong>compute the checksum from it</strong></li>
  <li>compare with the received checksum</li>
</ul>

<p>Although UDP provides error checking, it does ==not do anything to recover from an error==.</p>

<ul>
  <li>Some implementations of UDP simply discard the damaged segment;</li>
  <li>others pass the damaged segment to the application with a warning. (so that application layer can implement recovery/request for retransmission)</li>
</ul>

<blockquote>
  <p><strong>Disadvantage</strong></p>

  <ul>
    <li>Since if one bit of the data is flipped, the entire packet needs to be retransmitted. This means that the application needs to then <strong>request again <code class="language-plaintext highlighter-rouge">-&gt;</code></strong> costs times and round trips.</li>
  </ul>
</blockquote>

<hr />

<p><em>For Example:</em></p>

<p>Data is two lines of 16 bit numbers:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211018092111159.png" alt="image-20211018092111159" style="zoom:67%;" /></p>

<p>so technically there are errors that a checksum won’t detect. But the chances of that happening is low.</p>

<ul>
  <li>
    <p>then, to check the checksum, it takes ==1’s complement of the sum of the data (including) checksum==. If all correct, it should be all 0s.</p>

    <pre><code class="language-pseudocode">			   10101001
               00111001
               00011101 // checksum
               --------
   Sum         11111111
   Complement  00000000  means that the pattern is O.K.
</code></pre>

    <p>where notice that you sum the checksum as well.</p>
  </li>
</ul>

<h3 id="udp-summary">UDP Summary</h3>

<p>“no frills” protocol:</p>

<ul>
  <li>segments may be lost, delivered out of order</li>
  <li>best effort service: “send and hope for the best”</li>
</ul>

<p>UDP has its plusses:</p>

<ul>
  <li>no setup/handshaking needed (no RTT incurred)</li>
  <li>can function when network service is compromised</li>
  <li>helps with reliability (checksum)</li>
</ul>

<p>build additional functionality on top of UDP in application layer (e.g., HTTP/3)</p>

<h2 id="principle-of-reliable-data-transfer">Principle of Reliable Data Transfer</h2>

<p>Problem of implementing reliable data transfer occurs not only at the transport layer, but also at the link layer and the application layer
as well. So here it is an <strong>abstraction of how to ensure reliability</strong> on a high level.</p>

<p>The idea of having this (before introducing TCP) is</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211018143856980.png" alt="image-20211018143856980" /></p>

<p>In the above figure:</p>

<ul>
  <li>reliability happens to be implemented on Transport Layer, and any layer below the Transport Layer may be unreliable</li>
  <li>the sending side/==application calls <code class="language-plaintext highlighter-rouge">rdt_send()</code>==. It will pass the data to be delivered to the upper layer at the receiving side. (<code class="language-plaintext highlighter-rouge">rdt</code> for reliable data transfer)</li>
  <li>On the receiving side, <code class="language-plaintext highlighter-rouge">rdt_rcv()</code> will be called when a packet arrives from the receiving side of the channel.</li>
  <li>When the <code class="language-plaintext highlighter-rouge">rdt</code> protocol wants to <strong>deliver data to the upper layer</strong>, it will do so by calling <code class="language-plaintext highlighter-rouge">deliver_data()</code>, i.e. ==called by the <code class="language-plaintext highlighter-rouge">rdt</code> protocol implementation==</li>
  <li>so basically you need to implement whatever is between <code class="language-plaintext highlighter-rouge">rdt_send()</code> and <code class="language-plaintext highlighter-rouge">udt_send()</code>; <code class="language-plaintext highlighter-rouge">deliver_data()</code> and <code class="language-plaintext highlighter-rouge">rdt_rcv()</code></li>
</ul>

<blockquote>
  <p><strong>Note</strong></p>

  <ul>
    <li>TCP basically makes it <em>look like</em> being reliable above the network layer (below it is it unreliable)</li>
    <li>UDP does nothing, so it is hence no better than network layer unreliability</li>
  </ul>
</blockquote>

<p>In particular, note that the possibility of being <strong>unreliable at network layer</strong> would be, in descending order of complexity:</p>

<ol>
  <li>packet being lost (no idea if it is sent in the beginning)</li>
  <li>packet having corrupted data</li>
  <li>packet out of order</li>
</ol>

<p>To ensure reliability through them. the idea is to <strong>exchange message about the state of each other</strong>.</p>

<h3 id="building-a-reliable-data-transfer-protocol">Building a Reliable Data Transfer Protocol</h3>

<p><strong>FSM</strong>: Finite State Machine. We will use this to illustrate how to deal with each case of error mentioned above.</p>

<ul>
  <li>The initial state of the FSM is indicated by the dashed arrow.</li>
  <li>The ==event causing the transition is shown above the horizontal line== labeling the transition, and the actions taken when the event occurs are shown below the horizontal line</li>
</ul>

<h4 id="simplest-case-rdt10">Simplest Case: RDT1.0</h4>

<p>simplest case, in which the <strong>underlying channel is completely reliable.</strong></p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211018094626700.png" alt="image-20211018094626700" style="zoom:80%;" /></p>

<p>where:</p>

<ul>
  <li>there are separate FSMs for the sender and for the receiver</li>
</ul>

<p><strong>Sender</strong></p>

<ol>
  <li>sending side of simply accepts data from the upper layer via the <code class="language-plaintext highlighter-rouge">rdt_send()</code> event (e.g. ==application== called it). Then, it does:
    <ul>
      <li>creates a packet containing the data <code class="language-plaintext highlighter-rouge">packet=make_pkt(data)</code></li>
      <li>sends the packet into the channel <code class="language-plaintext highlighter-rouge">udt_send(packet)</code></li>
    </ul>
  </li>
</ol>

<p><strong>Receiver</strong></p>

<ol>
  <li><code class="language-plaintext highlighter-rouge">rdt</code> receives a packet from the underlying channel via the <code class="language-plaintext highlighter-rouge">rdt_rcv(packet)</code> event (e.g. ==network layer== called it) then:
    <ul>
      <li>removes the data from the packet (via the action <code class="language-plaintext highlighter-rouge">extract(packet, data)</code>)</li>
      <li>passes the data up to the upper layer (via the action <code class="language-plaintext highlighter-rouge">deliver_data(data)</code>).</li>
    </ul>
  </li>
</ol>

<blockquote>
  <p>This is simple because a perfectly reliable channel means: there is <strong>no need for the receiver side to provide any feedback</strong> to the sender since nothing can go wrong</p>
</blockquote>

<h4 id="bit-error-rdt20">Bit Error: RDT2.0</h4>

<p>When there are some <strong>bit errors</strong> (e.g. checksum didn’t match)</p>

<ul>
  <li>Such bit errors typically occur in the physical components of a network as a packet is transmitted, propagates, or is buffered.</li>
  <li>We’ll continue to assume for the moment that all transmitted packets are received (although their bits may be corrupted) in the order in which they were sent.</li>
</ul>

<p>Then, to recover, you <em>tell the sender of a Negative Acknowledgement (NACK)</em> (i.e. not understood/received)</p>

<blockquote>
  <p><strong>Acknowledgements (ACKs)</strong>: receiver explicitly tells sender that pkt received OK</p>

  <p><strong>Negative Acknowledgements (NAKs)</strong>: receiver explicitly tells sender that pkt had errors</p>
</blockquote>

<p>Therefore, if sender receives a NAK, then it will <em>retransmit</em> the packet.</p>

<ul>
  <li>==stop of wait==: sender sends one packet, then <strong>waits UNTIL received a response</strong> from the receiver</li>
  <li>In a computer network setting, reliable data transfer protocols based on such retransmission are known as <strong>ARQ (Automatic Repeat reQuest) protocols</strong>.</li>
</ul>

<p>The <strong>sender</strong> side FSM looks like:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211018145854632.png" alt="image-20211018145854632" /></p>

<p>where there are two states: waiting for data to be passed down from the upper layer; waiting for <code class="language-plaintext highlighter-rouge">ACK</code> or <code class="language-plaintext highlighter-rouge">NAK</code></p>

<ol>
  <li>when <code class="language-plaintext highlighter-rouge">rdt_send(data)</code> event occurs:
    <ul>
      <li>the sender will create a packet (<code class="language-plaintext highlighter-rouge">sndpkt</code>) containing the data to be sent, along with ==a packet checksum==</li>
      <li>send the packet via the <code class="language-plaintext highlighter-rouge">udt_send(sndpkt)</code> operation</li>
      <li><strong>transition</strong> to the rightmost state: waiting for an ACK or a NAK packet from the receiver.</li>
    </ul>
  </li>
  <li>when <strong>sender received response and it is <code class="language-plaintext highlighter-rouge">ACK</code></strong>, i.e. <code class="language-plaintext highlighter-rouge">rdt_rcv(rcvpkt) &amp;&amp; isACK(rcvpkt)</code>
    <ul>
      <li>the sender knows that the most recently transmitted packet has been received <em>correctly</em> and thus the protocol returns to the state of waiting for data from the upper layer. Nothing needs to be done $\Lambda$.</li>
    </ul>
  </li>
  <li>If a <code class="language-plaintext highlighter-rouge">NAK</code> is received:
    <ul>
      <li>the protocol <strong>retransmits the last packet and waits</strong> for an ACK or NAK to be returned by the receiver in response to the retransmitted data packet</li>
    </ul>
  </li>
</ol>

<blockquote>
  <p><strong>Blocking</strong></p>

  <ul>
    <li>It is important to note that when the sender is in the wait-for-ACK-or-NAK state, it cannot get more data from the upper layer; that is, the <code class="language-plaintext highlighter-rouge">rdt_send()</code> event ==cannot== occur; that will happen only after the sender receives an ACK and leaves this state.</li>
    <li>therefore, it is called ==stop-and-wait protocols==</li>
  </ul>
</blockquote>

<p>On the <strong>receiver’s side</strong>:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211018145903944.png" alt="image-20211018145903944" /></p>

<p>basically here the idea is simple. There is just one state as you <strong>just need to reply with either an <code class="language-plaintext highlighter-rouge">ACK </code>or a <code class="language-plaintext highlighter-rouge">NAK</code></strong></p>

<ol>
  <li>if the data is not corrupt, send back <code class="language-plaintext highlighter-rouge">ACK</code> and deliver the data to the application layer</li>
  <li>if the data is corrupt, send back <code class="language-plaintext highlighter-rouge">NAK</code> and do <strong>NOT</strong> deliver the data to the application</li>
</ol>

<h4 id="feedback-corrupted-rdt21">Feedback Corrupted: RDT2.1</h4>

<p>Now, there is an ==additional problem==. What if the <code class="language-plaintext highlighter-rouge">ACK/NAK</code> packet is corrupted in RDT2.0.</p>

<p>In specific, we will use the <strong>checksum</strong>, and add an additional field of <strong>sequence number</strong></p>

<ul>
  <li>if <code class="language-plaintext highlighter-rouge">ACK</code> becomes <code class="language-plaintext highlighter-rouge">NAK</code>, then you send a <strong>duplicate message</strong> (which might strew up receiver). In this case, you can:
    <ol>
      <li>sender add a sequence number to each packet</li>
      <li>receiver can now ==look at the sequence number and discard the duplicate==</li>
      <li>receiver sends back <code class="language-plaintext highlighter-rouge">ACK</code> again</li>
    </ol>
  </li>
  <li>if <code class="language-plaintext highlighter-rouge">NAK</code> becomes <code class="language-plaintext highlighter-rouge">ACK</code>, but the checksum is wrong, you still <strong>resend</strong> the packet.
    <ol>
      <li>if something is wrong with the feedback, just resend the packet</li>
      <li>so that you are safe on not missing a packet, until you receive a <strong>correct/uncorrupted <code class="language-plaintext highlighter-rouge">ACK</code></strong></li>
    </ol>
  </li>
</ul>

<p>Therefore, the state transition becomes, for the <strong>sender</strong></p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211020091020783.png" alt="image-20211020091020783" /></p>

<p>where here we just need 2 sequence numbers to disambiguate each packet, sequence number <code class="language-plaintext highlighter-rouge">0</code> or <code class="language-plaintext highlighter-rouge">1</code> (in this case)</p>

<ul>
  <li>if the received packet is corrupt, we just resend the most recent packet for safety</li>
  <li>we transition to the next state $\iff$ feedback is not corrupt ==AND== it is <code class="language-plaintext highlighter-rouge">ACK</code>.</li>
</ul>

<p>The <strong>receiver</strong> now does:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211020091410485.png" alt="image-20211020091410485" /></p>

<p>where notice that, for the receiver to resend a feedback packet, we now have two scenarios:</p>

<ol>
  <li>the packet from sender is corrupt, send <code class="language-plaintext highlighter-rouge">NAK</code></li>
  <li>the feedback I sent is corrupt, so now I get a duplicate. Then try to send <code class="language-plaintext highlighter-rouge">ACK</code> again.
    <ul>
      <li>Since the sender knows that a received <code class="language-plaintext highlighter-rouge">ACK </code>or <code class="language-plaintext highlighter-rouge">NAK </code>packet (whether garbled or not) was generated in response to
its most recently transmitted data packet, <code class="language-plaintext highlighter-rouge">ACK </code>and <code class="language-plaintext highlighter-rouge">NAK</code> packets <strong>do NOT themselves need to indicate the sequence number</strong></li>
    </ul>
  </li>
</ol>

<blockquote>
  <p><strong>Summary</strong></p>

  <p>At <strong>sender</strong>:</p>

  <ul>
    <li>==sequence number== is added (so that receiver can find duplicates)
      <ul>
        <li>a 1-bit sequence number will suffice <em>here</em>, since it will allow the receiver to know whether the sender is resending the <em>previously transmitted packet or a new one</em></li>
      </ul>
    </li>
    <li>must check if received <code class="language-plaintext highlighter-rouge">ACK</code>/<code class="language-plaintext highlighter-rouge">NAK</code> corrupted</li>
    <li>twice as many states
      <ul>
        <li>state must “remember” whether “expected” pkt should have seq # of 0 or 1</li>
      </ul>
    </li>
  </ul>

  <p>At <strong>receiver</strong>:</p>

  <ul>
    <li>must check if received packet is <strong>duplicate</strong>
      <ul>
        <li>state indicates whether 0 or 1 is expected pkt seq #</li>
      </ul>
    </li>
    <li>note: receiver can <em>not</em> know if its last ACK/NAK received OK at sender
      <ul>
        <li>i.e. the only way a receiver knows if an <code class="language-plaintext highlighter-rouge">ACK</code> is received is that a sender gives the <em>next packet</em>. But if you are at the last packet from the sender, there is no next packet.</li>
      </ul>
    </li>
  </ul>
</blockquote>

<h4 id="nak-free-rdt22">NAK-Free: RDT2.2</h4>

<p>There is another way to deal with corrupted data, which is (actually closer to how TCP gets implemented):  ==receiver sends <code class="language-plaintext highlighter-rouge">ACK</code> for last correct pkt received==.</p>

<ul>
  <li>
    <p>A sender that receives two ACKs for the same packet (that is, receives duplicate ACKs) knows that the receiver did not correctly receive the packet <em>following the packet that is being ACKed twice</em></p>
  </li>
  <li>
    <p>i.e. duplicate <code class="language-plaintext highlighter-rouge">ACK</code> at <strong>sender</strong> results in same action as <code class="language-plaintext highlighter-rouge">NAK</code>: <em>retransmit current pkt</em></p>
  </li>
</ul>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211020141802140.png" alt="" /></p>

<p>where the only difference with RDT2.1 is that:</p>

<ul>
  <li>receiver added a <code class="language-plaintext highlighter-rouge">SEQ</code> to the <code class="language-plaintext highlighter-rouge">ACK</code> packet. So now the check is on if the <em>latest correct <code class="language-plaintext highlighter-rouge">ACK SEQ</code> is up to date</em>. If not, for example the bottom left, then it means a <code class="language-plaintext highlighter-rouge">NAK</code>.</li>
  <li>note that again, we are assuming no packet loss can happen yet, so it is only about packet corruption.</li>
</ul>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211020142139843.png" alt="image-20211020142139843" /></p>

<p>where:</p>

<ul>
  <li>receiver must now include the ==sequence number of the packet being acknowledged== by an ACK message (this is done by including the <code class="language-plaintext highlighter-rouge">ACK, 0</code> or <code class="language-plaintext highlighter-rouge">ACK, 1</code>)</li>
</ul>

<h4 id="error-and-loss-rdt30">Error and Loss: RDT3.0</h4>

<p>Now we need to also deal with packet loss. This is a problem in our previous setup, since we had ==stop and wait==. If a packet such as <code class="language-plaintext highlighter-rouge">ACK</code> is lost, then e.g. the sender will <strong>wait forever</strong>. Therefore, we have two additional tasks to fulfill:</p>

<ol>
  <li>==how to detect packet loss== (this cannot be handled in RDT2.2)</li>
  <li>==what to do when packet loss occurs== (this in fact can be handled by RDT2.2)</li>
</ol>

<p>Here, we assume that we are using the <strong>NAK-Free Protocol</strong>.</p>

<blockquote>
  <p><strong>Idea</strong></p>

  <p>Here, we’ll put the burden of detecting and recovering from lost packets on the sender.</p>

  <ul>
    <li>Sender waits for a “reasonable” amount of time for <code class="language-plaintext highlighter-rouge">ACK</code>. So that
      <ol>
        <li>If either the data packet sent is lost, or the receiver’s ACK of that packet is lost, you get no response
          <ul>
            <li>in that case, you just <strong>time out</strong></li>
          </ul>
        </li>
        <li>if it is just delayed too much, then you retransmit anyway (<strong>duplicate</strong> packet).
          <ul>
            <li>This is the same as <code class="language-plaintext highlighter-rouge">NAK/ACK</code> is corrupted, receiver can handle duplicates anyway in RDT 2.2.</li>
          </ul>
        </li>
      </ol>
    </li>
    <li>Receiver doesn’t change much
      <ol>
        <li>since if the data packet is loss, it never received it anyway. The sender will eventually resend it</li>
        <li>if there are duplicates, it is the same as RDT2.2</li>
      </ol>
    </li>
  </ul>
</blockquote>

<p>For <strong>sender</strong></p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211020093800669.png" alt="image-20211020093800669" /></p>

<p>then basically:</p>

<ol>
  <li>if the data and the <code class="language-plaintext highlighter-rouge">ACK/NAK</code> are all correct, then you just get start and stop timers</li>
  <li>expect <code class="language-plaintext highlighter-rouge">ACK, 1</code>, but receiver sends <code class="language-plaintext highlighter-rouge">ACK, 0</code> or vice versa
    <ul>
      <li>we do nothing because, if the timer waiting for <code class="language-plaintext highlighter-rouge">ACK,0</code> timed out before receiving any response, so we resent. But then we received the first <code class="language-plaintext highlighter-rouge">ACK,0</code> and proceeded to send packet 1. Then there would still be an <code class="language-plaintext highlighter-rouge">ACK,0</code> on the way = 2 <code class="language-plaintext highlighter-rouge">ACK,0</code> due to timed out + resend.</li>
    </ul>
  </li>
  <li>if the sender <code class="language-plaintext highlighter-rouge">timeout</code>, then basically feedback is lost/delayed too much
    <ul>
      <li>either sender packet is lost, never reached receiver, or <code class="language-plaintext highlighter-rouge">ACK</code> reply is lost</li>
      <li>in any case, you retransmit</li>
    </ul>
  </li>
</ol>

<p><strong>Receiver</strong></p>

<ul>
  <li>
    <p>an exercise. Solution found online</p>

    <p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/rdt_30_receiver.png" alt="Interactive Problems, Computer Networking: A Top Down Approach" style="zoom:50%;" /></p>
  </li>
</ul>

<blockquote>
  <p><strong>Note that</strong></p>

  <p>This means we need to decide on <strong>how long must the sender wait</strong> to be certain that something has been lost. Technically, this should be at least one round trip. But that has a problem of:</p>

  <ul>
    <li>the value differs link to link, time to time</li>
    <li>difficult to measure</li>
    <li>wasted bandwidth for just waiting that data</li>
  </ul>
</blockquote>

<p>From the sender’s viewpoint, ==retransmission is a panacea==.</p>

<ul>
  <li>The sender does not know whether a data packet was lost, an ACK was lost, or if the packet or ACK was simply overly delayed.</li>
</ul>

<h4 id="rdt30-timeline">RDT3.0: Timeline</h4>

<p>Again, we are using the <code class="language-plaintext highlighter-rouge">NAK</code>-Free protocol.</p>

<p>When nothing went wrong:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211020093953419.png" alt="image-20211020093953419" /></p>

<p>When you have a packet loss:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211020094030067.png" alt="image-20211020094030067" /></p>

<p>When you have a <code class="language-plaintext highlighter-rouge">ACK</code> loss:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211020094130144.png" alt="image-20211020094130144" /></p>

<p>When your timeout is premature:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211020094414836.png" alt="image-20211020094414836" /></p>

<p>where the last case you do nothing because you have transmitted <code class="language-plaintext highlighter-rouge">pkt0</code> just now. You are waiting for <code class="language-plaintext highlighter-rouge">ACK0</code> already.</p>

<h3 id="stop-and-wait-vs-pipelining">Stop-and-Wait vs Pipelining</h3>

<p>Protocol rdt3.0 is a functionally <strong>correct</strong> protocol, but it is ==unlikely== that anyone would be happy with its <strong>performance</strong>.</p>

<p>Suppose we have two hosts, and the setup is:</p>

<ul>
  <li>propagation delay is $0.5\text{RTT}\equiv 15\text{ms}$ (assuming now processing delay, no queuing delay)</li>
  <li>transmission delay at sender is $L_s/R\equiv 0.008\text{ms}$ (e.g $R$, of 1 Gbps and $L_s$ is 1,000 bytes)</li>
  <li>transmission delay at receiver is $\approx 0$ since <code class="language-plaintext highlighter-rouge">ACK</code> packets are small</li>
</ul>

<p>Then, the timeline of a normal RDT3.0 looks like, without any error:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211020145815480.png" alt="image-20211020145815480" /></p>

<p>where if you calculate the utilization of the sender’s link, we basically only used $0.008$ millisecond out of $30.008$ second.</p>

\[U_{\text{sender}} = \frac{L/R}{RTT+L/R} = \frac{0.008}{30.008}=0.00027\]

<p>Viewed another way, the sender was able to send only 1,000 bytes in $30.008$ milliseconds, an effective throughput of only $267$ kbps.</p>

<blockquote>
  <p><strong>Utilization Time</strong></p>

  <p>The utilization of the sender (or the channel) as the <em>fraction of time the sender is actually busy sending bits into the channel</em>.</p>
</blockquote>

<p>The solution to this is simple: Rather than operate in a stop-and-wait manner, the sender is allowed to ==send multiple packets without waiting for acknowledgments==.</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211020150547421.png" alt="image-20211020150547421" /></p>

<p>note that more than 3 packets can be send simultaneously. This is just an illustration.</p>

<blockquote>
  <p><strong>Pipelining</strong></p>

  <p>Sender now sends <em>multiple</em>, “in-flight”, ==yet to be acknowledged== packets sequentially. Receiver can also send multiple <code class="language-plaintext highlighter-rouge">ACK</code>s.</p>

  <ul>
    <li>then, you are basically still sending while waiting. Saves time!</li>
  </ul>

  <p>But this means that you need:</p>

  <ol>
    <li>your <strong>sequence number therefore has to increase</strong> (<code class="language-plaintext highlighter-rouge">0</code> and <code class="language-plaintext highlighter-rouge">1</code> does not work)
      <ul>
        <li>each in-transit packet (not counting retransmissions) must have a unique sequence number</li>
      </ul>
    </li>
    <li>sender and receiver sides of the protocols may have to <strong>buffer more than one packet</strong>
      <ul>
        <li><em>sender</em>: buffer packets that have been transmitted but not yet acknowledged</li>
        <li><em>receiver</em>: buffer out-of-order packets. (see Go-Back-N and Selective Repeat)</li>
      </ul>
    </li>
  </ol>
</blockquote>

<p>To implement the above, realize that there is a relationship between range of sequence numbers needed and the buffering  requirements. In reality, there are two approaches:</p>

<ul>
  <li>Go-Back-N</li>
  <li>Selective Repeat</li>
</ul>

<h3 id="go-back-n-gbn">Go-Back-N (GBN)</h3>

<p>Basically, sender is constrained to have no more than some maximum allowable number, $N$, of <strong>unacknowledged packets</strong> in the pipeline.</p>

<ul>
  <li>this limit $N$ will be then used for <strong>flow control</strong>. If that is ==not needed, we don’t even need a limit here.==</li>
</ul>

<p>In the <strong>sender</strong>’s view of range of sequence number used in a GBN protocol (for buffering and resending):</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211025081902482.png" alt="image-20211025081902482" /></p>

<p>where we defined:</p>

<ul>
  <li>
    <p><code class="language-plaintext highlighter-rouge">base</code>: sequence number of the <strong>oldest unacknowledged packet</strong></p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">nextseqnum</code>: smallest <strong>unused sequence number</strong></p>
  </li>
  <li>
    <p>therefore, we get four intervals:</p>

    <ol>
      <li>$[0,\text{base}-1]$ transmitted and acknowledged</li>
      <li>$[\text{base}, \text{nextseqnum}-1]$ transmitted but not yet acknowledged</li>
      <li>$[\text{nextseqnum}, \text{base}+N-1]$ packets to be transmitted immediately (if there are)</li>
      <li>$[\text{base}+N,\infty]$ forbidden region for GBN, must wait for one more acknowledgement from the window</li>
    </ol>

    <p>note that technically, sequence number can only go up to $2^k$ for a field of $k$ bits. So you loop around when you reached $2^k$.</p>
  </li>
</ul>

<p>As the protocol operates, this <strong>window slides forward over the sequence number space</strong>. For this reason, $N$ is often referred to as thew window size and the GBN protocol itself as a sliding-window protocol.</p>

<p>Therefore, the FSM for <strong>sender</strong> looks like:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211025083618912.png" alt="image-20211025083618912" /></p>

<p>where notice that:</p>

<ul>
  <li><em>Receipt of an ACK</em>. In our GBN protocol, an acknowledgment for a packet with sequence number $n$ will be taken to be a <strong>cumulative acknowledgment</strong>, indicating that ==all packets with a sequence number up to and including $n$ have been correctly received at the receiver== (check receiver side implementation to see how it works)</li>
  <li><em>A timeout event</em>. timer will again be used to recover from <strong>lost data or acknowledgment packets</strong>. If a timeout occurs, the sender ==resends all packets that have been previously sent but that have not yet been acknowledged.==
    <ul>
      <li>basically, retransmit everything in the current window</li>
    </ul>
  </li>
  <li>if there is a duplicate <code class="language-plaintext highlighter-rouge">ACK</code>, ignore it</li>
</ul>

<blockquote>
  <p><strong>Timer in Sender GBN:</strong></p>

  <ul>
    <li>basically can be thought of as a timer for the <strong>oldest transmitted but not yet acknowledged packet</strong></li>
  </ul>
</blockquote>

<p>For <strong>receiver</strong>:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211025084634291.png" alt="image-20211025084634291" /></p>

<p>where:</p>

<ul>
  <li>If a packet with sequence number $n$ is received correctly and ==is in order==, then we deliver the data to APP and send <code class="language-plaintext highlighter-rouge">ACK</code></li>
  <li>otherwise, ==discard the packet and send most recent <code class="language-plaintext highlighter-rouge">ACK</code>== (we are in the <code class="language-plaintext highlighter-rouge">NAK</code>-free protocol). This made sure that the use of cumulative acknowledgments is a natural choice for GBN.
    <ul>
      <li>as a result, you will send <strong>duplicate <code class="language-plaintext highlighter-rouge">ACK</code></strong></li>
      <li>alternatively, you <em>could</em> buffer out of order packets. But there is no need here.</li>
    </ul>
  </li>
</ul>

<p>Therefore, for the receiver, the sequence number space looks like:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211025091418699.png" alt="image-20211025091418699" /></p>

<blockquote>
  <p><strong>In Summary</strong></p>

  <ul>
    <li>basically, the only exchange of “state” information between sender and receiver is the <strong>cumulative <code class="language-plaintext highlighter-rouge">ACK</code></strong></li>
    <li>this is simple to implement</li>
    <li>GBN is inefficient as it resend <em>all $N$ packets</em> in my window. For example, you received seq <code class="language-plaintext highlighter-rouge">1,2,5,6,7</code>, then you will give a cumulative <code class="language-plaintext highlighter-rouge">ACK</code> of <code class="language-plaintext highlighter-rouge">2</code>. So eventually, all packets <code class="language-plaintext highlighter-rouge">3,4,5,6,7</code> will be retransmitted.</li>
  </ul>
</blockquote>

<p>For a timeline series, GBN looks like:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211025091829311.png" alt="image-20211025091829311" /></p>

<p>where alternatively:</p>

<ul>
  <li>instead of ignoring duplicate <code class="language-plaintext highlighter-rouge">ACK</code>, sender could immediately retransmit the missing ones</li>
  <li>instead of discarding the out-of-order packets, receiver could buffer it</li>
</ul>

<h3 id="selective-repeat-sr">Selective Repeat (SR)</h3>

<p>The problem with GBN was:</p>

<ul>
  <li>A single packet error can thus cause GBN to retransmit a large number of packets, many unnecessarily (if receiver buffered)</li>
</ul>

<p>Hence, <strong>selective-repeat</strong> protocols ==avoid unnecessary retransmissions== by having the sender retransmit only those packets that it suspects were received in error. This means that:</p>

<ul>
  <li>
    <p>still has a window size of $N$, start of window = <strong>first unACKed/unreceived message</strong> in the sequence</p>
  </li>
  <li>now, both receiver and sender ==must have buffers==</li>
  <li>sender has <em>multiple timers</em>, each individually for unACKed packets</li>
</ul>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211025140007988.png" alt="image-20211025140007988" /></p>

<p>then for <strong>sender</strong>:</p>

<ol>
  <li><em>Data received from above</em>. Basically same as GBN, you check if it is within your window, and send only when it is within the window</li>
  <li><em>Timeout</em>. ==each packet must now have its own logical timer==, since only a single packet will be transmitted on timeout.</li>
  <li><em>ACK Received</em>. The sender marks that packet as having been received, provided it is in the window. If the packet’s sequence number is equal to <code class="language-plaintext highlighter-rouge">send_base</code>, the window base is <strong>moved forward to the next unacknowledged packet</strong> (basically the cumulative thing holds)</li>
</ol>

<p>For <strong>receiver</strong></p>

<ol>
  <li><em>Packet with sequence number in $[\text{rcv_base}, \text{rcv_base}+N-1]$ is correctly received</em>. Then the correctively received packets’ <code class="language-plaintext highlighter-rouge">ACK</code> are returned to sender. If the packet’s sequence number is equal to <code class="language-plaintext highlighter-rouge">rcv_base</code> is <strong>moved forward to the next unreceived packet.</strong></li>
  <li><em>Packet with sequence number in $[\text{rcv_base}-N, \text{rcv_base}-1]$ is correctly received.</em> In this case, ==an <code class="language-plaintext highlighter-rouge">ACK </code> for that old packet must be generated==, even though this is a packet that the receiver has previously acknowledged. (otherwise the sender won’t go forward)
    <ul>
      <li>e.g. you can receive past packet by a) your <code class="language-plaintext highlighter-rouge">ACK</code> simply got lost; b) basically sender timer timed out but your <code class="language-plaintext highlighter-rouge">ACK</code> received (delayed) right afterwards. In either case the receiver will have window moving forward already</li>
    </ul>
  </li>
  <li><em>Otherwise</em>. Ignore.</li>
</ol>

<blockquote>
  <p><strong>Note</strong></p>

  <ul>
    <li>
      <p>One important aspect of SR is that we have <strong>a lack of synchronization between sender and receiver windows</strong>. This will cause the following problem if we chose the wrong window size, as shown in <a href="#Dilemma with Selective Repeat">Dilemma with Selective Repeat</a>.</p>

      <p>Basically, the upshot is that you need your <em>range of sequence number</em> to be ==at least twice of the windows size.==</p>
    </li>
  </ul>
</blockquote>

<p>Time Series Example</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211025095604763.png" alt="" /></p>

<p>where after the <code class="language-plaintext highlighter-rouge">ACK2</code> arrives, the sender will then shift the window all the way to packet <code class="language-plaintext highlighter-rouge">base=6</code></p>

<h4 id="dilemma-with-selective-repeat">Dilemma with Selective Repeat</h4>

<p>Consider the case hat you have a window size of $3$, and your sequence number field is $2$ bits. So you only have sequence $0,1,2,3$. Now, consider the two scenarios:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">No problem</th>
      <th style="text-align: center">Problem</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211025094503005.png" alt="image-20211025094503005" /></td>
      <td style="text-align: center"><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211025094527464.png" alt="image-20211025094527464" /></td>
    </tr>
  </tbody>
</table>

<p>So from the <strong>receiver’s</strong> point of view, this looks like:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211025094618839.png" alt="image-20211025094618839" style="zoom:67%;" /></p>

<p>This happened because the ==window size is smaller than the sequence size== (see figure below). The solution is to keep your <strong>sequence number $2N$ and above, for $N$ being window size</strong>.</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211025142224250.png" alt="image-20211025142224250" style="zoom: 80%;" /></p>

<ul>
  <li>so even if the problem case (which is the worst) happened, there is <strong>no overlap between the two windows in sequence number</strong>. Otherwise the receiver has no idea it the above is the next round of message or retransmission.</li>
</ul>

<blockquote>
  <p><strong>Take Away Message</strong></p>

  <p>Selective repeat is basically a better version than GBN, but it ==added complexity== of:</p>

  <ol>
    <li>needs a <strong>wider range of sequence bits</strong> $\ge 2N$</li>
    <li>needs timer for each packet</li>
    <li>more processing on both receiver and sender side</li>
  </ol>
</blockquote>

<h3 id="gbn-vs-sr-model">GBN vs SR Model</h3>

<p>Consider a simple model where:</p>

<ul>
  <li>any packet transmission from sender is <strong>lost</strong> with probability, $p$</li>
  <li>ACKs never lost</li>
</ul>

<p>We assume that each packet is ==independent==.</p>

<hr />

<p>Therefore, for <strong>Selective Repeat</strong>, it is simple. Recall that:</p>

<ul>
  <li>sender knows exactly what receiver needs</li>
</ul>

<p>Therefore, each pkt can be “examined” in isolation. Let $T_{SR}$ is the number of transmissions of <strong>one packet</strong>. Then:</p>

\[\begin{align*}
P[T_{SR} &gt; i]
&amp;= P[T_{SR} = i+1] +  P[T_{SR} = i+2]...\\
&amp;= p^{i}[(1-p) + p(1-p) + p^2(1-p) + ...]\\
&amp;= p^i (1-p)[1+p+p^2+...]\\
&amp;= p^i (1-p)\frac{1}{1-p}\\
&amp;= p^i
\end{align*}\]

<p>Therefore, the <strong>average number of transmissions</strong> we need to do is:</p>

\[\begin{align*}
\mathbb{E}[T_{SR}]
&amp;= P(T_{SR}=1) + 2P(T_{SR}=2) + 3P(T_{SR}=3) + ...\\
&amp;= P(T_{SR}&gt;0) + P(T_{SR}&gt;1) + P(T_{SR}&gt;2) + ...\\
&amp;= \frac{1}{1-p}
\end{align*}\]

<hr />

<p>For <strong>Go-back-N</strong>, recall that</p>

<ul>
  <li>each round, sender transmits block of $N$ packets</li>
  <li>receiver informs sender of 1st lost pkt</li>
  <li>==sender== sends $N$ packets ==starting at 1st point of loss==</li>
  <li>==receiver== dumps any packet in window ==after a loss==.</li>
</ul>

<p>$S_N$= # pkts arriving in receive<strong>r before a loss</strong> occurred in window of $N$ (successful transmission). Then, for $0 \le i &lt; N$:</p>

\[\begin{align*}
P[S_{N} &gt; i]
&amp;= P[S_{N} = i+1] +  P[S_{N} = i+2]...\\
&amp;= (1-p)^{i+1}
\end{align*}\]

<p>basically at least the first $i+1$ packet is successfully transmitted.</p>

<p>Then the</p>

\[\begin{align*}
\mathbb{E}[S_{N}]
&amp;= P(S_{N}=1) + 2P(S_{N}=2) + ...+NP(S_{N} = N)\\
&amp;= P(S_{N}&gt;0) + P(S_{N}&gt;1) + ... + P(S_{N}&gt;N-1)\\
&amp;= \frac{1-p-(1-p)^{N+1}}{p}\\
&amp;= \frac{1-p}{p}(1-(1-p)^N)
\end{align*}\]

<p>Notice that, plotting in desmos shows you that:</p>

\[\lim_{p \to 0}\frac{1-p}{p}(1-(1-p)^N) = N\]

<p>Then let there be $m$ rounds of transmission, that we slide the window $m$ times. Since the window size is $N$:</p>

\[\mathbb{E}[T_{GBN}]= \frac{\sum_{j=1}^mN}{\sum_{j=1}^mS_{N,j}}=\frac{\sum_{j=1}^mN/m}{\sum_{j=1}^mS_{N,j}/m}\]

<p>where $S_{N,j}$ be the number of packets accepted in the j-th round of transmission ($j$-th window slide).</p>

<ul>
  <li>Notice that every time when a packet is lost, $S_{N,j} &lt; N$ so our number of messages transmitted is larger than $1$.</li>
</ul>

<p>Then, note that, since each <strong>round of transmission is independent</strong>:</p>

\[\lim_{m\to \infty}\frac{1}{m}\sum_{j=1}^mS_{N,j} = \mathbb{E}[S_N]\]

<p>this is because we are taking the mean of successful transmission in each round, then with the law of large numbers, we get the expected value. Similarly:</p>

\[\lim_{m\to \infty}\frac{1}{m}\sum_{j=1}^mN= N\]

<p>Hence we get:</p>

\[\mathbb{E}[T_{GBN}] = \frac{Np}{1-p-(1-p)^{N+1}}\]

<hr />

<p>Finally, graphing this, we can plot:</p>

\[\frac{\text{average tranmission per packet in GBN}}{\text{average tranmission per packet in SR}} = \frac{\mathbb{E}[T_{GBN}]}{\mathbb{E}[T_{SR}]}\]

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211027090810879.png" alt="image-20211027090810879" style="zoom: 67%;" /></p>

<p>note that:</p>

<ul>
  <li>
    <p>if the <strong>probability of packet loss increases</strong>, GBN needs to retransmit much more. Note that when the probability of loss is small $p\approx 0$, then the ratio is $1$, i.e. not much difference in performance</p>
  </li>
  <li>
    <p>if we <strong>increase the window size</strong>, then Go-Back-N does worse and worse since chance of a packet being lost is higher</p>
  </li>
</ul>

<h3 id="summary">Summary</h3>

<table>
  <thead>
    <tr>
      <th>Mechanism</th>
      <th>Use, Comments</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Checksum</td>
      <td>Used to detect bit errors in a transmitted packet.</td>
    </tr>
    <tr>
      <td>Timer</td>
      <td>Used to timeout/retransmit a packet, possibly because the packet (or its <code class="language-plaintext highlighter-rouge">ACK</code>) was lost within the channel. Because timeouts can occur ==when a packet is delayed== but not lost (premature timeout), or when a packet has been received by the receiver but the receiver-to-sender ACK has been lost, <strong>duplicate copies of a packet</strong> may be received by a receiver.</td>
    </tr>
    <tr>
      <td>Sequence number</td>
      <td>Used for sequential numbering of packets of data flowing from sender to receiver.<br />Gaps in the sequence numbers of received packets allow the receiver to <strong>detect a lost packet</strong>. Packets with duplicate sequence numbers allow the receiver to <strong>detect duplicate copies of a packet</strong>.</td>
    </tr>
    <tr>
      <td>Acknowledgment <code class="language-plaintext highlighter-rouge">ACK</code></td>
      <td>Used by the receiver to tell the sender that a packet or set of packets has been received correctly.</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">NAK</code></td>
      <td>Used by the receiver to tell the sender that a packet has not been received correctly. Negative acknowledgments will typically carry the sequence number of the packet that was not received correctly</td>
    </tr>
    <tr>
      <td>Window, pipelining</td>
      <td>By allowing multiple packets to be transmitted but not yet acknowledged, <strong>sender utilization can be increased</strong> over a stop-and-wait mode of operation. <br />Window size can further be set on the basis of the receiver’s ability to receive and buffer messages, or the <em>level of congestion in the network</em>, or both (see next chapter).</td>
    </tr>
  </tbody>
</table>

<h2 id="tcp">TCP</h2>

<p>Now that we have covered the underlying principles of reliable data transfer, let’s turn to TCP—the Internet’s transport-layer, connection-oriented, reliable transport protocol.</p>

<h3 id="the-tcp-connection">The TCP Connection</h3>

<p>Recall that some properties of a TCP connection is:</p>

<ul>
  <li><strong>connection-oriented</strong>,  because before one application process can begin to send data to another, the two processes must first “<strong>handshake</strong>” with each other (with the aim of initialize many TCP state variables)</li>
  <li><strong>point-to-point</strong>, that is, between a single sender and a single receiver</li>
  <li><strong>full-duplex service</strong>: If there is a TCP connection between Process A on one host and Process B on another host, then
<em>application-layer data can flow from Process A to Process B at the same time as application-layer data flows from Process B to Process A</em>.</li>
</ul>

<p>Now, let’s look at the basics of how a connection is established. Recall that we start with a ==client initiating the connection== with:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">clientSocket</span><span class="p">.</span><span class="n">connect</span><span class="p">((</span><span class="n">serverName</span><span class="p">,</span><span class="n">serverPort</span><span class="p">))</span>
</code></pre></div></div>

<p>the above basically results in:</p>

<ol>
  <li>the client first sends a special TCP segment informing the server</li>
  <li>the server responds with a special TCP segment as well</li>
  <li>the third segment is then sent from client to host again, which may or may not carry payload</li>
</ol>

<p>Because three segments are sent between the two hosts, this connection-establishment procedure is often referred to as a ==three-way handshake==. (which will be discussed in detail later)</p>

<p>After the connection is established, we basically send data with:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211103094339815.png" alt="image-20211103094339815" style="zoom:50%;" /></p>

<p>where basically:</p>

<ol>
  <li>
    <p>the client application process pass data throughout the socket</p>
  </li>
  <li>
    <p>then data is in the hands of TCP running in the client, which is directed into a <strong>send buffer</strong> (initialized during handshake)</p>
  </li>
  <li>
    <p>From time to time, TCP will <strong>grab</strong> chunks of data from the send buffer and add a TCP header, thereby forming TCP
segments.</p>

    <ul>
      <li>
        <p>The maximum amount of data that can be grabbed and placed in a segment is limited by the ==maximum segment size (MSS)==. This is set to ensure that a TCP segment (when encapsulated in an IP datagram) plus the TCP/IP header length (typically 40 bytes) will <strong>fit into a single link-layer frame</strong>.</p>

        <p>Note that the MSS is the maximum amount of <strong>application-layer data</strong> in the segment, not the maximum size of the TCP segment including headers.</p>
      </li>
    </ul>
  </li>
  <li>
    <p>segments are passed down to the network layer</p>
  </li>
  <li>
    <p>at the other end, the segment’s data is placed in the TCP connection’s receive buffer, and TCP would extract packets from that</p>
  </li>
  <li>
    <p>Finally, the receiver application reads data from there</p>
  </li>
</ol>

<blockquote>
  <p><strong>Take-Away Message</strong></p>

  <ul>
    <li>a TCP connection consists of <strong>buffers, variables, and a socket connection</strong> to a process in one host, and another set in another host.</li>
    <li>No buffers or variables are allocated to the connection in the network elements (routers, switches, and repeaters) between the hosts, since Transport Layer is only at the ends.</li>
    <li>It turns out that TCP uses ==cumulative ACKs==, which is more similar to GBN. Yet in reality implementation will have buffers to cache out-of-order packets, so it also has features of SR.</li>
  </ul>
</blockquote>

<h3 id="tcp-segment-structure">TCP Segment Structure</h3>

<p>Basically we have two parts:</p>

<ol>
  <li>header fields</li>
  <li>data field - a chunk of application data whose size is limited by MSS</li>
</ol>

<p>A TCP segment looks like the following:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211103095229452.png" alt="image-20211103095229452" style="zoom:50%;" /></p>

<p>where we have:</p>

<ul>
  <li>a <strong>source and destination port</strong> for multiplexing, and a <strong>checksum</strong>. This is the same for UDP as well.</li>
  <li>32-bit <strong>sequence number field</strong> and the 32-bit <strong>acknowledgment number field</strong>, used for reliable delivery
    <ul>
      <li>recall that we need 32 bit sequence number for pipelining</li>
      <li>the ACK number will be a cumulative ACK, which will be discussed below.</li>
      <li>we have both number, since this structure is used for all TCP segment/packets.</li>
    </ul>
  </li>
  <li>16-bit <strong>receive window field</strong> is used for flow control - number of bytes that a receiver is willing to accept
    <ul>
      <li>restrict the size of window for total number of unacknowledged packets. This is depending on your device/network performance.</li>
    </ul>
  </li>
  <li>4-bit <strong>header length field</strong> specifies the length of the TCP header - variable length due to the TCP options field</li>
  <li>optional and variable-length <strong>options field</strong> is used when a sender and receiver negotiate the maximum segment size (MSS) or as a window scaling factor for use in high-speed networks.</li>
  <li>the <strong>flag field</strong> contains 6 bits. Basically:
    <ul>
      <li><code class="language-plaintext highlighter-rouge">ACK</code> bit is used to indicate that the value carried in the acknowledgment field is <em>valid</em>, i.e. this segment contains <code class="language-plaintext highlighter-rouge">ACK</code>.</li>
      <li><code class="language-plaintext highlighter-rouge">RST</code>, <code class="language-plaintext highlighter-rouge">SYN</code>, and <code class="language-plaintext highlighter-rouge">FIN</code> bit is used for connection setup and teardown</li>
      <li><code class="language-plaintext highlighter-rouge">CWR</code>, and <code class="language-plaintext highlighter-rouge">ECE</code> bits are used in congestion notification</li>
      <li><code class="language-plaintext highlighter-rouge">PSH</code> bit indicates that the receiver should pass the data to the upper layer immediately</li>
      <li><code class="language-plaintext highlighter-rouge">URG </code>bit indicate there is urgent data</li>
    </ul>
  </li>
  <li>16-bit  <strong>urgent data pointer</strong> field indicates the location of the last byte of this urgent data if there is. In practice, TCP must <em>inform the receiving-side upper-layer entity</em> when urgent data exists and pass it a pointer to the end of the urgent data.</li>
</ul>

<h4 id="sequence-and-acknowledgement-number">Sequence and Acknowledgement Number</h4>

<p>Basically, consider Host A is sending data to Host B. In TCP:</p>

<ul>
  <li>The sequence number for a segment is therefore the <strong>byte-stream number of the first byte</strong> in the segment.</li>
  <li>The acknowledgment number that Host A puts is the <strong>sequence number of the next byte Host A is ==expecting==</strong> from Host B.
    <ul>
      <li>therefore, it is cumulative ACK.</li>
    </ul>
  </li>
</ul>

<p><em>For Example</em></p>

<p>Consider you are host A and you have 500,000 bytes, that the MSS is 1,000 bytes. Therefore, you need 500 segments. Suppose the <strong>first byte of the data stream is numbered 0</strong>.</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211103140018084.png" alt="image-20211103140018084" style="zoom:50%;" /></p>

<p>the sender Host A to B will have:</p>

<ul>
  <li>The first segment gets assigned sequence number 0</li>
  <li>the second segment gets assigned sequence number 1,000</li>
  <li>the third segment gets assigned sequence number 2,000</li>
  <li>and so on</li>
</ul>

<blockquote>
  <p><strong>Note</strong></p>

  <ul>
    <li>Here we assumed that initial sequence number start with $0$​. In truth, both sides of a TCP connection ==randomly choose an initial sequence number==. This is done to minimize the possibility that a segment that is still present in the network from an earlier, already-terminated connection.</li>
  </ul>
</blockquote>

<p>Since Host A may be <strong>receiving data from Host B while</strong> it sends data to Host B. Suppose that Host A has <strong>received all bytes numbered 0 through 535</strong> from B and suppose that it is about to send a segment to Host B.</p>

<ul>
  <li>Host A puts $536$ in the acknowledgment number field of the segment it sends to B, which is the byte number host A is waiting for.</li>
</ul>

<blockquote>
  <p><strong>Out-of-Order</strong></p>

  <p>What if Host A received $0$ to $535$ AND $900$ to $1000$. Then technically there is no requirement on what to do, so it is programmer’s choice:</p>

  <ul>
    <li>discard the $900$ to $1000$ byte</li>
    <li>store it in the buffer, which is often used ==in reality for performance==.</li>
  </ul>
</blockquote>

<hr />

<p><em>For Example</em>: Telnet Login Shell</p>

<p>Suppose that A is trying to login B, so A initiates the connection as a client. The basic idea under a login shell is:</p>

<ol>
  <li>user at the client type some character (not displayed on the screen yet),</li>
  <li>that character will be sent to the remote host</li>
  <li>remote host “echo back” the character is received and <strong>display it on the screen</strong>
    <ul>
      <li>this is why you sometimes experience lag when typing in a remote</li>
    </ul>
  </li>
</ol>

<p>Now, suppose your client <strong>start with sequence number $42$</strong>, and the <strong>server start with sequence number $79$</strong>. Then:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211103141907043.png" alt="image-20211103141907043" style="zoom:80%;" /></p>

<p>where:</p>

<ul>
  <li>the first packet has <code class="language-plaintext highlighter-rouge">Seq=42</code> because this is your first byte. It is expecting from server <code class="language-plaintext highlighter-rouge">Seq=79</code> (i.e. ==next incoming byte should be placed at position $79 - \text{start seq}$==) therefore it put <code class="language-plaintext highlighter-rouge">Ack=79</code>. Finally, we are sending data <code class="language-plaintext highlighter-rouge">C</code>, so that is in the payload.</li>
  <li>the next packet is trivial, which is sent so that the client get something on the screen
    <ul>
      <li>seq = 79, because server is telling client ==put <code class="language-plaintext highlighter-rouge">C</code> on the $79 - \text{server start seq}=0$th position of the buffer==</li>
      <li>ack = 43, because server is expects/want to know what is the next data, which will ==be placed on the $43-\text{client start seq}=1$st position on the buffer==</li>
    </ul>
  </li>
  <li>the third segment has an ==empty data field==, as its sole purpose is to acknowledge the data it has received from the server. Again the data design here is due to the implementation.
    <ul>
      <li>even though there is no data, but because TCP has a sequence number field, the segment needs to have some sequence number</li>
    </ul>
  </li>
</ul>

<h3 id="round-trip-time-estimation-and-timeout">Round-Trip Time Estimation and Timeout</h3>

<p>Now, we consider the TCP <strong>timeout</strong> that we had in our reliable delivery, which is needed basically for <strong>packet loss</strong>. In short, the consideration is:</p>

<ul>
  <li>timeout needs to be longer than RTT, but RTT could vary</li>
  <li>timeout cannot be too short, resulting unnecessary retransmission</li>
  <li>timeout cannot be too long, resulting too slow reaction to loss</li>
</ul>

<p>In reality, TCP determines this by first estimating the RTT value.</p>

<h4 id="estimating-rtt">Estimating RTT</h4>

<p>TCP sample some of its packet, ==measuring its <code class="language-plaintext highlighter-rouge">SampleRTT</code> for a segment==: the amount of time between when the segment is sent (that is, passed to IP) and when an acknowledgment for the segment is received, i.e. its RTT.</p>

<ul>
  <li>Instead of measuring a <code class="language-plaintext highlighter-rouge">SampleRTT</code> for every transmitted segment, most TCP implementations take only one <code class="language-plaintext highlighter-rouge">SampleRTT </code>measurement at a time. That is, <strong>at any point in time</strong>, the <code class="language-plaintext highlighter-rouge">SampleRTT </code>is being estimated for <strong>only one of the transmitted but currently unacknowledged segments</strong></li>
  <li>Also, TCP ==never== computes a <code class="language-plaintext highlighter-rouge">SampleRTT </code>for a segment that has been retransmitted</li>
</ul>

<blockquote>
  <p>As a result, a new value for <code class="language-plaintext highlighter-rouge">SampleRTT</code> is found approximately once every RTT time.</p>
</blockquote>

<p>Since RTT will fluctuate, some sort of average is taken to compute <code class="language-plaintext highlighter-rouge">EstimatedRTT</code>:</p>

\[\text{EstimatedRTT}':=(1-\alpha)\cdot \text{EstimatedRTT} + \alpha \cdot \text{SampleRTT}\]

<p>basically the new <code class="language-plaintext highlighter-rouge">EstimatedRTT</code> is the weighted sum of the previous estimate and the new data.</p>

<ul>
  <li>In statistics, such an average is called an ==exponential weighted moving average (EWMA)==.</li>
</ul>

<p>Graphically:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211103144628490.png" alt="image-20211103144628490" style="zoom: 33%;" /></p>

<p>where pink would be our estimate, taking $\alpha=0.125$.</p>

<ul>
  <li>however, we should ==not let timer be the <code class="language-plaintext highlighter-rouge">EstimatedRTT</code>==, because then a lot of packets in the graph above would have timed out. Therefore, we need some measure of safety margin</li>
</ul>

\[\text{DevRTT'} := (1-\beta) \cdot \text{DevRTT}  + \beta \cdot |\text{SampleRTT}  - \text{EstimateRTT} |\]

<p>where basically:</p>

<ul>
  <li>this measures the ==variability of the RTT==, so little fluctuation of <code class="language-plaintext highlighter-rouge">SampleRTT</code> will give small value for <code class="language-plaintext highlighter-rouge">DevRTT</code></li>
  <li>typically we take $\beta = 0.25$.</li>
</ul>

<p>Finally, we then have:</p>

\[\text{TimeoutInterval} = \text{EstimatedRTT} + 4\cdot \text{DevRTT}\]

<p>where an initial <code class="language-plaintext highlighter-rouge">TimeoutInterval </code>value of 1 second is recommended when there is no data in the beginning.</p>

<blockquote>
  <p><strong>Note</strong></p>

  <ul>
    <li>
      <p>when a <strong>timeout</strong> occurs, the value of <code class="language-plaintext highlighter-rouge">TimeoutInterval </code>is ==doubled== to avoid a premature timeout occurring for a subsequent segment that will soon be acknowledged. The value is changed back after the segment is received.</p>

      <ul>
        <li>also, when <code class="language-plaintext highlighter-rouge">TimeoutInterval</code> is smaller than Real RTT, if we <strong>do not double the interval</strong>, then TCP will use previous <code class="language-plaintext highlighter-rouge">TimeoutInterval</code> forever. Thus all packets will be retransmitted and no RTT mesurement happens.</li>
      </ul>

      <p>This timer for retransmission is often also called the ==Retranmission Timeout  Value (RTO)==.</p>
    </li>
  </ul>
</blockquote>

<h3 id="tcp-reliable-data-transfer">TCP Reliable Data Transfer</h3>

<p>TCP creates a reliable data transfer service on top of IP’s unreliable best effort service.</p>

<p>In reality, TCP implements:</p>

<ul>
  <li>use only ==a single retransmission timer==, even if there are multiple transmitted but not yet acknowledged segments.
    <ul>
      <li>though it is more effective to have one for each unacked packet in theory, it is a lot more overhead in practice</li>
    </ul>
  </li>
  <li>recover technique from packet loss includes <strong>both timer and duplicate ACK</strong>, as you will seen soon.</li>
</ul>

<h4 id="tcp-sender">TCP Sender</h4>

<p>Basically, at sender we deal with three major events related to data transmission and retransmission.</p>

<p><strong>Event: data received from application</strong></p>

<ol>
  <li>create segment with seq # (recall seq # is byte-stream number of first data byte)</li>
  <li>add the necessary fields in segment, as well as the data</li>
  <li>start timer if not already running
    <ul>
      <li>think of timer as for <strong>oldest unACKed segment</strong></li>
      <li>expiration interval: <code class="language-plaintext highlighter-rouge">TimeOutInterval </code></li>
    </ul>
  </li>
  <li>pass the assembled segment to IP layer</li>
</ol>

<p><strong>Event: timeout</strong></p>

<ol>
  <li>retransmit <strong>segment</strong> that caused timeout (note this is ==different== from GBN, which then retransmit all unacked packets)
    <ul>
      <li>since there is only <em>one timer</em>, this makes it a bit inefficient if many <em>consecutive packets are lost</em></li>
    </ul>
  </li>
  <li>restart timer</li>
</ol>

<p><strong>event: ACK received</strong></p>

<ol>
  <li>if ACK acknowledges previously unACKed segments
    <ul>
      <li>update what is known to be ACKed (starting from the <code class="language-plaintext highlighter-rouge">SendBase</code> of our sender window)</li>
      <li>==restart== timer if there are still unACKed segments</li>
    </ul>
  </li>
  <li>otherwise, ignore or check <a href="#Fast Retransmit">Fast Retransmit</a></li>
</ol>

<h4 id="tcp-receiver">TCP Receiver</h4>

<p>Here, the idea is to <em>minimize the number of <code class="language-plaintext highlighter-rouge">ACK</code></em>, by trying to get cumulative ACKs.</p>

<table>
  <thead>
    <tr>
      <th>Event</th>
      <th>TCP Action</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Arrival of expected seq #. All previous ACK sent already.</td>
      <td>delayed ACK. Wait for 500ms for next segment. If no segment, send ACK.</td>
    </tr>
    <tr>
      <td>Arrival of expected seq #. One other segment <em>hasn’t yet sent ACK</em></td>
      <td>immediately send ==cumulative ACK==, ACKing both segment.</td>
    </tr>
    <tr>
      <td>Arrival of higher, out-of-order segment.</td>
      <td>immediately send ==duplicate ACK==, indicating seq. # for next expected byte</td>
    </tr>
    <tr>
      <td>Arrival of segment that partially or <em>completely fills in gap</em> in received data.</td>
      <td>Immediately send ==normal ACK==, provided that segment starts at the lower end of gap.</td>
    </tr>
  </tbody>
</table>

<h4 id="tcp-retransmissions">TCP Retransmissions</h4>

<p>The following cases are bad, i.e. we have retranmissions:</p>

<p>| <img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211103150247080.png" alt="image-20211103150247080" style="zoom:50%;" /> | <img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211103150205021.png" alt="image-20211103150205021" style="zoom:50%;" /> |
| :———————————————————-: | :———————————————————-: |</p>

<p>where on the left:</p>

<ul>
  <li>when Host B receives the retransmission, it observes from the sequence number that the segment contains data that has already been received. Thus, <strong>TCP in Host B will discard the bytes in the retransmitted segment</strong> but still ==send the ACK==.</li>
</ul>

<p>On the right figure, when we have a premature timeout:</p>

<ul>
  <li>Host A retransmit when timed out. It is interesting here to notice how the <code class="language-plaintext highlighter-rouge">SendBase</code> of Host A is updated throughout time.</li>
</ul>

<p>Yet in this case, there is no retransmission:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211103150316162.png" alt="image-20211103150316162" style="zoom:50%;" /></p>

<p>Note that in this case, there is no problem since we are using <strong>cumulative ACK</strong>:</p>

<ul>
  <li>no timeout happened before the receipt of <code class="language-plaintext highlighter-rouge">ACK=120</code>, so the sender updates it base to 120, and no retransmission is needed.</li>
</ul>

<p>However, TCP gets <strong>smarter</strong> using the following techniques ==in addition==. These are some modifications that is commonly used today.</p>

<h5 id="fast-retransmit">Fast Retransmit</h5>

<p>Consider the following case where a packet is lost</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211103150729198.png" alt="image-20211103150729198" style="zoom: 67%;" /></p>

<p>where the sender has received <code class="language-plaintext highlighter-rouge">ACK=100</code> multiple times <strong>before timeout for <code class="language-plaintext highlighter-rouge">seq=100</code></strong>:</p>

<ul>
  <li>the sender has a ==high confidence== that I have a lost packet. Therefore sender should retransmit now.</li>
  <li>in many practical implementation, we use ==triple duplicate ACK== as a signal to initiate fast retransmit. (for Linux, it used double duplicate)</li>
</ul>

<h5 id="doubling-timeout-interval">Doubling Timeout Interval</h5>

<p>The idea is basically that, each time we timed out for a packet $X$, we double the <code class="language-plaintext highlighter-rouge">TimeoutInterval</code> from its previous value, ==without touching== the computed estimate from $\text{TimeoutInterval} = \text{EstimatedRTT} + 4\cdot \text{DevRTT}$.</p>

<ul>
  <li>the aim is to provide a from of congestion control: In times of congestion (e.g. ACK timeout perhaps due to it), if the <strong>sources continue to retransmit packets persistently, the congestion may get worse</strong>. The solution is to wait longer.</li>
</ul>

<hr />

<p><em>For Example</em></p>

<p>Suppose the timeout interval associated with the oldest transmitted yet unacked packet $X$ is $0.75$sec, which then expired.</p>

<ol>
  <li>retransmit the packet, and set Timeout to be $1.75 \times 2 = 1.5$sec</li>
  <li>if still timed out, perform doubling again</li>
</ol>

<p>Note that the above should not alter our most recent computation for $\text{TimeoutInterval}$, which TCP will continue with that computed value again once we received the ACK for packet $X$.</p>

<h3 id="tcp-flow-control">TCP Flow Control</h3>

<p>Here the idea is that what if network layer delivers data <strong>faster than application layer consumes the data</strong>?</p>

<ul>
  <li>recall that we have a receive buffer, which TCP place correctly received data for application to consume</li>
  <li>If the application is relatively slow at reading the data, the sender can very easily ==overflow the connection’s receive==
==buffer==</li>
</ul>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211103152243270.png" alt="image-20211103152243270" /></p>

<blockquote>
  <p><strong>Note</strong></p>

  <ul>
    <li>from the above it can be seen that each <strong>socket will have its own receive buffer</strong>. Therefore, ==demultiplexing== in TCP just need to ==put the data into the correct buffer==.</li>
  </ul>
</blockquote>

<p>The solution is to use the <strong>receive window</strong> field in our segment:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211103151740533.png" alt="image-20211103151740533" style="zoom:50%;" /></p>

<p>where:</p>

<ul>
  <li>Informally, the receive window is used to give the <strong>sender</strong> an idea of ==how much free buffer space is available at the receiver==.</li>
  <li>Because TCP is full-duplex, the sender at <strong>each side of the connection</strong> maintains a ==distinct== receive window.</li>
</ul>

<p>Hence, basically the value restored in the field is the value of <code class="language-plaintext highlighter-rouge">rwnd</code>:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211103152505902.png" alt="image-20211103152505902" style="zoom:50%;" /></p>

<p>Now, suppose that <strong>Host A is sending data to Host B</strong>.</p>

<p>So that if we let variable in Host B be: <code class="language-plaintext highlighter-rouge">LastByteRead</code> being the number of bytes in the data stream consumed in the buffer by application; <code class="language-plaintext highlighter-rouge">LastByteRcvd</code> being the number of last byte that has arrived and placed in the buffer:</p>

<ul>
  <li>
    <p>then <code class="language-plaintext highlighter-rouge">RcvBuffer</code> total space must be:</p>

\[\text{RcvBuffer} \ge \text{LastByteRcvd} - \text{LastByteRead}\]

    <p>since TCP does not permit overflowing buffer.</p>

    <p>In reality, this can be set in your program via options <code class="language-plaintext highlighter-rouge">RcvBuffer</code>, and by default it is usually 4096 bytes.</p>

    <ul>
      <li>many operating system will auto adjust <code class="language-plaintext highlighter-rouge">RcvBuffer</code></li>
    </ul>
  </li>
  <li>
    <p>the receive window is <code class="language-plaintext highlighter-rouge">rwnd</code> the <strong>free space left</strong> in the buffer:</p>

\[\text{rwnd} = \text{RcvBuffer} - (\text{LastByteRcvd} - \text{LastByteRead})\]
  </li>
</ul>

<p>Therefore, Host B tells Host A how much spare room it has in the connection buffer, then what host A can do is to keep two variables: <code class="language-plaintext highlighter-rouge">LastByteSend</code> and <code class="language-plaintext highlighter-rouge">LastByteAcked</code>. Therefore:</p>

<ul>
  <li>
    <p>the number of ==unacknowledged data byte== is (notice it is in the unit of byte)</p>

\[\text{LastByteSend} - \text{LastByteAcked}\]
  </li>
  <li>
    <p>to keep no overflowing at Host B, Host A can make sure that:</p>

\[\text{rwnd}_B \ge \text{LastByteSend} - \text{LastByteAcked}\]

    <p>this is because we only have three cases for unacknowledged bytes:</p>

    <ul>
      <li>segment loss - doesn’t harm receiver’s buffer since its lost</li>
      <li>segment ACK hasn’t received - this actually goes into the buffer for host $B$</li>
    </ul>

    <p>notice that only the second case we care, but that is <strong>exactly equal to the number of unacked bytes</strong>. Therefore, the above works.</p>
  </li>
</ul>

<h3 id="tcp-connection-management">TCP Connection Management</h3>

<p>Recall that before exchanging data, we have some kind of handshake:</p>

<ul>
  <li>agree to establish connection (each knowing the other willing to establish connection)</li>
  <li>agree on connection parameters (e.g., <strong>starting seq #s</strong>, which would be random)
    <ul>
      <li>random seq number is useful for preventing spoofing and receiving packets from previous connections</li>
    </ul>
  </li>
</ul>

<p>On a high level, when the connection <strong>are established</strong>, we would have settled several variables such as <code class="language-plaintext highlighter-rouge">seq #</code>, which we need to decide during our handshaking procedure.</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211108084856364.png" alt="image-20211108084856364" /></p>

<p>In general, there are multiple ways to do an establishment:</p>

<ul>
  <li>2 way handshake (problematic)</li>
  <li>3 way handshake (used today)</li>
</ul>

<h4 id="2-way-handshake">2 Way Handshake</h4>

<p>Consider having a 2 way handshake, so the idea is that:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211108084927223.png" alt="image-20211108084927223" style="zoom:50%;" /></p>

<p>where the top half is the human analogy. This might seem to work, but in reality, consider the two cases:</p>

<ol>
  <li>
    <p><strong>Half Open Connection</strong></p>

    <p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211108123200901.png" alt="image-20211108123200901" /></p>

    <p>where basically:</p>

    <ol>
      <li>the client and server had a normal procedure of <code class="language-plaintext highlighter-rouge">ESTAB</code> using two handshakes</li>
      <li>yet it happens that client ==retransmitted the request connection <code class="language-plaintext highlighter-rouge">SYN</code>==, such that it ==arrived after client termination==</li>
      <li>then, the problem is that after termination, server <strong>receives a <code class="language-plaintext highlighter-rouge">SYN</code> and <code class="language-plaintext highlighter-rouge">ESTAB</code></strong> but ==client has already terminated!==</li>
    </ol>

    <p>The upshot is that some <strong>resources at the server will then be wasted</strong>, which is actually used as a form of DOS attack to exhaust the server.</p>
  </li>
  <li>
    <p><strong>Duplicate Application Data</strong></p>

    <p>This is different from duplicate data due to packet losses, which can be solved using sequence number. Here it is a different issue.</p>

    <table>
      <thead>
        <tr>
          <th>Procedure</th>
          <th>What Server Sees After Termination</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211108085345957.png" alt="image-20211108085345957" style="zoom:50%;" /></td>
          <td><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211108123657313.png" alt="image-20211108123657313" style="zoom: 67%;" /></td>
        </tr>
      </tbody>
    </table>

    <p>where notice that the procedure is basically:</p>

    <ul>
      <li>client happens to retransmit <strong>both the <code class="language-plaintext highlighter-rouge">SYN</code> and some data</strong> which ==arrives after termination==</li>
      <li>however, the server sees the retransmission as a ==new connection with new data!==</li>
    </ul>
  </li>
</ol>

<blockquote>
  <p><strong>Take-Away Message</strong></p>

  <ul>
    <li>the problem is that client is establishing the connection “<strong>too easily</strong>” to the server, that essentially it becomes a “one way handshake” for the client to trigger <code class="language-plaintext highlighter-rouge">ESTAB</code> on the server.</li>
  </ul>
</blockquote>

<h4 id="3-way-handshake">3 Way Handshake</h4>

<p>Basically we have the following:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211108110654242.png" alt="image-20211108110654242" style="zoom:67%;" /></p>

<ol>
  <li><strong>client</strong> sends a special TCP segment - ==a <code class="language-plaintext highlighter-rouge">SYN</code> segment== - to the server-side TCP. This special segment contains no application-layer data but a <code class="language-plaintext highlighter-rouge">SYN</code> bit set to <code class="language-plaintext highlighter-rouge">1</code>. In addition, the client <strong>randomly selects a sequence number</strong> <code class="language-plaintext highlighter-rouge">client_isn</code>, and put it in the segment as well.</li>
  <li><strong>server</strong> replies back with a connection granted segment - ==a <code class="language-plaintext highlighter-rouge">SYNACK</code> segment==, that basically says “I received your <code class="language-plaintext highlighter-rouge">SYN </code>packet to start a connection with your initial sequence number, <code class="language-plaintext highlighter-rouge">client_isn</code>. I agree to establish this connection. My own initial sequence number is <code class="language-plaintext highlighter-rouge">server_isn</code>.” This is done by <strong>three header fields</strong>
    <ul>
      <li><code class="language-plaintext highlighter-rouge">SYN</code> bit set to <code class="language-plaintext highlighter-rouge">1</code></li>
      <li><code class="language-plaintext highlighter-rouge">ACK</code> set to <code class="language-plaintext highlighter-rouge">client_isn+1</code> (and also <code class="language-plaintext highlighter-rouge">ACK</code> bit is set to <code class="language-plaintext highlighter-rouge">1</code> since it contains an <code class="language-plaintext highlighter-rouge">ACK</code>)</li>
      <li>puts a <strong>randomly selected sequence number</strong> <code class="language-plaintext highlighter-rouge">server_isn</code> in the sequence field</li>
    </ul>
  </li>
  <li><strong>client</strong> host then sends the server this last segment, which <strong>acknowledges</strong> the server’s connection-granted segment.
    <ul>
      <li>note that the <code class="language-plaintext highlighter-rouge">SYN</code> bit is set to <code class="language-plaintext highlighter-rouge">0</code> since connection is established now</li>
      <li>techinically, this message <strong>can carry payload</strong>. This is why sometimes we see handshake takes $\approx$ 1 RTT.</li>
      <li>this makes the ==previous design of DOS attack not possible== since the <strong>last <code class="language-plaintext highlighter-rouge">ACK</code> from client</strong> will be dependent on the server’s <code class="language-plaintext highlighter-rouge">SYNACK</code>, which means it needs to read that message. Hence it is not possible to per-compose it before client termination.</li>
    </ul>
  </li>
</ol>

<p>In a picture with more details:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211108085607528.png" alt="image-20211108085607528" style="zoom:80%;" /></p>

<p>this is useful because it can solve hanging connection problem</p>

<ul>
  <li>note that we used <code class="language-plaintext highlighter-rouge">SYN</code> bit to start TCP connection</li>
</ul>

<h4 id="closing-tcp-connection">Closing TCP Connection</h4>

<p>Basically we also have some kind of handshake, but here <strong>either of the two processes participating in a TCP connection can end</strong>.</p>

<p>For instance, suppose the <strong>client</strong> decides to close the connection</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211108115402220.png" alt="image-20211108115402220" style="zoom:67%;" /></p>

<ol>
  <li>client start a special segment with <code class="language-plaintext highlighter-rouge">FIN </code>bit = 1</li>
  <li>server respond to received <code class="language-plaintext highlighter-rouge">FIN </code>with ACK
    <ul>
      <li>on receiving <code class="language-plaintext highlighter-rouge">FIN</code>, ACK can be combined with own <code class="language-plaintext highlighter-rouge">FIN</code></li>
    </ul>
  </li>
  <li>server then sends its own <strong>shutdown segment</strong>, which has the <code class="language-plaintext highlighter-rouge">FIN </code>bit set to 1</li>
  <li>client then replies with ACK
    <ul>
      <li>at this point the client can ==deallocate resource==</li>
      <li>but notice when the server/client is at the <code class="language-plaintext highlighter-rouge">CLOSED</code> state</li>
    </ul>
  </li>
</ol>

<h4 id="tcp-states">TCP States</h4>

<p>Therefore, we could <strong>summarize</strong> all the above by using TCP states.</p>

<p>For <strong>client</strong>:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211108120505183.png" alt="image-20211108120505183" /></p>

<p>where basically you start with the <code class="language-plaintext highlighter-rouge">CLOSED</code> state, then:</p>

<ol>
  <li>initiate a connection with the server by sending <code class="language-plaintext highlighter-rouge">SYN</code>. (done by the creating the <code class="language-plaintext highlighter-rouge">Socket</code> object in python)</li>
  <li>While in the <code class="language-plaintext highlighter-rouge">SYN_SENT </code>state, the client TCP waits for the <code class="language-plaintext highlighter-rouge">SYNACK</code> segment from the server
    <ul>
      <li>once received, it replies with an <code class="language-plaintext highlighter-rouge">ACK</code></li>
    </ul>
  </li>
  <li>Then, once handshake completes, the client TCP enters the <code class="language-plaintext highlighter-rouge">ESTABLISHED </code>state
    <ul>
      <li>this is when the TCP client can <strong>send and receive TCP segments containing payload</strong></li>
    </ul>
  </li>
  <li>Then, if the client wants to close the connection, it starts by sending <code class="language-plaintext highlighter-rouge">FIN=1</code> segment and enters <code class="language-plaintext highlighter-rouge">FIN_WAIT_1</code>
    <ul>
      <li>this is when it waits for the <code class="language-plaintext highlighter-rouge">ACK</code> from server for that <code class="language-plaintext highlighter-rouge">FIN</code></li>
    </ul>
  </li>
  <li>When it receives the <code class="language-plaintext highlighter-rouge">ACK</code> segment, the client TCP enters the <code class="language-plaintext highlighter-rouge">FIN_WAIT_2 </code>state- waiting for <strong>server to send <code class="language-plaintext highlighter-rouge">FIN=1</code></strong>.
    <ul>
      <li>once received, the client <strong>acknowledges</strong> the server’s segment and enters the <code class="language-plaintext highlighter-rouge">TIME_WAIT </code>state</li>
    </ul>
  </li>
  <li>The <code class="language-plaintext highlighter-rouge">TIME_WAIT </code>state lets the TCP client resend the final acknowledgment <em>in case the ACK is lost</em>
    <ul>
      <li>the time for waiting is implementation-dependent, could be 30sec, 1min, etc.</li>
      <li>After the wait, connection formally closes and <strong>all resources is released</strong> at the client (e.g. port number)</li>
    </ul>
  </li>
</ol>

<p>For the <strong>server</strong></p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211108120911148.png" alt="image-20211108120911148" /></p>

<p>where here we are assuming the <strong>client initiated the tear down</strong>. Otherwise everything should be clear.</p>

<blockquote>
  <p><strong>Note</strong></p>

  <ul>
    <li>here we technically haven’t talked about if both sides of a connection want to initiate or <strong>shut down at the same time.</strong> Those issues are not covered here.</li>
  </ul>
</blockquote>

<p>Yet one case you need to know is when, say the client <strong>sent a <code class="language-plaintext highlighter-rouge">SYN</code> segment</strong> to socket <code class="language-plaintext highlighter-rouge">80</code> (assume firewall lets it through), but <strong>no server socket is running on <code class="language-plaintext highlighter-rouge">80</code></strong>. Then, the host will send a special ==reset segment to the source==/client. This TCP segment has the <code class="language-plaintext highlighter-rouge">RST </code>flag bit set to 1.</p>

<ul>
  <li>this is basically saying “I don’t have a socket for that segment. Please do not resend the segment”</li>
</ul>

<p>Alternatively, if the client didn’t receive any message, then it could mean that <code class="language-plaintext highlighter-rouge">SYN </code>segment was blocked by an intervening firewall and <strong>never reached the target host</strong>.</p>

<h3 id="principles-of-congestion-control">Principles of Congestion Control</h3>

<blockquote>
  <p><em>Recall that</em></p>

  <ul>
    <li>in <strong>flow control</strong>, we were rate matching between the sender and the receiver, so that the receiver is not overwhelmed.</li>
    <li>in <strong>reliable data transfer</strong> where we designed retransmission (e.g. due to overflowing of router buffer), it solved the symptom of network congestion (i.e. packet loss) but didn’t solve network congestion itself.</li>
  </ul>
</blockquote>

<p>Here, we are matching the speed of the <strong>sender</strong> and the <strong>network</strong>, by perhaps <strong>throttling the sender</strong> so that you don’t have too much:</p>

<ul>
  <li>long delays (due to <em>network congestion</em>)</li>
  <li>packet loss (due to <em>network congestion</em>)</li>
</ul>

<blockquote>
  <p><strong>Task To Achieve</strong></p>

  <ul>
    <li>
      <p>Too many sources sending too much data ==too fast== for network to handle!</p>
    </li>
    <li>
      <p>but we also need to utilize the network ==as much as possible==!</p>
    </li>
  </ul>
</blockquote>

<p>The difficulty here is that:</p>

<ul>
  <li>this thing needs to be <strong>scalable</strong>, since the network core could be very complicated</li>
  <li>high variation within the network</li>
</ul>

<h4 id="causes-and-the-costs-of-congestion">Causes and the Costs of Congestion</h4>

<p>Here we begin by understanding the problem first: <strong>examine three scenarios</strong> in which congestion occurs.</p>

<p>In particular, we focus on what happens as ==hosts increase their transmission rate== and the network becomes congested.</p>

<hr />

<p><strong>Scenario 1: Two Senders, a Router with Infinite Buffer</strong></p>

<p>The setup is as follows:</p>

<ul>
  <li>two <strong>senders</strong> $A$, and $B$, sending at the same rate of $\lambda_{in}$ bytes/sec</li>
  <li><strong>router</strong> has infinite buffer, but a finite capacity of $R$</li>
  <li>the number of bytes/sec received at the <strong>receiver</strong> is $\lambda_{out}$</li>
  <li>==assume== no retransmission, no loss data, etc.</li>
</ul>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211108130238613.png" alt="image-20211108130238613" style="zoom:67%;" /></p>

<p>Then, if we measure the <strong>throughput</strong>, i.e. $\lambda_{out}$ as a function of $\lambda_{in}$ input, we see that:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211108130820859.png" alt="image-20211108130820859" style="zoom: 67%;" /></p>

<p>so:</p>

<ul>
  <li>the left figure basically shows that the <strong>throughput is bounded</strong> at $R/2$</li>
  <li>but as throughput approaches $R/2$. the ==average delay will get huge==!</li>
</ul>

<hr />

<p><strong>Scenario 2: Two Senders and a Router of Finite Buffer</strong></p>

<p>Now, we consider the same setup, but the modifications that:</p>

<ul>
  <li>router has a finite buffer, so packet will get dropped when it has full buffer</li>
  <li>we are using <strong>reliable data delivery</strong>, so we will <strong>have retransmission</strong></li>
  <li>hence while the application is sending at $\lambda_{in}$, <strong>TCP</strong> layer is actually sending at $\lambda_{in}’$ due to extra retransmission</li>
</ul>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211108091325030.png" alt="image-20211108091325030" style="zoom: 67%;" /></p>

<p>Then, the upshot is that determining $\lambda_{in}$ and throughput $\lambda_{out}$ ==depend strongly on how retransmission is performed==.</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211108131331111.png" alt="image-20211108131331111" style="zoom:80%;" /></p>

<p>where :</p>

<ul>
  <li>the <strong>best</strong> case we have Host A is able to somehow (magically!) determine whether or not a buffer is free in the router and thus sends a packet only when a buffer is free. In this case, <strong>no loss would occur</strong></li>
  <li>more <strong>realistic</strong> case, e.g. we retransmit for 3 duplicate ACK or timeout. Then, when we have $\lambda_{in}’=0.5R$, the ==throughput== is lower since some of the $0.5R$ will be duplicates.
    <ul>
      <li>in this case, $\lambda’<em>{in}=0.5R\to \lambda</em>{out}=0.333R$. This means that $0.5R-0.333R\approx 0.166R$ are <strong>duplicate retransmissions</strong></li>
    </ul>
  </li>
  <li>the <strong>worst</strong> case is that <em>every</em> packet is retransmitted from the sender</li>
</ul>

<blockquote>
  <p><strong>Note</strong></p>

  <ul>
    <li>
      <p>The upshot is that we will have both <strong>needed and unneeded</strong> (e.g. premature timeout) retransmissions, where arguably both needs to be taken into account/will affect the network.</p>

      <p>So the Figure 3.46 b) could be:</p>

      <p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211108091613948.png" alt="image-20211108091613948" style="zoom:50%;" /></p>

      <p>where that unneeded retransmission is more annoying.</p>
    </li>
  </ul>
</blockquote>

<hr />

<p><strong>Scenario 3: Multi-hop Path</strong></p>

<p>Here we:</p>

<ul>
  <li>assume that we have RDT implemented</li>
  <li>all hosts intent to transmit at the same rate of $\lambda_{in}$</li>
  <li>all 4 routes have the same capacity of $R$, and a finite buffer</li>
</ul>

<p>We have A sending to C, D sending to B over four routers</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211108091805181.png" alt="image-20211108091805181" style="zoom: 50%;" /></p>

<p>where notice that here we have another problem:</p>

<ul>
  <li>the maximum capacity of each router becomes $R/2$ since it is ==shared==</li>
  <li>consider if it happens that the ==GREEN packet is sending faster than $R/2$==, then it piles up at RIGHT router
    <ul>
      <li>since the RED packet from A-C <strong>also needs the RIGHT router</strong>, this will result in eventually no RED data arriving at host C, hence <strong>throughput of A-C will diminish!</strong></li>
      <li>if A-C throughput diminishes, then it could be the same as the TOP router ==just dropping RED packets and remain IDLE== = doing useless work! Basically it would be a waste of resource to even pick up red packets in this case.</li>
    </ul>
  </li>
</ul>

<p>Hence, in this unfortunate scenario, we get (e.g. for A-C in this case)</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211108133533708.png" alt="image-20211108133533708" /></p>

<p>where:</p>

<ul>
  <li>in the beginning when $\lambda_{in}$ is small, there is no competition</li>
  <li>as $\lambda_{in}’$ gets larger, competition happens and the <strong>multi-hop</strong> router basically becomes a disaster! It would be ==equivalent== of ==router doing useless work==!</li>
</ul>

<h5 id="summary-of-congestion-situations">Summary of Congestion Situations</h5>

<table>
  <thead>
    <tr>
      <th>Take Away Message</th>
      <th>Graph</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>throughput can never exceed capacity</td>
      <td><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211108133920569.png" alt="image-20211108133920569" style="zoom: 67%;" /></td>
    </tr>
    <tr>
      <td>§delay increases as capacity approached</td>
      <td><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211108133938863.png" alt="image-20211108133938863" /></td>
    </tr>
    <tr>
      <td>loss/retransmission decreases effective throughput</td>
      <td><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211108133955610.png" alt="image-20211108133955610" /></td>
    </tr>
    <tr>
      <td>un-needed duplicates further decreases effective throughput</td>
      <td><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211108134008793.png" alt="image-20211108134008793" /></td>
    </tr>
    <tr>
      <td>upstream transmission capacity/buffering wasted for packets lost downstream</td>
      <td><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211108134027959.png" alt="image-20211108134027959" /></td>
    </tr>
  </tbody>
</table>

<p>Up to this point, we discussed what it looks like for congestion to happen. Next we discuss how to fix/react to improve the situation.</p>

<h3 id="tcp-congestion-control">TCP Congestion Control</h3>

<blockquote>
  <p><strong>Heuristics</strong></p>

  <p>In general there could be two solutions:</p>

  <ol>
    <li>End systems <strong>infer</strong> congestion by looking at <strong>packet delay and packet loss</strong>
      <ul>
        <li>e.g. is delay is high or packet is loss, then it could be that the network is congested</li>
        <li>this is also called: End-to-end congestion control.</li>
      </ul>
    </li>
    <li><strong>Routers</strong> provides <strong>feedback</strong> to sender and receiver on current network status
      <ul>
        <li>i.e. the network layer is providing some assistance</li>
        <li>the problem here is to make it scalable</li>
        <li>this is also called: Network-assisted congestion control</li>
      </ul>
    </li>
  </ol>
</blockquote>

<h4 id="classic-tcp-congestion-control">Classic TCP Congestion Control</h4>

<p>here we cover the “classical” TCP —the version of TCP standardized in [RFC2581] and most recently [RFC 5681] — uses <strong>end-to-end congestion control</strong> rather than network-assisted congestion control.</p>

<p>In general, the idea is to answer the following to problems:</p>

<ul>
  <li>how does TCP <strong>throttle</strong> the sender</li>
  <li>how does TCP <strong>perceive congestion</strong></li>
</ul>

<hr />

<p><strong>Throttling the Sender</strong></p>

<p>This is done by TCP having an ==additional variable at the sender==, which is <code class="language-plaintext highlighter-rouge">cwnd</code> - <strong>congestion control window</strong>. Such that:</p>

\[\text{LastByteSend} - \text{LastByteAcked} \le \min \{ \text{cwnd}, \text{rwnd}  \}\]

<p>where notice that the LHS is just <strong>unacknowledged data</strong>.</p>

<ul>
  <li>==in practise, the window size is exactly $N \equiv \min{\text{cwnd}, \text{rwnd}}$==.</li>
</ul>

<p>Now, if we ==assume== that TCP receive buffer is so large that the receive-window constraint can be ignored; thus we only focus on <code class="language-plaintext highlighter-rouge">cwnd</code>, then approximately the sender sends at rate:</p>

\[\text{sending rate} \approx \frac{\text{cwnd}}{\text{RTT}} \text{ bytes/sec}\]

<p>because basically:</p>

<ul>
  <li>at the beginning of every RTT, the constraint permits the sender to send <code class="language-plaintext highlighter-rouge">cwnd </code>bytes of data into the connection</li>
  <li>after roughly the end of RTT, you can send new round of <code class="language-plaintext highlighter-rouge">cwnd</code> bytes.</li>
</ul>

<p>Graphically, your window size now is restricted by <code class="language-plaintext highlighter-rouge">cwnd</code>, so that you cannot send more than that:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211108140521422.png" alt="image-20211108140521422" style="zoom: 80%;" /></p>

<hr />

<p><strong>Perceiving the Congestion</strong></p>

<p>Then the problem is to ==decide what <code class="language-plaintext highlighter-rouge">cwnd</code>== we should take.</p>

<p>First, define that <strong>“loss event”</strong> at a TCP sender as the occurrence of either a timeout or the receipt of three duplicate ACKs from the receiver.</p>

<p>Then basically we have two scenarios:</p>

<ul>
  <li><strong>Congestion happens</strong>: We know that <strong>congestion will cause the loss event to happen</strong>, either due to large delay -&gt; timeout, or to full buffer at router -&gt; packet loss.
    <ul>
      <li>decrease the <code class="language-plaintext highlighter-rouge">cwnd</code> window</li>
    </ul>
  </li>
  <li><strong>Everything is Good</strong>: we receive <code class="language-plaintext highlighter-rouge">ACK</code>s as expected. So we can increase the congestion window size using <code class="language-plaintext highlighter-rouge">ACK</code> received
    <ul>
      <li>If <code class="language-plaintext highlighter-rouge">ACK</code> arrives fast, then <code class="language-plaintext highlighter-rouge">cwnd</code> increases fast</li>
      <li>if <code class="language-plaintext highlighter-rouge">ACK</code> arrives slow, then <code class="language-plaintext highlighter-rouge">cwnd</code> increases slow</li>
    </ul>
  </li>
</ul>

<p>Exactly what is the increasing rate and the decreasing rate of the <code class="language-plaintext highlighter-rouge">cwnd</code> window is implementation/algorithm dependent.</p>

<blockquote>
  <p><strong>Take-Away Message</strong></p>

  <table>
    <thead>
      <tr>
        <th>Situation</th>
        <th>Desired Action</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>A lost segment - congestion</td>
        <td>TCP sender’s rate should be decreased when a segment is lost</td>
      </tr>
      <tr>
        <td>An <code class="language-plaintext highlighter-rouge">ACK</code> received</td>
        <td>Sender’s rate can be increased when an ACK arrives for a previously unacknowledged segment</td>
      </tr>
    </tbody>
  </table>

  <p>Therefore, the overall approach is to do some <strong>bandwidth probing</strong></p>

  <ul>
    <li>adjusting its transmission rate is to increase its rate in response to arriving ACKs ==until a loss event occurs==</li>
  </ul>
</blockquote>

<h4 id="tcp-congestion-control-algorithms">TCP Congestion-Control Algorithms</h4>

<p>The algorithm has three major components:</p>

<ol>
  <li>slow start</li>
  <li>congestion avoidance</li>
  <li>fast recovery</li>
</ol>

<p>In many different variants of the algorithm, Slow start and congestion avoidance are mandatory components, but the ==difference== is in <strong>how they increase the size of <code class="language-plaintext highlighter-rouge">cwnd</code></strong> in response to received ACKs.</p>

<h5 id="component-slow-start">Component: Slow Start</h5>

<p>This describes the initial probing process when the sender knows nothing yet about the network.</p>

<ol>
  <li>
    <p>the value of <code class="language-plaintext highlighter-rouge">cwnd </code>is typically initialized to a small value of <strong>1 MSS</strong>. Therefore, the sending rate is approximately $\text{MSS}/\text{RTT}.$</p>
  </li>
  <li>
    <p>the value of <code class="language-plaintext highlighter-rouge">cwnd</code> <strong>increases by 1 MSS</strong> every time a transmitted segment is first <strong>acknowledged</strong>.</p>

    <ul>
      <li>i.e. we have a ==exponential== increase (not linear)</li>
    </ul>

    <p>graphically, this looks like</p>

    <p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211108142335426.png" alt="image-20211108142335426" style="zoom: 67%;" /></p>
  </li>
</ol>

<p>Now, slow start <strong>ends</strong> in the following three scenario:</p>

<ol>
  <li>If a timeout event occurs, then it sets a <strong>variable <code class="language-plaintext highlighter-rouge">ssthresh</code></strong> to $\text{cwnd}/2$, which is half of the value of <code class="language-plaintext highlighter-rouge">cwnd</code> ==when== the loss occurred. Then, set <code class="language-plaintext highlighter-rouge">cwnd=1</code> and start anew.</li>
  <li>If <code class="language-plaintext highlighter-rouge">cwnd</code> get larger to equal to <code class="language-plaintext highlighter-rouge">ssthresh</code>, it is not a good idea to continuous doubling so we switch to <strong>congestion avoidance</strong>, where you increase the <code class="language-plaintext highlighter-rouge">cwnd</code> in a more cautious manner.</li>
  <li>If three duplicate <code class="language-plaintext highlighter-rouge">ACK</code> is received, then you perform a fast retransmit and switch to the <strong>fast recovery</strong> state.</li>
</ol>

<p>Therefore, the ==full algorithm== can be also summarized in the FSM:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211108143509607.png" alt="image-20211108143509607" /></p>

<p>where you actually start with a non-zero <code class="language-plaintext highlighter-rouge">ssthresh</code>.</p>

<h5 id="component-congestion-avoidance">Component: Congestion Avoidance</h5>

<p>Remember that on entry to the congestion-avoidance state, t==he value of <code class="language-plaintext highlighter-rouge">cwnd </code>is approximately half== its value when congestion was last encountered. ==Congestion could be just around the corner==!</p>

<p>Therefore, here we actually pursue a more conservative, linear increase by:</p>

<ul>
  <li>
    <p>increases the value of <code class="language-plaintext highlighter-rouge">cwnd</code> by just a single MSS <strong>every RTT</strong> (instead of every <code class="language-plaintext highlighter-rouge">ACK</code>). The net result is you basically peform:</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cwnd += MSS * (MSS/cwnd)
</code></pre></div>    </div>

    <p>where notice that <code class="language-plaintext highlighter-rouge">(MSS/cwnd)</code> is the same as 1 over the number of segments sent within an RTT</p>
  </li>
  <li>
    <p>the result is having an actual linear increase in <code class="language-plaintext highlighter-rouge">cwnd</code></p>
  </li>
</ul>

<p>Finally, this increase <strong>ends</strong> in a similar manner as the slow start:</p>

<ol>
  <li>
    <p>a <strong>timeout</strong> occurs t: The value of <code class="language-plaintext highlighter-rouge">cwnd</code> is set to 1 MSS, and the value of <code class="language-plaintext highlighter-rouge">ssthresh</code> is updated to half the value of <code class="language-plaintext highlighter-rouge">cwnd</code> when the loss event occurred. (same as slow start)</p>
  </li>
  <li>
    <p>a <strong>triple duplicate <code class="language-plaintext highlighter-rouge">ACK</code></strong> occurs, here it is different. Because this is at least an indication of the network is <em>continuing to deliver some segments</em> from sender to receiver, the reaction is ==less dramatic to a timeout.==</p>

    <p>TCP halves the value of <code class="language-plaintext highlighter-rouge">cwnd </code>(adding in 3 MSS for good measure to account for the triple duplicate ACKs received) and records the value of <code class="language-plaintext highlighter-rouge">ssthresh </code>to be half the value of <code class="language-plaintext highlighter-rouge">cwnd</code> when the triple duplicate ACKs were received.</p>
  </li>
</ol>

<h5 id="component-fast-recovery">Component: Fast Recovery</h5>

<p>Here, the value of <code class="language-plaintext highlighter-rouge">cwnd</code> is increased by 1 MSS for every ==duplicate ACK== received for the ==missing segment== that caused TCP to enter fast-recovery.</p>

<p>Then a transition/recovery is done when:</p>

<ol>
  <li>an normal ==ACK== arrives for the ==missing segment==, TCP enters back the <strong>congestion avoidance</strong></li>
  <li>a <strong>timeout</strong> occurs, then fast recovery transitions to the <strong>slow-start</strong> state after performing the same actions as in slow start and congestion avoidance.</li>
</ol>

<blockquote>
  <p><strong>Note</strong></p>

  <ul>
    <li>Fast recovery is a recommended, but not required, component of TCP</li>
  </ul>
</blockquote>

<hr />

<p><em>Example</em>: TCP Tahoe and TCP Reno.</p>

<p>Basically Reno implemented the Fast Recovery, where Tahoe didn’t and just cuts the <code class="language-plaintext highlighter-rouge">cwnd=1</code> every time when a timeout occurs.</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211108145250921.png" alt="image-20211108145250921" style="zoom:67%;" /></p>

<p>then, the comparison is shown here:</p>

<ul>
  <li>in the beginning up to the 8-th tranmission round, performance is the same</li>
  <li>at the 4-th transmission, <strong>both entered congestion avoidance state</strong>.</li>
  <li>when at the 8-th transmission round, a <strong>loss (triple ACK)</strong> occurred, Tahoe cuts to <code class="language-plaintext highlighter-rouge">cwnd=1</code> the next round while Reno has $0.5\cdot 12 + 3=9$ as <code class="language-plaintext highlighter-rouge">cwnd</code>  and then grows linearly.
    <ul>
      <li>both still has the <code class="language-plaintext highlighter-rouge">ssthresh</code> to be $0.5 \cdot 12=6$. So Reno then immediately enters congestion avoidance</li>
    </ul>
  </li>
</ul>

<h5 id="summary-aimd">Summary: AIMD</h5>

<p>The TCP congestion control algorithm can be summarized in the FSM</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211108143509607.png" alt="image-20211108143509607" /></p>

<p>But additionally, if we <strong>ignore the initial slow start period</strong> and ==assuming losses is only triple duplicates== (i.e. no timeouts, never went back to slow start), then you ==always== are either increasing linearly or halving the <code class="language-plaintext highlighter-rouge">cwnd</code>:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211108150006291.png" alt="image-20211108150006291" style="zoom:67%;" /></p>

<p>Therefore, TCP congestion control is often referred to as an <strong>additive-increase, multiplicative decrease</strong> (AIMD) form of congestion control.</p>

<blockquote>
  <p><strong>Why AIMD works out in reality?</strong></p>

  <p>AIMD – a <strong>distributed</strong>, asynchronous algorithm – has been shown to:</p>

  <ul>
    <li>
      <p>there is almost no shared information needed across users, except perhaps for sharing the same multiplicate constant $\beta$</p>
    </li>
    <li>
      <p>optimize congested flow rates network wide!</p>
    </li>
    <li>
      <p>have desirable stability properties</p>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Note</strong></p>

  <p>If we were to draw the performance graph, the one similar to economics</p>

  <p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211115090713999.png" alt="image-20211115090713999" style="zoom:50%;" /></p>

  <p>basically here we have two important lines:</p>

  <ul>
    <li>fairness line so the bandwidth is the same</li>
    <li>full utilization line</li>
  </ul>

  <p>Then, what AIMD does is basically:</p>

  <p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211115090741987.png" alt="image-20211115090741987" style="zoom:50%;" /></p>

  <p>where we start with <em>non-equable/efficient</em> usage, but:</p>

  <ul>
    <li>
      <p>when we are probing, there is a multiplicative increase so the gradient is $1$.</p>
    </li>
    <li>when overutilization occurs, we get $u_1/\beta, u_2/\beta$, for $\beta$ being the constant used in the multiplicate decrease, so that they go close to the line joining with point $0,0$</li>
    <li>eventually it oscillates towards the “best point”</li>
    <li>this works for $N$ dimensions, so it scales</li>
  </ul>
</blockquote>

<h5 id="tcp-cubic">TCP CUBIC</h5>

<p>This is <strong>another algorithm</strong> that slightly tweaks the classical implementation, and turns out to ==work better== and gets used today most often.</p>

<blockquote>
  <p><strong>Heuristics</strong></p>

  <ul>
    <li>cutting the sending rate in half and increasing lineally could be <strong>overly cautious</strong>? Perhaps the linear increase part could be done quicker to utilize the internet more?</li>
  </ul>
</blockquote>

<p>Graphically, CUBID does the same thing for <strong>slow start</strong> and <strong>fast recovery</strong>, but ==differs in congestion avoidance==, resoling in:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211108095152573.png" alt="image-20211108095152573" style="zoom: 67%;" /></p>

<p>where:</p>

<ul>
  <li>the area difference is the <strong>gain in network bandwidth</strong>.</li>
  <li>this is ==employed often in reality==</li>
</ul>

<p>In more details, it basically use a <strong>cubic</strong> increase instead of a linear increase. The idea is actually simple, so for <strong>congestion avoidance</strong>:</p>

<ul>
  <li>Let $W_{max}$ be the TCP’s congestion <code class="language-plaintext highlighter-rouge">cwnd</code> when a loss is detected. Let $K$ be the ==estimated time== you will reach another $W_{max}$ in the future.</li>
  <li>CUMIC <strong>increases</strong> the congestion window as a function of $(t-K)^3$ (along with several tunable parameters)</li>
  <li>Since it is a cubic function, as $t$ exceeds $K$, CUBIC can ==more quickly find a new operating point== if the congestion level of the link that caused loss has changed ==significantly==</li>
</ul>

<p>Graphically:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211108150849139.png" alt="image-20211108150849139" style="zoom:80%;" /></p>

<p>where, again ==assuming loss = triple duplicate==:</p>

<ul>
  <li>when $t &lt; K$, the rate increases as $(t-K)^3$, hence reaches $W_{max}$ faster</li>
  <li>when it turns out $t &gt; K$ and our network is still good, we want to find out the new limit. Cubic function increases/find it <em>fast</em> when the new congestion level has changed <strong>significantly</strong>.</li>
</ul>

<h2 id="network-assisted-and-delay-based-algorithm">Network Assisted and Delay-Based Algorithm</h2>

<p>One problem with AIMD is that, we basically takes action <strong>when the packet is drop = after buffer is full</strong>. But what is perhaps ==better== is to just be careful when ==buffer is about to be full==, so we avoid packet loss which causes <em>loss detection/recovery to take a long time</em>.</p>

<ul>
  <li>this is these are recent changes to the TCP algorithm when the network layer are revamped</li>
  <li>they basically either build on top of the AIMD principle we discussed before, both basically aims to ==detect congestion BEFORE packet loss occurs==.</li>
</ul>

<h3 id="explicit-congestion-notification">Explicit Congestion Notification</h3>

<blockquote>
  <p><strong>ECN</strong> basically lets ==routers== use an <code class="language-plaintext highlighter-rouge">ECN</code> bit to indicate congestion (close to full packet). Then the sender should treat that <code class="language-plaintext highlighter-rouge">ECN</code> the same as a loss packet by reducing the window size to half - preventing from packet loss.</p>
</blockquote>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211115152538360.png" alt="image-20211115152538360" /></p>

<p>where, after a sender (Host A) sent something:</p>

<ol>
  <li>
    <p>when a router along the path congested (about to be full), it sets the <code class="language-plaintext highlighter-rouge">ECN</code> bit to 1 of all packets in the buffer in a probabilistic manner</p>

    <ul>
      <li>
        <p>deciding on when a router “is congested” is implementation dependent</p>
      </li>
      <li>
        <p>the first bit of <code class="language-plaintext highlighter-rouge">ECN</code> is to inform routers whether if sender/receiver is <code class="language-plaintext highlighter-rouge">ECN</code> capable (==TODO: not sure if true==)</p>
      </li>
      <li>
        <p>the probabilistic maner means it sets all packets with <code class="language-plaintext highlighter-rouge">ECN=11</code> with a probability of $p$ defined as:</p>

\[\frac{R}{N} =\frac{c}{\mathrm{RTT}\sqrt{p}}\]

        <p>where:</p>

        <ul>
          <li>$R$ is the bandwidth it has, $N$ is the number of users using it. So $R/N$ is the ideal/fair throughput per user</li>
          <li>the RHS is the real life approximated throughput per user, with $p$ being the probability of packet loss, $c$ being some constant</li>
          <li>so the more the user $N$, the higher the computed $p$, the more packets will be marked with <code class="language-plaintext highlighter-rouge">ECN=11</code></li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>when the receiver received the packet, if the <code class="language-plaintext highlighter-rouge">ECN</code> is set to 1, it <strong>also</strong> sets the <code class="language-plaintext highlighter-rouge">ECE</code> (explicit congestion echo) bit to 1 to <strong>inform the sender</strong></p>
  </li>
  <li>
    <p>when the sender received the <code class="language-plaintext highlighter-rouge">ACK</code> with <code class="language-plaintext highlighter-rouge">ECE=1</code>, it does a multiplicative decrease by halving the window (as if in fast retransmit)</p>

    <ul>
      <li>the sender also sets the <code class="language-plaintext highlighter-rouge">CWR </code>(Congestion Window Reduced) bit in the header of the next transmitted TCP sender-to-receiver segment</li>
    </ul>
  </li>
</ol>

<blockquote>
  <p><strong>Note</strong></p>

  <ul>
    <li>this is network assisted because the router needs to do things: <strong>routers</strong> need to have the <strong>network layer/IP</strong> with the two bits <code class="language-plaintext highlighter-rouge">ECN</code> set.</li>
    <li>since we avoid packet losses, we could achieve a shorter overall delay as well (by avoiding costly packet loss and retransmission). So this principle is also employed in transport protocols used in Data Centers.</li>
    <li>this scales since router <strong>itself</strong> doesn’t need to do too much work.</li>
  </ul>
</blockquote>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211115092522354.png" alt="image-20211115092522354" /></p>

<h3 id="delay-based-congestion-control">Delay-Based Congestion Control</h3>

<p>Similar to the above, the aim is to proactively detect congestion onset <strong>before packet loss occurs</strong>/full buffer. However, this is ==not network assisted==, so everything is done at the sender.</p>

<p>Basically:</p>

<ol>
  <li>
    <p>Sender measures the RTT of the source-to destination path for all acknowledged packets</p>
  </li>
  <li>
    <p>compute the minimum $\mathrm{RTT}_\min$, which represents the case with low congestion and low queuing delay</p>
  </li>
  <li>
    <p>compute the <strong>uncongested throughput</strong> rate to be:</p>

\[\frac{\mathrm{cwnd}}{\mathrm{RTT}_\min}\]
  </li>
  <li>
    <p>so if current throughput is <em>close</em> to that, <em>increase</em> your $\mathrm{cwnd}$, i.e. network is uncongested now. Otherwise, if it is significantly less than it, decrease the sending rate similarly by doing multiplicative decrease.</p>
  </li>
</ol>

<h2 id="fairness">Fairness</h2>

<p>First let us consider the world with TCP only.</p>

<blockquote>
  <p><strong>Fairness</strong></p>

  <p>Suppose we have $K$ TCP connections, but all passing through a <strong>bottleneck</strong> link with transmission rate $R$ bps.</p>

  <p>Then a control mechanism is said to be <strong>fair</strong> if the average transmission rate of each user is $R/K$.</p>
</blockquote>

<p>We can illustrate the above concept in a 2D example that easily generalizes into $K$ dimension:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211115162225090.png" alt="image-20211115162225090" style="zoom:80%;" /></p>

<p>Now, let us investigate if the TCP algorithms covered above are fair/efficient.</p>

<hr />

<p><strong>TCP AIMD</strong></p>

<p>Assume that we have two connections, and they have the <strong>same MSS and RTT</strong> (so that if they have the same congestion window size, then they have the same throughput). And suppose we ignore the slow start, such that they start at point $A$ in the graph below.</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211115162758281.png" alt="image-20211115162758281" /></p>

<p>then notice that:</p>

<ul>
  <li>when they are below the efficiency line, they do <strong>additive increase</strong>, each increase by 1 MSS = ==parallel to the $[1,1]^T$ vector==.</li>
  <li>when they experience loss above the efficiency line, they do <strong>multiplicate decrease</strong> of reducing window size of half. Hence this basically is ==halving the $\vec{OB}$ vector==.</li>
</ul>

<p>After some iterations, AIMD will oscillate along the fairness line, so it is a fair algorithm in this condition.</p>

<blockquote>
  <p><strong>Note</strong></p>

  <ul>
    <li>This works iff the RTT is the same. In general, those sessions with a <strong>smaller RTT are able to grab the available bandwidth</strong> at that link more quickly as it becomes free. Hence client-server applications can thus obtain very <strong>unequal</strong> portions of link bandwidth.</li>
  </ul>
</blockquote>

<h3 id="fairness-and-udp">Fairness and UDP</h3>

<p>Many multimedia applications, such as Internet phone and video conferencing, often do not run over TCP for this very reason above. So they use UDP because they <strong>do not want their transmission rate throttled</strong>!</p>

<p>Now the question is, is UDP fair when we have both TCP and UDP?</p>

<p>The answer is no, because:</p>

<ul>
  <li>When running over UDP, applications can pump their audio and video into the network <strong>at a constant rate</strong> (at the expense of occasionally lose packets)</li>
  <li>therefore, since <strong>UDP does not decrease transmission rate</strong> during congestion <strong>but TCP will</strong>, it is possible for UDP sources to crowd out TCP traffic.</li>
</ul>

<p>(But luckily, there are a number of congestion-control mechanics that prevents UDP from taking over TCP.)</p>

<h3 id="fairness-and-parallel-tcp">Fairness and Parallel TCP</h3>

<p>Even if UDP gets to be forced to behave fairly, there is another way to “rob bandwidth”: using multiple parallel connections.</p>

<p>Therefore obviously this is not being fair as well and needs to be considered:</p>

<ul>
  <li>suppose there were only two user, each has only one connection. Then with bottleneck router of bandwidth $R$, each user gets $R/2$</li>
  <li>A new user joins in but opens <strong>2 parallel TCP connection</strong>. Now the router would give $R/4$ <strong>per connection</strong>! This gives the third user an overall $R/2$ bandwidth but the other 2 only $R/4$.</li>
</ul>

<h2 id="evolving-transport-layer-functionality">Evolving Transport Layer Functionality</h2>

<p>Up to know we discussed mainly TCP and UDP.</p>

<p>Over times, we have identified circumstances in which <strong>neither is ideally suited</strong>, and so the design and implementation of transport layer functionality has continued to <strong>evolve</strong>.</p>

<p>For example:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211115094626231.png" alt="image-20211115094626231" style="zoom: 50%;" /></p>

<p>So over times, as we have seen before, there are many variations to a TCP protocol, and now perhaps the only common features of these protocols is that they use the TCP segment format.</p>

<h3 id="quic-quick-udp-internet-connections">QUIC: Quick UDP Internet Connections</h3>

<p>This is an popular evolving protocol in place of TCP for HTTP. QUIC is a new application-layer protocol designed from the ground up to <strong>improve the performance of transport-layer services for secure HTTP</strong>.</p>

<ul>
  <li>Google has deployed QUIC on many of its public-facing Web servers, in its mobile video streaming YouTube app, in its Chrome browser, etc.</li>
  <li>technically, QUIC is an application protocol, but it is interesting how it <strong>implements some features of TCP</strong>, and then use UDP for transport layer</li>
</ul>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211115170016989.png" alt="image-20211115170016989" /></p>

<p>Some features of QUIC in the <strong>application layer</strong> include:</p>

<ul>
  <li>
    <p><strong>Connection-Oriented and Secure</strong>: now it basically does handshake in application layer, where it combines the handshake for <em>connection establishment</em> AND <em>authentication + encryption</em> (see Figure 3.58 (a)). Hence, it only needs to do one handshake, which speeds up the connection establishment procedure.</p>

    <p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211115170339000.png" alt="image-20211115170339000" /></p>
  </li>
  <li><strong>Streams</strong>: QUIC allows several different application-level “==streams==” to be multiplexed through a single QUIC connection, and once a QUIC connection is established, new streams can be quickly added. This basically solves the Head of Line problem mentioned in HTTP 1.1.
    <ul>
      <li>Each connection has a connection ID (established during the handshake), and each stream within a connection has a stream ID; <strong>both of these IDs are contained in a QUIC packet header</strong></li>
      <li>Then, data from multiple streams may be contained within a single QUIC segment, which is carried over UDP.</li>
      <li>Hence, the separate streams also solves the HOL blocking when a packet is lost, i.e. in the HTTP1.1 case, all the other HTTP request packets are delayed/have to wait. However, with QUIC we have packers delivered per-stream basis, a lost UDP segment <strong>only impacts those streams whose data was carried in that segment</strong>; HTTP messages in ==other streams can continue to be received== and delivered to the application.</li>
    </ul>
  </li>
  <li><strong>Reliable, TCP-friendly congestion control</strong>: QUIC provides reliable data transfer ==to each QUIC stream separately==.
    <ul>
      <li>Reliability is the same as TCP <code class="language-plaintext highlighter-rouge">ACK</code> mechanism</li>
      <li>Congestion control is based on TCP NewReno [RFC 6582] - a slight modification to the TCP Reno protocol (see <a href="#Component: Fast Recovery">Component: Fast Recovery</a>)</li>
    </ul>
  </li>
</ul>

<p>Overview of QUIC protocol architecture:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211115170556343.png" alt="image-20211115170556343" /></p>

<p>Finally, the advantage of application layer protocol is that <strong>changes can be made to QUIC at “application-update timescales,”</strong> that is, much faster than TCP or UDP update timescales.</p>

<h1 id="chapter-4-network-layer-data-plane">Chapter 4 Network Layer: Data Plane</h1>

<p>Now basically we deal with IP address: given a message, deliver a message <strong>from an IP address to another IP address</strong></p>

<ul>
  <li>in transport layer, it delivers from one port to another port</li>
  <li>in application layer, it delivers from one process to another process</li>
</ul>

<blockquote>
  <p><strong>Note</strong></p>

  <p>Remember that Physical, Link, Network Protocol is implemented on all devices, where as Transport and Application Layer is only on end devices.</p>
</blockquote>

<p>Basically we want to discuss host-to-host communication service: how do ==packets go from one host to another==.</p>

<p>The network layer is actually a complicated one, so we will <strong>cover it in two goes</strong>:</p>

<ul>
  <li>==data plane== functions of the network layer — the per-router functions in the network layer that determine how a datagram (that is, a network-layer packet) arriving on one of <strong>a router’s input links is forwarded to one of that router’s output links</strong>.</li>
  <li>==control== plane functions of the network layer—the network-wide logic that controls how a datagram is <strong>routed among routers along an end-to-end path</strong> from the source host to the destination host</li>
</ul>

<h2 id="overview">Overview</h2>

<p>Also notice that now we are at the ==network core==:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211120125452780.png" alt="image-20211120125452780" style="zoom:80%;" /></p>

<p>where:</p>

<ul>
  <li>routers (the round ones) are in <strong>Network Layer</strong> (our focus)</li>
  <li>switches (the squared ones) are in <strong>Link Layer</strong></li>
</ul>

<p>The upshot is that basically a router/network layer has to do ==two things==. Suppose you are at R1 and want to send stuff eventually to H2:</p>

<ol>
  <li><strong>Routing</strong>: you need to <strong>determine which next router to send to</strong>. (Routing Algorithm is in the control plane)
    <ul>
      <li>==Network-wide== process. Takes place on much longer timescales (typically seconds), and as we will see is often implemented in software.</li>
    </ul>
  </li>
  <li><strong>Forwarding</strong>: once you determined which next hop is, <strong>move the packet</strong> to the appropriate output link (this is covered here)
    <ul>
      <li>this sounds easy, but we need to do it as efficiently as possible</li>
      <li>==Router-Local== process. Forwarding takes place at very short timescales (typically a few nanoseconds), and thus is typically implemented in hardware</li>
    </ul>
  </li>
</ol>

<p>In particular, the data plane switches packet by using a key element in every network router is its ==forwarding table==:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211120131229860.png" alt="image-20211120131229860" style="zoom:80%;" /></p>

<ol>
  <li>examining the value of one or more fields in the arriving packet’s header (e.g. IP address)</li>
  <li>use the headers to index into the table and decide which router to send to</li>
</ol>

<h3 id="quick-overview-of-control-plane">Quick Overview of Control Plane</h3>

<p>Though it is not the focus here, it is good to know what it does on a high level.</p>

<p>Basically the routing algorithm needs to figure out the ==content of the forward table==.</p>

<p>The traditional approach:</p>

<ul>
  <li>A a <strong>routing algorithm runs in each and every router</strong> and both forwarding and routing functions are contained within a router. Routing algorithm function in one router ==communicates== (via routing protocol) with the routing algorithm function in other routers to compute the values for its forwarding table
    <ul>
      <li>so basically it is again a <strong>distributed</strong> algorithm that each router runs</li>
    </ul>
  </li>
  <li>this has the advantage of you yourself can <em>adjust your router’s algorithm</em> to take into account some policies, such as minimize the cost of money</li>
</ul>

<p>The modern Software-Defined Approach (SDN):</p>

<ul>
  <li>A physically separate, remote controller computes and distributes the forwarding tables to be used by each and every router</li>
  <li>This is quite common in Data Centers: routing device performs <strong>forwarding only</strong>, while the remote controller computes and distributes forwarding tables.
    <ul>
      <li>therefore, it is <em>less flexible</em> as it is a more <strong>localized</strong> setup, but it is <em>more efficient</em> if you are using it ==within your own network== (e.g. the data center network)</li>
    </ul>
  </li>
  <li>network is “software-defined” because the controller that computes forwarding tables and interacts with routers is implemented in software.</li>
</ul>

<p>Graphically, the SDN looks like:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211120131122215.png" alt="image-20211120131122215" style="zoom:80%;" /></p>

<p>note that:</p>

<ul>
  <li>the remote controller is <strong>not directly connected to each router</strong>. To send the forward tables to the router, we need ==routing itself to work to reach those routers from the controller==. So if there is a failure, updates cannot be pushed to the router. This will basically becomes quite complicated.</li>
  <li>Again, the details will be covered in Chapter 5.</li>
</ul>

<h3 id="overview-of-services">Overview of Services</h3>

<p>Here we consider some <strong>potential services</strong> that a network layer can provide:</p>

<ul>
  <li>Guaranteed delivery</li>
  <li>Guaranteed delivery with Bounded Delay</li>
  <li>In-order packet delivery</li>
  <li>Guaranteed Minimal Bandwidth</li>
  <li>Security</li>
</ul>

<p>However, in reality, the ==Internet’s network layer== provides basically none of them:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211120133357559.png" alt="image-20211120133357559" /></p>

<p>But it kind of works because</p>

<ul>
  <li>
    <p>the Internet’s basic best-effort service model combined with adequate bandwidth provisioning and bandwidth-adaptive application-level protocols such as the DASH protocol we encountered in Section 2.6.2 have arguably proven to be more than “<strong>good enough</strong>” to enable an amazing range of applications. Also:</p>
  </li>
  <li>
    <p><strong>simplicity</strong> makes it widely adopted (hence easy to scale as well, e.g. CDNs)</p>
  </li>
</ul>

<p>Yet there are ofc algorithms that implements some of the service, but in reality the best effort one is the best</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211120133948532.png" alt="image-20211120133948532" /></p>

<h2 id="inside-a-router">Inside A Router</h2>

<p>let’s turn our attention to its forwarding function—the actual <strong>transfer of packets from a router’s incoming links to the appropriate outgoing links</strong> at that router.</p>

<p>First of all, a clarification of our previous abstraction:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211120134706510.png" alt="image-20211120134706510" style="zoom:67%;" /></p>

<p>basically we don’t have bidirectional links in reality between two routers.</p>

<p>Now, it makes sense that a router has <strong>four components</strong></p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211120134925531.png" alt="image-20211120134925531" /></p>

<p>where here we assumed the router is connected to two routers, so we have two pairs of input/output port</p>

<ul>
  <li><strong>Switching fabric</strong>. The switching fabric connects the router’s input ports to its output ports. This must be fast so that we can fast fast internet</li>
  <li><strong>Routing processor</strong> performs control-plane functions, e.g. by running routing algorithms and etc.
    <ul>
      <li>basically this is for computing the look-up table. It will not interfere with the performance of switching in data plane.</li>
    </ul>
  </li>
  <li><strong>Input port</strong> and <strong>Output port</strong> will be covered below.</li>
  <li>notice that usually the forwarding plane here needs to operate as fast as possible! (much faster than control plane - routing algorithm)</li>
</ul>

<h3 id="input-port-processing">Input Port Processing</h3>

<p>A more detailed view of input processing is shown in Figure below.</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211120140008502.png" alt="image-20211120140008502" /></p>

<p>where basically the important part is the red part</p>

<ul>
  <li>
    <p>input port’s line-termination function and link-layer processing implement the <strong>physical and link layers</strong> for that individual input link</p>
  </li>
  <li>
    <p>==lookup== performed in the input port is central to the router’s operation—it is here that the router uses the <strong>forwarding table to look up the output port</strong> to which an arriving packet will be forwarded via the switching fabric</p>
  </li>
</ul>

<p>Let’s now consider the “simplest” case that the output port to which an incoming packet is to be switched is based on the packet’s destination address, i.e. the 32-bit IP. Then the table looks like:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211120140310107.png" alt="image-20211120140310107" style="zoom: 33%;" /></p>

<p>where note that:</p>

<ul>
  <li>a brute force approach is to have an entry for <em>each IP address</em>, then there are $2^{32}$ options which is too large to store</li>
  <li>if you use a range, the problem is what if those ranges <strong>don’t divide up so nicely</strong>?</li>
</ul>

<blockquote>
  <p><strong>Note</strong></p>

  <ul>
    <li>If you are on Columbia network, you will notice that all your devices’ IP has the form <code class="language-plaintext highlighter-rouge">160.39.xxx.xxx</code>. In fact, those IP are distributed/granted for Columbian students to use are given in <strong>blocks</strong>: any $2^{16}$ addresses within <code class="language-plaintext highlighter-rouge">160.39.0.0</code> to <code class="language-plaintext highlighter-rouge">160.39.255.255</code> are allowed to use.</li>
    <li>This also means that for ==some== of the routers, all it matters is to determine where <code class="language-plaintext highlighter-rouge">160.39.xxx.xxx</code> should go! This is useful because:
      <ul>
        <li><strong>saves space</strong> in forwarding table, i.e. less entries</li>
        <li><strong>routing decision can be made quicker</strong> only on those prefixes</li>
      </ul>
    </li>
  </ul>
</blockquote>

<p>Now, suppose the ranges don’t divide up so nicely, e.g. in a private network. Then:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211120141845962.png" alt="image-20211120141845962" style="zoom:80%;" /></p>

<p>The router can perform a ==longest prefix match==:</p>

<ul>
  <li>e.g. if you have an IP of <code class="language-plaintext highlighter-rouge">1100xxxx xxxxxxx 00010000 00000101</code>, then 3 will be returned as it has the <strong>longest match</strong></li>
</ul>

<p>Therefore, we see that router just need to <strong>store prefixes</strong>, and <strong>perform a longest prefix match</strong>. So routing table usually looks like this:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211120142231883.png" alt="image-20211120142231883" style="zoom: 50%;" /></p>

<p>where notice that the length of prefix is variable, up to 32 bits.</p>

<p><strong>Note that</strong>, at Gigabit transmission rates, this lookup must be performed in ==nanoseconds== (e.g. for a 10 Gbps link and a 64-byte IP datagram, each packet needs to be sent within around 6 nanoseconds). Therefore, we need some fast hardware for <strong>memory access time</strong></p>

<ul>
  <li>this results in designs with embedded <strong>on-chip DRAM</strong> and faster SRAM (used as a DRAM cache) memories. In practice, ==Ternary Content Addressable Memories (TCAMs)== are also often used for lookup.
    <ul>
      <li>TCAM is expensive, but it can retrieve addresses ==in one clock cycle regardless of table size==!</li>
      <li>i.e. when an IP address is given to TCAM, it gives you the link interface in one clock answer</li>
    </ul>
  </li>
</ul>

<p>Now, once you determine the output port/interface, you give it to switching fabric to do the actual switching</p>

<blockquote>
  <p><strong>Note</strong></p>

  <ul>
    <li>If packets from other input ports are currently using the fabric, a packet may be <strong>temporarily blocked</strong> from entering the fabric. <strong>A blocked packet will be queued at the input port</strong> and then scheduled to cross the fabric at a later point in time.</li>
    <li>Remember that although although “lookup” is arguably the most important action in input port processing, <strong>many other actions must be taken</strong>:
      <ol>
        <li>physical- and link-layer processing must occur, as discussed previously;</li>
        <li>the packet’s version number, checksum and time-to-live field must be checked and the latter two fields rewritten;</li>
        <li>counters used for network management (such as the number of IP datagrams received) must be updated.</li>
      </ol>
    </li>
  </ul>
</blockquote>

<h3 id="switching-fabric">Switching Fabric</h3>

<p>Once a packet’s output port/interface has been determined via the lookup, the packet can be <strong>sent into the switching fabric</strong>. In general, there three popular ways to do the switching:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211120144050113.png" alt="image-20211120144050113" style="zoom: 80%;" /></p>

<p>where</p>

<ul>
  <li>we are interested in their <strong>switching rate</strong>: rate at which packets can be transferred from inputs to outputs
    <ul>
      <li>often measured as multiple input/output line rate (i.e. when we have $N$ input/outputs)</li>
    </ul>
  </li>
  <li>the <strong>slowest</strong> is memory, then bus, and finally now we use Interconnection Network.</li>
</ul>

<h4 id="switching-via-memory">Switching via Memory</h4>

<p>The idea here is simple. Given a packet from a port, and we have a CPU (for the routing processor)</p>

<ol>
  <li>write/copy the entire packet from input buffer into memory
    <ul>
      <li>input port signaled the routing processor via an interrupt</li>
    </ul>
  </li>
  <li>write/copy the packet from memory to the output buffer
    <ul>
      <li>routing processor here ==does the lookup== for the IP address and put it in the correct output buffer</li>
    </ul>
  </li>
</ol>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211120144737088.png" alt="image-20211120144737088" style="zoom:50%;" /></p>

<p>Therefore, for each single switching, we need to do <strong>2 memory operations</strong>.</p>

<h4 id="switching-via-bus">Switching via Bus</h4>

<p>Basically a bus <strong>directly connects all input to all output</strong>. So the idea is that:</p>

<ol>
  <li>==Input does the lookup==, and prepend the result as a header to the packet (switch -internal label)</li>
  <li>That packet is transferred to <strong>all output ports</strong> on the bus</li>
  <li>Each output bus checks the switch-internal label, and keeps the packet if there is a match
    <ul>
      <li>i.e. only one output port will keep the packet in the end</li>
    </ul>
  </li>
  <li>The matched output port removes the label, and you are done</li>
</ol>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211120145352036.png" alt="image-20211120145352036" /></p>

<p>However, similar as above, if multiple packets arrive to the router at the same time, each at a different input port, <strong>all but one must wait</strong> since only one packet can cross the bus at a time.</p>

<h4 id="switching-via-interconnection-network">Switching via Interconnection Network</h4>

<p>Basically we want to be able to do simultaneous things, and the result is to consider the following:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211120150333127.png" alt="image-20211120150333127" /></p>

<p>where if we have $N$ input/output ports, we take $2N$ bus, such that we have $N^2$ ==intersections==. The idea is that each intersection can be ==opened or closed (packet can pass)== at any time by the switch fabric controller (this part of logic is part of the switching fabric itself)</p>

<ul>
  <li>e.g. if you send from $A$ to $Y$, then I just need to close the intersection of $A$ and $Y$ bus, and <strong>send to ALL bus</strong>! (but this time only $Y$ will receive it)</li>
  <li>therefore, if $A$-to-$Y$ and $B$-to-$X$ packets use different input and output busses, there is <strong>no blocking!</strong>
    <ul>
      <li>but if you have $A-Y$ AND $B-Y$, then there is still blocking, i.e. one of them must wait.</li>
    </ul>
  </li>
</ul>

<p>Therefore, this could cause Head of Line blocking</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211122130406451.png" alt="image-20211122130406451" style="zoom: 67%;" /></p>

<p>where basically:</p>

<ul>
  <li>the first packet in the third input port has to WAIT, so the packet destined to the second output port is blocked</li>
  <li>the net result is one of the output port is FREE even if there is a message destined for the second output port (under utilization)</li>
</ul>

<p>In fact, it is shown that due to HOL blocking, the input queue <strong>will grow</strong> to unbounded length (i.e. significant packet loss entails) if the <strong>packet arrival rate on input link reach</strong></p>

\[2-\sqrt{2} \approx 58 \% \text{ of capacity }\]

<p>(basically you waste at least $42\%$ of the capacity)</p>

<p>To solve this issue, consider using virtual queue:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211122132613943.png" alt="image-20211122132613943" /></p>

<p>where now, no more HOL occurs and the for each clock cycle, you have 100% utilization.</p>

<ul>
  <li>you still have queuing, but the utilization is now optimal</li>
</ul>

<hr />

<p>However, we CAN make packets from different input ports to proceed towards the <strong>same output port at the same time</strong> through the ==multi-stage switching fabric==</p>

<h3 id="output-port-processing">Output Port Processing</h3>

<p>Basically we know this already. Output port processing, essentially just need to take whatever that is passed to its output buffer, and transmit it.</p>

<ol>
  <li>takes packets that have been stored in the output port’s memory</li>
  <li>transmits them over the output link.
    <ul>
      <li>This includes selecting (i.e., scheduling) and de-queueing packets for transmission</li>
    </ul>
  </li>
</ol>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211122131403011.png" alt="image-20211122131403011" style="zoom:50%;" /></p>

<h3 id="queueing-in-router">Queueing in Router</h3>

<p>Note that queueing occurs at both Input port AND the output ports. Factors we need to consider here are:</p>

<ul>
  <li>traffic load</li>
  <li>the relative speed of the switching fabric</li>
  <li>and the line speed</li>
</ul>

<p>For instance, if each input port/output port (link) has a transmission rate of $R_{line}$ packets per second. If there are $N$ ports, then the worst case is you have $R_{line}\cdot N$ packets all going for the same output port.</p>

<ul>
  <li>but if your switching fabric has $R_{switch}=R_{line}\cdot N$, then there is <strong>minimal INPUT queuing</strong> in the worst case all data is still placed on output ports. (But output port will have some queueing)</li>
</ul>

<h4 id="input-port-queueing">Input Port Queueing</h4>

<p>Assume we are using crossbar, so multiple packets can be transferred in parallel, as long as their output ports are different. Then, we have:</p>

<ul>
  <li>switch fabric $R_{switch} &lt; R_{line}\cdot N$ is <em>not fast enough</em> to transfer all arriving packets through the fabric
    <ul>
      <li>queuing occurs here regardless if data sent to the same output port or not</li>
    </ul>
  </li>
  <li>Head of line blocking, causes queuing</li>
</ul>

<h4 id="output-port-queueing">Output Port Queueing</h4>

<p>Now suppose the worst case again when all input ports are sending to the <strong>same output port</strong>, and assume each input/output port has a transmission rate of $R$ packets per second.</p>

<p>Then, for that output port:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211122135038751.png" alt="image-20211122135038751" /></p>

<p>where basically:</p>

<ul>
  <li>you get $NR$ messages coming in, but you can only transmit $R$ packets out</li>
  <li>so eventually queues build up at your output port, and if exceeds buffer/memory, packet is lost.</li>
</ul>

<p>Since this is common and often unavoidable, we then need to consider:</p>

<ol>
  <li><strong>Drop Policy</strong>: if no free buffer left, which datagram/packet should we drop?</li>
  <li><strong>Scheduling Discipline</strong>: which queued packet should be sent first for transmission, so that we ensure performance?</li>
</ol>

<h4 id="buffer-length">Buffer Length</h4>

<p>Then the question is how much buffer is good for a port. Given the link capacity coming into/out of the router is $C$, and the average RTT is about $\text{RTT}$, then:</p>

\[\text{buffer length} \approx \frac{\text{RTT}\cdot C}{\sqrt{N}}\]

<p>for $N$ being the number of input/output ports.</p>

<ul>
  <li>notice that this comes from the fact that “more buffering might not be better” as buffering can be used to <strong>absorb short-term statistical fluctuations</strong> in traffic but can also ==lead to increased queuing delay==. (large buffers means larger queueing delay, which might even be worse than dropping packets if you are gaming)</li>
  <li>basically this is to make sure your queuing delay is not too large</li>
</ul>

<hr />

<p><em>For Example</em>:</p>

<p>Consider the setup of a gamer’s house with a router being able to send a packet every $20 ms$. Suppose the RTT to the gaming server is $200ms$, and suppose there is no other queuing delay on the network except for the home router. Then:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211122142202532.png" alt="image-20211122142202532" style="zoom:67%;" /></p>

<ol>
  <li>suppose at $t=0$, router got 25 packets in a burst</li>
  <li>after $t=200ms$, the first ACK comes back, but we only sent $10$ packets</li>
  <li>the next TCP packet is now sent, but it has to <strong>wait for 15 packets in front</strong>! Resulting in some queueing delay due to the buffer size being large.</li>
</ol>

<p>This scenario is also called the Buffer Bloat.</p>

<h3 id="packet-scheduling">Packet Scheduling</h3>

<p>Basically we need to consider the problem of determining the <strong>order which packets are transmitted</strong>. (Also related to which packets to drop)</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211122143327165.png" alt="image-20211122143327165" /></p>

<p>Some basic ideas are:</p>

<ul>
  <li>FCFS</li>
  <li>Priority Queuing</li>
  <li>Round Robin</li>
  <li>Weighted Fair Queue</li>
</ul>

<h4 id="scheduling-fifo">Scheduling: FIFO</h4>

<p>Basically, assume that each packet takes three units of time to be transmitted. Under the FIFO discipline, packets leave in the same order in which they arrived.</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211122143752183.png" alt="image-20211122143752183" /></p>

<h4 id="scheduling-priority">Scheduling: Priority</h4>

<p>Now, sometimes real time application such as Voice communication needs to be transmitted with low latency. In this case, consider splitting packets into different priority (e.g. by looking at which port it comes from).</p>

<p>Then, the idea is to transmit a packet from the <strong>highest priority class that has a nonempty queue</strong> (i.e. low priority only looked at when high priority are all gone - i.e. could be exhausted).</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211122144044968.png" alt="image-20211122144044968" /></p>

<p>where in this example:</p>

<ul>
  <li>Packets 1, 3, and 4 belong to the high-priority class</li>
  <li>packets 2 and 5 belong to the low-priority class</li>
</ul>

<h4 id="scheduling-rr">Scheduling: RR</h4>

<p>Basically, the only difference here is that:</p>

<ul>
  <li>you still have multiple classes</li>
  <li>RR transmit <strong>one packet per class, and moves on next</strong></li>
</ul>

<p>Therefore, assuming we have two classes (e.g. could be priority class):</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211122144326007.png" alt="image-20211122144326007" style="zoom:80%;" /></p>

<p>where again:</p>

<ul>
  <li>packets 1, 2, and 4 belong to class 1, and packets 3 and 5 belong to the second class</li>
  <li>packet 3 is transmitted before packet 2 because RR checks the next class to be fair</li>
</ul>

<h4 id="scheduling-wfq">Scheduling: WFQ</h4>

<p>The principle is basically just a Weighted Round Robin, where you assign a weight $w_i$ to each class representing how important they are, so that class i will then be guaranteed to receive a fraction of service equal to:</p>

\[\frac{w_i}{\sum_i w_i} \text{ of the service time}\]

<p>Therefore, basically it circulates through all the classes but gives more time on more important classes.</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211122144651509.png" alt="image-20211122144651509" /></p>

<p>This is also implemented the most today.</p>

<blockquote>
  <p><strong>Network Neutrality</strong></p>

  <p>The idea of giving weight/class for different classes gives ISP/providers for routers some choices to exploit it:</p>

  <ul>
    <li>prioritize packets from specific IP (e.g. business that paid more)</li>
    <li>charge packets from specific IP more than others (e.g. charge packets from Google less)</li>
    <li>etc</li>
  </ul>

  <p>Those basically gives unfair advantages for some content providers, which is bad, so there are laws that goes against them.</p>
</blockquote>

<h2 id="the-ip-protocol-ipv4-ipv6-and-more">The IP Protocol: IPv4, IPv6 and more</h2>

<p>A roadmap of where we are:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211122145857996.png" alt="image-20211122145857996" /></p>

<p>basically we have discussed how forwarding table works, and now we look at the content of packet in IP protocol.</p>

<h3 id="ipv4-datagram-format">IPv4 Datagram Format</h3>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211122150141727.png" alt="image-20211122150141727" style="zoom: 80%;" /></p>

<p>where basically:</p>

<ul>
  <li><strong>Version number</strong>. These 4 bits specify the IP protocol version of the datagram</li>
  <li><strong>Header length</strong>. Because an IPv4 datagram can contain a variable number of options</li>
  <li><strong>Type of service</strong>. The type of service (TOS) bits were included in the IPv4 header to allow different types of IP datagrams.
    <ul>
      <li>e.g. distinguish real time datagrams from non-real-time traffic</li>
      <li>e.g. the last two TOS bits are used for Explicit Congestion Notification,  ==ECN==.</li>
    </ul>
  </li>
  <li><strong>Datagram length</strong>. This is the total length of the IP datagram (header plus data), measured in bytes.
    <ul>
      <li>Since it is 16 bit, the theoretical maximum size is 65,535 bytes. However, datagrams are rarely larger than 1,500 bytes, which allows an IP datagram to <em>fit in the payload field of a maximally sized Ethernet frame</em></li>
    </ul>
  </li>
  <li><strong>Identifier, flags, fragmentation offset</strong>. These three fields have to do with so-called IP fragmentation. Basically used when reassembling the packet
    <ul>
      <li>.e. configured when it is fragmented, used when reassembling</li>
    </ul>
  </li>
  <li><strong>Time-to-live.</strong> The time-to-live (TTL) field is included to ensure that datagrams do not circulate forever. This is decremented by 1 every time when a router processed the packet</li>
  <li><strong>Protocol</strong>. This field is typically used only when an IP datagram reaches its final destination. The value of this field indicates the ==specific transport-layer protocol== its data field has, e.g. TCP or UDP.</li>
  <li><strong>Header checksum</strong>. The header checksum aids a router in detecting bit errors in a received IP datagram
    <ul>
      <li>notice it is only for the IP headers, not for payload</li>
    </ul>
  </li>
  <li>==Source and destination IP addresses==. When a source creates a datagram, it inserts its IP address into the source IP address field and inserts the address of the ultimate destination into the destination IP address field</li>
  <li><strong>Options</strong>: allow an IP header to be extended. Header options were meant to be used rarely.</li>
  <li>==Data/Payload==: data field of the IP datagram contains the <strong>transport-layer segment</strong> (TCP or UDP) to be delivered to the destination</li>
</ul>

<h3 id="ipv4-addressing">IPv4 Addressing</h3>

<p>First of all, a few terminologies:</p>

<ul>
  <li>
    <p><strong>(Network) Interface</strong>: the boundary between the host and the “physical” link is called an interface.</p>

    <ul>
      <li>e.g. your laptop has two interface, one for Ethernet link, one for Wireless link</li>
      <li>e.g. a router with $N$ input port has $2N$ interfaces.</li>
    </ul>
  </li>
  <li>
    <p>dotted-decimal notation that IP uses:</p>

    <p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211122153023935.png" alt="image-20211122153023935" style="zoom:80%;" /></p>

    <p>where router basically use the <strong>binary form only</strong> (e.g. lookup table)</p>
  </li>
  <li>
    <p><strong>Subnet</strong>: A network that contains connected hosts but with no routers, so hosts talk to each other directly</p>

    <ul>
      <li>for example, the top left network in Figure 4.18 is a subnet, with <code class="language-plaintext highlighter-rouge">233.1.1.0/24</code></li>
    </ul>
  </li>
</ul>

<p>Then, the ==setup== is:</p>

<ul>
  <li>IP address is technically <strong>associated with an interface (one end of a connection)</strong>, not with a host
    <ul>
      <li>e.g. if you have 2 interfaces, you have 2 IP</li>
    </ul>
  </li>
  <li>IP address is not given randomly, a portion of an interface’s IP address will be determined by the ==subnet==</li>
</ul>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211122152557532.png" alt="image-20211122152557532" /></p>

<p>where notice that:</p>

<ul>
  <li>if the top left subnet is defined by <code class="language-plaintext highlighter-rouge">233.1.1.0/24</code>, it means the <strong>first 24 bit is a subnet mask</strong>, that the first 24 bits is shared for interfaces in that network. i.e. all must have the IP of <code class="language-plaintext highlighter-rouge">223.1.1.xxx</code></li>
  <li>An organization is typically assigned a block of contiguous addresses, that is, a range of addresses with a common prefix</li>
</ul>

<p><strong>Classless Interdomain Routing (CIDR)</strong></p>

<ul>
  <li>basically instead of forcing a choice of either 8,16,24 bits for mask, you can now have something like 21 bits for mask. This is so that you can have:
    <ul>
      <li><code class="language-plaintext highlighter-rouge">a.b.c.d/21</code> being the organization’s block</li>
      <li><code class="language-plaintext highlighter-rouge">a.b.c.d/24</code> a specific subnet ==within== the organization</li>
    </ul>
  </li>
</ul>

<p>So the subnet structure of the Figure 4.18 is basically:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211122153553790.png" alt="image-20211122153553790" style="zoom:80%;" /></p>

<p>A more complicated example would be:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211122154229450.png" alt="image-20211122154229450" style="zoom:80%;" /></p>

<p>where now you have 6 subnets.</p>

<hr />

<p>Now, we know how the IP address means. The question is how is it assigned?</p>

<ul>
  <li>how does Host get an IP within a subnet?</li>
  <li>how does the entire network know which IP range to use?</li>
</ul>

<h4 id="obtaining-host-address-dhcp">Obtaining Host Address: DHCP</h4>

<p>Before, those IP address are configured by hand by the network administrator. Now they are automated using DCHP.</p>

<blockquote>
  <p><strong>DHCP</strong> allows a <strong>host</strong> to <strong>obtain (be allocated) an IP address automatically</strong>.</p>

  <ul>
    <li>in fact, it’s a server that also tells your device its <strong>subnet mask</strong>, the address of its <strong>first-hop router</strong> (often called the ==default gateway==, which is different from gateway router), and the address of its <strong>local DNS server</strong></li>
    <li>the IP of gateway router may sound “useless” at this point, but you will see in <a href="#Routing to Another Subnet">Routing to Another Subnet</a> that this will be used for figuring our the MAC address of that router (using ARP broadcast), and then <strong>getting the packet to the router</strong> which connects to the outer world (via ==Link Layer== delivering packets through those switchess)</li>
  </ul>
</blockquote>

<p>DHCP’s <strong>advantage</strong> is that/works because:</p>

<ul>
  <li>
    <p>people tend to spend only limited amount of time using the internet anyway, so permanent IP address is wasteful (since there is only a limited amount of IP addresses)</p>
  </li>
  <li>
    <p>each person’s IP is not important, i.e. we are not well known serves that people need to know our IP beforehand!</p>
  </li>
</ul>

<blockquote>
  <p><strong>DHCP</strong> is a <strong>client-server protocol</strong>.</p>

  <ul>
    <li>A client is typically a newly arriving host wanting to obtain network configuration information, including an IP address for itself.</li>
    <li>In the simplest case, each subnet (in the addressing sense of Figure 4.20) will have a DHCP server. In some other times a router of a subnet can act as a relay to another DCHP server.</li>
  </ul>
</blockquote>

<p>Therefore, when your laptop is connected to a subnet:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211122162927426.png" alt="image-20211122162927426" style="zoom:80%;" /></p>

<p>Detailed steps of what happened is shown here:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211122164318688.png" alt="image-20211122164318688" /></p>

<ol>
  <li><strong>DHCP server discovery</strong>. The first task of a newly arriving host is to find a DHCP server with which to interact. This is done using a DHCP discover message. This is done by a client send a UDP packet to port <code class="language-plaintext highlighter-rouge">67</code>.
    <ul>
      <li>but who to send it to? The client has no idea what IP is even used. This is basically done by a ==broadcasting== message with <code class="language-plaintext highlighter-rouge">dest=255.255.255.255</code> and <code class="language-plaintext highlighter-rouge">source=0.0.0.0</code></li>
    </ul>
  </li>
  <li><strong>DHCP server offer(s)</strong>. A DHCP server receiving a DHCP discover message responds to the client with a DHCP offer message that is ==broadcast to all== (because the client now has no IP)
    <ul>
      <li>therefore, <code class="language-plaintext highlighter-rouge">dest=255.255.255.255:68</code> where port <code class="language-plaintext highlighter-rouge">68</code> is where sender initiated the request</li>
      <li>some important fields here include <code class="language-plaintext highlighter-rouge">your_ip_address=yiaddr</code> which is the offer, and the <strong>lifetime</strong> (after which you need to refresh)</li>
    </ul>
  </li>
  <li><strong>DHCP request.</strong> The newly arriving client will choose from among one or more server offers and respond to its selected offer with a DHCP request message, echoing back the configuration parameters.
    <ul>
      <li>notice it is another ==broadcast== since it needs to tell all DCHP servers.</li>
      <li>also notice that <code class="language-plaintext highlighter-rouge">DCHP Discover</code> has a different transaction ID than <code class="language-plaintext highlighter-rouge">DCHP Request</code></li>
    </ul>
  </li>
  <li><strong>DHCP ACK</strong>. The server responds to the DHCP request message with a DHCP ACK message, confirming the requested parameters.
    <ul>
      <li>this is when you are finally done.</li>
    </ul>
  </li>
</ol>

<blockquote>
  <p><strong>Broadcast IP address</strong></p>

  <ul>
    <li>the IP broadcast address <code class="language-plaintext highlighter-rouge">255.255.255.255</code>. When a host sends a datagram with destination address <code class="language-plaintext highlighter-rouge">255.255.255.255</code>, the message is ==delivered to all hosts on the same subnet==. Routers optionally forward the message into neighboring subnets as well (although they usually don’t).</li>
  </ul>
</blockquote>

<h4 id="obtaining-network-address-address-aggregation">Obtaining Network Address: Address Aggregation</h4>

<p>The Internet’s address assignment strategy is known as Classless Interdomain Routing (CIDR—pronounced cider), which we covered before. Here, we provide an example of <strong>ISP that connects eight organizations</strong> to the Internet, to show how carefully allocated CIDRized addresses facilitate ==routing==.</p>

<ol>
  <li>
    <p>the ISP (which we’ll call Fly-By-Night-ISP) advertises to the outside world that it should be sent any datagrams whose first 20 address bits match <code class="language-plaintext highlighter-rouge">200.23.16.0/20</code>. The rest of the world need not know that within the address block <code class="language-plaintext highlighter-rouge">200.23.16.0/20</code> there are in fact eight other organizations, each with its own subnets.</p>

    <ul>
      <li>This ability to use a single prefix to advertise multiple networks is often referred to as ==address aggregation== (also route aggregation or route summarization).</li>
    </ul>
  </li>
  <li>
    <p>Organization 1 now ==switched the ISP to ISPs-R-Us==</p>

    <p>Then either you need to:</p>

    <ul>
      <li>Organization 1 could renumber all of its routers and hosts to have addresses within the ISPs-R-Us address block <code class="language-plaintext highlighter-rouge">199.31.0.0/16</code>. (costly if we need to do this everytime when switched to a new ISP)</li>
      <li>Organization 1 to keep its IP addresses in <code class="language-plaintext highlighter-rouge">200.23.18.0/23</code>, and the ISP do something (right figure)</li>
    </ul>
  </li>
  <li>
    <p>The solution commonly employed is to let Organization 1 keep its IP addresses, but ISPs-R-US also advertises <code class="language-plaintext highlighter-rouge">200.23.18.0/23</code>, which would work due to ==longest prefix matching==. (data sent to organization 1 matches both ISP, but the longest prefixing matching means they will be forwarded to ISPs-R-US.)</p>

    <ul>
      <li>note that you might want to do some merging of addresses afterwards in ISPs-R-Us if this happens often</li>
    </ul>
  </li>
</ol>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Router Aggregation</th>
      <th style="text-align: center">ISPs-R-Us has a more specific route</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211127163159823.png" alt="image-20211127163159823" style="zoom: 67%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211127163212978.png" alt="image-20211127163212978" style="zoom: 67%;" /></td>
    </tr>
  </tbody>
</table>

<h4 id="network-address-translation-nat">Network Address Translation: NAT</h4>

<p>Basically it is a trick to saving IP addresses:</p>

<ul>
  <li>
    <p>there are three portions of IP address space that is ==reserved in [RFC 1918] for a private network== or a realm with private addresses:</p>

    <ul>
      <li><code class="language-plaintext highlighter-rouge">192.168.0.0</code> – <code class="language-plaintext highlighter-rouge">192.168.255.255</code></li>
      <li><code class="language-plaintext highlighter-rouge">172.16.0.0</code> – <code class="language-plaintext highlighter-rouge">172.31.255.255 </code></li>
      <li><code class="language-plaintext highlighter-rouge">10.0.0.0</code> – <code class="language-plaintext highlighter-rouge">10.255.255.255</code></li>
    </ul>

    <p>Then, this means that they are ==thousands of devices have the same IP in those range==, but the meaning of their IP only makes sense ==within their network==.</p>

    <ul>
      <li>Devices within a given home network can send packets to each other using those IP <strong>only within the network</strong>.</li>
    </ul>
  </li>
  <li>
    <p>NAT-enabled router does not look like a router to the outside world. Instead the NAT router behaves to the outside world as a ==single device== with a single IP address.</p>
  </li>
</ul>

<p>Graphically:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211122165523263.png" alt="image-20211122165523263" /></p>

<p>where we see that:</p>

<ul>
  <li>all traffic leaving the home router for the larger Internet has a source IP address of <code class="language-plaintext highlighter-rouge">138.76.29.7</code>, and all traffic entering the home router must have a destination address of <code class="language-plaintext highlighter-rouge">138.76.29.7</code>.</li>
  <li>use a NAT translation table to know finally <strong>which device to forward to</strong> by essentially ==port $\to$ IP + port==</li>
</ul>

<p>Note then this basically means we are using ==one IP for all your private devices!== (hence essentially saving some IP addresses for use)</p>

<blockquote>
  <p>Now, in this case, the IPs are configured by:</p>

  <ol>
    <li>the router gets its address from the <strong>ISP’s DHCP server</strong>,</li>
    <li>the router runs a DHCP server to provide addresses to computers within the NAT-DHCP-router-controlled home network</li>
  </ol>
</blockquote>

<p>However, some problems you need to consider:</p>

<ol>
  <li>routers should only process up to layer 3, this is doing too much customization</li>
  <li>NAT traversal: what if client wants to connect to a server behind NAT? Need more configuration.
    <ul>
      <li>technically you can hard-code the mapping, but in the end it requires quite a lot of work.</li>
    </ul>
  </li>
</ol>

<h4 id="obtaining-block-of-address">Obtaining Block of Address</h4>

<p>Now, how does Columbia for example get the <code class="language-plaintext highlighter-rouge">160.39.0.0/16</code> block? Basically:</p>

<ul>
  <li>given by the ==upstream ISP==</li>
  <li>(the upstream ISP eventually gets their IPs from ICANN, which is Internet Corporation for Assigned Names and Numbers)</li>
</ul>

<p>For example</p>

<p>The ISP may itself have been allocated the address block <code class="language-plaintext highlighter-rouge">200.23.16.0/20</code>. The ISP, in turn, could divide its address block into subspaces and give to organizations:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211122162127509.png" alt="image-20211122162127509" style="zoom:80%;" /></p>

<h3 id="ipv6">IPv6</h3>

<p>Basically used for the problem of IPv4 running out of addresses. This has the advantage of:</p>

<ul>
  <li>more IP address available, now it is <strong>$2^6=128$ bits</strong></li>
  <li><strong>fixed</strong> 40-byte length header, so faster processing speed</li>
</ul>

<p>Then the datagram format looks like:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211122170228493.png" alt="image-20211122170228493" /></p>

<p>where:</p>

<ul>
  <li><strong>Version</strong>. This 4-bit field identifies the IP version number. Not surprisingly, IPv6 carries a value of <code class="language-plaintext highlighter-rouge">6</code> in this field</li>
  <li><strong>Traffic class</strong>. The 8-bit traffic class field, like the TOS field in IPv4, can be used to give priority to certain datagrams within a flow</li>
  <li><strong>Flow label</strong>. As discussed above, this 20-bit field is used to identify a flow of datagrams (meaning of flow still not well defined today)</li>
  <li><strong>Payload length.</strong> This 16-bit value is treated as an unsigned integer giving the number of bytes in the IPv6 datagram following the fixed 40 byte header.</li>
  <li><strong>Next header</strong>. This field identifies the protocol to which the contents (data field) of this datagram will be delivered (for example, to <strong>TCP or UDP</strong>)</li>
  <li><strong>Hop limit</strong>: TTL</li>
  <li>==Source and destination addresses.== The various formats of the IPv6 128-bit address</li>
  <li>==Data==: same as the data in IPv4 packet, basically the TCP/UDP segment.</li>
</ul>

<p>What is missing here is:</p>

<ul>
  <li>==Fragmentation/reassembly==. <strong>IPv6 does not allow</strong> for fragmentation and reassembly at intermediate routers</li>
  <li>==Header checksum==. Because the transport-layer (for example, TCP and UDP) and link-layer (for example, Ethernet) protocols in the Internet layers perform check-summing, the designers of IP probably felt that this functionality was sufficiently redundant.</li>
  <li><strong>Options</strong>: just as TCP or UDP protocol headers can be the next header within an IP packet, so too can an
options field</li>
</ul>

<h4 id="tunning-from-ipv4-to-ipv6">Tunning from IPv4 to IPv6</h4>

<p>Many routers are now using IPv4, if you send IPv6, how does that work?</p>

<blockquote>
  <p><strong>Heuristics</strong></p>

  <ul>
    <li>
      <p>IPv6 datagram carried as <strong>payload in IPv4 datagram</strong> among only IPv4 enabled routers.</p>

      <p>As a result, those packets look like:</p>

      <p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211122171400887.png" alt="image-20211122171400887" /></p>
    </li>
  </ul>
</blockquote>

<p>Then, what you do is:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211122171421378.png" alt="image-20211122171421378" /></p>

<p>where:</p>

<ul>
  <li>for IPv6 enabled routers, they transmit the message normally
    <ul>
      <li>the receiver IPv6 (node E) will realize that the datagram has <code class="language-plaintext highlighter-rouge">protocol=41</code> in the header, which means ==IPv6 embedded in payload==.</li>
    </ul>
  </li>
  <li>for IPv4 router, in the tunnel route this IPv4 datagram among themselves, just as they would any other datagram
    <ul>
      <li>note that the <code class="language-plaintext highlighter-rouge">source/dest IP</code> in the packets become the 32-bit IP of ==router <code class="language-plaintext highlighter-rouge">B,E</code>== respectively. This makes sense since now the IPv6 IP is 128 bits.</li>
    </ul>
  </li>
</ul>

<h2 id="generalized-forwarding-and-sdn">Generalized Forwarding and SDN</h2>

<p>Basically this is the extension of the idea that <strong>match-plus-action</strong> used for sending packet from input port to output port can be used in many other functionalities such as <strong>load-balancing, firewalling, etc</strong>. Essentially, instead of considering matching a single header/doing a single action:</p>

<ul>
  <li>match a ==set of headers== and perform a ==set of actions==</li>
  <li>have each router store a table of ==match-plus-action table== (local <strong>flow table</strong>)</li>
</ul>

<blockquote>
  <p><strong>Note</strong></p>

  <ul>
    <li>since now we could match headers potentially using link-layer headers, this is more general than a router. Hence, those routers are often referred to as <strong>packet switches</strong> (different form both a router and linl-layer switch)
      <ul>
        <li>hence we will refer to those routers are packet switches for this section</li>
      </ul>
    </li>
  </ul>
</blockquote>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211127172425345.png" alt="image-20211127172425345" style="zoom:67%;" /></p>

<p>note that</p>

<ul>
  <li>while it is possible for the control components at the individual packet switches to interact with each other (e.g., in a distributed manner similar to that in Figure 4.2), in practice, generalized match-plus-action capabilities are implemented via a <strong>remote controller that computes, installs, and updates these flow tables</strong>.</li>
  <li>essentially the <strong>flow table is a programmable API</strong> such that we can control the behavior of individual packet switch</li>
  <li>Figure 4.28 is an example of the OpenFlow 1.0 architecture, where the ==flow table== eseentially includes:
    <ul>
      <li><strong>a <em>set</em> of header field values</strong> to which an incoming packet will be matched.</li>
      <li><strong>a <em>set</em> of counters</strong> that are updated as packets are matched to flow table entries. These counters might include the number of packets that have been matched by that table entry, and the time since the table entry was last updated.</li>
      <li><strong>a <em>set</em> of actions</strong> to be taken when a packet matches a flow table entry. These actions might be to forward the packet to a given output port, to drop the packet, makes copies of the packet and sent them to multiple output ports, and/or to rewrite selected header fields.</li>
    </ul>
  </li>
</ul>

<h1 id="chapter-5-network-layer-control-plane">Chapter 5 Network Layer: Control Plane</h1>

<p>In the data plane, we had ==forwarding table== (in the case of destination-based forwarding) and the ==flow table== (in the case of generalized forwarding) were the principal elements that linked the network layer’s data and control planes.</p>

<p>Then, in this chapter, we learn how those ==forwarding and flow tables are computed, maintained and installed.==</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211129142506981.png" alt="image-20211129142506981" style="zoom:67%;" /></p>

<p>where:</p>

<ul>
  <li>Each router has a routing component that ==communicates with the routing components in other routers== to compute the values for its forwarding table</li>
  <li>while the routing algorithm runs, the data plane stuff runs in parallel</li>
</ul>

<p>Additionally, we basically want to make <strong>routing scalable</strong>. So we also need the <strong>hierarchy design principles</strong>:</p>

<ul>
  <li>the basic idea is to split the work to: a) route within a network, b) route between networks (autonomous system)</li>
  <li>i.e. for Google to reach your device at Columbia, Google just needs to know how to route to Columbia. Then, the Columbia network/gateway routers will route to your device</li>
</ul>

<blockquote>
  <p><strong>Logically Centralized Control</strong></p>

  <p>As we have discussed above, we could have also centralized everything</p>

  <p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211129142740023.png" alt="image-20211129142740023" style="zoom:50%;" /></p>

  <p>where here we:</p>

  <ul>
    <li>lose the scalability</li>
    <li>The controller interacts with a <strong>control agent (CA)</strong> in each of the routers via a well-defined protocol to configure and manage that router’s flow table
      <ul>
        <li>CA has minimum functionality; its job is to communicate with the controller, and to do as the controller command</li>
        <li>unlike the other case, here CAs do not directly interact with each other</li>
      </ul>
    </li>
  </ul>
</blockquote>

<h2 id="routing-algorithms">Routing Algorithms</h2>

<p>Now we study routing algorithms, whose goal is to ==determine good paths (equivalently, routes), from senders to receivers==, through the network of routers.</p>

<ul>
  <li>Typically, a “good” path is one that has the least cost. We’ll see that in practice, however, real-world concerns such as policy issues, so cost is defined differently at different places.</li>
  <li>no matter you use the per-router approach or the logically centralized approach, we always need a well-defined sequence of routers for the path</li>
</ul>

<p>Here, we first formalize our discussion with graphs:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211129143610101.png" alt="image-20211129143610101" style="zoom:67%;" /></p>

<p>where we have $G=(N,E)$ being the set of nodes and weighted edges</p>

<ul>
  <li>it is an undirected graph</li>
  <li>weight represent cost, e.g. $c(x,y)=1$ could be cost of delay, monetary cost, or etc</li>
</ul>

<p>So our goal in this chapter is to find a ==least-cost paths== between sources and destinations.</p>

<ul>
  <li>if cost are the same, then least-cost path = ==shortest path==</li>
</ul>

<p>Now, in reality, we actually use per-router algorithm (decentralized) and locally centralized algorithm (centralized) <strong>together</strong>. Therefore, we consider:</p>

<ul>
  <li><strong>centralized routing algorithm</strong>:
    <ul>
      <li>The algorithm knows connectivity between all nodes and all link costs as inputs in advance. Then, since it knows ==the complete information==, it can just perform a Dijkstra algorithm.</li>
      <li>Algorithms with global state information are often referred to as ==link-state (LS) algorithm==.</li>
    </ul>
  </li>
  <li><strong>decentralized routing algorithm</strong>:
    <ul>
      <li>No node has complete information about the costs of all network links. Each node ==only== has info about its ==immediate neighbors==. So we will need some iterative process of calculation and exchange of information with its neighboring nodes to compute a least cost</li>
      <li>here we use ==distance-vector (DV) algorithm==, because each node maintains a vector of estimates of the costs (distances) to all other nodes</li>
    </ul>
  </li>
</ul>

<blockquote>
  <p><strong>Other Algorithm Classes</strong></p>

  <p>Some other classification of algorithms include:</p>

  <ul>
    <li><strong>static vs dynamic routing algorithms</strong>: whether if route changes in direct response of chance of topology</li>
    <li><strong>load-sensitive vs insensitive algorithms</strong>: whether if link costs vary dynamically to reflect the current level of congestion in the underlying link</li>
  </ul>
</blockquote>

<h3 id="link-state-routing-algorithm">Link-State Routing Algorithm</h3>

<p>Recall that in a link-state algorithm, the network topology and all link costs ==are known in advance==.</p>

<ul>
  <li>To deliver all the info in advance, we need each <strong>node broadcast link-state packets to all other nodes</strong> in the network, with each link-state packet containing the identities and costs of its attached links. (this is done in practice by the link-state broadcast algorithm)</li>
  <li>The result of the nodes’ broadcast is that ==all nodes have an identical and complete view of the network==. Then, each node can just run the LS algorithm (Dijkstra’s Algorithm)</li>
</ul>

<p>Dijkstra’s algorithm computes the least-cost path from one node (the source, which we will refer to as $u$) to all other nodes in the network.</p>

<ul>
  <li>$D(v)$: cost/distance of the <strong>least-cost path</strong> from the source node to destination $v$ as of this iteration of the algorithm.</li>
  <li>$p(v)$: previous node (neighbor of $v$) along the <strong>current least-cost path</strong> from the source to $v$.</li>
  <li>$N’$: subset of nodes; $v$ is in $N’$ if the least-cost path from the source to $v$ is definitively known. (i.e. is done)</li>
</ul>

<p>Then the Dijkstra Algorithm is doing:</p>

<ol>
  <li>
    <p>initialization</p>
  </li>
  <li>
    <p>perform the <strong>Greedy Step</strong>, assuming the one with <strong>smallest $D$</strong> is already <strong>settled/known</strong> (put in $N’$)</p>

    <table>
      <thead>
        <tr>
          <th>Vertex</th>
          <th>Known</th>
          <th>Dv/Distance</th>
          <th>Pv/Previous</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>$V_1$</td>
          <td>T</td>
          <td>0</td>
          <td>N/A</td>
        </tr>
        <tr>
          <td>$V_2$</td>
          <td>F</td>
          <td>$\infty$</td>
          <td>$V_1$</td>
        </tr>
        <tr>
          <td>$V_3$</td>
          <td>F</td>
          <td>$\infty$</td>
          <td>-</td>
        </tr>
        <tr>
          <td>$V_4$</td>
          <td>F</td>
          <td>$\infty$</td>
          <td>$V_1$</td>
        </tr>
        <tr>
          <td>$V_5$</td>
          <td>F</td>
          <td>$\infty$</td>
          <td>-</td>
        </tr>
        <tr>
          <td>$V_6$</td>
          <td>F</td>
          <td>$\infty$</td>
          <td>-</td>
        </tr>
        <tr>
          <td>$V_7$</td>
          <td>F</td>
          <td>$\infty$</td>
          <td>-</td>
        </tr>
      </tbody>
    </table>
  </li>
  <li>
    <p>run through the <strong>Adjacency List/Neighbor</strong> of that <strong>settled vertex</strong> and update the table</p>

    <ol>
      <li>try to add the value of <strong>$D$</strong> of the settled <strong>vertex</strong> up to each of the <strong>vertex</strong> in the list</li>
      <li>we update the $D$ only when it is better than the current $D$ belonging to that <strong>vertex</strong></li>
    </ol>

    <table>
      <thead>
        <tr>
          <th>Vertex</th>
          <th>Known</th>
          <th>Dv/Distance</th>
          <th>Pv/Previous</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>$V_1$</td>
          <td>T</td>
          <td>0</td>
          <td>N/A</td>
        </tr>
        <tr>
          <td>$V_2$</td>
          <td>F</td>
          <td>2</td>
          <td>$V_1$</td>
        </tr>
        <tr>
          <td>$V_3$</td>
          <td>F</td>
          <td>$\infty$</td>
          <td>-</td>
        </tr>
        <tr>
          <td>$V_4$</td>
          <td>F</td>
          <td>1</td>
          <td>$V_1$</td>
        </tr>
        <tr>
          <td>$V_5$</td>
          <td>F</td>
          <td>$\infty$</td>
          <td>-</td>
        </tr>
        <tr>
          <td>$V_6$</td>
          <td>F</td>
          <td>$\infty$</td>
          <td>-</td>
        </tr>
        <tr>
          <td>$V_7$</td>
          <td>F</td>
          <td>$\infty$</td>
          <td>-</td>
        </tr>
      </tbody>
    </table>
  </li>
  <li>
    <p>Repeat step 3 to 4 until all vertices are known</p>

    <p>e.g. the next iteration of step 2 becomes:</p>

    <table>
      <thead>
        <tr>
          <th>Vertex</th>
          <th>Known</th>
          <th>Dv/Distance</th>
          <th>Pv/Previous</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>$V_1$</td>
          <td>T</td>
          <td>0</td>
          <td>N/A</td>
        </tr>
        <tr>
          <td>$V_2$</td>
          <td>F</td>
          <td>2</td>
          <td>$V_1$</td>
        </tr>
        <tr>
          <td>$V_3$</td>
          <td>F</td>
          <td>$\infty$</td>
          <td>-</td>
        </tr>
        <tr>
          <td>$V_4$</td>
          <td>==T==</td>
          <td>1</td>
          <td>$V_1$</td>
        </tr>
        <tr>
          <td>$V_5$</td>
          <td>F</td>
          <td>$\infty$</td>
          <td>-</td>
        </tr>
        <tr>
          <td>$V_6$</td>
          <td>F</td>
          <td>$\infty$</td>
          <td>-</td>
        </tr>
        <tr>
          <td>$V_7$</td>
          <td>F</td>
          <td>$\infty$</td>
          <td>-</td>
        </tr>
      </tbody>
    </table>

    <p>so eventually a path from $V_1$ to any other node is recorded by $P$.</p>
  </li>
</ol>

<p>In terms of code, it looks like:</p>

<pre><code class="language-pseudocode">// again, we assumes a non-negative cycle

void dijkstra(Vertex s){
    for each Vertex v{
        v.dist = INFINITY;
        v.known = false;
    }
    
    s.dist = 0;
    
    // this happens |V| times
    while(there is an unknown vertex){
        // if you find the min by scanning through the list
        // then this is also |V|
        Vertex v = smallest known vertex
        
        v.known = true;
        
        // this loop goes IN TOTAL |E| times
        for each Vertex w adjacent to v{
            if(!w.known){
                // the next step/edge's cost
                DistType cvn = cost of edge from v to w;
                
                // if we did find something smaller
                if(v.dist + cvn &lt; w.dist){
                    // update w
                    // in this version, w.dist = v.dist+cvw works the same
                    
                    // this is useful, because there is actually ANOTHER way of doing this
                    decrease(w.dist to v.dist+cvn); 
                    w.pv = v;
                }
            }
        }
    }
}
</code></pre>

<p>Therefore, this algorithm tells us that when the LS algorithm terminates, we have, for each node, its predecessor along the <strong>least-cost path from the ==source node==</strong>.</p>

<p>Then the forwarding table in node $u$ will basically be the next-hop node on the shortest path to $t$:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Graph</th>
      <th style="text-align: center">Forwarding Table for $u$</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211129143610101.png" alt="image-20211129143610101" style="zoom: 50%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211129152038665.png" alt="image-20211129152038665" style="zoom:50%;" /></td>
    </tr>
  </tbody>
</table>

<p>(note that the worst case computation complexity for this is $O(N^2)$)</p>

<h4 id="oscillations-of-dijkstras-algorithm">Oscillations of Dijkstra’s Algorithm</h4>

<p>When ==link cost depends on traffic volume==, <strong>route oscillation</strong> is possible, because the cost itself then changes based on whether if I chose a specific route or not.</p>

<p>For instance, consider sending stuff from <code class="language-plaintext highlighter-rouge">C</code> to <code class="language-plaintext highlighter-rouge">A</code>. Let <code class="language-plaintext highlighter-rouge">B</code> want to same traffic of <code class="language-plaintext highlighter-rouge">1</code>, <code class="language-plaintext highlighter-rouge">C</code> want to send traffic of <code class="language-plaintext highlighter-rouge">e</code>, and <code class="language-plaintext highlighter-rouge">D</code> want to send traffic size of <code class="language-plaintext highlighter-rouge">1</code>, Then:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">t=0</th>
      <th style="text-align: center">t=1</th>
      <th style="text-align: center">t=2</th>
      <th style="text-align: center">t=3</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211201091426106.png" alt="image-20211201091426106" /></td>
      <td style="text-align: center"><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211201091639130.png" alt="image-20211201091639130" /></td>
      <td style="text-align: center"><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211201091646654.png" alt="image-20211201091646654" /></td>
      <td style="text-align: center"><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211201091707710.png" alt="image-20211201091707710" /></td>
    </tr>
    <tr>
      <td style="text-align: center">least weight<code class="language-plaintext highlighter-rouge">C-B-A</code></td>
      <td style="text-align: center">least weight <code class="language-plaintext highlighter-rouge">C-D-A</code></td>
      <td style="text-align: center">least weight<code class="language-plaintext highlighter-rouge">C-B-A</code></td>
      <td style="text-align: center">least weight <code class="language-plaintext highlighter-rouge">C-D-A</code></td>
    </tr>
  </tbody>
</table>

<p>where basically:</p>

<ul>
  <li>suppose at <code class="language-plaintext highlighter-rouge">t=0</code> we have the route computed already to be <code class="language-plaintext highlighter-rouge">C-B-A</code>. Since we are sending stuff which will cause an increase in traffic, this causes the same route to have a cost of $e+(1+e)$</li>
  <li>then, since the other route <code class="language-plaintext highlighter-rouge">C-D-A</code> has only a cost of $1$, we switch to <code class="language-plaintext highlighter-rouge">C-D-A</code>. But now we are sending traffic there as well! So at $t=1$ we know have a cost of $e+(1+e)$,</li>
  <li>repeat
    <ul>
      <li>notice that $t=0=2$ and $t=1=3$ happens because <strong>each router updates the new path at the SAME TIME</strong></li>
    </ul>
  </li>
</ul>

<p><strong>Solution</strong></p>

<ol>
  <li>mandate that link costs <strong>not</strong> depend on the amount of traffic [==not acceptable==]
    <ul>
      <li>doesn’t make sense since the aim of routing is to avoid congestion = high traffic!</li>
    </ul>
  </li>
  <li>ensure that ==not== all routers run the LS algorithm ==at the same time==
    <ul>
      <li>e.g. randomize the time it sends out a link advertisement.</li>
    </ul>
  </li>
</ol>

<h3 id="distance-vector-routing-algorithm">Distance-Vector Routing Algorithm</h3>

<p>This basically is an <strong>iterative and distributive</strong> algorithm, because:</p>

<ul>
  <li>distributive: each node receives some information from one or more of its directly attached neighbors, performs a calculation, and then ==distributes the results of its calculation back to its neighbors==.</li>
  <li>iterative: this process ==continues on until no more information is exchanged== between neighbors</li>
</ul>

<p>First thing to notice is that, for the Greedy Algorithm to work, we neede the <strong>Bellman-Ford Equation</strong> that, if $d_X(y)$ is the ==cost of least-cost path== from $x$ to $y$, then:</p>

\[d_x(y) = \min_v \{ c(x,v) + d_v(y) \}\]

<p>which makes sense as $d_v(y)$ is the min path, and we have positive edges only.</p>

<ul>
  <li>after traveling from $x$ to $v$, if we then take the least-cost path from $v$ to $y$, the path cost will be $c(x, v) + d_v(y)$.</li>
  <li>therefore, if $v^<em>$ is the <strong>neighbor of $x$ and achieves the $\min$</strong>, then the forwarding table to get data from $x\to y$ means $x$ should ==forward to $v^</em>$==.</li>
  <li>this is technically the same equation used in Dijkstra’s algorithm</li>
</ul>

<p>Graphically, it is just doing:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211201121512568.png" alt="image-20211201121512568" /></p>

<p>where:</p>

<ul>
  <li>the best path from $D_u(z)$ would be $\min(\text{path to neighbor} + \text{path from neighbor to$z$})$</li>
  <li>therefore, this basically is done ==iteratively== for all nodes ==until no changes/all information propagated==</li>
</ul>

<p>Then the algorithm is as follows:</p>

<pre><code class="language-pseudocode">Initialization:
	for all destinations y in Node:
		Dx(y)= c(x,y) /* if y is not a neighbor then c(x,y)= infty */
	for each neighbor w
		Dw(y) = ? for all destinations y in N
	for each neighbor w
		send distance vector Dx = [Dx(y): y in N] to w

Main loop
	wait (until I see a link cost change to some neighbor w or
		until I receive a distance vector from some neighbor w)

	for each y in N:
		Dx(y) = min_v{c(x,v) + Dv(y)} /* Bellman-Ford Equation, update distance vector */

	if Dx(y) changed for any destination y /* tell others IFF there is a change! */
		send distance vector Dx = [Dx(y): y in N] to all neighbors

forever
</code></pre>

<p>basically the key idea is that, for a node $x$ in the graph:</p>

<ol>
  <li>
    <p>initialize all cost $D_x(y)$ to any other node in the graph ($D_x(y)=c(x,y)$ if $y$ is a neighbor, otherwise initialize with $\infty$)</p>
  </li>
  <li>
    <p>send your current $D_x(y)$ vector to your neighbor</p>
  </li>
  <li>
    <p>receive $D_v(y)$ from your neighbor $v$, and update your $D_x(y)$ since you can now compute:</p>

\[D_x(y) \leftarrow \min_v \{ D_v(y) + c(x,v) \}\]

    <p>where $c(x,v)$ you can directly measure by $x$ itself since $v$ are its neighbor</p>
  </li>
  <li>
    <p>send the $D_x(y)$ result that changed to your neighbors (so they can update)</p>
  </li>
  <li>
    <p>repeat 2-4 until no changes</p>
  </li>
</ol>

<p><em>For Example</em></p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211129154902953.png" alt="image-20211129154902953" /></p>

<p>where notice that:</p>

<ul>
  <li>each row is a <strong>distance vector</strong> in the algorithm</li>
  <li>the update on the <code class="language-plaintext highlighter-rouge">x</code> table for $x-y$ in iteration 2 happens because $c(x,y)+D_y(z)=3$ is smaller than the current value $7$. Therefore, we have updated the table</li>
  <li>remember that in the end we just need to know the next-hop for the table! So we also needed store the next hop information as well when updating our $D_x(y)$.</li>
</ul>

<p>Another more animated view is this <strong>(here we only focus on router <code class="language-plaintext highlighter-rouge">b</code>)</strong></p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">t=1</th>
      <th style="text-align: center">t=2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211201122833159.png" alt="image-20211201122833159" /></td>
      <td style="text-align: center"><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211201122945603.png" alt="image-20211201122945603" /></td>
    </tr>
    <tr>
      <td style="text-align: center">Initialize the $D_x(y)$ and send</td>
      <td style="text-align: center">Router $b$ computes, and deliver</td>
    </tr>
  </tbody>
</table>

<p>where here we focused on a specific router <code class="language-plaintext highlighter-rouge">b</code>. In reality all other routers are also doing this action <strong>at the same time</strong>!</p>

<h4 id="link-cost-changes-and-link-failure">Link Cost Changes and Link Failure</h4>

<p>The issue with <strong>distributed algorithm</strong> in general is their speed of convergence can be slow if there are changes!</p>

<ul>
  <li>good news travel fast, but ==bad news travel very slowly==! (e.g. due to change in traffic)</li>
</ul>

<hr />

<p><strong>Case 1: Good News</strong></p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211201124148017.png" alt="image-20211201124148017" /></p>

<p>We focus here ==only on <code class="language-plaintext highlighter-rouge">y</code>’ and <code class="language-plaintext highlighter-rouge">z</code>’s distance table== entries to destination <code class="language-plaintext highlighter-rouge">x</code>.</p>

<ol>
  <li>At time $t=0$, y detects the link-cost change (the cost has changed from 4 to 1), updates its distance vector, and informs its neighbors of this change since its distance vector has changed, i.e. $D_y(x)=1$.</li>
  <li>At time $t=1$, z receives the update from y and updates its table. It computes a new least cost to x (it has ==decreased from a cost of $D_z(x)=5$ to a cost of $D_z(x)=1+D_y(x)=2$==) and sends its new distance vector to its neighbors.
    <ul>
      <li>here we are basically done</li>
    </ul>
  </li>
  <li>At time $t=2$, y receives z’s update and updates its distance table. y’s least costs do not change and hence y does not send any message to z. The algorithm comes to a quiescent state.</li>
</ol>

<hr />

<p><strong>Case 2: Bad News</strong></p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211201124228618.png" alt="image-20211201124228618" /></p>

<p>We focus here ==only on <code class="language-plaintext highlighter-rouge">y</code>’ and <code class="language-plaintext highlighter-rouge">z</code>’s distance table== entries to destination <code class="language-plaintext highlighter-rouge">x</code>.</p>

<p>Before the link cost changes, $D_y(x) = 4, D_y(z) = 1, D_z(y) = 1$, and $D_z(x) = 5$ globally.</p>

<ol>
  <li>At $t=0$, y detects the link-cost change (the cost has changed from $c(y,x)=4$ to $c(y,x)=60$). y computes its new minimum-cost path to x to have a cost of</li>
</ol>

\[D_y(x) = \min \{ c(y,x)+D_x(x); c(y,z)+D_z(x) \} = \min \{60+0; 1+5\}=  6\]

<p>which is ==wrong temporarily== (recall that it is correct only when converged) because the only information node y has is that its direct cost to x is 60 and that ==z has last told y that $D_z(x)=5$==, which is the wrong one.</p>

<ul>
  <li>notice that this happens because a actually $D_z(x)=5\iff z-y-x$, but this ==path information is hidden/not conveyed!== Now, if we picked $D_y(x)=6 \iff y - z - y -x$ will cause a ==routing loop for $y-z-y$== until the forwarding tables are changed.</li>
  <li>node y has computed a new minimum cost to x, it informs z of its new distance vector at time t1.</li>
</ul>

<ol>
  <li>
    <p>At $t=1$​, z receives the update, which indicates that y’s minimum cost to x is $D_y(x)=6$. z knows it can get to y with a cost of 1 and hence computes a new least cost to x of:</p>

\[D_z(x) = \min \{50 + 0,1 + 6 \} = 7\]

    <p>which is ==wrong temporarily again==, due to the same reason that it didn’t knw $D_y(x)=6 \iff y - z - y -x$. So z will ==still route through $y$==.</p>

    <ul>
      <li>since z’s cost increased/changed, it sends the update to its neighbor</li>
    </ul>
  </li>
  <li>
    <p>At $t=2$, y receives the update and now the path is</p>

\[D_y(x) = \min \{ c(y,x)+D_x(x); c(y,z)+D_z(x) \} = \min \{60+0; 1+7\}=  8\]

    <p>and sends to node z</p>
  </li>
  <li>
    <p>At $t=3$, z receives the update and find $D_z(x)=9$, and etc.</p>
  </li>
</ol>

<p>Notice that at the 4rd iteration we basically successfully updated our path $D_z(x)=7+2=9$ by $2$ steps, where the correct result should be $D_z(x)=50$. Therefore, we needed $50-6=44$ iterations in total to reach the correct result.</p>

<p><strong>Solution: Poisoned Reverse</strong></p>

<p>The idea is simple - if <code class="language-plaintext highlighter-rouge">z</code> routes through <code class="language-plaintext highlighter-rouge">y</code> to get to destination <code class="language-plaintext highlighter-rouge">x</code>, ==i.e. $z-y-x$,== then <code class="language-plaintext highlighter-rouge">z</code> will ==advertise to <code class="language-plaintext highlighter-rouge">y</code> that $D_z(x) = \infty$== (even though z knows $D_z(x) = 5$ in truth).</p>

<ul>
  <li>basically the idea is to prevent the loop from happening, which will speed up the convergence</li>
  <li>z will continue telling this little white lie to y as long as it routes to x via y.</li>
</ul>

<p>Since y believes that z has no path to x, y will ==never attempt to route to x via z==, as long as z continues to route to x via y (and lies about doing so).</p>

<hr />

<p><em>Example: Poisoned Reverse</em>:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211201124228618.png" alt="image-20211201124228618" /></p>

<p>Now using poisoned reverse:</p>

<ol>
  <li>
    <p>$t=0$, y knows that $D_z(x)=\infty$ (since $D_z(x)\iff z-y-x$ before, which goes through y).</p>

    <p>Therefore, $D_y(x)=60$ on the first iteration.</p>

    <ul>
      <li>still wrong, but it converges faster</li>
      <li>y updates and informs its neighbor</li>
    </ul>
  </li>
  <li>
    <p>$t=1$, z receives the update and now it will compute $D_z(x)=50$</p>

    <ul>
      <li>correct on the second iteration</li>
      <li>now $D_z(x)\iff z-x$, it does not pass through y so we can send this one to y!</li>
    </ul>
  </li>
  <li>
    <p>$t=2$, y receives the update and now it gets $D_y(x)=50+1=51$!</p>

    <ul>
      <li>done</li>
    </ul>
  </li>
</ol>

<blockquote>
  <p><strong>Note</strong></p>

  <p>Though this technique solves the current problem, it does ==not solve the problem completely==.</p>

  <ul>
    <li>You should convince yourself that <strong>loops involving three or more nodes</strong> (rather than simply two immediately neighboring nodes) ==will not be detected by the poisoned reverse technique==.</li>
  </ul>
</blockquote>

<h3 id="comparison-between-ls-and-dv">Comparison between LS and DV</h3>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211201133912427.png" alt="" /></p>

<p>where what is important here is that:</p>

<ul>
  <li><strong>robustness</strong>: LS is more robust in terms of ==router error== (e.g. router made a mistake in calculation). Since each router essentially ==only computes its own table==, the router only causes problem to himself in <strong>LS algorithm</strong>. However, the <strong>DV algorithm</strong> would be a big problem because the error will ==propagate through the network== and cause a vast change.</li>
</ul>

<h2 id="intra-as-routing-in-the-internet-ospf">Intra-AS Routing in the Internet: OSPF</h2>

<p>The algorithms we discussed before has a problem: each router was indistinguishable from another in the sense that ==all routers executed the same routing algorithm==. This is not practical in reality because:</p>

<ul>
  <li>
    <p><strong>scalability issue</strong>: we have hundreds of millions of routers. For each router to store some table such as the DV algorithm would require enormous memory, and it will take so long that it won’t converge today</p>
  </li>
  <li>
    <p><strong>administrative autonomy</strong>: ISPs would like to control their routers!</p>
  </li>
</ul>

<p>Therefore, this goes back to the hierarchy setup we had in mind:</p>

<ul>
  <li>organizing routers into ==autonomous systems (ASs)==, with each AS consisting of a group of routers that are under the ==same== administrative control, routing algorithm and information about each other.
    <ul>
      <li>then communication/exchange of information within an AS is called ==intra-autonomous system routing protocol==</li>
    </ul>
  </li>
  <li>finally, we just need to connect different AS together.
    <ul>
      <li>this routing algorithm is hence called ==inter-autonomous system routing protocol==</li>
    </ul>
  </li>
</ul>

<p>Hence, on a high level it looks like:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211129085638840.png" alt="image-20211129085638840" style="zoom:67%;" /></p>

<p>where the gateway routers (<code class="language-plaintext highlighter-rouge">3a</code>, <code class="language-plaintext highlighter-rouge">1c</code>, <code class="language-plaintext highlighter-rouge">1b</code>, and <code class="language-plaintext highlighter-rouge">2a</code>) will <strong>contain entries:</strong></p>

<ul>
  <li>for external addresses, it sends to the external output port (decided by <strong>inter-AS-protocol</strong>)</li>
  <li>for internal addresses, it (decided by <strong>intra-AS-protocol</strong>)</li>
</ul>

<h3 id="ospf">OSPF</h3>

<p>Open Shortest Path First (OSPF) is a link-state protocol that uses ==flooding of link-state information== and a ==Dijkstra’s least-cost path algorithm==.</p>

<p>Therefore, OSPF basically does:</p>

<ul>
  <li>each router floods OSPF link-state advertisements (directly over IP rather than using TCP/UDP) to <strong>all other routers</strong> in entire AS
    <ul>
      <li>the weights are typically set by network administrator. A simple example would be setting everything to <code class="language-plaintext highlighter-rouge">1</code>, so basically it becomes the minimum hop path.</li>
      <li>therefore, you can also customize the weights to represent information such as network delay</li>
    </ul>
  </li>
  <li>so <strong>each router</strong> constructs a complete topological map (that is, a graph) of the <strong>entire autonomous system</strong> (not for routers outside the system!)
    <ul>
      <li>When multiple paths to a destination have the same cost, OSPF allows multiple paths to be used (by splitting the traffic)</li>
    </ul>
  </li>
</ul>

<p><strong>Hierarchical OSFP</strong></p>

<p>In this case, we do <strong>not flood information to all routers</strong>, but in a two-level hierarchy: local area, backbone.</p>

<ul>
  <li>link-state advertisements flooded ==only in area==, or ==only in backbone==</li>
  <li>each node has detailed area topology; only knows direction to reach other destinations</li>
</ul>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211129090713835.png" alt="image-20211129090713835" style="zoom:67%;" /></p>

<p>then, the last thing you need to do is to configure connection between gateway routes of your backbone and those areas.</p>

<h2 id="inter-as-routing-bgp">Inter-AS Routing: BGP</h2>

<p>Now, to route a packet across multiple ASs, we need an inter-autonomous system routing protocol.</p>

<ul>
  <li>intra-AS algorithm completely determines the route within an AS.</li>
</ul>

<p>Since an inter-AS routing protocol involves coordination among multiple ASs, communicating ASs must run the <strong>same inter-AS routing</strong>
<strong>protocol</strong>. In fact, in the Internet, all ASs run the same inter-AS routing protocol, called the ==Border Gateway Protocol (BGP)==.</p>

<ul>
  <li>BGP glues the thousands of ISPs in the Internet together. As we will soon see, BGP is a <strong>decentralized</strong> and asynchronous protocol in the vein of <strong>distance-vector</strong> routing</li>
</ul>

<p>In BGP, packets are not routed to a specific destination address, but instead to CIDRized prefixes such as <code class="language-plaintext highlighter-rouge">138.16.68/22</code>.</p>

<p>Therefore, a router’s forwarding table using BGP will include something like:</p>

\[(\text{prefix}, \text{output})=(138.16.68/22, 3)\]

<p>where $3$ means this is for output port.</p>

<p>Hence BGP does two things:</p>

<ol>
  <li>Obtain prefix reachability information from neighboring ASs. In particular, BGP allows each subnet to advertise its existence to the rest of the Internet</li>
  <li>Determine the “best” routes to the prefixes. A router may learn about two or more different routes to a specific prefix.</li>
</ol>

<h3 id="advertising-bgp-route-information">Advertising BGP Route Information</h3>

<p>Consider the following topology, where subnet with prefix <code class="language-plaintext highlighter-rouge">x</code> joined Autonomous System 3.</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211129162437291.png" alt="image-20211129162437291" style="zoom:67%;" /></p>

<p>Then, to advertise <code class="language-plaintext highlighter-rouge">x</code> existence, we need to:</p>

<ol>
  <li>propagate <code class="language-plaintext highlighter-rouge">x</code>’s information all the way to <code class="language-plaintext highlighter-rouge">3a</code>, that <code class="language-plaintext highlighter-rouge">x</code> is <strong>inside <code class="language-plaintext highlighter-rouge">AS3</code></strong></li>
  <li><code class="language-plaintext highlighter-rouge">3a</code> tells <code class="language-plaintext highlighter-rouge">2c</code> in AS2 that <strong><code class="language-plaintext highlighter-rouge">x</code> is reachable via <code class="language-plaintext highlighter-rouge">AS3</code></strong>
    <ul>
      <li>we denote this message by <code class="language-plaintext highlighter-rouge">AS3-x</code></li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">2c</code> propagate within the AS, and then gets to <code class="language-plaintext highlighter-rouge">2a</code></li>
  <li><code class="language-plaintext highlighter-rouge">2a</code> tells <code class="language-plaintext highlighter-rouge">1c</code> in AS1 that <code class="language-plaintext highlighter-rouge">x</code> is reachable via <code class="language-plaintext highlighter-rouge">AS2-AS3</code>
    <ul>
      <li>we denote this message by <code class="language-plaintext highlighter-rouge">AS2-AS3-x</code></li>
    </ul>
  </li>
</ol>

<blockquote>
  <p><strong>Note</strong></p>

  <p>For each AS, each router is either a <strong>gateway</strong> router or an <strong>internal</strong> router.</p>

  <ul>
    <li>A gateway router is a router on the edge of an AS that directly connects to one or more routers in other AS (e.g. <code class="language-plaintext highlighter-rouge">1c</code>)</li>
    <li>An internal router connects only to hosts and routers within its own AS. (e.g. <code class="language-plaintext highlighter-rouge">1a</code>)</li>
  </ul>
</blockquote>

<p>Therefore, in the above example, we see that we needed ==two types of BGP messages==</p>

<ul>
  <li>a BGP connection that spans two ASs is called an <strong>external BGP (eBGP) connection</strong></li>
  <li>a BGP session between routers in the same AS is called an <strong>internal BGP (iBGP) connection</strong></li>
</ul>

<p>(so BGP exchange routing information over ==semi-permanent TCP connections== using port <code class="language-plaintext highlighter-rouge">179</code>.)</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211129162829411.png" alt="image-20211129162829411" style="zoom:67%;" /></p>

<p>In this process,</p>

<ol>
  <li>gateway router <code class="language-plaintext highlighter-rouge">3a </code>first sends an eBGP message “AS3 x” to gateway router <code class="language-plaintext highlighter-rouge">2c</code>.</li>
  <li>Gateway router <code class="language-plaintext highlighter-rouge">2c </code>then sends the iBGP message “AS3 x” to all of the other routers in AS2, including to gateway router <code class="language-plaintext highlighter-rouge">2a</code>.</li>
  <li>Gateway router <code class="language-plaintext highlighter-rouge">2a </code>then sends the eBGP message “AS2 AS3 x” to gateway router <code class="language-plaintext highlighter-rouge">1c</code>.</li>
</ol>

<p>So it looks more like:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211129170529844.png" alt="image-20211129170529844" /></p>

<p>notice that:</p>

<ul>
  <li>here the path information is a <strong>path-vector</strong>, in contract to the <strong>distance-vector</strong> which has the problem of causing loops!</li>
</ul>

<blockquote>
  <p><strong>Note</strong></p>

  <p>Here we only discussed how to get the information across. We haven’t discussed what route will then be chosen, which is the next section</p>

  <p>Also, notice that then gateway routes need to run <strong>both eBGP and iBGP</strong></p>

  <p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211129091912479.png" alt="image-20211129091912479" style="zoom:67%;" /></p>
</blockquote>

<h3 id="determining-the-best-routes">Determining the Best Routes</h3>

<p>When BGP advertises reachability, it includes information of prefix (e.g. <code class="language-plaintext highlighter-rouge">138.16.68/22</code>) + attributes.</p>

<ul>
  <li>prefix: destination being advertised</li>
  <li>two of the most important attributes:
    <ul>
      <li><code class="language-plaintext highlighter-rouge">AS-PATH</code>: list of ASN (unique ID for each AS) through which prefix advertisement has passed (contains the path information)
        <ul>
          <li>this is implemented by just having AS adds its ASN to the existing list in the AS-PATH</li>
          <li>basically this is the ==path vector==. So BGP is Path Vector Protocol</li>
        </ul>
      </li>
      <li><code class="language-plaintext highlighter-rouge">NEXT-HOP</code>: indicates specific internal-AS router ==IP== to next-hop AS
        <ul>
          <li>because the route only contains ASN, which gave no IP information!</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<blockquote>
  <p><strong>Other BGP Message Fields</strong></p>

  <p>BGP since is over TCP, contains also the following fields</p>

  <ul>
    <li>
      <p>OPEN: opens TCP connection to remote BGP peer and authenticates sending BGP peer</p>
    </li>
    <li>
      <p>UPDATE: advertises new path (or withdraws old)</p>
    </li>
    <li>
      <p>KEEPALIVE: keeps connection alive in absence of UPDATES; also ACKs OPEN request</p>
    </li>
    <li>
      <p>NOTIFICATION: reports errors in previous msg; also used to close connection</p>
    </li>
  </ul>
</blockquote>

<p>For instance, consider <code class="language-plaintext highlighter-rouge">1d</code> receiving advertisement to subnet with prefix <code class="language-plaintext highlighter-rouge">x</code>:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211129164111542.png" alt="image-20211129164111542" style="zoom:80%;" /></p>

<p>In this case, it will receive two entries:</p>

\[\text{NEXT-HOP; AS PATH; destination prefix} =
\begin{cases}
\text{IP address of leftmost interface for router 2a; AS2-AS3; x}\\
\text{IP address of leftmost interface of router 3d; AS3; x}
\end{cases}\]

<p>Then, with this information, we finally discuss two algorithms used for BGP routing:</p>

<ul>
  <li><strong>hot potato routing</strong></li>
  <li><strong>Route-Selection Algorithm</strong></li>
</ul>

<h4 id="hot-potato-routing">Hot Potato Routing</h4>

<p>This is a simple algorithm where the route chosen (from among all possible routes) is that route with the **least cost to the NEXTHOP **router beginning that route.</p>

<p>For example, consider we wanting to send data from <code class="language-plaintext highlighter-rouge">1b-x</code>. Then, if <code class="language-plaintext highlighter-rouge">1b</code> uses hot potato routing:</p>

<ul>
  <li>recall that ==BGP is used when we want to send data outside of AS==</li>
</ul>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211129164111542.png" alt="image-20211129164111542" style="zoom:80%;" /></p>

<p>here we have two paths that <code class="language-plaintext highlighter-rouge">1b</code> is looking at:</p>

<ul>
  <li>
    <p>the least-cost <strong>intra-AS path</strong> to NEXT-HOP router <code class="language-plaintext highlighter-rouge">2a</code></p>
  </li>
  <li>
    <p>the least-cost <strong>intra-AS path</strong> to NEXT-HOP router <code class="language-plaintext highlighter-rouge">3d</code></p>
  </li>
  <li>
    <p>note that we need to ==consult intra-AS routing information==!</p>

    <ul>
      <li>
        <p>e.g. from ==iBGP==, router <code class="language-plaintext highlighter-rouge">1d</code> knows <code class="language-plaintext highlighter-rouge">1c</code> is needed to get to <code class="language-plaintext highlighter-rouge">x</code></p>
      </li>
      <li>
        <p>then from ==OSPF== of the intra-AS algorithm, <code class="language-plaintext highlighter-rouge">1d</code> knows how to get to <code class="language-plaintext highlighter-rouge">1c</code></p>

        <p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211129094243523.png" alt="image-20211129094243523" /></p>
      </li>
    </ul>
  </li>
</ul>

<p>If the weights are all the same for intra-AS path, then:</p>

<ul>
  <li>the least-cost <strong>intra-AS path</strong> to NEXT-HOP router <code class="language-plaintext highlighter-rouge">2a</code> = 2 Hops</li>
  <li>the least-cost <strong>intra-AS path</strong> to NEXT-HOP router <code class="language-plaintext highlighter-rouge">2a</code> = 3 Hops</li>
</ul>

<p>Hence router <code class="language-plaintext highlighter-rouge">2a </code>would therefore be selected, and Router <code class="language-plaintext highlighter-rouge">1b </code>would then consult its forwarding table (configured by its intra-AS algorithm) and find the interface <code class="language-plaintext highlighter-rouge">I </code>that is on the least-cost path to router <code class="language-plaintext highlighter-rouge">2a</code>.</p>

<ul>
  <li>then, it ==adds <code class="language-plaintext highlighter-rouge">(x, I)</code> to its forwarding table.==</li>
</ul>

<blockquote>
  <p><strong>Note</strong></p>

  <p>reduce the cost in its own AS while ignoring the other components of the end-to-end costs outside its AS</p>

  <ul>
    <li>so in this case, we see the actual shorter path could be <code class="language-plaintext highlighter-rouge">AS3-x</code> which goes through <code class="language-plaintext highlighter-rouge">1d</code>. Hence this algorithm is a bit short-sighted.</li>
  </ul>
</blockquote>

<h4 id="route-selection-algorithm">Route-Selection Algorithm</h4>

<p>In practice, BGP uses an algorithm that is more complicated than hot potato routing, but nevertheless incorporates hot potato routing.</p>

<p>Recall that, for any destination prefix <code class="language-plaintext highlighter-rouge">x.x.x.x/y</code>, the input for BGP is the <strong>set of all routes</strong> to that prefix that have been learned and <strong>accepted</strong> by the router (rejection of a route can happen due to some policy issues)</p>

<ul>
  <li>
    <ul>
      <li>since you can reject routes, advertisement of accepted routes can also be seen as a reflection of a <strong>policy</strong></li>
    </ul>
  </li>
</ul>

<p>If there are two or more routes to the same prefix, then BGP ==sequentially invokes the following elimination rules until one route remains:==</p>
<ol>
  <li>The routes with the <strong>highest local preference values</strong> are selected</li>
</ol>

<ul>
  <li>
    <p>A route is assigned a local preference value as one of its attributes (in addition to the AS-PATH and NEXT-HOP attributes).</p>
  </li>
  <li>
    <p>The value of the local preference attribute is a <strong>policy decision</strong> that is left entirely up to the AS’s network administrator.</p>
    <ul>
      <li>The local preference of a route could have been set by the router or could have been learned from another router in the same AS.</li>
    </ul>
  </li>
</ul>

<ol>
  <li>From the remaining routes (all with the same highest local preference value), the route with the <strong>shortest AS-PATH is selected</strong>.</li>
</ol>

<ul>
  <li>If this rule were the only rule for route selection, then BGP would be using a DV algorithm for path determination, where the distance metric uses the number of AS hops rather than the number of router hops.</li>
</ul>

<ol>
  <li>
    <p>From the remaining routes (all with the same highest local preference value and the same AS-PATH length), <strong>hot potato routing</strong> is used, that is, the route with the closest NEXT-HOP router is selected.</p>
  </li>
  <li>
    <p>If more than one route still remains, the router uses <strong>BGP identifiers</strong> to select the route;</p>
  </li>
</ol>

<p><em>For Example</em></p>

<p>Consider the same example of Figure 5.10, where we want to send data from <code class="language-plaintext highlighter-rouge">1b-x</code>.</p>

<ul>
  <li>rule 2 is applied before rule 3, causing BGP to select the route that bypasses AS2, since that route has a ==shorter AS PATH==.</li>
  <li>hence, we will select the path to <code class="language-plaintext highlighter-rouge">1d</code>!</li>
</ul>

<blockquote>
  <p><strong>Note</strong></p>

  <ul>
    <li>
      <p>In reality, BGP routing tables often contain over half a million routes, as it is the de facto for the internet today.</p>
    </li>
    <li>
      <p>if <code class="language-plaintext highlighter-rouge">X</code> disconnects, BGP will advertise a <strong>withdraw message</strong>.</p>
    </li>
  </ul>
</blockquote>

<h3 id="routing-policy">Routing Policy</h3>

<p>Here we discuss how local preferences/polices can be used to prevent unintentional network traffic flowing through due to BGP.</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211129171834468.png" alt="image-20211129171834468" /></p>

<p>where:</p>

<ul>
  <li>A,B,C are provider networks</li>
  <li>x,w,y are <strong>customer</strong> (of provider networks)</li>
  <li>==``x` does not want to route from B to C via x!==</li>
</ul>

<p>Then, the policy to enforce is simply <strong>advertises (to its neighbors <code class="language-plaintext highlighter-rouge">B</code> and <code class="language-plaintext highlighter-rouge">C</code>) that it has no paths to any other destinations</strong> except itself.</p>

<p>Another example would be to consider from <code class="language-plaintext highlighter-rouge">B</code>, that it wants to tell its customer <code class="language-plaintext highlighter-rouge">x</code> that it contains a route to <code class="language-plaintext highlighter-rouge">w</code></p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">B </code>also wants to advertise the path <code class="language-plaintext highlighter-rouge">BAW</code> to its customer, <code class="language-plaintext highlighter-rouge">X </code>so that X knows that it can route to W via B.</li>
  <li>But <code class="language-plaintext highlighter-rouge">B </code>should ==not advertise <code class="language-plaintext highlighter-rouge">BAW</code> to <code class="language-plaintext highlighter-rouge">C</code>==, who would then route traffic to <code class="language-plaintext highlighter-rouge">w</code> from <code class="language-plaintext highlighter-rouge">BAW</code>!</li>
</ul>

<h2 id="software-defined-network">Software Defined Network</h2>

<p>Our study here <strong>builds on our earlier discussion</strong> of generalized SDN forwarding in Section <a href="#Generalized Forwarding and SDN">Generalized Forwarding and SDN</a>.</p>

<ul>
  <li>again, here we adopt the terminology of routers are ==packet switches== since the <strong>forwarding decisions</strong> can be made on the basis of network-layer source/destination addresses, link-layer source/destination addresses, as well as many other values in transport-, network-, and link-layer packet-header fields.</li>
</ul>

<p>Some key characteristic of SDN:</p>

<ol>
  <li><strong>Flow-based forwarding</strong>. Packet forwarding by SDN-controlled switches can be based on any number of header field values (see section <a href="#Generalized Forwarding and SDN">Generalized Forwarding and SDN</a> with more on OpenFlow1.0)</li>
  <li><strong>Separation of data plane and control plane</strong>. Recall again that now the entirety of control plane is in the remote controller in Figure 5.2. So packet switches ==just need to execute the “match plus action” rules in their flow tables== (delivered to them by the remote controller)</li>
  <li><strong>A programmable network</strong>. The network is programmable through the ==network control applications== running in the control plane. Basically you can just program them and inject by using the Northbound API to the controllers. (Figure 5.14)</li>
</ol>

<p>Basically the key difference is that we <strong>no longer do per-router control</strong>, such that we have a ==remote centralized controller==.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Overview of SDN</th>
      <th style="text-align: center">More Detailed SDN</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211129142740023.png" alt="image-20211129142740023" style="zoom: 80%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211201150246606.png" alt="image-20211201150246606" /></td>
    </tr>
  </tbody>
</table>

<p>where:</p>

<ul>
  <li>in Figure 5.14, control plane <strong>itself consists of two components</strong>. an SDN controller (or network operating system) and a set of network-control applications</li>
  <li>so it is more similar to the LS algorithm where there is a centralized agency</li>
</ul>

<p>So SDN is really ==three components: data plane switches, SDN controllers, and network-control applications==!</p>

<blockquote>
  <p><strong>Advantage of Centralized Control</strong></p>

  <p>The unbundling/separation into three components gives us a rich, open ecosystem driven by innovation in all three of these areas, as now software and hardware are <strong>decoupled!</strong></p>

  <ul>
    <li>load balancing
      <ul>
        <li>those decision would go against least-weight path</li>
      </ul>
    </li>
    <li>higher priority traffic to low cost and low priority to high cost link
      <ul>
        <li>SDN hence used extensively for cellular networks!</li>
      </ul>
    </li>
  </ul>

</blockquote>

<p>so the difference from the traditional distributed algorithm becomes:</p>

<ul>
  <li>using a centralized controller to compute table/figure out route (so control plane of routers don’t need to compute those routes)</li>
  <li>more functionality using <strong>flow table</strong></li>
</ul>

<h3 id="sdn-controller-architecture">SDN Controller Architecture</h3>

<p>In short, the controller part needs to do three things:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211201152101418.png" alt="image-20211201152101418" style="zoom:80%;" /></p>

<p>where basically:</p>

<ol>
  <li><strong>A communication layer</strong>: communicating between the SDN controller and controlled network devices. So here we basically have a protocol (OpenFlow or SNMP) to transfer information between the controller and that device.
    <ul>
      <li>e.g. need communicating a message indicating that an attached link has gone up or down, that a device has just joined the network, or a heartbeat indicating that a device is up and operational</li>
    </ul>
  </li>
  <li>
    <p><strong>A network-wide state-management layer</strong>: basically stores state of the entire lower layer packet switches. This will be used by the upper layer “brain” software to implement load balancing and etc.</p>
  </li>
  <li><strong>The interface to the network-control application layer.</strong> Provide API to the software above for computation, i.e. giving the Northbound API.</li>
</ol>

<blockquote>
  <p><strong>Note</strong></p>

  <p>In this architecture, the ==controller plane does NOT compute route==. It only maintains those route related information and it is the ==upper layer software== that computes the route (see Figure 5.15).</p>
</blockquote>

<h3 id="openflow-protocol">OpenFlow Protocol</h3>

<p>Here we zoom into the communication between the control layer and the packet switches below (see Figure 5.15), The OpenFlow protocol operates over TCP, with a default port number of <code class="language-plaintext highlighter-rouge">6653</code>.</p>

<p>Among the important messages flowing ==from the controller== to the controlled packet switch are the following:</p>

<ul>
  <li><em>Configuration</em>: controller to query and set a switch’s configuration parameters.</li>
  <li><em>Modify-State</em>. This message is used by a controller to <strong>add/delete or modify entries in the switch’s flow table</strong>, and to set switch port properties.</li>
  <li><em>Read-State</em>. This message is used by a controller to <strong>collect statistics and counter values</strong> from the switch’s flow table and ports.</li>
  <li><em>Send-Packet</em>. This message is used by the controller to send a specific packet out of a specified port at the controlled switch. The message itself contains the packet to be sent in its payload.</li>
</ul>

<p>Among the messages flowing ==from the SDN-controlled packet switch== to the controller are the following:</p>

<ul>
  <li><em>Flow-Removed</em>. This message informs the controller that a flow table entry has been removed, e.g. due to <em>Modify-State</em> message</li>
  <li><em>Port-status.</em> This message is used by a switch to inform the controller of a change in port status.</li>
  <li><em>Packet-in.</em> Recall from section <a href="#Generalized Forwarding and SDN">Generalized Forwarding and SDN</a>. that a packet arriving at a switch port and <strong>not matching any flow table entry is sent to the controller</strong> for additional processing</li>
</ul>

<h3 id="interaction-with-network-application-layer">Interaction with Network Application Layer</h3>

<p>Here we can just walk through an example of running Dijkstra’s algorithm to figure out the shortest path among the routers.</p>

<p>Consider the case that <strong>router <code class="language-plaintext highlighter-rouge">S1</code> and <code class="language-plaintext highlighter-rouge">S2</code> link is suddenly down</strong>. Then:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211201153458008.png" alt="image-20211201153458008" style="zoom:80%;" /></p>

<ol>
  <li>Switch s1, experiencing a link failure between itself and s2, ==notifies the SDN controller== of the link-state change using the ==OpenFlow <em>port-status</em> message==</li>
  <li>The SDN controller receives the OpenFlow message indicating the link-state change, and notifies the link-state manager, which ==updates a link-state database==</li>
  <li>The network-control application that implements Dijkstra’s link-state routing has previously <strong>registered to be notified</strong> when link state changes. That ==application receives the notification== of the link-state change.</li>
  <li>link-state routing application interacts with the link-state manager to get updated link state, and perhaps also consult other components in the state-management layer for computation (e.g. Network Graph)</li>
  <li>application ==finished computing==, then interacts with the flow table manager, which ==determines the flow tables== to be updated</li>
  <li>The flow table manager then uses the OpenFlow protocol to ==update flow table== entries at affected switches</li>
</ol>

<h3 id="sdn-challenges">SDN Challenges</h3>

<ol>
  <li>Robustness: what happens if a link between the <strong>controller and the router</strong> breaks? Then you cannot push updates/fixes!
    <ul>
      <li>problem with all centralized system - single point of failure</li>
    </ul>
  </li>
</ol>

<h2 id="icmp-internet-control-message-protocol">ICMP: Internet Control Message Protocol</h2>

<p>The ICMP is basically used for hosts and routers to ==communicate network-layer information== to each other. This is needed especially for ==error reporting==.</p>

<ul>
  <li>e.g. an IP router was unable to find a path to the host specified in your HTTP request. Then that <strong>router will create and sent an ICMP message to your host indicating the error</strong></li>
  <li>this example above is how you receive error message such as “Destination network unreachable.”</li>
</ul>

<h3 id="icmp-messages">ICMP Messages</h3>

<p>ICMP is often considered part of IP, but architecturally (its layer) it lies just above IP, as ICMP messages are carried inside IP datagrams.</p>

<ul>
  <li>i.e. that is, <strong>ICMP messages are carried as IP ==payload==</strong>, just as TCP or UDP segments are carried as IP payload</li>
  <li>therefore, when demultiplexing an IP packet, you can have TCP, UDP or ICMP</li>
</ul>

<p>Now, ICMP messages typically have:</p>

<ul>
  <li>a <strong>type</strong> and a <strong>code</strong> field (2-tuple)</li>
  <li>a <strong>header</strong></li>
  <li>first <strong>8 bytes of the IP datagram</strong> that <strong>caused the ICMP message</strong> to be generated in the first place
    <ul>
      <li>so you know which packet caused the issue</li>
    </ul>
  </li>
</ul>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211206141546724.png" alt="image-20211206141546724" /></p>

<blockquote>
  <p><strong>Note</strong></p>

  <ul>
    <li>In reality the ICMP messages are usually ==generated by the OS== directly in response to something. So there is no specific “server program” you would run.</li>
  </ul>
</blockquote>

<h3 id="examples-of-icmp-usages">Examples of ICMP Usages</h3>

<p><em>Example:</em> <code class="language-plaintext highlighter-rouge">ping</code></p>

<p>The well-known ping program does this:</p>

<ol>
  <li>client sends an ICMP <strong>type 8 code 0</strong> message to the specified host.</li>
  <li>The destination host, seeing the echo request, sends back a <strong>type 0 code 0</strong> ICMP echo reply.</li>
</ol>

<p>Notice that, as mentioned before, most TCP/IP implementations support the ping server <strong>directly in the operating system</strong></p>

<hr />

<p><em>Example</em>: <code class="language-plaintext highlighter-rouge">traceroute</code></p>

<p>Traceroute is implemented with ICMP messages. As we know, basically Traceroute in the source sends a series of ordinary <strong>IP datagrams</strong>, each of these datagrams <strong>carries a UDP segment</strong> with an unlikely UDP port number.</p>

<ol>
  <li>The first of these datagrams has a <code class="language-plaintext highlighter-rouge">TTL </code>of 1, the second of 2, the third of 3, and so on</li>
  <li>The source also starts timers for each of the datagrams</li>
  <li>When the $n$th datagram arrives at the $n$th router, the $n$th router observes that the <strong>TTL of the datagram has just expired.</strong></li>
  <li>The ==router== discards the datagram (according to IP protocol) and <strong>sends an ICMP warning message to the source</strong> (type 11 code 0).
    <ul>
      <li>This warning message includes the <strong>name of the router and its IP address</strong>.</li>
    </ul>
  </li>
  <li>When this ICMP message arrives back at the source, the source obtains the round-trip time from the timer and the name and IP address of the nth router from the ICMP message</li>
  <li>Repeat step 2 to 5 until received Port Unreachable ICMP Message
    <ul>
      <li>Because this datagram contains a UDP segment with an <strong>unlikely port number</strong>, the ==final destination host sends a port unreachable ICMP message== (type 3 code 3) back to the source</li>
    </ul>
  </li>
</ol>

<h2 id="network-management-snmp-and-netconfyang">Network Management, SNMP, and NETCONF/YANG</h2>

<p>Basically, here we discuss a set of network management tools and approaches that help the network administrator monitor, manage, and control the network.</p>

<ul>
  <li>e.g. what if we want to shut down/restart a router? We cannot do what with ==SDN + OpenFlow as they are for routing purposes==.</li>
  <li>here we basically discuss tools we can use to <strong>control/execute commands on a cluster of routes/devices</strong></li>
</ul>

<p>A brief glimps on what will be covered:</p>

<ul>
  <li>how to communicate status information (e.g. server/router down)</li>
  <li>how to execute commands</li>
</ul>

<blockquote>
  <p>In reality, as they are tools used to <strong>manage the actions (not routing) of a cluster of routers</strong>, it is very relevant to Data Center and their Software defined network.</p>
</blockquote>

<h3 id="network-management-framework">Network Management Framework</h3>

<p>Basically we have some network managers controlling a <strong>managing server</strong>, which can in turn collect statistics of the devices (not only routers) in the particular AS.</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211206143745053.png" alt="image-20211206143745053" /></p>

<p>where:</p>

<ul>
  <li><strong>Managing server</strong>. The managing server is an application, typically with network managers (humans) in the loop, running in a centralized network management station in the network operations center (NOC). The aim is to configure, monitor, and control the network’s managed devices</li>
  <li><strong>Managed device.</strong> A managed device might be a host, router, switch, middlebox, modem, ==thermometer==, or other network-connected device.</li>
  <li><strong>Data</strong>. Each ==managed device== will have data, also known as “state.” Typically you have
    <ul>
      <li><em>Configuration data</em> is device information explicitly configured by the network manager. e.g. configured IP address or interface speed</li>
      <li><em>Operational data</em> is information that the device acquires as it operates, for example, the list of immediate neighbors in OSPF protocol.</li>
      <li><em>Device statistics</em> are status indicators and counts that are updated as the device operators</li>
    </ul>
  </li>
  <li><strong>Network management agent.</strong> The network management agent is a ==software== process running in the ==managed device== that communicates with the managing server.
    <ul>
      <li>this is the program that actually <strong>taking local actions at the managed device</strong> under the command and control of the managing server</li>
    </ul>
  </li>
  <li><strong>Network Management Protocol</strong>. The protocol between the managing server and the devices , so that ==agents== can use the network management protocol to
    <ul>
      <li>inform the managing server of exceptional events (e.g., component failures).</li>
      <li>take actions as designated from the server</li>
    </ul>
  </li>
</ul>

<hr />

<p>Then, in practise, we have three main ways where a network admin use to manage the network, using:</p>

<ul>
  <li>
    <p><strong>CLI</strong>. Access the device directly using command line interface, by <code class="language-plaintext highlighter-rouge">ssh</code> into it.</p>
  </li>
  <li>
    <p><strong>SNMP/MIB</strong>. Admin can query/set the ==data contained in a device’s Management Information Base (MIB)== objects using the Simple Network Management Protocol (SNMP).</p>

    <ul>
      <li>Some MIBs are device- and vendor-specific, while other MIBs are device agnostic, i.e. generic</li>
      <li>this is used often in combination of CLI, i.e. you collect statistics from SNMP, and use CLI to do actions</li>
    </ul>

    <p>Note that both approaches above manage devices ==individually==.</p>
  </li>
  <li>
    <p><strong>NETCONF/YANG</strong>. Used for large system as it <strong>scales</strong>! It can control a collective of devices.</p>

    <ul>
      <li>NETCONF protocol [RFC 6241] is used to communicate YANG-compatible actions and data to/from/among remote devices</li>
      <li>YANG [RFC 6020] is a data modeling ==language== used to model <strong>configuration and operational data</strong>.</li>
    </ul>
  </li>
</ul>

<h3 id="snmp-and-mib">SNMP and MIB</h3>

<p>The Simple Network Management Protocol version 3 (SNMPv3) [RFC 3410] is an application-layer protocol used to convey network-management control and information messages <strong>between a managing server and an agent</strong> executing on behalf of that managing server.</p>

<p>The typical usage of SNMP is in a request-response mode in which:</p>

<ul>
  <li>an SNMP managing <strong>server</strong> sends a <strong>request</strong> to an SNMP agent</li>
  <li>the SNMP <strong>agent</strong> who received the request, will perform some action and sends a <strong>response</strong> back</li>
</ul>

<p>Another important usage is when some urgent things happened (e.g. an error):</p>

<ul>
  <li>an SNMP <strong>agent</strong> send unsolicited message/trap message to server</li>
</ul>

<p>So basically it looks like:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Normal</th>
      <th style="text-align: center">Trap Situation</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211206145541927.png" alt="image-20211206145541927" style="zoom:80%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211206145537156.png" alt="image-20211206145537156" style="zoom:80%;" /></td>
    </tr>
  </tbody>
</table>

<p>where:</p>

<ul>
  <li>the left is the typical situation mentioned above, it is “triggered by server”</li>
  <li>the right is when something bad happened. It is “triggered by agent”</li>
</ul>

<p>Then, SNMPv3 defines ==seven types of messages==, known generically as <strong>protocol data units—PDUs—</strong>as shown in the table and figure below.</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211206090036845.png" alt="image-20211206090036845" style="zoom:50%;" /></p>

<p>where notice that:</p>

<ul>
  <li>the last to messages are sent <strong>from agent to manager</strong></li>
</ul>

<p>And a PDU that is the packet actually sent looks like</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211206150008722.png" alt="image-20211206150008722" style="zoom: 80%;" /></p>

<h3 id="netconf-and-yang">NETCONF and YANG</h3>

<p>In this paradigm, we need managing server <strong>actively controls a managed device</strong> by sending it configurations, which are specified in a structured XML document, and activating a configuration at the managed device.</p>

<ul>
  <li>all done in a remote procedure call (RPC) paradigm</li>
</ul>

<blockquote>
  <p><em>Reminder</em></p>

  <p>A remote procedure call is simply</p>

  <p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211206150947876.png" alt="image-20211206150947876" style="zoom: 67%;" /></p>

  <p>the take-away message is that:</p>

  <ul>
    <li>for the client, it is basically asking <strong>somebody (remote) as to do the computation and return the result</strong> (execution resumes as if returning from a regular procedure call. )</li>
  </ul>
</blockquote>

<p>Under the hood, it is basically doing this</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211206150504344.png" alt="image-20211206150504344" style="zoom: 67%;" /></p>

<p>where we are using a ==connection-oriented session of TLS over TCP==, and:</p>

<ol>
  <li>server establishes a secure connection to the managed client (agent)</li>
  <li>the managing server and the managed device exchange <code class="language-plaintext highlighter-rouge">&lt;hello&gt;</code> messages, declaring their “capabilities”</li>
  <li>Interactions between the managing server and managed device take the form of a remote procedure call, using the <code class="language-plaintext highlighter-rouge">&lt;rpc&gt;</code> and <code class="language-plaintext highlighter-rouge">&lt;rpc-response&gt;</code> messages.</li>
</ol>

<p>Then some actoins that NETCONF can take is</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211206151335371.png" alt="image-20211206151335371" style="zoom:80%;" /></p>

<p>notice the emphasis on <strong>configuration of devices</strong>.</p>

<p>And interestingly, the actual message doing those actions are not in the format of HEADER + KEY-VALUE pairs, but now in XML format</p>

<p><em>Example: <code class="language-plaintext highlighter-rouge">&lt;get&gt;</code></em></p>

<div class="language-xml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">&lt;?xml version=”1.0” encoding=”UTF-8”?&gt;</span>
<span class="nt">&lt;rpc</span> <span class="na">message-id=</span><span class="s">”101”</span>
     <span class="na">xmlns=</span><span class="s">”urn:ietf:params:xml:ns:netconf:base:1.0”</span><span class="nt">&gt;</span>
    <span class="nt">&lt;get/&gt;</span>
<span class="nt">&lt;/rpc&gt;</span>
</code></pre></div></div>

<p>where this is a NETCONF <code class="language-plaintext highlighter-rouge">&lt;get&gt;</code> command requesting all device configuration</p>

<ul>
  <li>the RPC message itself spans lines 02–05, basically:
    <ul>
      <li>RPC has a message ID value of 101</li>
      <li>RPC contains a single command of <code class="language-plaintext highlighter-rouge">&lt;get&gt;</code></li>
    </ul>
  </li>
</ul>

<p>Then the reply could look like</p>

<div class="language-xml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">&lt;?xml version=”1.0” encoding=”UTF-8”?&gt;</span>
<span class="nt">&lt;rpc-reply</span> <span class="na">message-id=</span><span class="s">”101”</span>
           <span class="na">xmlns=</span><span class="s">”urn:ietf:params:xml:ns:netconf:base:1.0”</span><span class="nt">&gt;</span>
    <span class="c">&lt;!--"."."."all configuration data returned... --&gt;</span>
    ...
<span class="nt">&lt;/rpc-reply&gt;</span>
</code></pre></div></div>

<hr />

<p>More complicated example:</p>

<p><strong>Server</strong> wants to sets the Maximum Transmission Unit (MTU) of an interface named “Ethernet0/0” to 1500 bytes.</p>

<div class="language-xml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">&lt;?xml version=”1.0” encoding=”UTF-8”?&gt;</span>
<span class="nt">&lt;rpc</span> <span class="na">message-id=</span><span class="s">”101”</span>
     <span class="na">xmlns=</span><span class="s">”urn:ietf:params:xml:ns:netconf:base:1.0”</span><span class="nt">&gt;</span>
    <span class="nt">&lt;edit-config&gt;</span>
        <span class="nt">&lt;target&gt;</span>
            <span class="nt">&lt;running/&gt;</span>
        <span class="nt">&lt;/target&gt;</span>
        <span class="nt">&lt;config&gt;</span>
            <span class="nt">&lt;top</span> <span class="na">xmlns=</span><span class="s">”http://example.com/schema/</span>
                 <span class="err">1.2/config”</span><span class="nt">&gt;</span>
                <span class="nt">&lt;interface&gt;</span>
                    <span class="nt">&lt;name&gt;</span>Ethernet0/0<span class="nt">&lt;/name&gt;</span>
                    <span class="nt">&lt;mtu&gt;</span>1500<span class="nt">&lt;/mtu&gt;</span>
                <span class="nt">&lt;/interface&gt;</span>
            <span class="nt">&lt;/top&gt;</span>
        <span class="nt">&lt;/config&gt;</span>
    <span class="nt">&lt;/edit-config&gt;</span>
<span class="nt">&lt;/rpc&gt;</span>
</code></pre></div></div>

<p>where:</p>

<ul>
  <li>RPC message itself spans lines 02–17</li>
  <li>contains a single NETCONF <code class="language-plaintext highlighter-rouge">&lt;edit-config&gt;</code> command, spanning lines 04–15.</li>
</ul>

<p>Then the reply looks like</p>

<div class="language-xml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">&lt;?xml version=”1.0” encoding=”UTF-8”?&gt;</span>
<span class="nt">&lt;rpc-reply</span> <span class="na">message-id=</span><span class="s">”101”</span>
           <span class="na">xmlns=</span><span class="s">”urn:ietf:params:xml:ns:netconf:base:1.0”</span><span class="nt">&gt;</span>
    <span class="nt">&lt;ok/&gt;</span>
<span class="nt">&lt;/rpc-reply&gt;</span>
</code></pre></div></div>

<h4 id="yang">YANG</h4>

<p>YANG is the data modeling language used to precisely specify the structure, syntax, and semantics of <strong>network management data used by NETCONF</strong>.</p>

<p>Basic YANG then allows programmability for <strong>easier XML-based message</strong></p>

<ul>
  <li>variables, loops, etc to do configuration</li>
</ul>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211206090522407.png" alt="image-20211206090522407" style="zoom:50%;" /></p>

<h1 id="chapter-6-link-layer">Chapter 6 Link Layer</h1>

<p><strong>Recap</strong>: Network layer provides a communication service between any two network hosts (by doing a bunch of routing through routers). Between the two hosts, datagrams travel over a series of communication links (routing).</p>

<p>Here, we consider how packets are ==sent across the individual links== that make up the end-to-end communication path.</p>

<p>In particular, you will see that there are two types of link-layer channels usde to “deliver packet from one device to another” (e.g. your phone to a router)</p>

<ul>
  <li><strong>broadcast channels</strong>, which connect multiple hosts in wireless LANs,
    <ul>
      <li>many hosts are connected to the same broadcast communication channel, a so-called medium access protocol is needed to coordinate frame transmission</li>
      <li>i.e. how to share the medium</li>
    </ul>
  </li>
  <li><strong>point-to-point communication link</strong>, such as that often found between two routers connected by a long-distance link, or between a user’s office computer and the nearby Ethernet switch</li>
</ul>

<h2 id="introduction-to-the-link-layer">Introduction to the Link Layer</h2>

<p>Here, we use the terminology that:</p>

<ul>
  <li>refer to <strong>any device that runs a link-layer</strong> (i.e., layer 2) protocol as a ==node==
    <ul>
      <li>e.g. hosts, routers, switches, and WiFi access points</li>
    </ul>
  </li>
  <li>communication <strong>channels</strong> that ==connect adjacent nodes== along the communication path as ==links==.</li>
</ul>

<p>For example, sending from a laptop (host) to some server across the network:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211206155454952.png" alt="image-20211206155454952" style="zoom:80%;" /></p>

<p>where again, we relied on the network layer to figure out the route</p>

<ul>
  <li>then, <strong>link layer</strong> needs to deal with encapsulating IP datagram and sending it over the <strong>6 links traversed</strong></li>
  <li>notice that the first link is between a <em>host and a wireless router</em>!</li>
</ul>

<blockquote>
  <p><strong>Distinguishing between Network and Link</strong></p>

  <p>Consider the analogy of planning a trip for a tourist traveling from Princeton, New Jersey, to Lausanne, Switzerland.</p>

  <ol>
    <li>
      <p>You made a plan to</p>

      <ul>
        <li>take a limousine from Princeton to JFK airport</li>
        <li>then a plane from JFK airport to Geneva’s airport,</li>
        <li>a train from Geneva’s airport to Lausanne’s train station</li>
      </ul>

      <p>then you make reservations for them as well</p>
    </li>
    <li>
      <p>You actually do the trip, and then:</p>

      <ul>
        <li>Princeton <em>limousine company</em> to get you from Princeton to JFK;</li>
        <li>it is the responsibility of the <em>airline company</em> to get the tourist from JFK to Geneva</li>
        <li>it is the responsibility of the <em>Swiss train service</em> to get the tourist from Geneva to Lausanne</li>
      </ul>
    </li>
  </ol>

  <p>In total we got three “links”, and in particular</p>

  <ul>
    <li>you are the <strong>datagram</strong></li>
    <li>travel agent <strong>deciding the route</strong> is a routing protocol (<strong>network</strong>)</li>
    <li>each transportation segment is a link</li>
    <li>the <strong>transportation mode along the route</strong> (e.g. train or plane) is a <strong>link-layer protocol</strong>
      <ul>
        <li>notice that routing, in that sense, doesn’t care about <em>how the transportation is being done</em>. It just cares about where it is going.</li>
        <li>e.g. network layer ensures that Host <code class="language-plaintext highlighter-rouge">A</code> -&gt;  Router <code class="language-plaintext highlighter-rouge">R</code> will work. But in reality there are many switches to reach router <code class="language-plaintext highlighter-rouge">R</code> from host A in some subnet. Therefore, link layer <strong>deals with the delivery among switches/hosts</strong> to get to ==its end points (host or router)==</li>
      </ul>
    </li>
  </ul>
</blockquote>

<h3 id="link-layer-services">Link Layer Services</h3>

<p>Possible services that can be offered by a link-layer protocol include:</p>

<ul>
  <li><strong>Framing</strong>. Almost all link-layer protocols encapsulate each network-layer datagram within a link-layer frame before transmission over the link
    <ul>
      <li>MAC addresses in frame headers identify source, destination (<strong>different from IP address</strong>!)</li>
    </ul>
  </li>
  <li><strong>Link Access</strong>. A medium access control (MAC) protocol specifies the rules by which a frame is transmitted onto the link. Basically the two cases that:
    <ul>
      <li>if there is only a point-to-point link, i.e. a single sender and a receiver, then MAC is simple or nonexistent</li>
      <li>The more interesting case is when <strong>multiple nodes share a single broadcast link</strong>—the so-called multiple access problem. Here, the MAC protocol serves to coordinate the frame transmissions of the many nodes.</li>
    </ul>
  </li>
  <li><strong>Reliable Delivery.</strong> First note that this is different from the higher layer reliable deliver such as TCP ==(host to host)==. Here, the the aim is to guarantees to move each network-layer datagram across the link without error ==(node to node)==.
    <ul>
      <li>in the end, it is the achieved the same with acknowledgments and retransmissions (see Section 3.4).</li>
      <li>this is often used for links that are prone to <strong>high error rates</strong>, such as wireless link, so that ==error are corrected immediately/locally== (as compared to realizing only at the destination host that something is wrong). Links with low error rates such as fiber do not typically use this, so there is a less overhead.</li>
    </ul>
  </li>
  <li><strong>Error detection and Correction</strong>. Bits are basically electric signals, so bit error can occur due to attenuation and electromagnetic noise. If error can be discovered fast, then we don’t waste time to forward it all the way to destination.
    <ul>
      <li>This is done by having the <strong>transmitting</strong> node include <strong>error-detection bits</strong> in the frame, and having the <strong>receiving</strong> node perform an <strong>error check</strong>. (more sophisticated than checksum)</li>
    </ul>
  </li>
</ul>

<blockquote>
  <p><strong>Recall</strong></p>

  <p>Each time for a <em>single message</em> to be exchanged, you went:</p>

  <ul>
    <li>from application layer all the way down to physical of a host (when sending)</li>
    <li>from physical layer all the way up to application layer of a host (when received)</li>
  </ul>
</blockquote>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211206092528986.png" alt="image-20211206092528986" /></p>

<p>where basically the red parts are the link-layer’s job.</p>

<h3 id="where-is-the-link-layer-implemented">Where Is the Link Layer Implemented</h3>

<p>Link layer is basically implemented in every device in the network that can communicate/send/switch packets.</p>

<p><strong>In a host</strong>, e.g. your laptop <strong>link layer</strong> is implemented on a ==chip== called the ==network adapter==</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211206162255593.png" alt="image-20211206162255593" /></p>

<p>where:</p>

<ul>
  <li>the network adapter is sometimes known as a <strong>network interface controller (NIC)</strong>.</li>
  <li>Thus, <strong>much</strong> of a link-layer controller’s functionality is implemented in <strong>hardware</strong> (controller).
    <ul>
      <li>part of the link layer is implemented in software that runs on the host’s CPU, e.g. handling controller interrupts when received data.</li>
    </ul>
  </li>
  <li>for a ==sender==, the ==controller==
    <ol>
      <li>takes the datagram created/ready from the <strong>memory</strong></li>
      <li>encapsulate it into an <strong>link-layer frame</strong>
        <ul>
          <li>potentially setting error detection bits as well</li>
        </ul>
      </li>
      <li>transmit it into the physical transmissions part</li>
    </ol>
  </li>
  <li>for a ==receiver==, then ==controller==
    <ol>
      <li>receive the tram from the link</li>
      <li>extract the network layer datagram
        <ul>
          <li>potentially perform error detection</li>
        </ul>
      </li>
      <li>puts it in the memory and informs CPU that data is received</li>
    </ol>
  </li>
</ul>

<h2 id="error-detection-and-correction">Error Detection and Correction</h2>

<p>In this section, we’ll examine a few of the simplest techniques that can be used to detect and, <strong>in some cases</strong>, even <strong>fix the bit error</strong>.</p>

<ul>
  <li>so here we assume (and this is commonly done anyway) that sender configured the ==error-detection and -correction bits (EDC)==.</li>
</ul>

<p>Essentially, given the new frame <code class="language-plaintext highlighter-rouge">D'</code>, <code class="language-plaintext highlighter-rouge">EDC'</code>:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211206163423570.png" alt="image-20211206163423570" /></p>

<p>where:</p>

<ul>
  <li>notice that <code class="language-plaintext highlighter-rouge">EDC'</code> might also be flipped</li>
  <li>We thus want to choose an error-detection scheme that keeps the probability of “receiving a corrupted packet and not noticing” to be small.
    <ul>
      <li>there is always the case that everything could go wrong, so we want to keep the probability of that small</li>
    </ul>
  </li>
</ul>

<h3 id="parity-checks">Parity Checks</h3>

<p>Perhaps the simplest form of error detection is the use of a single parity bit. Here you have two schemes to choose from (basically same idea)</p>

<p>Let the entire information to be sent, $D$, include $d$ bits.</p>

<ol>
  <li>
    <p>Using an ==even parity scheme==:</p>

    <p>The sender simply includes one additional bit and chooses its value such that the <strong>total number of 1s in the $d + 1$ bits</strong> (including the parity bit) is <strong>even</strong>.</p>

    <ul>
      <li>i.e. put $1$ if there were odd number of 1s in the $d$ bits. Otherwise, put $0$.</li>
    </ul>
  </li>
  <li>
    <p>Using an ==odd parity scheme==</p>

    <p>The sender includes the parity bit such that there is an <strong>odd number of $1$s</strong> in the $d+1$ bits.</p>
  </li>
</ol>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211206164141950.png" alt="image-20211206164141950" /></p>

<p>However, this is not used in reality because:</p>

<ul>
  <li>multiple errors often happen in a cluster. So sometimes error become <strong>undetected</strong> as you only used 1 bit for error
    <ul>
      <li>it was shown that under burst error condition, this could happen about 50 percent of the time</li>
    </ul>
  </li>
  <li>no idea <strong>how to correct</strong> the error, as you don’t know <em>where</em> the error is.</li>
</ul>

<p>But this idea is <em>not useless</em>. Consider using a ==two-dimensional generalization of the single-bit parity scheme==.</p>

<ul>
  <li>Here, the $d$ bits in $D$ are divided into $i$ rows and $j$ columns.</li>
  <li>A parity value is computed <strong>for each row and for each column</strong>.</li>
</ul>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211206164648195.png" alt="image-20211206164648195" /></p>

<p>where:</p>

<ul>
  <li>the $d_{i+1,j+1}$ is the parity bit for that parity bits’ column and row</li>
</ul>

<p>Then, this is possible to <strong>detect and CORRECT a ==single bit error==</strong>.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">No Error</th>
      <th style="text-align: center">Error Detected</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211206093539516.png" alt="image-20211206093539516" /></td>
      <td style="text-align: center"><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211206093604751.png" alt="image-20211206093604751" /></td>
    </tr>
  </tbody>
</table>

<p>where we assumed that we are using <strong>even parity</strong></p>

<ul>
  <li>if there is <strong>a single bit error</strong> in the data, it is detectable and correctable</li>
  <li>if there is <strong>a single bit error</strong> in the parity bits, it is also detectable and correctable</li>
  <li>if there are <strong>two errors</strong>, this can only detect but <em>not correct</em> the errors.</li>
</ul>

<blockquote>
  <p><strong>Forward Error Correction (FEC)</strong></p>

  <p>The ability of receiver to both detect and correct errors is known as forward error correction (FEC).</p>

  <ul>
    <li>again, those FEC techniques are valuable because they can decrease the number of sender retransmissions required. Perhaps more important, they allow for <strong>immediate correction</strong> of errors at the receiver, instead of waiting for an entire round-trip propagation delay.</li>
  </ul>
</blockquote>

<h3 id="checksumming-methods">Checksumming Methods</h3>

<p>In checksumming techniques, the $d$ bits of data in Figure 6.4 are treated as a sequence of $k$-bit integers (e.g. $k=16$ for the Internet Checksum)</p>

<ul>
  <li>for $k=16$, then bytes of data are treated as 16-bit integers and summed</li>
</ul>

<p>Basically for ==sender==, the checksum is computed by <strong>taking 1’s complement of the sum of data</strong>:</p>

<ul>
  <li>1’s complement is basically inverting all the bits in the binary representation</li>
</ul>

<pre><code class="language-pseudocode">              10101001
              00111001
              --------
   Sum        11100010
   Checksum:  00011101
</code></pre>

<p>Then, the checksum is used by receiver ==so that summing all of them== (including checksum) and taking 1’s complement should give you all 0s.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>			   10101001
               00111001
               00011101 // checksum
               <span class="nt">--------</span>
   Sum         11111111
   Complement  00000000  means that the pattern is O.K.
</code></pre></div></div>

<p>Again, this is fast but does <strong>not tell you</strong> where the error is. So it cannot be corrected.</p>

<blockquote>
  <p><strong>Note</strong></p>

  <p>Checksumming methods require relatively little packet overhead. However, they provide relatively weak protection against errors as compared with cyclic redundancy check. But the question is then <em>why is TCP and UDP not using cyclic redundancy check</em>?</p>

  <ul>
    <li>Because <strong>transport-layer error detection</strong> is <strong>implemented in software</strong>, it is important to have a simple and ==fast== error-detection scheme such as checksumming.</li>
    <li>On the other hand, error detection at the <strong>link layer</strong> is implemented in dedicated <strong>hardware</strong> in adapters, which can rapidly perform the more ==complex== CRC operations.</li>
  </ul>
</blockquote>

<h3 id="cyclic-redundancy-check-crc">Cyclic Redundancy Check (CRC)</h3>

<p>CRC codes operate as follows. Consider the $d$-bit piece of data, $D$, that the sending node wants to send to the receiving node. The sender and receiver must ==first agree on an $r + 1$ bit pattern==, known as a generator, which we will denote as $G$.</p>

<ul>
  <li>ofc we need the most significant (leftmost) bit of $G$ be a $1$.</li>
</ul>

<p>Then, the idea is as follows:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211206174103664.png" alt="image-20211206174103664" /></p>

<ol>
  <li>For a given piece of data, $D$, the <strong>sender</strong> will choose $r$ additional bits, $R$, and append them to $D$ ==such that the resulting $d + r$ bit== pattern (interpreted as a binary number) ==is exactly divisible by $G$==</li>
  <li>The <strong>receiver</strong> divides the $d + r$ received bits by $G$. If the ==remainder is nonzero==, the receiver knows that an error has occurred</li>
</ol>

<p>Then, how do we come up with the $R$?</p>

<blockquote>
  <p>All CRC calculations are done in ==modulo-2 arithmetic without carries in addition or borrows in subtraction==. Same case for division and multiplication.</p>

  <p>Therefore:</p>

  <ul>
    <li>
      <p>addition and subtraction are the same, and both are the same as <strong>XOR</strong> operation</p>

      <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1011 - 0101 <span class="o">=</span> 1110
1011 + 0101 <span class="o">=</span> 1110
</code></pre></div>      </div>

      <p>and XOR:</p>

      <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1011 XOR 0101 <span class="o">=</span> 1110
</code></pre></div>      </div>
    </li>
    <li>
      <p>division and multiplication in binary basically does:</p>

      <ul>
        <li>
          <p>multiplication by $2^k$ left shifts a bit pattern by $k$ places</p>
        </li>
        <li>
          <p>an example of division looks like the follows</p>

          <p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211206174020936.png" alt="image-20211206174020936" /></p>

          <p>where basically:</p>

\[101110000 \div 1001 = 101011 ... 011\]

          <p>where $R=011$ is a remainder.</p>
        </li>
      </ul>
    </li>
  </ul>
</blockquote>

<p>Now, given the division above, you will see that what is sent is eventually:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211206174529155.png" alt="image-20211206174529155" /></p>

<p>In other words, choose $R$ such that:</p>

\[nG = D \cdot 2^r - R = D \cdot 2^r  \text{ XOR } R\]

<p>where $G,r,D$ are given in the setup. So our task is to <em>*figure out what is $R$.</em>, such that our data is divisible by $G$.</p>

<p>Then, since we know $(A \text{ XOR }B) \text{ XOR }B = A$, then:</p>

\[\begin{align*}
D \cdot 2^r  \text{ XOR } R 
&amp;= nG\\
D\cdot 2^r
&amp;= nG  \text{ XOR } R\\
\text{remainder} \frac{D\cdot 2^r}{G} &amp;= R
\end{align*}\]

<p>where the last equality comes from the fact that $D\cdot 2^r= nG  \text{ XOR } R$ means $R$ is the remainder if you divide $D\cdot 2^r$ by $nG$.</p>

<ul>
  <li>see Figure 6.7 above which basically has $r=3$, $G=1011$ and $D=1011101$ as an example.</li>
</ul>

<blockquote>
  <p><strong>Note</strong></p>

  <ul>
    <li>recall that $r$ is fixed, and $G$ is a given $r+1$ bit pattern. Only $R$ is computed.</li>
    <li>This can detect all burst errors less than $r+1$ bits (i.e. <strong>any error formed with $r$ consecutive bits or fewer</strong> will be detected)</li>
  </ul>
</blockquote>

<p>International standards have been defined for 8-, 12-, 16-, and 32-bit generators, $G$. The CRC-32 32-bit standard, which has been adopted in a number of link-level IEEE protocols, uses:</p>

\[G_{CRC-32} = 100000100110000010001110110110111\]

<p>where</p>

<ul>
  <li>in addition to detect any $r$ bit or fewer consecutive errors, each of the CRC standards can detect any <strong>odd number of bit errors</strong></li>
</ul>

<h2 id="multiple-access-links-and-protocols">Multiple Access Links and Protocols</h2>

<blockquote>
  <p><em>Recall</em></p>

  <p>We have two types of network links:</p>

  <ol>
    <li><strong>A point-to-point link</strong>: consists of a single sender at one end of the link and a single receiver at the other end of the link.
      <ul>
        <li>Many link-layer protocols have been designed for point-to-point links; the point-to-point protocol (PPP) and high-level data link control (HDLC) are two such protocols</li>
        <li>this is simple, so not discussed here</li>
      </ul>
    </li>
    <li><strong>broadcast link</strong>: multiple host wants to send and receive connected to the same single <em>shared broadcast channel</em>
      <ul>
        <li>discussed below</li>
        <li>the term <em>broadcast</em> is used because when a node sends stuff, all the other node can “hear”/receive that</li>
      </ul>
    </li>
  </ol>
</blockquote>

<p>Consider you are the teacher (i.e. <strong>wireless router</strong>) in the classroom, and your students (i.e. <strong>hosts</strong> such as laptops, phones) want to ask some questions (<strong>transmit</strong> data to you). Then, the problem is:</p>

<ul>
  <li>to receive something, a student needs to speak up</li>
  <li>if more than one student speaks up, you cannot hear what is happening as voice overlaps</li>
  <li>the broadcast channel in this case is the classroom</li>
</ul>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Analogy</th>
      <th style="text-align: center">Shared Wireless</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211206182220081.png" alt="image-20211206182220081" /></td>
      <td style="text-align: center"><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211206182327468.png" alt="image-20211206182327468" /></td>
    </tr>
  </tbody>
</table>

<p>So the problem is how to ==coordinate the access of multiple sending and receiving nodes== to a ==shared broadcast channel==—the <strong>multiple access problem</strong>.</p>

<ul>
  <li>i.e. signals of the colliding frames become inextricably tangled together when more than two nodes are transmitting at the same time (again, because (radio) ==waves is used to transmit information== for WiFi, so it is broadcasted and can be mingled with others.)</li>
  <li>note one crucial difference with the classroom analogy is that, a teacher can <strong>see AND hear</strong> students (e.g. raising hand). However, a wireless router can <strong>only hear</strong>, i.e. everything happens within the same single channel. Your ==data channel== and ==control channel== is the same is causing more problem!</li>
</ul>

<p>To solve this issue, computer networks have  protocols—so-called <strong>multiple access protocols</strong>. In the ideal case, we want the following to happen when there is a shared/broadcast channel with multiple nodes:</p>

<ol>
  <li>When only <strong>one node</strong> has data to send, that node has a throughput of $R$ bps.</li>
  <li>When <strong>$M$ nodes</strong> have data to send, each of these nodes has a throughput of $R/M$ bps.
    <ul>
      <li>This need not necessarily imply that each of the M nodes always has an instantaneous rate of R/M, but rather that each node should have an average transmission rate of $R/M$ over some suitably defined interval of time.</li>
    </ul>
  </li>
  <li>The protocol is ==decentralized==; that is, there is no master node that represents a single point of failure for the network.</li>
  <li>The protocol is simple, so that it is ==inexpensive== to implement.</li>
</ol>

<p>Until today, over many years of research, we have made <strong>many working protocols for multiple access links</strong>, and they can be classified in general to the following three classes:</p>

<ul>
  <li><strong>channel partitioning</strong>
    <ul>
      <li>divide channel into smaller “pieces” (time slots, frequency, code)</li>
      <li>allocate piece to node for exclusive use</li>
    </ul>
  </li>
  <li><strong>random access</strong>
    <ul>
      <li>channel not divided, allow collisions</li>
      <li>“recover” from collisions by asking each node to randomly retransmit</li>
    </ul>
  </li>
  <li><strong>“taking turns”</strong>
    <ul>
      <li>nodes take turns, but nodes with more to send can take longer time in a turn</li>
    </ul>
  </li>
</ul>

<h3 id="channel-partitioning">Channel Partitioning</h3>

<p>Basically there are two protocols used: TDM which divides by timeslot, and FDM which divides by frequency.</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211208145422269.png" alt="image-20211208145422269" style="zoom: 80%;" /></p>

<p>For the below discussion, let channel <strong>supports $N$ nodes</strong> and that the <strong>transmission rate of the channel is $R$ bps.</strong></p>

<hr />

<p><strong>TDMA</strong>: time division multiple access</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211208145631472.png" alt="image-20211208145631472" style="zoom:80%;" /></p>

<ol>
  <li>TDM divides time into ==time frames== (nothing to do with “frame” of a link layer packet) and further divides each time frame into ==$N$ time slots==</li>
  <li>Each ==time slot== is then assigned to one of the $N$ nodes.
    <ul>
      <li>slot sizes are chosen so that a <strong>single packet</strong> can be transmitted during a slot <strong>time</strong>.</li>
    </ul>
  </li>
</ol>

<p>Therefore, it is <strong>fair</strong> in that each node gets a <strong>dedicated transmission rate of $R/N$ bps during each frame time</strong>. However, some obvious problems is:</p>

<ul>
  <li>unused slots go idle, waste to time slot/efficiency</li>
  <li>a node is limited to only $R/N$ <strong>rate</strong> even if someone is not sending stuff</li>
  <li>a node must always <strong>wait</strong> for its turn in the transmission sequence—again, even when it is the only node with a frame to send.</li>
</ul>

<hr />

<p><strong>FDMA</strong>: frequency division multiple access</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211208150203906.png" alt="image-20211208150203906" style="zoom: 80%;" /></p>

<ol>
  <li>FDM divides the $R$ bps channel into different <strong>frequencies</strong> (each with a bandwidth of $R/N$)</li>
  <li><strong>assigns each frequency</strong> to one of the $N$ nodes.</li>
</ol>

<p>Again, it avoids collisions and divides the bandwidth <strong>fairly</strong> among the $N$ nodes, but:</p>

<ul>
  <li>a node is <strong>limited to a bandwidth</strong> of $R/N$, even when it is the only node with packets to send.</li>
</ul>

<h3 id="random-access-protocol">Random Access Protocol</h3>

<p>The basic principle between protocols under this category is:</p>

<ol>
  <li>no coordination, node ==always== transmits at the <strong>full rate of the channel</strong>, namely, $R$ bps.</li>
  <li>then two or more nodes transmitting at the same time, we have a  “collision”. (otherwise done)</li>
  <li>Then each node ==repeatedly retransmits== its frame (that is, packet) ==until== its frame gets through ==without a collision==.
    <ul>
      <li>in fact, there will be a random delay before retransmitting the frame, whose mechanism will be decided by the specific protocol.</li>
      <li>however, it is kind of like “hope and pray”, as there is a chance that both nodes still picked the same delay</li>
    </ul>
  </li>
</ol>

<h4 id="slotted-aloha">Slotted ALOHA</h4>

<p>Our following discussion ==assumes== the following:</p>

<ul>
  <li>All frames consist of exactly $L$ bits.</li>
  <li>Time is divided into ==slots== of size $L/R$ seconds (that is, a time slot equals the <strong>time to transmit one frame</strong>).</li>
  <li>Nodes start to transmit frames only at the <strong>beginnings</strong> of slots.
    <ul>
      <li>so nodes’ <strong>clocks are synchronized</strong> so that each node knows when the slots begin.</li>
    </ul>
  </li>
  <li>If two or more frames collide in a slot, then <strong>all the nodes detect the collision</strong> event before the slot ends.</li>
</ul>

<p><strong>Operation</strong>: Let $p$ be a probability configured beforehand (optimal $p^*$ discussed below). Then:</p>

<ol>
  <li>when node obtains fresh frame, waits until the beginning of the next slot and transmit</li>
  <li><em>if no collision:</em> success and done</li>
  <li><em>if collision:</em> node ==retransmits== frame in each subsequent slot ==with probability $p$ until success==
    <ul>
      <li>i.e. in each subsequent slot, toss the biased coin with $p$ and decide whether to retransmit</li>
      <li>hopefully, eventually only one node will transmit within a slot - success</li>
    </ul>
  </li>
</ol>

<p>Some <strong>advantages</strong> include:</p>

<ul>
  <li>slotted ALOHA allows a node to transmit continuously at the <strong>full rate, $R$</strong>, when there is only one active node</li>
  <li>highly decentralized, because each node detects collisions and independently decides when to retransmit
    <ul>
      <li>yet clocks needs to be synchronized</li>
    </ul>
  </li>
  <li>simple to implement</li>
</ul>

<p>Some ==problems==:</p>

<ul>
  <li>
    <p>many time slots will be wasted if more than one active nodes:</p>

    <p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211208085721161.png" alt="image-20211208085721161" style="zoom: 50%;" /></p>

    <p>in this example, only 3 slots were “successful”, and 6 were wasted.</p>

    <p>We can in fact compute the efficiency (which is $1/e\approx 0.37$, and then derive the optimal $p^*$.</p>
  </li>
</ul>

<blockquote>
  <p><strong>Efficiency of a slotted multiple access protocol</strong></p>

  <p>This efficiency is defined to be the long-run ==fraction of successful slots== in the case when there are a large number of active nodes.</p>
</blockquote>

<p>To keep the derivation simple, ==assume== that ==each node always has a frame to send== and that the node transmits with probability $p$ ==for a fresh frame as well== as for a frame that has already suffered a collision.</p>

<p>Then, we know that:</p>

<ul>
  <li>the probability <strong>one given node</strong> has a success is $p(1 - p)^{N-1}$, i.e. only one decided to retransmit</li>
  <li>Because there are $N$ nodes, the probability that <strong>any one of the $N$ nodes</strong> has a success is $Np(1 - p)^{N-1}$. (multiply by ${n \choose 1} = N$)</li>
</ul>

<p>Therefore, efficiency with $N$ active nodes is:</p>

\[Np(1 - p)^{N-1}\]

<p>Let $p^*$ be the probability that maximizes this:</p>

<ul>
  <li>take derivatives to find best $p^*$</li>
  <li>take $\lim_{N \to \infty}$ with $p^*$ to find maximum efficiency</li>
</ul>

<p>Then, you will find that maximum efficiency of the protocol is given by $1/e \approx 0.37$.</p>

<ul>
  <li>when a large number of nodes have many frames to transmit, then (at best) only 37 percent of the slots do useful work</li>
  <li>the ==effective transmission rate== of the channel is not $R$ bps but only $0.37 R$ bps</li>
</ul>

<h4 id="pure-aloha">Pure ALOHA</h4>

<p>Basically without the slotted ALOHA without clock synchronization, such that they transmit/retransmit immediately if coin toss is successful.</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211208090143684.png" alt="image-20211208090143684" /></p>

<p><strong>Operation</strong></p>

<ol>
  <li>when a frame first arrives, the node <strong>immediately</strong> transmits the frame in its entirety into the broadcast channel</li>
  <li>if collided, the node will then <strong>immediately</strong> (after completely transmitting its collided frame) <strong>toss a coin with probability $p$</strong> and then retransmit the frame if coin said yes</li>
</ol>

<p>Now, what is the effiency and the best $p^*$? Intuitively it must be less than the slotted ALOHA due to non-coordination (the efficiency is only $1/(2e) \approx 18\%$.</p>

<p>Then, consider:</p>

<ul>
  <li>
    <p>given <strong>one node</strong> transmitted successfully when it started at $t_0$. This means that:</p>

    <ul>
      <li>no other node transmitted during $[t_0 - 1, t_0]$, this happens with $(1-p)^{N-1}$</li>
      <li>no other node begins transmission during $[t_0, t_0+1]$. This happens also with $(1-p)^{N-1}$</li>
    </ul>

    <p>therefore, it is successful only when <strong>both events happen</strong>, hence one node success is:</p>

\[(1-p)^{2(N-1)}\]
  </li>
  <li>
    <p>then for $N$ nodes, multiply this by ${n \choose 1} = N$</p>
  </li>
</ul>

<p>Finally by taking limits as in the slotted ALOHA case, we find that the maximum efficiency of the pure ALOHA protocol is only $1/(2e)$.</p>

<h4 id="csma">CSMA</h4>

<p>This basically tries to address one simple optimization of the previous protocols: if you see someone transmitting, you know a collision will happen so you should stop wasting your time trying it!</p>

<ul>
  <li>
    <p><strong>Listen before speaking</strong>. If someone else is speaking, wait until they are finished. In the networking world, this is called ==carrier sensing==— listens to the channel before transmitting</p>

    <ul>
      <li>i.e. begin transmission only if it hears no one speaking</li>
    </ul>
  </li>
  <li>
    <p><strong>If someone else begins talking at the same time, stop talking</strong>. In the networking world, this is called ==collision detection==. This can still happen as it takes time for one’s voice to reach the other.</p>

    <ul>
      <li>
        <p>e.g. if you have 4 nodes, two nodes $B,D$ wants to transmit something</p>

        <p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211208154849308.png" alt="image-20211208154849308" style="zoom:67%;" /></p>

        <p>notice that $t_0$, $B$ didn’t hear anything, and at $t_1$, $D$ also didn’t hear anything yet.</p>
      </li>
    </ul>
  </li>
</ul>

<p><strong>Operation</strong>: CSMDA (without collision detection)</p>

<ol>
  <li>a node listens to the channel before transmitting.</li>
  <li>if it detects no transmissions for a short amount of time, start transmitting</li>
  <li>If it detects that another node is transmitting an <strong>interfering</strong> frame (e.g. Figure 6.12 collision)
    <ul>
      <li>it waits until transmission finished (no abort)</li>
      <li>==waits a random amount of time before repeating== the sense-and-transmit-when-idle cycle.</li>
    </ul>
  </li>
</ol>

<p>As shown in Figure 6.12, performance of this protocol will be greatly affected by the <strong>channel’s propagation delay</strong>.</p>

<ul>
  <li>The <strong>longer this propagation delay</strong>, the <strong>larger the chance</strong> that a carrier-sensing node is not yet able to sense a transmission that has already begun at another node in the network.</li>
</ul>

<h4 id="csmacd">CSMA/CD</h4>

<p>Basically here we add the abortion to CSMA, so it is added CD for collision detection.</p>

<p><strong>Operatoin</strong>:</p>

<ol>
  <li>a node listens to the channel before transmitting.</li>
  <li>if it detects no transmissions for a short amount of time, start transmitting</li>
  <li>While transmitting, the adapter ==monitors for the presence of signal energy coming from other adapters== using the broadcast channel</li>
  <li>If it detects that another node is transmitting an <strong>interfering</strong> frame, abort transmission.
    <ul>
      <li>After aborting, the adapter <strong>waits a random amount of time</strong> (otherwise forever collision) and then returns to step 1.</li>
    </ul>
  </li>
</ol>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211208160053926.png" alt="image-20211208160053926" style="zoom:80%;" /></p>

<p>In this way, we can basically start the next cycle of wait and transmit earlier = more efficient. But one problem is <strong>what is a good interval of time for backoff</strong> (after abort)?</p>

<ul>
  <li>If the interval is <em>large</em> and the number of colliding nodes is small, nodes are likely to wait a large amount time = wasted</li>
  <li>if the interval is <em>small</em> and the number of colliding nodes is large, it’s likely that the chosen random values will be nearly the same, and transmitting nodes will again collide.</li>
</ul>

<blockquote>
  <p><strong>Binary Exponential Backoff Algorithm</strong></p>

  <p>when transmitting a frame that has already experienced $n$ collisions, a node ==chooses the value of $K$ at random== from:</p>

\[\{0,1,2,..., 2^{n}-1\}\]

  <p>where the maximum/range it can choose grows exponentially.</p>

  <ul>
    <li>thus, the <strong>more collisions</strong> experienced by a frame, the <strong>larger the interval</strong> from which $K$ is chosen.</li>
    <li>For Ethernet, the actual amount of time a node waits is $K \cdot 512$ bit times (i.e., $K$ times the amount of time needed to send 512 bits into the Ethernet)</li>
  </ul>
</blockquote>

<p><em>Example</em></p>

<p>Suppose that a node attempts to transmit a frame for the <strong>first time</strong> and while transmitting it detects a collision.</p>

<ol>
  <li>The node then chooses $K = 0$ with probability $0.5$ or chooses $K = 1$ with probability $0.5$.
    <ul>
      <li>If the node chooses $K = 0$, then it immediately begins sensing the channel.</li>
      <li>If the node chooses $K = 1$, it waits $512$ bit times (e.g., 5.12 microseconds for a 100 Mbps Ethernet) before beginning the sense-and-transmit-when-idle cycle.</li>
    </ul>
  </li>
  <li>After a second collision, $K$ is chosen with equal probability from ${0,1,2,3}$.</li>
  <li>After three collisions, $K$ is chosen with equal probability from ${0,1,2,3,4,5,6,7}$.</li>
  <li>etc.</li>
</ol>

<hr />

<p><strong>Efficiency of CSMA/CD</strong></p>

<p>Basically derivattion is skipped, and we were computing for the long-run ==fraction of time== during which frames are transmitted without collisions.</p>

\[\text{Efficiency} = \frac{1}{1+5d_{\mathrm{prop}}/d_{\text{trans}}}\]

<p>where:</p>

<ul>
  <li>$d_{\mathrm{prop}}$ is the <strong>maximum</strong> time it takes for a signal energy to propagate between two adapters</li>
  <li>$d_{\mathrm{trans}}$ is the time to transmit a <strong>maximum size</strong> frame</li>
  <li>if $d_{\mathrm{prop}} \to 0$, then efficiency is $1$.</li>
  <li>as $d_{\mathrm{trans}}$ becomes very large, efficiency approaches 1. This is also intuitive because when a frame grabs the channel, it will <strong>hold on to the channel</strong> for a very long time;</li>
</ul>

<h3 id="taking-turns-protocols">Taking-Turns Protocols</h3>

<p>Recall that two desirable properties of a multiple access protocol are</p>

<ol>
  <li>when only <strong>one</strong> node is active, the active node has a throughput of $R$ bps</li>
  <li>when <strong>$M$ nodes are active</strong>, then each active node has a throughput of nearly $R/M$ bps.</li>
</ol>

<p>Both ALOHA and CSMA can only achieve the first but not the second. This creates the desire for those taking-turns protocols which basically tries to <strong>round-robin</strong> among the nodes.</p>

<p>Here we introduce two protocols:</p>

<ul>
  <li>polling protocol</li>
  <li>token-passing protocol</li>
</ul>

<hr />

<p><strong>Polling Protocol Operation</strong></p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211208162158384.png" alt="image-20211208162158384" style="zoom:80%;" /></p>

<ol>
  <li>one of the nodes to be designated as a master node</li>
  <li>master node polls each of the nodes in a round-robin fashion.
    <ul>
      <li>master node first sends a message to node 1, saying that <strong>it (node 1) can transmit up to some maximum number of frames</strong></li>
    </ul>
  </li>
  <li>After node 1 transmits some frames, the master node <strong>tells node 2</strong> it (node 2) can transmit up to the maximum number of frames.
    <ul>
      <li>master node can determine when a node has finished sending its frames by observing the ==lack of a signal== on the channel</li>
    </ul>
  </li>
  <li>Repeats step 2 to 3 in a cyclic manner</li>
</ol>

<p>We notice that even though it “eliminates” the collisions and empty slots that plague random access protocols, it! also has a few drawbacks:</p>

<ul>
  <li>
    <p>introduces a polling delay—the amount of time required to notify a node that it can transmit. Therefore, technically the transmission is less than $R$ bps if only one active node.</p>
  </li>
  <li>
    <p>(single point of failure) if the ==master node fails==, the entire channel becomes inoperative.</p>
  </li>
</ul>

<hr />

<p><strong>Token-Passing Protocol</strong></p>

<p>No master node, but a small, ==special-purpose frame known as a token is exchanged== among the nodes in some ==fixed order==.</p>

<ol>
  <li>node 1 holds the token, can transmit if needed. If not, ==always== send the token to node 2.
    <ul>
      <li>If a node does have frames to transmit when it receives the token, it sends <strong>up to a maximum number of frames</strong></li>
    </ul>
  </li>
  <li>repeat step 1</li>
</ol>

<p>Token passing is decentralized and highly efficient, but again problems can occur:</p>

<ul>
  <li>the failure of one node (e.g. losing the token) can crash the entire channel.</li>
</ul>

<h3 id="docsis-protocol-for-cable-access">DOCSIS: Protocol for Cable Access</h3>

<p>A cable access network will make for an excellent case study here, as we’ll find aspects of <strong>each of these three classes</strong> of multiple access protocols with the cable access network!</p>

<p>Recall that the basic architecture looks like</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211208163354678.png" alt="image-20211208163354678" /></p>

<p>where</p>

<ul>
  <li>cable access network typically connects several thousand residential cable modems to a cable modem termination system (CMTS) at the cable network headend.</li>
  <li>The Data-Over-Cable Service Interface Specifications (<strong>DOCSIS</strong>) [DOCSIS 3.1 2014; Hamzeh 2015] <strong>specifies the cable data network architecture and its protocols</strong>.</li>
</ul>

<p>In a simpler view:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211208163536230.png" alt="image-20211208163536230" /></p>

<p>where:</p>

<ol>
  <li>Each upstream and downstream channel is a <strong>broadcast channel</strong>, so we need to consider multiple access!
    <ul>
      <li>since there is just a single CMTS transmitting into the downstream channel, this is technically easy</li>
    </ul>
  </li>
  <li>DOCSIS uses ==FDM== to divide the downstream (CMTS to modem) and upstream (modem to CMTS) network segments into multiple frequency channels.
    <ul>
      <li>first partition the single channel into multiple channels, so we can split downstream and upstream</li>
    </ul>
  </li>
  <li>Then, each upstream channel is further <strong>divided into intervals of time</strong> (==TDM==-like), each containing a sequence of mini-slots during which cable modems can transmit to the CMTS.</li>
  <li>For a cable modem to send upstream, it needs to:
    <ol>
      <li>send ==mini-slot-request== frames to the CMTS during a special set of interval <strong>mini-slots that are dedicated for this purpose</strong> (the ones on the front in Figure 6.14)</li>
      <li>the mini-slot-request frames are transmitted in a ==random access== manner and so may collide with each other
        <ul>
          <li>cable modems has no collision detection ability, so it only infer a collision if it did not receive a response</li>
          <li>When a collision is inferred, a cable modem uses ==binary exponential backoff==</li>
        </ul>
      </li>
      <li>CTMS <strong>responds</strong> to the requests by sending a <strong>MAP message</strong>. Basically each message explicitly grants permission to individual cable modems to ==transmit during specific mini-slots== as specified in the MAP message.
        <ul>
          <li>==taking-turns== alike strategy, so CMTS can ensure there are no colliding for data upstream.</li>
        </ul>
      </li>
    </ol>
  </li>
</ol>

<h2 id="switched-local-area-network">Switched Local Area Network</h2>

<p>Figure 6.15 shows a! switched local network connecting three departments, two servers and a router with! four switches.</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211208164613193.png" alt="image-20211208164613193" style="zoom:80%;" /></p>

<p>where here:</p>

<ul>
  <li>switches operate at the link layer, so they switch link-layer frames</li>
  <li>those switches ==don’t recognize network-layer addresses== (IP address), and ==don’t use routing algorithms like OSPF== to determine the path.
    <ul>
      <li>it might be confusing first why we needed two addresses, MAC and IP, but the rest of this sectoin should clarify</li>
    </ul>
  </li>
</ul>

<h3 id="link-layer-addressing-and-arp">Link-Layer Addressing and ARP</h3>

<p>We know that Hosts and routers have network-layer IP addresses. But it turns out that they also have <strong>link-layer addresses</strong>.</p>

<ul>
  <li>you will see why the ==two layers of addresses== are useful and, in fact, indispensable.</li>
  <li>basically imaging IP address as your post address, which changes as you move, MAC address as your SSN/ID actual identity</li>
</ul>

<blockquote>
  <p>it is not hosts and routers that have link-layer addresses but rather ==their adapters== (that is, network interfaces) that have link-layer addresses (MAC address)</p>
</blockquote>

<h4 id="mac-addresses">MAC Addresses</h4>

<p>We know that for layer 3 (network) and above, we use <strong>MAC address</strong></p>

<ul>
  <li>link-layer address is variously called a LAN address, a physical address, or a MAC address</li>
  <li>the MAC address is 6 bytes long, <strong>giving $2^{48}$ possible MAC addresses</strong>.</li>
  <li>typically expressed in <strong>hexadecimal</strong> notation, with each byte of the address expressed as a pair of hexadecimal numbers.</li>
  <li>no two adapters have the same address. It is ==globally unique.== (IEEE manages the MAC address space)</li>
</ul>

<p>E.g. a MAC address could look like:</p>

\[\text{1A-2F-BB-76-09-AD
}\]

<p>moreover:</p>

<ul>
  <li>An adapter’s MAC address has a <strong>flat structure</strong> (as opposed to a hierarchical structure) and doesn’t change no matter where the adapter goes</li>
</ul>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211208170657622.png" alt="image-20211208170657622" style="zoom:80%;" /></p>

<p>notice that a switch has no MAC addresses, but routers/hosts do.</p>

<p>When an <strong>adapter</strong> wants to send a frame <strong>to some destination adapter</strong>:</p>

<ol>
  <li>the ==sending== adapter ==inserts the destination adapter’s MAC address== into the frame</li>
  <li>sends the frame into the LAN with switches
    <ul>
      <li>sometimes, switches will <strong>broadcast a frame to all interfaces</strong>. So, when an adapter receives a frame, it will check to see whether the destination MAC address matches its own.</li>
      <li>if a sending adapter does <strong>want all the other adapters</strong> on the LAN to receive and process the frame it is about to send. In this case, the sending adapter ==inserts a special MAC broadcast address== into the destination address field of the frame: $\text{FF-FF-FF-FF-FF-FF}$</li>
    </ul>
  </li>
  <li>switches do something (see below)</li>
</ol>

<blockquote>
  <p>The basic function of a ==switch== is ==transparent bridging== - for this, it doesn’t need any MAC address of its own</p>

  <ul>
    <li><strong>Transparent bridging</strong> does not alter the frame. Layer 2 switches do not need the base Ethernet MAC address of the device nor its switch port MAC addresses to operate.
      <ul>
        <li>The source and destination MAC addresses of the incoming frame are examined, the first one being saved in the MAC address table along with the receiving port, while the destination MAC address being looked up in the MAC address table to see if there is an associated port.</li>
        <li>If there is the frame is forwarded out that port only, otherwise it gets broadcast out all ports, except the source port (split horizon rule).</li>
      </ul>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Note that:</strong></p>

  <ul>
    <li>in the second step, we needed <strong>MAC address to check if packet belongs to us</strong>. This is the same situation in real life as IP=postal address and MAC=actual identity.
      <ul>
        <li>some packages (e.g. from Amazon) might end up at your postal address</li>
        <li>==you (MAC address) check if it is really belonging to you== (could belong to the <strong>previous person living here</strong>)</li>
      </ul>
    </li>
    <li>how a switch knows where to send is covered in section <a href="#Link-Layer Switches">Link-Layer Switches</a></li>
  </ul>
</blockquote>

<p>Now, the question is, how do you know what is the MAC address of a destination adapter?</p>

<h4 id="arp-address-resolution">ARP: Address Resolution</h4>

<p>How do we know the MAC address given an IP address?</p>

<ul>
  <li>This problem occurs because lower layer (link layer) uses ==MAC address to identify each other==, instead of IP.</li>
</ul>

<p>Then, basically you need some <strong>broadcasting</strong> to query information, using the <strong>Address Resolution Protocol</strong> (ARP).</p>

<blockquote>
  <p><strong>ARP resolves IP addresses only for hosts and router interfaces on the same subnet</strong></p>

  <ul>
    <li>to see what to do when sending across subnets, see next section.</li>
  </ul>
</blockquote>

<p>For this example, we ==assume transmitting within the same subnet==. Now, suppose that the host with IP address <code class="language-plaintext highlighter-rouge">222.222.222.220 </code> wants to send an IP datagram to host <code class="language-plaintext highlighter-rouge">222.222.222.222</code>:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211208172320504.png" alt="image-20211208172320504" /></p>

<ol>
  <li>
    <p>The sending adapter will then construct a link-layer frame, put its own MAC address as source, and need to <strong>figure out the destination’s MAC address</strong></p>
  </li>
  <li>
    <p>Each host and router has an ARP table in its memory, which contains mappings of IP addresses to MAC addresses.</p>

    <p>For <code class="language-plaintext highlighter-rouge">222.222.222.220</code>, it might have:</p>

    <p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211208172530487.png" alt="image-20211208172530487" /></p>
  </li>
  <li>
    <p>Using ARP protocol, first the sender <strong>constructs a special packet called an ARP packet</strong>.</p>

    <ul>
      <li>including the sending MAC addresses and receiving IP address as $\text{FF-FF-FF-FF-FF-FF}$</li>
      <li>The purpose of the ARP query packet is to ==query all the other hosts== and routers on the subnet to determine the MAC address corresponding to the IP address that is being resolved</li>
    </ul>
  </li>
  <li>
    <p>Send the packet to the MAC broadcast address, namely, $\text{FF-FF-FF-FF-FF-FF}$, to the subnet</p>
  </li>
  <li>
    <p>The frame containing the ARP query is received by all the other adapters on the subnet, and each of the ARP modules parses the packet and <strong>check if the destination IP is itself.</strong></p>

    <ul>
      <li>The one with a ==match sends back to the querying host a response ARP packet== with the desired mapping (its MAC address)</li>
    </ul>
  </li>
  <li>
    <p>The querying host <code class="language-plaintext highlighter-rouge">222.222.222.220</code> can then update its ARP table and send its IP datagram in step 1</p>
  </li>
</ol>

<blockquote>
  <p><strong>Note</strong></p>

  <ul>
    <li>query ARP message is sent within a broadcast frame, whereas the <strong>response</strong> ARP message is sent within a <strong>standard frame</strong>.</li>
    <li>ARP is plug-and-play, the <strong>ARP table gets built automatically</strong></li>
    <li>an ARP packet is encapsulated within a link-layer frame and thus lies architecturally above the link layer. However, an ARP packet has fields containing link-layer addresses and thus is arguably a link-layer protocol, but it also contains network-layer addresses and thus is also arguably a network-layer protocol.
      <ul>
        <li>In the end, ARP is probably best considered a protocol that straddles the boundary between the link and network layers</li>
      </ul>
    </li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Blocking of Switch</strong></p>

  <p>If we are sending from different host to different output, obviously you have to buffer as each link can only transmit one thing at a time.</p>

  <p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211208094829689.png" alt="image-20211208094829689" style="zoom:50%;" /></p>

  <p>e.g. if both 1 and 2 sends to 4, then you need to buffer.</p>

  <ul>
    <li>but if 1 sends to 4 and 2 sends to 5, no need to buffer.</li>
  </ul>
</blockquote>

<hr />

<p><em>Example</em>: <code class="language-plaintext highlighter-rouge">ping</code> some IP address within the network</p>

<ol>
  <li>your <code class="language-plaintext highlighter-rouge">ARP</code> table does not contain the MAC of the IP you want to ping
    <ul>
      <li>check if by typing <code class="language-plaintext highlighter-rouge">ARP -A</code></li>
    </ul>
  </li>
  <li>do a <code class="language-plaintext highlighter-rouge">ping</code>, and it should work
    <ul>
      <li>under the hood <code class="language-plaintext highlighter-rouge">ping</code> does the <code class="language-plaintext highlighter-rouge">ARP</code> for you</li>
    </ul>
  </li>
  <li>Now check again your <code class="language-plaintext highlighter-rouge">ARP -A</code>. You should notice that you got an additional <code class="language-plaintext highlighter-rouge">MAC</code> address from broadcast</li>
</ol>

<h4 id="routing-to-another-subnet">Routing to Another Subnet</h4>

<p>now let’s look at the more complicated situation when a host on a subnet wants to send a network-layer datagram to a host off the subnet.</p>

<blockquote>
  <p>Since each adapter are the ones physically receiving packets <strong>on each link/egde</strong> on the graph, we need to <strong>“change”</strong> MAC addresses of the packet as otherwise they will be dropped!</p>
</blockquote>

<p>Consider the case you want to deliver from <code class="language-plaintext highlighter-rouge">111.111.111.111</code> to <code class="language-plaintext highlighter-rouge">222.222.222.222</code></p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211208174529497.png" alt="image-20211208174529497" style="zoom: 50%;" /></p>

<p>note that routers have MAC addresses, as they are the ones bridging <strong>between subnets</strong> and possibly the outside world. Also one important point is: ==link layer treats router and hosts as the same==. As their job is to realize the host-router or host-host delivery.</p>

<ol>
  <li>
    <p>First the sender <strong>fills out the IP as normal</strong>, and the source MAC. We know we need to send to <code class="language-plaintext highlighter-rouge">R</code> first</p>
  </li>
  <li>
    <p>So, we want to <strong>obtain</strong> the MAC address of <code class="language-plaintext highlighter-rouge">R</code> by using <code class="language-plaintext highlighter-rouge">ARP</code> broadcast (<code class="language-plaintext highlighter-rouge">R</code> would be the first hop router for <code class="language-plaintext highlighter-rouge">A</code>). This can be done since we ==know the IP for first-hop/default gateway router== from DCHP configuration (see <a href="#Obtaining Host Address: DCHP">Obtaining Host Address: DCHP</a>)</p>

    <ul>
      <li>If the sending adapter were to use that MAC address of <code class="language-plaintext highlighter-rouge">222.222.222.222</code>, then <strong>none of the adapters on Subnet 1 would bother to pass the IP datagram up to its network layer</strong>, since the frame’s destination address would not match the MAC address of any adapter on Subnet 1. Therefore, all the <strong>hosts/routers will have dropped</strong> the frame (there is only one case that a switch would have dropped. See next section)</li>
      <li>to the ==link-layer,== a ==router = host== is indistinguishable. Therefore, without putting <code class="language-plaintext highlighter-rouge">R</code> as the destination MAC address, <code class="language-plaintext highlighter-rouge">R</code> would have rejected it and you are done. Hence, this change of MAC address is ==only when your next hop is a router==. (see section <a href="#Switched Network Example">Switched Network Example</a></li>
    </ul>
  </li>
  <li>
    <p>Construct the packet with MAC address of <code class="language-plaintext highlighter-rouge">R</code>, and sends the frame into Subnet 1</p>

    <p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211208174420759.png" alt="image-20211208174420759" /></p>
  </li>
  <li>
    <p>Router <code class="language-plaintext highlighter-rouge">R</code> sees that the link-layer frame is addressed to it, and therefore passes the frame to the network layer of the router</p>
  </li>
  <li>
    <p>The router now has to determine the <strong>correct interface on which the datagram is to be forwarded</strong>, by consulting a forwarding table in the router and the <code class="language-plaintext highlighter-rouge">IP Dest</code>.</p>

    <ul>
      <li>The forwarding table tells the router that the datagram is to be forwarded via router interface <code class="language-plaintext highlighter-rouge">222.222.222.220</code></li>
      <li>now it is related to network layer routing</li>
    </ul>
  </li>
  <li>
    <p>Router determined the interface, pass it to its adapter. Then, to make sure correct delivery, the MAC addresses are again changed. But what is the MAC address of it’s next hop for <code class="language-plaintext highlighter-rouge">222.222.222.222</code>?</p>
  </li>
  <li>
    <p>Use <code class="language-plaintext highlighter-rouge">ARP</code> to determine the MAC address of <code class="language-plaintext highlighter-rouge">222.222.222.222</code>, then the packet is finally formed</p>

    <p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211208175240582.png" alt="image-20211208175240582" /></p>
  </li>
  <li>
    <p>The router’s adapter send it to the subnet 2, and <code class="language-plaintext highlighter-rouge">222.222.222.222</code>’s ==adapter== will correctly receive it</p>

    <p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211208175323208.png" alt="image-20211208175323208" /></p>
  </li>
</ol>

<p>Basically MAC changes is needed to make sure the ==correct adapters== (person) living under the IP (postal address) will ==take in== the frame.</p>

<h3 id="ethernet">Ethernet</h3>

<p>Today, <strong>Ethernet</strong> is by far the most prevalent <strong>wired LAN technology</strong>, and it is likely to remain so for the foreseeable future. One might say that Ethernet has been to local area networking what the Internet has been to global networking.</p>

<p>Switched ethernet is more popular today</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211208094530797.png" alt="image-20211208094530797" /></p>

<p>Skipped.</p>

<h4 id="link-layer-switches">Link-Layer Switches</h4>

<p>role of the switch is to receive incoming link-layer frames and ==forward them onto outgoing links==. Some important mechanisms covered here include:</p>

<ul>
  <li>how a switch figured out what’s the next switch to send to, given a <code class="language-plaintext highlighter-rouge">dst MAC</code></li>
</ul>

<blockquote>
  <p><strong>Note</strong></p>

  <p>Again, remember that switch itself is <strong>transparent</strong> to the <strong>hosts and routers</strong> in the subnet; that is, a ==host/router== addresses a frame to another host/router (by just filling the IP), and ==assumes that the transmission is host to router==!</p>

  <ul>
    <li>in reality, we know that switches are doing the forwarding and receiving of the frame</li>
  </ul>
</blockquote>

<h5 id="forwarding-and-filtering">Forwarding and Filtering</h5>

<p>The two key <strong>functions</strong> of a switch to <strong>operate as we expected</strong> is:</p>

<ul>
  <li><strong>Filtering</strong> is the switch function that determines whether a frame should be forwarded to some interface or ==should just be dropped==.</li>
  <li><strong>Forwarding</strong> is the switch function that ==determines the interfaces to which a frame should be directed==, and then moves the frame to those interface. If it has no idea, it will <strong>flood</strong> to all except the incoming port.</li>
</ul>

<p>Switch filtering and forwarding are done with a <strong>switch table</strong>. The switch table contains entries for some, but not necessarily all, of the <strong>hosts and routers on a LAN</strong>.</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211208194203579.png" alt="image-20211208194203579" /></p>

<p>where this idea is indeed similar to a forwarding table of a router.</p>

<ul>
  <li>But one important distinction is that switches forward packets ==based on MAC addresses== rather than on IP addresses.</li>
</ul>

<p>To understand how switch filtering and forwarding work, suppose a frame with <strong>destination</strong> address <code class="language-plaintext highlighter-rouge">DD-DD-DD-DD-DD-DD</code> arrives at the switch on interface <code class="language-plaintext highlighter-rouge">x</code>. Then the switch indexes its table with the MAC address<code class="language-plaintext highlighter-rouge"> DD-DD-DD-DD-DD-DD.</code></p>

<ul>
  <li>There is ==no entry== in the table for <code class="language-plaintext highlighter-rouge">DD-DD-DD-DD-DD-DD</code>. In this case, the switch ==forwards copies of the frame to the output buffers== preceding all interfaces except for interface <code class="language-plaintext highlighter-rouge">x</code>.
    <ul>
      <li>note that unless it is forwarding to a router, it will <strong>not change</strong> the source MAC address (used for self-learning) capability. An example in <a href="#Switched Network Example">Switched Network Example</a> could clarify.</li>
    </ul>
  </li>
  <li>There is an entry in the table, associating <code class="language-plaintext highlighter-rouge">DD-DD-DD-DD-DD-DD</code> <strong>with interface <code class="language-plaintext highlighter-rouge">x</code></strong>. In this case, the frame is coming from a LAN segment that contains adapter <code class="language-plaintext highlighter-rouge">DD-DD-DD-DD-DD-DD</code>. Filter the frame.
    <ul>
      <li>this is because it means that <code class="language-plaintext highlighter-rouge">dst DD-DD-DD-DD-DD-DD</code> is broadcasted to it. And since the output interface is <code class="language-plaintext highlighter-rouge">x</code>, it means the frame should have already been received by the host with <code class="language-plaintext highlighter-rouge">DD-DD-DD-DD-DD-DD</code></li>
      <li>this is the only case that a ==switch drops a packet== intentionally. (recall that a switch has no MAC address)</li>
    </ul>
  </li>
  <li>There is an entry in the table, associating <code class="language-plaintext highlighter-rouge">DD-DD-DD-DD-DD-DD</code> with interface $y\neq x$. In this case, the frame needs to be forwarded to the LAN segment attached to interface <code class="language-plaintext highlighter-rouge">y</code>.</li>
</ul>

<hr />

<p><em>Example</em>: The situation with upper switch in Figure 6.15.</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211208201224236.png" alt="image-20211208201224236" style="zoom:80%;" /></p>

<ul>
  <li>
    <p>Suppose that a frame with destination address <code class="language-plaintext highlighter-rouge">62-FEF7-11-89-A3</code> arrives at the switch from interface <code class="language-plaintext highlighter-rouge">1</code>. Suppose we already have the table:</p>

    <p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211208194203579.png" alt="image-20211208194203579" /></p>

    <p>then, it sees interface is still <code class="language-plaintext highlighter-rouge">1</code>, so it filters/discards it. (stops the frame to flood to the other subnets!)</p>
  </li>
  <li>
    <p>suppose a frame with the <strong>same destination</strong> address arrives from interface <code class="language-plaintext highlighter-rouge">2</code>. Then it forwards to interface <code class="language-plaintext highlighter-rouge">1</code></p>
  </li>
</ul>

<blockquote>
  <p>It should be clear from this example that ==as long as the switch table is complete and accurate==, the switch forwards frames toward destinations ==without any broadcasting.==</p>
</blockquote>

<p>Then, the natural question to ask is how to fill out the forward table?</p>

<h5 id="self-learning">Self-Learning</h5>

<p>Basically it is filled out automatically as there are traffic flowing.</p>

<ol>
  <li>
    <p>The switch table is initially empty.</p>
  </li>
  <li>
    <p>For each incoming frame received on an interface, the switch stores in its table</p>

    <ul>
      <li>the MAC address in the frame’s ==source address field== (if it knows where it comes from, it knows where to send to next time)</li>
      <li>the interface from which the frame arrived</li>
      <li>the current time. (aging time is more like hard-coded)</li>
    </ul>

    <p>In this manner, the switch records in its table the LAN segment on which the sender resides. If <strong>every host in the LAN eventually sends a frame</strong>, then <strong>every host will eventually get recorded</strong> in the table.</p>
  </li>
  <li>
    <p>The switch deletes an address in the table if no frames are received with that address as the source address after some period of time (the aging time). In this manner, if a PC is replaced by another PC (with a different adapter), the MAC address of the original PC will eventually be purged from the switch table.</p>
  </li>
</ol>

<p><em>Example</em></p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211208201929051.png" alt="image-20211208201929051" /></p>

<ul>
  <li>Suppose at time 9:39 a frame with ==source== address <code class="language-plaintext highlighter-rouge">01-12-23-34-45-56</code> arrives from interface 2. Suppose that this address is not in the switch table. Then the switch ==adds a new entry to the table==, as shown in Figure 6.23</li>
  <li>suppose that the ==aging time== for this switch is 60 minutes, and no frames with source address <code class="language-plaintext highlighter-rouge">62-FE-F7-11-89-A3</code> arrive to the switch between 9:32 and 10:32. Then at time 10:32, the switch removes this address from its table.</li>
</ul>

<h5 id="properties-of-switches">Properties of Switches</h5>

<p>One key difference of switches against <strong>multiaccess medium</strong> is that:</p>

<ul>
  <li><strong>Elimination of collisions</strong>. In a LAN built from switches (and without hubs), there is no wasted bandwidth due to collisions, since we have dedicated buffers/links, everything is in order.</li>
  <li><strong>Heterogeneous links</strong>. Because a switch isolates one link from another, the different links in the LAN can <strong>operate at different speeds</strong> and can run over different media.</li>
  <li><strong>Management.</strong> In addition to providing enhanced security (see sidebar on Focus on Security), a switch also eases network management. For example, if an adapter malfunctions and continually sends Ethernet frames (called a jabbering adapter), a switch can detect the problem and internally disconnect the malfunctioning adapter.</li>
</ul>

<h3 id="switched-network-example">Switched Network Example</h3>

<p>Here we demonstrate an example of delivering from Host <code class="language-plaintext highlighter-rouge">A</code> to Host <code class="language-plaintext highlighter-rouge">B</code> through <strong>two switches</strong> in the same network.</p>

<blockquote>
  <p><strong>Resource</strong></p>

  <ul>
    <li>animation is from https://www.practicalnetworking.net/stand-alone/communication-through-multiple-switches/</li>
  </ul>
</blockquote>

<p>Consider the following setup</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211211144312026.png" alt="image-20211211144312026" /></p>

<p>and suppose Host <code class="language-plaintext highlighter-rouge">A</code> already know the MAC address of Host <code class="language-plaintext highlighter-rouge">B</code></p>

<ul>
  <li>if it didn’t, then host <code class="language-plaintext highlighter-rouge">A</code> will send out <code class="language-plaintext highlighter-rouge">FF-FF-FF-FF</code> ARP broadcast and flood all the way to host <code class="language-plaintext highlighter-rouge">B</code>. During that process, the learning of mapping in switches will happen in the <strong>same manner</strong> as below</li>
  <li>but regardless, to begin, the MAC address tables for <em>both</em> switches will be empty.</li>
</ul>

<p>Then, to send from <code class="language-plaintext highlighter-rouge">A</code> to <code class="language-plaintext highlighter-rouge">B</code>:</p>

<ol>
  <li>
    <p>Sender <code class="language-plaintext highlighter-rouge">A</code> composes a frame with destination IP and MAC filled to be <code class="language-plaintext highlighter-rouge">BB-BB-BB-BB</code>, and  send to the blue switch</p>

    <p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211211144809637.png" alt="image-20211211144809637" /></p>
  </li>
  <li>
    <p>frame arrives on the blue switch. Empty MAC table, so blue switch ==learns the MAC address== <code class="language-plaintext highlighter-rouge">aaaa.aaaa.aaaa</code> exists on port <code class="language-plaintext highlighter-rouge">1</code>.</p>
  </li>
</ol>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211211144817844.png" alt="image-20211211144817844" /></p>

<ol>
  <li>
    <p>since the blue switch does not yet have an entry in his MAC address table for <code class="language-plaintext highlighter-rouge">bbbb.bbbb.bbbb</code>, the frame is duplicated and ==flooded out== every port (notice we ==do not change <code class="language-plaintext highlighter-rouge">src/dst</code> MAC== like the case with router, as ==only router changes that==)</p>

    <table>
      <thead>
        <tr>
          <th style="text-align: center">Flooding</th>
          <th style="text-align: center">Filtering</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td style="text-align: center"><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211211145037034.png" alt="image-20211211145037034" /></td>
          <td style="text-align: center"><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211211145046096.png" alt="image-20211211145046096" /></td>
        </tr>
      </tbody>
    </table>

    <p>where due to filtering Host <code class="language-plaintext highlighter-rouge">C</code> will reject/discard the packet</p>
  </li>
  <li>
    <p>The frame will also arrive on the green switch. Just like the other switch, the first thing the green switch will do is ==learn== that it received a frame on port <code class="language-plaintext highlighter-rouge">4</code> with a source MAC address of <code class="language-plaintext highlighter-rouge">aaaa.aaaa.aaaa</code>.</p>

    <p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211211145146475.png" alt="image-20211211145146475" /></p>
  </li>
  <li>
    <p>Just like the other switch, the green switch does not know where the MAC address <code class="language-plaintext highlighter-rouge">bbbb.bbbb.bbbb</code> exists, so the frame will again be duplicated and ==flood== out each switch port.</p>

    <table>
      <thead>
        <tr>
          <th style="text-align: center">Flooding</th>
          <th style="text-align: center">Filtering</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td style="text-align: center"><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211211145244660.png" alt="image-20211211145244660" /></td>
          <td style="text-align: center"><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211211145251717.png" alt="image-20211211145251717" /></td>
        </tr>
      </tbody>
    </table>
  </li>
  <li>
    <p>Delivered and Mapping learnt!</p>
  </li>
</ol>

<p>Now, for reply, host <code class="language-plaintext highlighter-rouge">B</code> want to reply to host <code class="language-plaintext highlighter-rouge">A</code>. This time it is easier as we <strong>already learned the mapping to <code class="language-plaintext highlighter-rouge">aaaa.aaaa.aaaa.aaaa</code></strong></p>

<ol>
  <li>
    <p>In the response frame sent by Host B to Host A, the Layer2 header will have a Source MAC address of <code class="language-plaintext highlighter-rouge">bbbb.bbbb.bbbb</code> and a Destination MAC address of <code class="language-plaintext highlighter-rouge">aaaa.aaaa.aaaa</code>. Then host <code class="language-plaintext highlighter-rouge">B</code> sends to the green switch</p>

    <p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211211145633334.png" alt="image-20211211145633334" /></p>
  </li>
  <li>
    <p>The response frame will first arrive on the green switch on port <code class="language-plaintext highlighter-rouge">6</code>. Therefore, the green switch will ==learn== that the MAC address <code class="language-plaintext highlighter-rouge">bbbb.bbbb.bbbb</code> exists out port <code class="language-plaintext highlighter-rouge">6</code>.</p>

    <p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211211145658842.png" alt="image-20211211145658842" /></p>
  </li>
  <li>
    <p>green switch then consults its MAC address table to determine that the frame destined to <code class="language-plaintext highlighter-rouge">aaaa.aaaa.aaaa</code> should be ==forwarded== out port <code class="language-plaintext highlighter-rouge">4</code>. (notice how we <strong>don’t have flooding now</strong>, since we know where to send!)</p>

    <p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211211145741148.png" alt="image-20211211145741148" /></p>
  </li>
  <li>
    <p>blue switch will ==learn== the MAC address <code class="language-plaintext highlighter-rouge">bbbb.bbbb.bbbb</code> exists out port <code class="language-plaintext highlighter-rouge">3</code>.</p>
  </li>
</ol>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211211145803542.png" alt="image-20211211145803542" /></p>

<ol>
  <li>
    <p>blue switch then consults its MAC address table to determine that the frame destined to <code class="language-plaintext highlighter-rouge">aaaa.aaa.aaaa</code> should be ==forwarded== out to port <code class="language-plaintext highlighter-rouge">1</code>. (again, <strong>no need to flood!</strong>)</p>

    <p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211211145855606.png" alt="image-20211211145855606" /></p>
  </li>
  <li>
    <p>Host <code class="language-plaintext highlighter-rouge">A</code> received the packet</p>

    <p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211211145912032.png" alt="image-20211211145912032" /></p>
  </li>
</ol>

<p>Notice that:</p>

<ul>
  <li>the backward trip will be easier than the forward trip as <strong>routers will have learned the <code class="language-plaintext highlighter-rouge">src_MAC</code></strong></li>
  <li>after two messages (one round trip), both routers have <strong>learned both the mappings fully!</strong></li>
</ul>

<h2 id="vlans">VLANS</h2>

<p>Consider the following case</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211213132537943.png" alt="image-20211213132537943" style="zoom:80%;" /></p>

<p>But now, we would like to solve the following problem:</p>

<ol>
  <li><strong>traffic isolation</strong>: broadcast traffic (e.g., frames carrying ARP and DHCP messages or frames whose destination has not yet been learned by a self-learning switch) must still <strong>traverse the entire institutional network</strong>, and we ==don’t want that== so we can:
    <ul>
      <li>improve LAN performance as we have less traffic</li>
      <li>provide <strong>security/isolation</strong> between departments so packets don’t freely go anywhere</li>
    </ul>
  </li>
  <li><strong>Inefficient use of switches</strong>: what if we have 10 departments but we don’t want to use 10 switches?</li>
  <li><strong>Managing users.</strong> If an employee ==moves== between groups, the physical cabling must be changed to connect the employee to a different switch in Figure 6.15. Employees belonging to two groups make the problem even harder</li>
</ol>

<p>Whereas the <strong>first problem</strong> technically can be solved by replacing the central switch <code class="language-plaintext highlighter-rouge">S3</code> with 6 ports to be a <strong>router</strong>, such that:</p>

<ul>
  <li>
    <p>if an EE laptop wants to talk to CS laptop, and suppose they know the IPs, then:</p>

    <ol>
      <li>Link Layer broadcast will only aims to obtain the MAC of router <code class="language-plaintext highlighter-rouge">R3=S3</code></li>
      <li>Packet sent to that router <code class="language-plaintext highlighter-rouge">R3</code></li>
      <li>Router sends out to port 2 due to OSPF, switch <code class="language-plaintext highlighter-rouge">S2</code> receives it</li>
      <li>Switch <code class="language-plaintext highlighter-rouge">S2</code> broadcast to know the MAC of that CS laptop</li>
      <li>Switch delivers the packet with filled in MAC addresses to the CS laptop</li>
    </ol>

    <p>so we see that in the end, <strong>broadcast never crossed from CS to EE</strong>, and we can ==still talk to each other==</p>
  </li>
</ul>

<p>However, this does not solve the second and third problem. So in general, the <strong>solutions is to use VLAN (virtual local area network)+ embedded router</strong>.</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211213133214385.png" alt="image-20211213133214385" style="zoom:80%;" /></p>

<p>where <strong>in a single switch</strong></p>

<ul>
  <li>the switch’s ports (interfaces) are ==divided into groups== by the network manager, and ==each group constitutes a VLAN==, with the ports in each VLAN forming a broadcast domain</li>
  <li>therefore, hosts within a VLAN communicate with each other as if they (and no other hosts) were connected to the switch
    <ul>
      <li>now, if we stop here, CS and EE are isolated since broadcast can never reach across as they are in the same switch. But this also means they <strong>cannot talk to each other</strong> at all.</li>
    </ul>
  </li>
  <li>connect a VLAN switch port (e.g., port 1 in Figure 6.25) to an external router and configure that <strong>port (e.g. port 1) to belong both the EE and CS</strong> VLANs. This is usually done ==internal by a device that contains both VLAN and router== (built by the vendor)
    <ul>
      <li>in the end, both router and switch does the task of: given packet, forward to a port. The difference is what is inside the forwarding table. So this is certainly doable to make such a product.</li>
    </ul>
  </li>
</ul>

<blockquote>
  <p>The upshot of what we are doing is so that:</p>

  <ul>
    <li><strong>physical</strong> configuration looks like EE and CS departments share the <strong>same physical switch</strong>
      <ul>
        <li>gives isolation</li>
        <li>shares/saves switches</li>
      </ul>
    </li>
    <li><strong>logical</strong> configuration would look as if the EE and CS departments had <strong>separate switches connected via a router.</strong>
      <ul>
        <li>An IP datagram going from the EE to the CS department would first cross the EE VLAN to reach the router and then be forwarded by the router back over the CS VLAN to the CS host.</li>
        <li>again, isolation and communication would both work.</li>
      </ul>
    </li>
  </ul>
</blockquote>

<hr />

<p>Now, this is up and working. Often there comes another requirement that <strong>people in the same department lives in different buildings</strong>. Therefore, you cannot just have a single switch to do VLAN.</p>

<p>Then, you come up with two solutions:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211213134329136.png" alt="image-20211213134329136" style="zoom:80%;" /></p>

<ul>
  <li>solution A: for each VLAN group, use a cable to connect them. This means if you have $N$ VLAN groups and two switches, you need $2N$ ports <strong>dedicates to do just that</strong>. Hence this doesn’t scale!</li>
  <li>solution B: ==VLAN trunking==. A special port on each switch (port 16 on the left switch and port 1 on the right switch) is configured as a trunk port to interconnect the two VLAN switches by <strong>belonging to ALL VLAN</strong>.
    <ul>
      <li>this means that, if you want to send to (any) the EE VLAN, port 16 will <strong>also forward it to switch on the right</strong>, but also ==added== a <strong>tag</strong> to tell the the trunk link on the other side <strong>which VLAN this is aimed at</strong> (i.e. VLAN EE)</li>
      <li>this adding of tag is the <strong>extended Ethernet frame format,</strong> 802.1Q, for frames crossing VLAN trunk</li>
    </ul>
  </li>
</ul>

<p>The extended ethernet frame therefore looks like this:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211213085900344.png" alt="image-20211213085900344" style="zoom:67%;" /></p>

<p>where it is specifically used for VLAN trunking:</p>

<ul>
  <li>VLAN tag is ==added== into a frame by the switch at the ==sending== side of a VLAN <strong>trunk</strong></li>
  <li>then, <strong>parsed</strong>, and ==removed== by the switch at the ==receiving== side of the <strong>trunk</strong>.</li>
</ul>

<blockquote>
  <p><strong>Therefore</strong>, in for every VLAN switch, we need <strong>two special/reserved ports</strong>:</p>

  <ul>
    <li>port for “routing” in between VLANS (e.g. port 1)</li>
    <li>port for trunking (e.g. port 16)</li>
  </ul>
</blockquote>

<h2 id="data-center-networking">Data Center Networking</h2>

<p>Broadly speaking, data centers serve three purposes.</p>

<ol>
  <li>First, they provide content such as Web pages, search results, e-mail, or streaming video to users.
    <ul>
      <li>therefore, <strong>latency</strong> is the single most important metric!</li>
    </ul>
  </li>
  <li>Second, they serve as massively-parallel computing infrastructures for specific data processing tasks, such as distributed index computations for search engines.</li>
  <li>Third, they provide cloud computing to other companies.
    <ul>
      <li>so 2 and 3 combined also means you need <strong>thousands of hosts/servers</strong> running.</li>
    </ul>
  </li>
</ol>

<p>Therefore, the networking evolved to be some interesting architecture</p>

<h3 id="data-center-architectures">Data Center Architectures</h3>

<p>The worker bees in a data center are the <strong>hosts</strong>. The hosts in data centers, called ==blades== and resembling pizza boxes, are generally commodity hosts that include CPU, memory, and disk storage.</p>

<ul>
  <li>
    <p>So, it looks like this.</p>

    <p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211213090515586.png" alt="image-20211213090515586" style="zoom:50%;" /></p>

    <p>where</p>

    <ul>
      <li>
        <p>hosts are stacked in <strong>racks</strong>, with each rack typically having 20 to 40 blades.</p>
      </li>
      <li>
        <p>At the <strong>top of each rack</strong>, there is a switch, aptly named the ==Top of Rack (TOR) switch==, that interconnects the hosts in the rack with each other and with other switches in the data center</p>
      </li>
    </ul>
  </li>
</ul>

<p>Then, remember that we need to eventually deal with connections in between hosts. So we also need switches that interconnect the TOR switches:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211213140538866.png" alt="image-20211213140538866" style="zoom:50%;" /></p>

<p>Then, since there are lot of them, we need another layer</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211213140548455.png" alt="image-20211213140548455" style="zoom:50%;" /></p>

<p>where:</p>

<ul>
  <li>we basically have a <strong>fully connected graph for the T2 Switch and T1 switch</strong>, so we can ensure traffic inside can go to anywhere</li>
</ul>

<p>Finally since he data center network supports two types of traffic:</p>

<ul>
  <li>traffic flowing between <strong>external clients</strong> and internal hosts</li>
  <li>traffic flowing between internal hosts</li>
</ul>

<p>We finish the topology by putting ==border routers== which can connect to the outer world</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211213090749838.png" alt="image-20211213090749838" style="zoom:50%;" /></p>

<p>notice that:</p>

<ul>
  <li>only the very top layer has router.</li>
  <li>all the layers below uses switches for faster communication</li>
</ul>

<h4 id="load-balancing-in-data-centers">Load Balancing in Data Centers</h4>

<p>Often we <strong>also have load balancer</strong> servers in the network so we can sustain the millions of request coming everyday</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211213141335669.png" alt="image-20211213141335669" style="zoom:80%;" /></p>

<p>where obviously the job of load balancer is to <strong>simply decide and forward requests/traffic</strong> so that the load is balanced in your network.</p>

<ul>
  <li>now all the requests are centralized to load balancer, but that’s ok since you can <strong>easily duplicate/scale</strong> them as they <strong>only performs simple, stateless tasks!</strong></li>
</ul>

<p>Therefore, when a request comes, this happens:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211213141609371.png" alt="image-20211213141609371" style="zoom: 67%;" /></p>

<ol>
  <li>the ==load balancer== <strong>forwards</strong> it to one of the hosts that handles the application. (red line)
    <ul>
      <li>this means if need to map the external IP to some internal IP for work</li>
    </ul>
  </li>
  <li>A <strong>host</strong> may then invoke the services of <strong>other hosts to help</strong> process the request. (green line)</li>
  <li>results sent back to load balancer (the only one who knows external/client IP), which is then replied back (blue line)
    <ul>
      <li>translate the internal IP back to the target external IP</li>
    </ul>
  </li>
</ol>

<blockquote>
  <p><strong>Notice</strong></p>

  <p>The load balancer not only balances the work load across hosts, but also provides a NAT-like function:</p>

  <ul>
    <li>translating the public <strong>external</strong> IP address to the <strong>internal</strong> IP address of the appropriate host</li>
    <li>then translating back for packets traveling in the <strong>reverse</strong> direction back to the clients.</li>
  </ul>
</blockquote>

<h4 id="hierarchical-structure-in-real-life">Hierarchical structure in Real life</h4>

<p>In real life, a bit <strong>more</strong> is happening that the figure below:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211213142211943.png" alt="image-20211213142211943" style="zoom: 67%;" /></p>

<p>where:</p>

<ul>
  <li>
    <p>some network components are duplicated for doing redundant work, so <strong>high availability is ensured</strong></p>
  </li>
  <li>the hosts below each ==access router== form a <strong>single subnet</strong>. In order to localize ARP broadcast traffic, each of these subnets is further partitioned into smaller <strong>VLAN subnets</strong></li>
  <li>there are <strong>more than 1 connection link</strong> between a TOR and a switch, and a T1 switch with T2 switch (below discusses why)</li>
</ul>

<hr />

<p><strong>Multiple Routes</strong></p>

<p>Consider the setup of, in Figure 6.30:</p>

<ul>
  <li>each <strong>host</strong> connects to its TOR switch with a 10 Gbps link</li>
  <li>links between <strong>switches</strong> are 100 Bbps</li>
</ul>

<p>Then this means two hosts in the same rack can always communicate at a full 10 Gbps. But what if we have ==40 simultaneous flows between 40!pairs of hosts in different racks.==</p>

<ul>
  <li>e.g. each of 10 hosts in rack 1 in Figure 6.30 sends a flow to a corresponding host in rack 5. then rack 2 to rack 6, rack 3 to rack 7, and finally rack 4 to rack 8.</li>
  <li>notice that all racks 1-4 above are <strong>in the same Tier 2 switch</strong>!</li>
</ul>

<p>If each flow evenly shares a link’s capacity with other flows traversing that link, then the 40 flows crossing the 100 Gbps A-to-B link (as well as the 100 Gbps B-to-C link) will each only receive:</p>

\[100 \text{ Gbps } / 40 = 2.5 \text{ Gbps }\]

<p>which is less than 10 Gbps of the TOR link can handle at max.</p>

<p>There are many solutions, but the common one used is to <strong>provide multiple path</strong> by <strong>increase connectivity in the graph</strong></p>

<ul>
  <li>e.g. each TOR switch could be connected to two tier-2 switches, which then provide for multiple link- and switch-disjoint paths between racks</li>
</ul>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211213143343055.png" alt="image-20211213143343055" style="zoom:80%;" /></p>

<p>Therefore, now you have:</p>

<ul>
  <li>four distinct paths between the first tier-2 switch and the second tier-2 switch, together providing an ==aggregate capacity of 400 Gbps between the first two tier-2 switches==</li>
</ul>

<blockquote>
  <p><strong>Take-away message</strong></p>

  <p>Therefore, one key difference between routing inside data centers and Internet is that:</p>

  <ul>
    <li>instead of choosing between them (like routers in routing), you ==use all of them==.</li>
    <li>you want to have multipath routing being the <strong>default standard!</strong></li>
  </ul>
</blockquote>

<h3 id="datacenter-networks-protocol-innovations">Datacenter Networks: Protocol Innovations</h3>

<p>Usually, to transfer things between host, we needed to form packets. send across, receive, and etc.</p>

<p>Again, since <strong>latency is critical</strong>, congestion control protocols such as TCP and its variants do not scale well in data centers.</p>

<p>Therefore:</p>

<ul>
  <li><strong>link layer:</strong>
    <ul>
      <li>RoCE: remote DMA (RDMA) over Converged Ethernet. This can
        <ul>
          <li>directly read/write into memory in remote hosts</li>
          <li>gives a huge saving to CPUs</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>transport layer:</strong>
    <ul>
      <li>ECN (explicit congestion notification) used in transport-layer congestion control (DCTCP, DCQCN).
        <ul>
          <li>We use ECN because we cannot <strong>afford using <code class="language-plaintext highlighter-rouge">timeout</code>/packet drops</strong> as loss event, which will cause a ==large loss of capacity== even if it is just a few seconds.</li>
          <li><strong>latency/performance</strong> is the <strong>biggest thing</strong> in datacenter networks</li>
        </ul>
      </li>
      <li>experimentation with hop-by-hop (backpressure) congestion control</li>
    </ul>
  </li>
  <li><strong>routing, management:</strong>
    <ul>
      <li>SDN widely used within/among organizations’ datacenters</li>
      <li>place related services, data as close as possible (e.g., in same rack or nearby rack) to minimize tier-2, tier-1 communication
        <ul>
          <li>e.g. MAP-reduce: doing computations for servers that are close to each other</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h2 id="a-day-in-life-of-web-page-request">A Day in Life of Web Page Request</h2>

<p>our journey down the protocol stack is now complete!</p>

<ul>
  <li>
    <p>application, transport, network, link</p>
  </li>
  <li>
    <p>putting-it-all-together: synthesis!</p>
  </li>
</ul>

<p>Suppose you want to do something on google, and you sent a request</p>

<ol>
  <li>
    <p>Suppose your <strong>laptop on campus</strong> does it. First, when your Laptop connects, you need ==DHCP== to give you IPs!</p>

    <ol>
      <li>
        <p>DCHP request inside UDP segment, and then inside IP datagram with a broadcast <strong>IP destination address</strong> (<code class="language-plaintext highlighter-rouge">255.255.255.255</code>) and a <strong>source IP address</strong> of <code class="language-plaintext highlighter-rouge">0.0.0.0</code></p>
      </li>
      <li>
        <p>Gets into a frame, and the destination will be <code class="language-plaintext highlighter-rouge">FF-FF-FF-FF</code> so hopefully it will reach the DHCP server. The frame’s source MAC address is that of Bob’s laptop, <code class="language-plaintext highlighter-rouge">00:16:D3:23:68:8A</code></p>
      </li>
      <li>
        <p>switch <strong>broadcasts</strong> the incoming frame on all outgoing ports, including the port connected to the router.</p>
      </li>
      <li>
        <p>The <strong>router</strong> receives the broadcast Ethernet frame containing the DHCP request on its interface (with MAC address <code class="language-plaintext highlighter-rouge">00:22:6B:45:1F:1B</code>). The datagram’s broadcast IP destination address indicates that this <em>IP datagram should be processed by upper layer protocols at this nod</em>e, so the datagram’s payload (a UDP segment) is thus demultiplexed (Section 3.2) up to UDP, and the <strong>DHCP request message is extracted</strong> from the UDP segment.</p>
      </li>
      <li>
        <p>Suppose DHCP server allocates address <code class="language-plaintext highlighter-rouge">68.85.2.101</code> to Bob’s laptop. Then DHCP server creates a DHCP ACK message (Section 4.3.3) containing this IP address, <strong>as well as</strong></p>

        <ul>
          <li>the IP address of the <strong>DNS</strong> server (68.87.71.226)</li>
          <li>the IP address for the <strong>default gateway</strong> router (68.85.2.1)</li>
          <li>the <strong>subnet</strong> block (68.85.2.0/24) (equivalently, the “network mask”).</li>
        </ul>

        <p>The Ethernet frame has a <strong>source</strong> MAC address of the router’s interface to the home network (<code class="language-plaintext highlighter-rouge">00:22:6B:45:1F:1B</code>) and a <strong>destination</strong> MAC address of Bob’s laptop (<code class="language-plaintext highlighter-rouge">00:16:D3:23:68:8A</code>).</p>
      </li>
      <li>
        <p>Ethernet frame containing the DHCP ACK is sent (unicast) by the router to the switch. Because the switch is self-learning (Section 6.4.3) and previously received an Ethernet frame (containing the DHCP request) from Bob’s laptop, the switch knows to forward a frame addressed to <code class="language-plaintext highlighter-rouge">00:16:D3:23:68:8A</code> <strong>only to the output port leading to Bob’s laptop</strong>.</p>
      </li>
      <li>
        <p>Bob’s DHCP client then records its IP address and the IP address of its DNS server. It also installs the address of the default gateway into its IP forwarding table (Section 4.1). Bob’s laptop will ==send all datagrams with destination address outside of its subnet <code class="language-plaintext highlighter-rouge">68.85.2.0/24</code> to the default gateway==</p>
      </li>
    </ol>

    <p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211213144705877.png" alt="image-20211213144705877" /></p>
  </li>
  <li>
    <p>Then, when Bob types the URL for www.google.com into his Web browser. To in the end connect to the server with a TCP socket, we we want to do <strong>DNS query</strong> to find out the ==IP address first==</p>

    <ol>
      <li>The operating system on Bob’s laptop thus creates a <strong>DNS query message</strong>, putting the string “www.google.com” in the question section of the DNS message. This is then packed into a UDP, and then an IP packet with
        <ul>
          <li>an IP destination address of <code class="language-plaintext highlighter-rouge">68.87.71.226</code> (the address of the ==(not local) DNS server== returned in the DHCP ACK above)</li>
          <li>a <strong>source</strong> IP address of <code class="language-plaintext highlighter-rouge">68.85.2.101.</code></li>
        </ul>
      </li>
      <li>Since the IP is outside the subnet, it will be first <strong>sent to the gateway router</strong> in Bob’s school’s network. However, though we know the IP of that, we don’t know the gateway router’s <strong>MAC addres</strong>s. In order to obtain the MAC address of the gateway router, Bob’s laptop will need to use the ==ARP protocol==</li>
      <li>Bob’s laptop creates an ARP query message with a target IP address of <code class="language-plaintext highlighter-rouge">68.85.2.1</code> (the default gateway), places the ARP message within an Ethernet frame with a <strong>broadcast</strong> destination address (<code class="language-plaintext highlighter-rouge">FF:FF:FF:FF:FF:FF</code>) and <strong>sends/floods the Ethernet frame to the switch</strong></li>
      <li><strong>All</strong> connected devices, including the gateway router received the Link Broadcast. The <strong>gateway router</strong> finds that the target IP address of <code class="language-plaintext highlighter-rouge">68.85.2.1</code> in the ARP message <strong>matches</strong> the IP address of its interface. Then:
        <ul>
          <li>The gateway router thus prepares an ==ARP reply==, indicating that its MAC address of <code class="language-plaintext highlighter-rouge">00:22:6B:45:1F:1B</code></li>
          <li>It places the ARP reply message in an Ethernet frame, with a destination address of <code class="language-plaintext highlighter-rouge">00:16:D3:23:68:8A</code> (Bob’s laptop) and sends the frame to the switch</li>
        </ul>
      </li>
      <li>Bob’s laptop receives the frame containing the ARP reply message and extracts the MAC address of the gateway router (<code class="language-plaintext highlighter-rouge">00:22:6B:45:1F:1B</code>) from the ARP reply message.</li>
      <li>Bob’s laptop can now (finally!) address the Ethernet frame containing the ==DNS query== to the gateway router’s MAC address.
        <ul>
          <li>Note that the IP datagram in this frame has an IP destination address of <code class="language-plaintext highlighter-rouge">68.87.71.226</code> (the DNS server), while the frame has a ==MAC== destination address of <code class="language-plaintext highlighter-rouge">00:22:6B:45:1F:1B </code>(the gateway router).</li>
        </ul>
      </li>
    </ol>

    <p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211213145840050.png" alt="image-20211213145840050" style="zoom:80%;" /></p>
  </li>
  <li>
    <p>Finally, Bob can send the DNS query with the packet information complete. Now we need to ==route the packet==</p>

    <ol>
      <li>The <strong>gateway router first receives</strong> the frame and extracts the IP datagram containing the DNS query. The router looks up the destination address of this datagram (<code class="language-plaintext highlighter-rouge">68.87.71.226</code>) and determines from its forwarding table that the datagram should be sent to the leftmost router in the Comcast network
        <ul>
          <li>eBGP tells the gateway and passed information throughout the internal AS reachability of IP such as Comcast’s network.</li>
          <li>iBGP tells each router inside the network <strong>which gateway router to go to</strong> depending on which AS I want to go to. This will be used if the first-hop router is not the gateway router.</li>
          <li>then the route to that gateway is done by OSPF</li>
        </ul>
      </li>
      <li>leftmost router in the <strong>Comcast network</strong> receives the frame, extracts the IP datagram, examines the datagram’s destination address (<code class="language-plaintext highlighter-rouge">68.87.71.226</code>)
        <ul>
          <li>look at its own forwarding table, which has been filled in with intra-domain protocol (such as RIP, ==OSPF== or IS-IS)</li>
          <li>determines the outgoing interface</li>
        </ul>
      </li>
      <li>Eventually the IP datagram containing the DNS query <strong>arrives</strong> at the DNS server. Then:
        <ul>
          <li>looks up the name www.google.com in its DNS database, and finds the DNS resource record that contains the IP address (<code class="language-plaintext highlighter-rouge">64.233.169.105</code>) for www.google.com</li>
          <li>if this doesn’t have it, we will need to do the query to authoritative DNS server or TLD server, and etc.</li>
          <li>forms a DNS reply message containing this hostname-to-IP address mapping, and places the ==DNS== reply message in a ==UDP== segment to get back to Bob</li>
        </ul>
      </li>
      <li>Bob’s laptop extracts the IP address of the server www.google.com from the DNS message. Finally, after a lot of work, Bob’s laptop is now ready to contact the www.google.com server</li>
    </ol>
  </li>
  <li>
    <p>Then, you got a DNS reply and has an IP for google.com. Now you <strong>establish the TCP connection</strong> to that IP.</p>

    <ol>
      <li>
        <p>create the TCP socket (Section 2.7) that will be used to send the HTTP GET message (Section 2.2.3) to www.google.com</p>

        <ul>
          <li>route all the way to google’s IP</li>
          <li>perform a three-way handshake (Section 3.5.6) with the TCP in www.google.com</li>
          <li>essentially TCP segment inside an IP datagram with a destination IP address of <code class="language-plaintext highlighter-rouge">64.233.169.105</code> (www.google.com), places the datagram inside a frame with a destination <strong>MAC address of <code class="language-plaintext highlighter-rouge">00:22:6B:45:1F:1B</code> (the gateway router)</strong> and sends the frame to the switch.</li>
        </ul>
      </li>
      <li>
        <p>routers in the school network, Comcast’s network, and Google’s network forward the datagram containing the TCP SYN toward www.google.com, using the forwarding table in each router</p>

        <ul>
          <li>includes ==both== intra-domain protocol such as ==OSPF== and inter-domain routing such as ==GBP==</li>
        </ul>
      </li>
      <li>
        <p>the datagram containing the TCP SYN <strong>arrives</strong> at www.google.com.</p>

        <ul>
          <li>The TCP SYN message is extracted from the datagram and demultiplexed to the welcome socket associated with port 80.</li>
          <li>A connection socket is created for the TCP connection between the Google HTTP server and Bob’s laptop.</li>
          <li>TCP <code class="language-plaintext highlighter-rouge">SYNACK </code>is sent back to Bob’s laptop (routes all the way back)</li>
        </ul>
      </li>
      <li>
        <p>(some steps skipped for three-way handhshake)</p>
      </li>
      <li>
        <p>With the socket on Bob’s laptop now (finally!) ready to send bytes to www.google.com, Bob’s browser creates the HTTP <code class="language-plaintext highlighter-rouge">GET</code> message (Section 2.2.3) containing the URL to be fetched.</p>

        <ul>
          <li>==HTTP== <code class="language-plaintext highlighter-rouge">GET </code>message is then written into the socket, with the <code class="language-plaintext highlighter-rouge">GET </code>message becoming the payload of a TCP segment.</li>
          <li>The segment is placed in a datagram and delivered all the way alike step 1 - 3 mentioned above</li>
        </ul>
      </li>
      <li>
        <p>Google does the same thing to respond</p>

        <p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211213151942489.png" alt="image-20211213151942489" style="zoom:80%;" /></p>
      </li>
    </ol>
  </li>
</ol>

<p>This completes the entire tour!</p>

<h1 id="miscellaneous">Miscellaneous</h1>

<p>Useful stuff learnt throughout the semester</p>

<h2 id="wireshark">Wireshark</h2>

<p>The basic structure of this is:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211004153011588.png" alt="image-20211004153011588" style="zoom:67%;" /></p>

<p>where the packet sniffer, is shown within the dashed rectangle in Figure 1</p>

<p><strong>First</strong>, we have the capturing:</p>

<ul>
  <li>the actual capturing is the <strong>COPYING of Link Layer Frames</strong> which happesn in the Kernel Space</li>
  <li>messages exchanged by higher layer protocols such as HTTP, FTP, TCP, UDP, DNS, or IP ==all are eventually encapsulated in link-layer frames== that are transmitted over physical media</li>
</ul>

<p><strong>Then</strong>, we have the analysis to displays the contents of all fields within a protocol message</p>

<ul>
  <li>
    <p>In order to do so, the packet analyzer must ==“understand” the structure of all messages== exchanged by protocols</p>

    <p>For example, it needs to:</p>

    <ol>
      <li>understand the format of <em>Ethernet frames</em>, and so can identify the IP datagram within an Ethernet frame.</li>
      <li>It also understands the <em>IP datagram</em> format, so that it can extract the TCP segment within the IP datagram.</li>
      <li>Then, it understands the <em>TCP segment</em> structure, so it can extract the HTTP message contained in the TCP segment.</li>
      <li>Finally, it understands the <em>HTTP protocol</em> and so, for example, knows that the first bytes of an HTTP message will contain the string “GET,” “POST,” or “HEAD,” as shown in Figure 2.8 in the text.</li>
    </ol>
  </li>
</ul>

<blockquote>
  <p>Technically speaking, Wireshark is a packet analyzer that uses a packet capture library in your computer</p>
</blockquote>

<h3 id="intro-to-wireshark">Intro to Wireshark</h3>

<p>After you select which network interface (网卡) to capture, you will see stuff like this:</p>

<ul>
  <li>
    <p>if you clicked the wrong one accidentally, you can change it here:</p>

    <p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211004155422153.png" alt="image-20211004155422153" style="zoom:67%;" /></p>
  </li>
</ul>

<p>Then, your screen looks like this</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211004155103491.png" alt="image-20211004155103491" style="zoom: 50%;" /></p>

<p>where basically:</p>

<ul>
  <li><strong>packet content</strong> contains <em>entire contents of the captured frame</em> in ASCII and hexadecimal without parsing</li>
  <li><strong>packet details</strong> contains the parsed contents</li>
</ul>

<p>The rest is basic and you know already.</p>

<h2 id="distributed-hash-tables">Distributed Hash Tables</h2>

<p>Recall that it is useful when you have ==P2P==, we are <strong>centralizing</strong> all the information, which might be bad for load balance or availability.</p>

<p>Here, we consider having a <strong>distributed node</strong> for maintaining the information as a solution.</p>

<p>The simplest idea:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211027091343938.png" alt="image-20211027091343938" /></p>

<p>where if you do a exhaustive search, then if only $K$ out of $N$ nodes have the information, your <strong>expected search cost</strong> is at least $N/K$ searches, which is $O(N)$.</p>

<p>Therefore, the aim is to <strong>minimize the search cost using distributed search table</strong>.</p>

<blockquote>
  <p><strong>Heuristics</strong></p>

  <p>This is slow because we are doing some exhausted search. So we want to speed up by having a more <strong>directed search</strong></p>

  <ol>
    <li>assign particular nodes to <em>hold particular content</em> (or know where it is, like an information booth)</li>
    <li>when a node wants that content, <em>go to the node directly that is supposed to have or know about it</em></li>
  </ol>
</blockquote>

<h3 id="dht-step-1-the-hash">DHT Step 1: The Hash</h3>

<p>First we need to design a hash function $h$, that hashes the ==content being searched for to a identifier==.</p>

\[h(\text{"movie xxx"}) = 8045\]

<p>Then distribute that range of hash function (==responsibility==) among all nodes.</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211027091942729.png" alt="image-20211027091942729" style="zoom:67%;" /></p>

<p>note that multiple nodes can hold the same content ofc.</p>

<ul>
  <li>one problem still remains is how to figure out ==where to go== when we have the hash</li>
</ul>

<h3 id="dht-step-2-routing">DHT Step 2: Routing</h3>

<p>Now we need to find a way to reach the object when we have the hash. Obviously we want to achieve that:</p>

<ol>
  <li>For each object, node(s) whose range(s) cover that object (i.e. is responsible for it) must be <strong>reachable</strong> via a “short” path</li>
  <li>number of neighbors for each node should <strong>not go $O(N)$</strong>, otherwise its like a centralized system.</li>
</ol>

<p>In essence, the different approaches (CAN,Chord,Pastry,Tapestry) differ fundamentally <strong>only in the routing approach</strong></p>

<h3 id="case-studies">Case Studies</h3>

<p>Here we cover In alphabetical order:</p>

<ul>
  <li>CAN (Content Addressable Network)</li>
  <li>Chord</li>
</ul>

<p>In particular, consider the questions:</p>

<ol>
  <li>How is hash space divided “evenly” among existing nodes?</li>
  <li>How is <strong>routing implemented</strong> that connects an arbitrary node to the node responsible for a given object?</li>
  <li>How is the hash space repartitioned when nodes <strong>join/leave</strong>? (i.e. how is the structure changing)</li>
</ol>

<p>For the following discussion:</p>

<ul>
  <li>Let $N$ be the number of nodes in the overlay</li>
  <li>$H$ be the size of the range of the hash function (when applicable)</li>
</ul>

<h4 id="can">CAN</h4>

<p>Every content/object maps to a <strong>point in this cartesian space</strong>. We decide on a dimension $D$ that we want to have. Here, let us take $D=2$. Therefore, we basically have:</p>

<ul>
  <li>hash value for each point in the space</li>
  <li>each node is responsible for a <strong>volume of hash value/points</strong> in the space</li>
</ul>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211027092737370.png" alt="image-20211027092737370" /></p>

<p>where basically:</p>

<ul>
  <li>
    <p>**every square is occupied by Some numbers are not labelled for clarity purposes.</p>
  </li>
  <li>you are ==directedly connect to your neighbor==, which is defined to be the cube that is <strong>touching your cube</strong>. Therefore, there is only $O(D)$ neighbors.</li>
  <li>this is assumed to be wrapped around, so node $7$ and $8$ are neighbors.</li>
  <li>in this setup, we can figure out the path geometrically</li>
</ul>

<h5 id="can-routing">CAN Routing</h5>

<p>The upshot is that each <strong>coordinate</strong> on the map is <strong>related to the hash value</strong> of the object. Therefore, each node/square on the diagram knows exactly where to look at.</p>

<p>Consider in this case that <code class="language-plaintext highlighter-rouge">1</code> wants to get the information <code class="language-plaintext highlighter-rouge">X</code> which is in the lower half of node <code class="language-plaintext highlighter-rouge">8</code>.</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211027093515847.png" alt="image-20211027093515847" /></p>

<ol>
  <li>compute the cartesian distance to the data <code class="language-plaintext highlighter-rouge">X</code>. In this case, the route through <code class="language-plaintext highlighter-rouge">2</code> is the shortest due to the wrap around.</li>
  <li>therefore, since <code class="language-plaintext highlighter-rouge">node 1</code> can only contact its neighbor, it send it to <code class="language-plaintext highlighter-rouge">node 2</code>.</li>
  <li>this happens iteratively until it reaches <code class="language-plaintext highlighter-rouge">node 8</code>.</li>
</ol>

<h5 id="can-node-insertion">CAN Node Insertion</h5>

<p>Basically when you have a new node:</p>

<ol>
  <li>find some node in the CAN network</li>
  <li>choose a point in that space uniformly at random</li>
  <li>using CAN, <strong>inform the node</strong> that currently covers the space (because you are going to take some responsibility from it soon)</li>
  <li>the node will then split its space into half by ==dimension== (i.e. along some axis)</li>
</ol>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211027093839613.png" alt="image-20211027093839613" style="zoom:67%;" /></p>

<p>So basically every new node will take <em>half of the space</em> of some existing node. This can therefore <strong>achieve load balancing</strong>, since for node with high responsibility = large area = high probability of being shared when a node joined.</p>

<h5 id="can-removal-process">CAN Removal Process</h5>

<p>Basically like balancing a tree. In general, there are two situations:</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211107110845558.png" alt="image-20211107110845558" style="zoom: 67%;" /></p>

<ol>
  <li>
    <p>You can simply collpase the removed node’s portion to form a bigger rectangle</p>

    <ul>
      <li>e.g. if 6 is removed, then its portion is given back to 1</li>
    </ul>
  </li>
  <li>
    <p>The node is the only one in the rectangle. Then you need juxtaposition</p>

    <ul>
      <li>
        <p>e.g. if 3 is removed, then it should merge the space back to node 2,4,5. One way is to let 5 take over that space, while node 2 take over node 5’s previous space</p>
      </li>
      <li>
        <p>basically it looks like balancing a tree</p>

        <p>| <img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211107111317602.png" alt="image-20211107111317602" style="zoom: 67%;" /> | <img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211027094614867.png" alt="image-20211027094614867" /> |
| :———————————————————-: | :———————————————————-: |</p>

        <p>so the ==algorithm== basically becomes the follows. Suppose node <code class="language-plaintext highlighter-rouge">s</code> is leaving:</p>

        <ol>
          <li>
            <p>Find a leaf node <code class="language-plaintext highlighter-rouge">t</code> that is either</p>

            <ul>
              <li>
                <p><code class="language-plaintext highlighter-rouge">s</code>’s sibling (i.e. in the first case mentioned above)</p>
              </li>
              <li>
                <p>descendant of <code class="language-plaintext highlighter-rouge">s</code>’s sibling where <code class="language-plaintext highlighter-rouge">t</code>’s sibling is also a leaf node (i.e. the second case mentioned above)</p>
                <ul>
                  <li>in this case, if <code class="language-plaintext highlighter-rouge">s</code> is node 6, then <code class="language-plaintext highlighter-rouge">t</code> is either node 2 or 5. Node 4 does not work since its sibling is not a leaf.</li>
                </ul>
              </li>
            </ul>
          </li>
          <li>
            <p>Found <code class="language-plaintext highlighter-rouge">t</code>, then let <code class="language-plaintext highlighter-rouge">t</code> take over <code class="language-plaintext highlighter-rouge">s</code>’s space</p>
          </li>
          <li>
            <p><code class="language-plaintext highlighter-rouge">t</code>’s sibling then take over the <code class="language-plaintext highlighter-rouge">t</code>’s previous space</p>
          </li>
        </ol>
      </li>
    </ul>
  </li>
</ol>

<h4 id="chord">Chord</h4>

<p>The only difference here is basically we are having nodes <strong>all in a 1-dimensional space</strong>. Therefore, instead of hashes that gives some d-dimensional coordinate, this gives a <strong>one dimensional <code class="language-plaintext highlighter-rouge">ID</code></strong>.</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211027094640836.png" alt="image-20211027094640836" /></p>

<p>where the chord is basically wrapped around to form a circle.</p>

<blockquote>
  <p><strong>Hence Chord Basically works as follows</strong></p>

  <ul>
    <li>hash the IP address of a node</li>
    <li>each node covers <strong>object/data from previous hashed ID</strong> up to its own
      <ul>
        <li>therefore, the hash of object itself tells you where to look for the node</li>
      </ul>
    </li>
  </ul>
</blockquote>

<h5 id="chord-routing">Chord Routing</h5>

<p>First we need decide the “<strong>neighbors each node knows</strong>”. In this case, each node knows <em>several other nodes beside its immediate neighbor</em> (in contrast to CAN).</p>

<p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211107124907695.png" alt="image-20211107124907695" style="zoom:50%;" /></p>

<p>where here, we are node 2345, and we:</p>

<ul>
  <li>know 6 other nodes’ ID</li>
  <li>then if we need data with hash of <code class="language-plaintext highlighter-rouge">1000</code>, we will ask node <code class="language-plaintext highlighter-rouge">1254</code> (since each node covers object from <em>previous ID up to its own</em>)</li>
</ul>

<blockquote>
  <p>in terms of implementation, the finger table needs to be ==ordered clockwise==. (most often)</p>
</blockquote>

<hr />

<p><strong>Implementation</strong></p>

<p>Let the range of the hash function be $H$ (i.e. the length of the chord is $H$). Then, we can define:</p>

<ul>
  <li>
    <p>A node <code class="language-plaintext highlighter-rouge">t</code>’s neighbor as the ==closest== node to:</p>

\[t + \text{mod}_H(2^i )\]

    <p>for some $i$. Basically this ==ensures that there is at most $\log_2 H \to \log_2 N$== neighbors, since we only have $N$ nodes in the chord. (In contrast to CAN, which is independent of $N$).</p>
  </li>
  <li>
    <p>notice that the length of the chord between two nodes is proportional to the probability of being picked when a new node inserts. This basically achieves <strong>load balancing</strong>.</p>
  </li>
</ul>

<p>For instance, if you are node <code class="language-plaintext highlighter-rouge">67</code>, iterating all the <code class="language-plaintext highlighter-rouge">i</code>’s gives you:</p>

<p>| <img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211107130027908.png" alt="image-20211107130027908" style="zoom:50%;" /> | <img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211107130128866.png" alt="image-20211107130128866" style="zoom:67%;" /> |
| :———————————————————-: | :———————————————————-: |</p>

<p>where here we took $H=100$, then:</p>

<ul>
  <li>the <strong>blue lines are the computed neighbor</strong></li>
  <li>the black numbers are the <strong>actual neighbors</strong> (i.e. closest to the computed one)</li>
  <li>the table on the right are the values</li>
</ul>

<h5 id="chord-node-insertion">Chord Node Insertion</h5>

<p>Suppose we are adding node <code class="language-plaintext highlighter-rouge">82</code> into the system.</p>

<ol>
  <li>
    <p>First we need find the <code class="language-plaintext highlighter-rouge">82</code>’s predecessor, which is basically node <code class="language-plaintext highlighter-rouge">72</code></p>

    <p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211107132227347.png" alt="image-20211107132227347" style="zoom:67%;" /></p>
  </li>
  <li>
    <p>Then, we can <strong>set the finger table for node <code class="language-plaintext highlighter-rouge">82</code></strong> by ==computing from node <code class="language-plaintext highlighter-rouge">72</code>== (i.e. let node <code class="language-plaintext highlighter-rouge">72</code> compute the data and put it in node <code class="language-plaintext highlighter-rouge">82</code>):</p>

    <p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211107132411474.png" alt="image-20211107132411474" style="zoom:50%;" /></p>

    <p>where basically:</p>

    <ul>
      <li>the value $t + \text{mod}_H(2^i )$ is computed from node <code class="language-plaintext highlighter-rouge">82</code></li>
      <li>the lookup for closest node from that value is done by node <code class="language-plaintext highlighter-rouge">72</code></li>
    </ul>
  </li>
  <li>
    <p>Next, we need to update the finger table of other nodes who ==should now contain entries to <code class="language-plaintext highlighter-rouge">82</code>==. This can be done by:</p>

    <ol>
      <li>
        <p>Go to the largest node before or at ID $82 - 2^i$, and let us call that node <code class="language-plaintext highlighter-rouge">t</code>.</p>

        <p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211107132933786.png" alt="image-20211107132933786" style="zoom:50%;" /></p>

        <p>e.g., for $i=1$, we will reach node <code class="language-plaintext highlighter-rouge">72</code>, which we know <strong>should update its finger table</strong>.</p>
      </li>
      <li>
        <p>==If== node <code class="language-plaintext highlighter-rouge">t</code>’s $2^i$ finger points to a node larger than $82$:</p>

        <ol>
          <li>
            <p>change that pointer to $82$</p>
          </li>
          <li>
            <p>set node <code class="language-plaintext highlighter-rouge">t</code> to its current predecessor, and repeat step 2</p>

            <p>e.g. for $i=3$, we will need to update the red highlighted nodes:</p>

            <p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211107134036337.png" alt="image-20211107134036337" style="zoom:67%;" /></p>

            <p>where basically:</p>

            <ul>
              <li>we first jumped to node <code class="language-plaintext highlighter-rouge">72</code> and change the $2^3$ finger of node <code class="language-plaintext highlighter-rouge">72</code> to now point to node <code class="language-plaintext highlighter-rouge">82</code> instead of <code class="language-plaintext highlighter-rouge">86</code></li>
              <li>go to <code class="language-plaintext highlighter-rouge">72</code>’s predecessor and do the same, for its $2^3$ finger</li>
              <li>go to <code class="language-plaintext highlighter-rouge">32</code>, and realize that we need no update. Hence we terminate here for $i=3$.</li>
            </ul>
          </li>
        </ol>

        <p>==Else==, move on to the next $i$ value</p>
      </li>
      <li>
        <p>Repeat for all the $i$ values.</p>

        <ul>
          <li>therefore, in total it takes $O(\log^2N)$ time to find and update all.</li>
        </ul>
      </li>
    </ol>
  </li>
</ol>

<h5 id="chord-node-deletion">Chord Node Deletion</h5>

<p>The idea is basically the same as insertion, where suppose node <code class="language-plaintext highlighter-rouge">82</code> is to be deleted, then we need to replace the finger table with node <code class="language-plaintext highlighter-rouge">86</code> instead:</p>

<ol>
  <li>
    <p>Find node <code class="language-plaintext highlighter-rouge">82</code>’s successor, which is node <code class="language-plaintext highlighter-rouge">86</code></p>
  </li>
  <li>
    <p>Perform step 3 in the <a href="#Chord Node Insertion">Chord Node Insertion</a>, basically ==undoing it for node <code class="language-plaintext highlighter-rouge">82</code>==</p>

    <p>e.g. if we are at $i=3$ now, then we compute $82-2^3$</p>

    <p><img src="/lectures/images/2021-12-16-CSEE4119_Computer_Networks/image-20211107135216932.png" alt="image-20211107135216932" style="zoom:67%;" /></p>

    <p>where notice that we are computing $82-2^3$ ==at node <code class="language-plaintext highlighter-rouge">86</code>==:</p>

    <ul>
      <li>first jumped to node <code class="language-plaintext highlighter-rouge">72</code> and change the finger back to node <code class="language-plaintext highlighter-rouge">86</code> if it was pointing to node <code class="language-plaintext highlighter-rouge">82</code></li>
      <li>etc.</li>
    </ul>
  </li>
</ol>

<h2 id="using-newudpl">Using <code class="language-plaintext highlighter-rouge">newudpl</code></h2>

<p>This section includes details on how to use and debug <code class="language-plaintext highlighter-rouge">newudpl</code> from http://www.cs.columbia.edu/~hgs/research/projects/newudpl/newudpl-1.4/newudpl.html</p>

<p>The mechanism seems as follows. If you run:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>➜ ./newudpl <span class="nt">-i</span> 127.0.0.1:41192 <span class="nt">-s50</span> <span class="nt">-d2</span>.004 <span class="nt">-v</span>
</code></pre></div></div>

<p>Then it will:</p>

<ul>
  <li>only <strong>accept packets from <code class="language-plaintext highlighter-rouge">-i 127.0.0.1:*</code></strong>, and listens on the <strong>default address</strong> <code class="language-plaintext highlighter-rouge">127.0.0.1:41192</code> (so your client needs to send there)</li>
  <li>and it redirects packet <strong>out to the default address <code class="language-plaintext highlighter-rouge">127.0.0.1:41194</code></strong> (so your server needs to listen here)</li>
</ul>

<p>Then, what you then do is to:</p>

<ol>
  <li>
    <p>let python <code class="language-plaintext highlighter-rouge">client</code> to send data to <code class="language-plaintext highlighter-rouge">41192</code>, assuming it is using some port <code class="language-plaintext highlighter-rouge">sender_port</code></p>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">➜</span> <span class="n">python</span> <span class="n">tcpclient</span><span class="p">.</span><span class="n">py</span> 
<span class="n">Input</span><span class="p">:</span> <span class="n">aaa</span>
<span class="n">yeet</span> <span class="c1"># recevied from server after step 2
</span></code></pre></div>    </div>
  </li>
  <li>
    <p>let python <code class="language-plaintext highlighter-rouge">server</code> to receive data from <code class="language-plaintext highlighter-rouge">41194</code>, and reply <strong>directly to <code class="language-plaintext highlighter-rouge">sender_port</code> of the client</strong></p>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">➜</span> <span class="n">python</span> <span class="n">tcpserver</span><span class="p">.</span><span class="n">py</span> 
<span class="n">The</span> <span class="n">server</span> <span class="ow">is</span> <span class="n">ready</span> <span class="n">to</span> <span class="n">s</span> <span class="n">ss</span> <span class="n">receive</span>
<span class="p">[</span><span class="n">LOG</span><span class="p">]</span> <span class="n">servicing</span> <span class="p">(</span><span class="s">'127.0.0.1'</span><span class="p">,</span> <span class="mi">41193</span><span class="p">)</span>
<span class="n">rcvd</span> <span class="n">aaa</span>
<span class="c1"># sending "yeet" directly to sender
</span></code></pre></div>    </div>
  </li>
</ol>

<h3 id="errors-encounted">Errors Encounted</h3>

<p><strong>Problem</strong></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>➜ ./newudpl
newudpl: Could not retrieve localhost IP.
newudpl: Error: printing title.
</code></pre></div></div>

<p><strong>Solution</strong></p>

<ol>
  <li>
    <p>First, to understand what generated that error messgage, you will eventually find:</p>

    <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp"># inside newudpl.c
</span><span class="k">if</span> <span class="p">((</span><span class="n">localHIp</span> <span class="o">=</span> <span class="n">getLHnameIp</span><span class="p">(</span><span class="n">localHname</span><span class="p">,</span> <span class="n">STRSIZE</span><span class="p">))</span> <span class="o">==</span> <span class="p">(</span><span class="n">in_addr_t</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">fprintf</span><span class="p">(</span><span class="n">stderr</span><span class="p">,</span> <span class="s">"%s: Could not retrieve localhost IP.</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">o</span><span class="o">-&gt;</span><span class="n">argv0</span><span class="p">);</span>
    <span class="k">return</span> <span class="o">-</span><span class="mi">1</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div>    </div>

    <p>which then goes into <code class="language-plaintext highlighter-rouge">akiralib.c</code>:</p>

    <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp"># inside akiralib.c
</span>   
<span class="n">in_addr_t</span> <span class="nf">getLHnameIp</span><span class="p">(</span><span class="kt">char</span> <span class="o">*</span><span class="n">hName</span><span class="p">,</span> <span class="kt">size_t</span> <span class="n">len</span><span class="p">)</span>
<span class="p">{</span>
   
  <span class="cm">/* impliment code when host name was not retrieved */</span>
  <span class="k">struct</span> <span class="n">hostent</span> <span class="o">*</span><span class="n">hostEnt</span><span class="p">;</span>
  <span class="k">struct</span> <span class="n">utsname</span> <span class="n">myname</span><span class="p">;</span>
  <span class="k">struct</span> <span class="n">in_addr</span> <span class="o">*</span><span class="n">ipAddr</span><span class="p">;</span>
   
  <span class="k">if</span> <span class="p">(</span><span class="n">uname</span><span class="p">(</span><span class="o">&amp;</span><span class="n">myname</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="o">-</span><span class="mi">1</span><span class="p">;</span>
   
  <span class="n">printf</span><span class="p">(</span><span class="s">"I got from %s I got %s, %s "</span><span class="p">,</span> <span class="n">myname</span><span class="p">,</span> <span class="n">myname</span><span class="p">.</span><span class="n">nodename</span><span class="p">,</span> <span class="n">gethostbyname</span><span class="p">(</span><span class="n">myname</span><span class="p">.</span><span class="n">nodename</span><span class="p">));</span>
  <span class="k">if</span> <span class="p">((</span><span class="n">hostEnt</span> <span class="o">=</span> <span class="n">gethostbyname</span><span class="p">(</span><span class="n">myname</span><span class="p">.</span><span class="n">nodename</span><span class="p">))</span> <span class="o">==</span> <span class="nb">NULL</span><span class="p">)</span>
    <span class="k">return</span> <span class="o">-</span><span class="mi">1</span><span class="p">;</span>
  <span class="n">ipAddr</span> <span class="o">=</span> <span class="p">(</span><span class="k">struct</span> <span class="n">in_addr</span> <span class="o">*</span><span class="p">)</span> <span class="n">hostEnt</span><span class="o">-&gt;</span><span class="n">h_addr_list</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">strlen</span><span class="p">(</span><span class="n">myname</span><span class="p">.</span><span class="n">nodename</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">len</span><span class="p">)</span>
    <span class="k">return</span> <span class="o">-</span><span class="mi">1</span><span class="p">;</span>
  <span class="n">strcpy</span><span class="p">(</span><span class="n">hName</span><span class="p">,</span> <span class="n">myname</span><span class="p">.</span><span class="n">nodename</span><span class="p">);</span>
   
  <span class="k">return</span> <span class="n">ipAddr</span><span class="o">-&gt;</span><span class="n">s_addr</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div>    </div>

    <p>Then, you see the problem is actually this:</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>➜ ./newudpl
newudpl: Could not retrieve localhost IP.
newudpl: Error: printing title.
I got from Darwin I got Xiaos-MBP.lan1, <span class="o">(</span>null<span class="o">)</span> 
</code></pre></div>    </div>

    <p>therefore:</p>

    <ul>
      <li><code class="language-plaintext highlighter-rouge">Xiaos-MBP.lan1</code> basically is not tranlated to <code class="language-plaintext highlighter-rouge">127.0.0.1</code></li>
    </ul>
  </li>
  <li>
    <p>Add the mapping from <code class="language-plaintext highlighter-rouge">Xiaos-MBP.lan1</code> to <code class="language-plaintext highlighter-rouge">127.0.0.1</code> in <code class="language-plaintext highlighter-rouge">/etc/hosts</code></p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>➜ERROR <span class="nb">cat</span> /etc/hosts
127.0.0.1	localhost
127.0.0.1	Xiaos-MBP.lan1
<span class="c"># other mapping omitted</span>
</code></pre></div>    </div>
  </li>
</ol>


  </div><a class="u-url" href="/lectures/2021@columbia/CSEE4119_Computer_Networks.html/" hidden></a>
  <script src="/lectures/assets/js/my_navigation.js"></script>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/lectures/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Lecture Notes</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Lecture Notes</li><li><a class="u-email" href="mailto:jasonyux17@gmail.com">jasonyux17@gmail.com</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/jasonyux"><svg class="svg-icon"><use xlink:href="/lectures/assets/minima-social-icons.svg#github"></use></svg> <span class="username">jasonyux</span></a></li><li><a href="https://www.linkedin.com/in/xiao-yu2437"><svg class="svg-icon"><use xlink:href="/lectures/assets/minima-social-icons.svg#linkedin"></use></svg> <span class="username">xiao-yu2437</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>An inexhaustive collection of markdown/latex(PDF) notes that I took since college. </p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
