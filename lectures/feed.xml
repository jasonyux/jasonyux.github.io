<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.1">Jekyll</generator><link href="/lectures/feed.xml" rel="self" type="application/atom+xml" /><link href="/lectures/" rel="alternate" type="text/html" /><updated>2024-10-20T19:44:26+00:00</updated><id>/lectures/feed.xml</id><title type="html">Lecture Notes</title><subtitle>An inexhaustive collection of markdown/latex(PDF) notes that I took since college. </subtitle><entry><title type="html">COMS4733 Computational Aspects of Robotics</title><link href="/lectures/2024@columbia/COMS4733_Computational_Aspects_of_Robotics.html/" rel="alternate" type="text/html" title="COMS4733 Computational Aspects of Robotics" /><published>2024-06-02T00:00:00+00:00</published><updated>2024-06-02T00:00:00+00:00</updated><id>/lectures/2024@columbia/COMS4733_Computational_Aspects_of_Robotics</id><content type="html" xml:base="/lectures/2024@columbia/COMS4733_Computational_Aspects_of_Robotics.html/"><![CDATA[<p><strong>Table of Contents:</strong></p>

<p>[toc]</p>

<h1 id="logistics">Logistics:</h1>

<ul>
  <li>Will be quite heavy in <strong>math</strong>: linear algebra + probability and stats</li>
  <li><strong>Textbooks</strong>: Principle of Robot Motion (mostly), Planning Algorithms</li>
  <li><strong>OH</strong>: 712 CEPSR, details posted on <em>Edstem</em> Live Calendar</li>
  <li><strong>Grades</strong>: HW 40%, Midterm 30%, Final 30%</li>
</ul>

<h1 id="introduction-to-robotics">Introduction to Robotics</h1>

<p>Robots can be classified into many categories by various methods:</p>
<ul>
  <li>
    <p>one way of classification:
|                                            Manipulator                                             |                                               Mobile                                               |                                              Humanoid                                              |
| :————————————————————————————————: | :————————————————————————————————: | :————————————————————————————————: |
| <img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240120164617.png" style="zoom:80%;" /> | <img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240120164637.png" style="zoom:80%;" /> | <img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240120164645.png" style="zoom:80%;" /> |</p>

    <p>where manipulators are often fixe in place and used in industry a lot (e.g., warehouses), mobile robots tend to interact with dynamic and unknown environments (e.g., self-driving cars), and humanoid robots are mainly designed to assist and interact humans</p>
  </li>
  <li>
    <p>or we can classify them by functions:
|                                             Industrial                                             |                                               Field                                                |                                              Service                                               |
| :————————————————————————————————: | :————————————————————————————————: | :————————————————————————————————: |
| <img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240120164950.png" style="zoom:80%;" /> | <img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240120165004.png" style="zoom:80%;" /> | <img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240120165023.png" style="zoom:80%;" /> |</p>

    <p>where industrial robots are often pre-programmed, field robots need to operate in unstructured environments, and service robots are designed to assist humans in daily life</p>
  </li>
</ul>

<p>What kinds of computation problems do we care about in robotics?</p>
<ol>
  <li>How do you <strong>represent</strong> and model your robot and its environment? (so that you can easily compute things)</li>
  <li>How do you <strong>control</strong> your robot?
    <ul>
      <li>robot kinematics: if you moved a joint by this bit, how much does the end-effector move?</li>
      <li>motion planning and automation</li>
    </ul>
  </li>
  <li>Robot sensors have a lot of noises. Need <strong>estimation, localization, and mapping</strong> to perceive what is happening in the environment</li>
  <li><strong>AI learning and perception</strong></li>
</ol>

<h1 id="rigid-body-transformations">Rigid-Body Transformations</h1>

<p>Let the world be represented with $\mathcal{W}$, and let a subset of points $\mathcal{A}$ be what we interested in (e.g. obstacles, our robot, etc)</p>

<p>We will also typically use coordinates <strong>relative</strong> to either a <strong>fixed</strong> world frame, or <strong>fixed</strong> robot’s body frame.</p>

<blockquote>
  <p><strong>Rigid-body transformation:</strong> A transformation function $h: \mathcal{A} \to \mathcal{W}$ such that relative distance and orientations between all points in $\mathcal{A}$ are preserved (i.e., your robot is not stretching itself, and is not “flipping” itself). Examples include:</p>

  <ul>
    <li>translations</li>
    <li>rotations</li>
  </ul>
</blockquote>

<p><strong>A 2D translation</strong> <mark>by</mark> $\mathbf{p} = (x_t, y_t)$ applied to <mark>all points in $\mathcal{A}$</mark></p>

\[h(x, y ) = (x+x_t, y+y_t)\]

<p>this can be interpreted in two ways:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">you transformed the points in the robot</th>
      <th style="text-align: center">you transformed the origin of the frame</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240119143903155.png" alt="image-20240119143903155" style="zoom: 50%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240119143912482.png" alt="image-20240119143912482" style="zoom:50%;" /></td>
    </tr>
  </tbody>
</table>

<p><strong>A 2D rotation</strong>: suppose we rotate our robot counter-clockwise about the origin of the world frame by an angle $\theta$. You can do this</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Visually</th>
      <th style="text-align: center">Mathematically</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240119144112167.png" alt="image-20240119144112167" style="zoom: 50%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240119144130121.png" alt="image-20240119144130121" style="zoom: 33%;" /></td>
    </tr>
  </tbody>
</table>

<p>so now your function becomes:</p>

\[h(\mathbf{x}) = R(\theta) \mathbf{x}\]

<p>in fact, there is a simple interpretation of this rotation matrix:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240119144440374.png" alt="image-20240119144440374" style="zoom:33%;" /></p>

<p>The first column of $R$, which is $[\cos \theta, \sin\theta]^T$, is the <strong>coordinate of $x_1$ w.r.t the old frame</strong>, and the second columd is the <strong>coordinate of $y_1$ w.r.t the old frame</strong>! So the operation of:</p>

\[\begin{bmatrix} \cos\theta &amp; -\sin\theta \\ \sin\theta &amp; \cos \theta \end{bmatrix} \begin{bmatrix}x \\ y\end{bmatrix} = x \begin{bmatrix} \cos\theta \\ \sin\theta \end{bmatrix} + y \begin{bmatrix} -\sin\theta \\ \cos\theta \end{bmatrix}\]

<p>so it is basically the “same $(x ,y)$” but in a new coordinate frame!</p>

<blockquote>
  <p><strong>Properties of Rotation Matrix</strong>: a rotation matrix is quite important, and it has a lot of useful properties:</p>

  <ul>
    <li>$R(\theta)$ produces a counter-clockwise rotation</li>
    <li>it is orthogonal: $R(\theta)^{-1} = R(\theta)^T$​</li>
    <li>additional $R(\theta)^{-1} = R(-\theta)$​, so inverse is just a clockwise rotation</li>
    <li>$\det(R(\theta)) = 1$, so rotation does <strong>not change length, size, or magnitude</strong> (i.e., does not stretch points, rigid-body transformation!)</li>
    <li>is composable $R(\theta_1 + \theta_2) = R(\theta_1)R(\theta_2)$</li>
    <li>2D rotation transformation is communicative (but not for 3D) $R(\theta_1)R(\theta_2) = R(\theta_2)R(\theta_1)$​</li>
    <li>rotation matrices represent rotation as <strong>linear transformations</strong></li>
  </ul>
</blockquote>

<h2 id="homogenous-transformations">Homogenous Transformations</h2>

<p>Now you can combine rotaion and translation:</p>

\[\begin{bmatrix}x' \\ y'\end{bmatrix} = R(\theta) \begin{bmatrix}x \\ y\end{bmatrix} + \begin{bmatrix}x_t \\ y_t\end{bmatrix}\]

<p>is a valid rigid body transformation, but is now <strong>affine</strong>, not linear transformation. Some common trick to make this a linear transformation (so math is simpler later) is to add a dimension $(x,y) \to (x,y,1)$:</p>

\[\begin{bmatrix} 
x' \\ y' \\ 1 
\end{bmatrix} = \begin{bmatrix} 
\cos \theta &amp; -\sin \theta &amp; x_t \\ 
\sin \theta &amp; \cos \theta &amp; y_t \\
0 &amp; 0 &amp; 1
\end{bmatrix}  \begin{bmatrix} 
x \\ y \\ 1
\end{bmatrix}
= T(\theta, x_t, y_t) \begin{bmatrix}
x \\ y \\ 1
\end{bmatrix}\]

<p>so that both rotation and translation is expressed as a <strong>homogeneous linear transformation</strong> (in 2D space). This turns out to be a general form:</p>

<blockquote>
  <p><strong>Homogenous Transformation Matrix</strong>: this form generalizes if you are doing rotations and translations only:</p>

\[T(\theta, x_t, y_t) = \begin{bmatrix} 
\cos \theta &amp; -\sin \theta &amp; x_t \\ 
\sin \theta &amp; \cos \theta &amp; y_t \\
0 &amp; 0 &amp; 1
\end{bmatrix} = \begin{bmatrix}
R(\theta) &amp; \mathbf{p} \\
\mathbf{0}^T &amp; 1
\end{bmatrix}\]

  <p>so for example:</p>

  <ul>
    <li>
      <p>to do pure rotation, substitute $\mathbf{p}=[0,0]^T$, and for pure translation, substitute $R(\theta) = I$</p>
    </li>
    <li>
      <p>no longer orthogonal, so inverse is a bit more compllicated</p>

\[T^{-1} = \begin{bmatrix}
R^-1 &amp; -R^{-1}\mathbf{p}\\
\mathbf{0}^T &amp; 1
\end{bmatrix}\]
    </li>
    <li>
      <p>not commutative: $T_1 T_0(x,y,1) \neq T_0 T_1(x,y,1)$</p>
    </li>
  </ul>
</blockquote>

<p>For example, consider visually what would happen if I do $T_0$ being pure rotation by $\pi/4$, and $T_1$ being translation to right by $3$</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240120161732.png" style="zoom:100%;" /></p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Step 0</th>
      <th style="text-align: center">Step 1</th>
      <th style="text-align: center">Step 2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240120162036.png" style="zoom:100%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240120162548.png" style="zoom:100%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240120162622.png" style="zoom:100%;" /></td>
    </tr>
  </tbody>
</table>

<p>If you do in reverse order</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Step 0</th>
      <th style="text-align: center">Step 1</th>
      <th style="text-align: center">Step 2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240120162036.png" style="zoom:100%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240120162110.png" style="zoom:100%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240120162312.png" style="zoom:100%;" /></td>
    </tr>
  </tbody>
</table>

<p><mark>note that all intermediate transformations are relative to the original frame</mark>.</p>

<h2 id="3d-transformations">3D Transformations</h2>

<p>Essentially the same idea as 2D transformations, but:</p>

<ul>
  <li>
    <p><strong>3D translations</strong> are still simple: $h(x,y,z)=(x+x_t, y+y_t, z+z_t)$</p>
  </li>
  <li>
    <p><strong>3D rotations</strong> is much more complicated because you can <strong>rotate relative to many axis</strong></p>

    <ul>
      <li>
        <p>e.g., rotation around the $z$-axis</p>

\[R_z(\alpha) = \begin{bmatrix}
\cos \alpha &amp; -\sin \alpha &amp; 0\\
\sin \alpha &amp; \cos \alpha &amp; 0 \\
0 &amp; 0 &amp; 1
\end{bmatrix} \to \begin{bmatrix}
\mathbf{x_1} &amp; \mathbf{y_1} &amp; \mathbf{z_1}
\end{bmatrix}\]

        <p>and again, the interpretation is the same as before: <strong>rotation matrix describes the new coordinate axis</strong></p>

        <p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240119151643911.png" alt="image-20240119151643911" style="zoom:33%;" /></p>

        <p>notice that:</p>

        <ul>
          <li>
            <p>the zeros and ones is intuitive: since <strong>$z$-axis isn’t moving</strong>, they have to appear like this!</p>
          </li>
          <li>
            <p>and the upper part of this matrix is exactly the same as the 2D transformation matrix $R(\theta)$</p>
          </li>
        </ul>
      </li>
      <li>
        <p>e..g, since you have three axis, you have two more rotation matrices</p>

\[R_y(\beta) = \begin{bmatrix}
\cos \beta &amp; 0 &amp; \sin \beta \\
0 &amp; 1 &amp; 0 \\
-\sin \beta &amp; 0 &amp; \cos \beta
\end{bmatrix},\quad R_x(\gamma) = \begin{bmatrix}
1 &amp; 0 &amp; 0 \\
0 &amp; \cos \gamma &amp; -\sin \gamma \\
0 &amp; \sin \gamma &amp; \cos \gamma
\end{bmatrix}\]
      </li>
      <li>
        <p>right-hand-rule: a 3D “positive rotation” by $\theta$ about some axis $\mathbf{v}$ is a counter-clockwise rotation in the plan normal to $\mathbf{v}$. Visually, it is just right-hand-rule:</p>

        <p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240119152520204.png" alt="image-20240119152520204" style="zoom:50%;" /></p>
      </li>
      <li>
        <p>rotations about the same axis is commutative (as in 2D), but <strong>not commutative</strong> when you are rotating about different axes (in 3D)</p>

        <p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240119153258097.png" alt="image-20240119153258097" style="zoom: 50%;" /></p>
      </li>
      <li>
        <p>but <strong>each 3D rotation matrix is orthogonal</strong></p>
      </li>
    </ul>
  </li>
</ul>

<p><em>For example,</em> consider our “robot” is a box, and we want to transform all points of this box by $\pi$ in the $z$-axis (let us just visualize one point of the box):</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240119152934685.png" alt="image-20240119152934685" style="zoom: 50%;" /></p>

<p><em>For example</em>: transform a vector $\mathbf{v}$ by $\pi/2$ in the $y$-axis</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240119153034529.png" alt="image-20240119153034529" style="zoom:50%;" /></p>

<h2 id="3d-homogeneous-transformations">3D Homogeneous Transformations</h2>

<p>Similar to 2D, if we do one rotation and and one translation: we can make it into <strong>one linear transformation matrix</strong> by uplifting one dimension.</p>

<p><em>For example</em>, rotating about $y$-axis by $\beta$ followed by a translation:</p>

\[T = \begin{bmatrix}
R_y(\beta) &amp; \mathbf{p} \\
\mathbf{0}^T &amp; 1
\end{bmatrix}
= \begin{bmatrix}
\cos \beta &amp; 0 &amp; \sin \beta &amp; x_t \\
0 &amp; 1 &amp; 0 &amp; y_t \\
-\sin \beta &amp; 0 &amp; \cos \beta &amp; z_t \\
0 &amp; 0 &amp; 0 &amp; 1
\end{bmatrix}\]

<p>As an exercise, try to figure out the transformation matrix from frame 0 to frame 1, and then from frame 1 to frame 2:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240119154101897.png" alt="image-20240119154101897" style="zoom:40%;" /></p>

<ul>
  <li>
    <p>from frame 0 to frame 1: we are rotating about $x_0$ by $\pi/2$, rotate about $y_0$ by $\pi/2$, and translate along $z_0$​ by 1unit</p>

    <table>
      <thead>
        <tr>
          <th>Step 0</th>
          <th>Step 1</th>
          <th>Step 2</th>
          <th>Step 3</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240121154430948.png" alt="image-20240121154430948" style="zoom:67%;" /></td>
          <td><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240121154713679.png" alt="image-20240121154713679" style="zoom:67%;" /></td>
          <td><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240121154727122.png" alt="image-20240121154727122" /></td>
          <td><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240121154840717.png" alt="image-20240121154840717" /></td>
        </tr>
      </tbody>
    </table>

    <p>therefore the full transformation matrix look like:</p>

\[T_1^0 = \begin{bmatrix}
I &amp; [0,0,1]^{T} \\
\mathbf{0}^T &amp; 1
\end{bmatrix} \begin{bmatrix}
R_{y}(\pi/2) &amp; \mathbf{0} \\
\mathbf{0}^T &amp; 1
\end{bmatrix} \begin{bmatrix}
R_{x}(\pi/2) &amp; \mathbf{0} \\
\mathbf{0}^T &amp; 1
\end{bmatrix}  = \begin{bmatrix}
0 &amp; 1 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; -1 &amp; 0 \\
-1 &amp; 0 &amp; 0 &amp; 1 \\
0 &amp; 0 &amp; 0 &amp; 1
\end{bmatrix}\]

    <p>note that in this case</p>

    <ul>
      <li><strong>each column represents the new coordinate’s axis relative to the original frame!</strong> (e.g., $x_1$’s coordinate is exactly <strong>pointing at</strong> $[0,0,-1]$, and the <strong>new origin at</strong> $[0,0,1]$ from the last column).</li>
      <li>Also note that we <strong>do translation last</strong>, since it is the simplest as all transformation (i.e., the rotations) are relative to the <strong>original frame</strong>.</li>
      <li>we denote $T^0_1$ means we are transforming from frame 0 to frame 1</li>
    </ul>
  </li>
  <li>
    <p>from frame 1 to frame 2: left as an exercise</p>
  </li>
</ul>

<h2 id="composition-ordering">Composition Ordering</h2>

<p>But what if I already give you the transformation of $T^0_2$?</p>

\[T_2^0 = \begin{bmatrix}
0 &amp; 0 &amp; -1 &amp; 0\\
-1 &amp; 0 &amp; 0 &amp; 1 \\
0 &amp; 1 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 1
\end{bmatrix}\]

<p>Can you tell me what is $T^1_2$ given this information and your previous result of $T^0_1$?</p>

<ul>
  <li>
    <p>attempt 1: can say that:</p>

\[T^1_2 \overset{?}{=} T^0_2 T^1_0  = T_2^0 (T^0_1)^{-1}\]

    <p>No, because the two transformations are done in <strong>different basis</strong>. The first transformation $T^1_0$ is based on frame 1, and the second $T^0_2$ is based on frame 0!</p>
  </li>
  <li>
    <p>attempt 2: we need to <strong>write $T^{0}_2$ transformation relative to frame 1</strong>. This is a similarity transformation:</p>

\[T^0_2 \to (T^0_1)^{-1} T^0_2 (T^0_1)\]

    <p>Therefore, the correct transformation is:</p>

\[T^{1}_2 = (T^0_1)^{-1} T^0_2 (T^0_1) (T^0_1)^{-1} = (T^0_1)^{-1} T^0_2 = T^{1}_0 T^{0}_2\]

    <p>and note that this is almost the <mark>same as the first attempt, but flipped!</mark></p>
  </li>
</ul>

<p>This turns out to be turn in general. Consider two homogenous transformations $A,B$:</p>

<blockquote>
  <ul>
    <li>if both are written <strong>relative to the same frame</strong>, then you can simply combine them and the result is intuitive. E.g., $C=BA$ transformation means you first do $A$ and then $B$.</li>
    <li>
      <p>if they are <strong>not written relative to the same frame</strong>, for example $A=T^{i}_j$ is w.r.t. frame $i$ and $B=T^{j}_k$ is w.r.t. frame $j$, then:</p>

\[T^{i}_j T^{j}_k = T^{i}_k\]

      <p>is transforming from frame $i$ (left matrix) to frame $k$ (right matrix).</p>
    </li>
  </ul>
</blockquote>

<p>So in some sense, you can say “absolute transformations” (same frame) are pre-multiplied (right to left), and “relative transformations” (different frame) are post-multiplied (left to right).</p>

<h1 id="configuration-space">Configuration Space</h1>

<blockquote>
  <p><strong>Configuration</strong>: Description of the positions of all points of a robot</p>

  <p><strong>Configuration Space</strong> (C-Space): the space of all possible configurations of the robot.</p>

  <ul>
    <li>In theory, there may have an infinite list of point positions, but in practice we consider parameterized representations of C-space</li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Group</strong> $(G, \circ)$ is a set $G$ with binary operatoin $\circ$ such that for all $a,b,c\in G$:</p>

  <ul>
    <li>Closure: $a\circ b \in G$</li>
    <li>Associativity: $(a\circ b) \circ c = a \circ (b \circ c)$</li>
    <li>Identity: $\exists e \in G$ such that $e \circ a = a \circ e = a$</li>
    <li>Inverse: $\forall a \in G$, $\exists a^{-1} \in G$ such that $a \circ a^{-1} = a^{-1} \circ a = e$</li>
  </ul>
</blockquote>

<p>For example, $(\Z, +)$ is a group, where of course adding two integers still gives an integer, etc.
Alternatively, the group $(\R - {0}, \times )$ also works. Note that zero is taken out since it does not have multiplicative inverse.</p>

<blockquote>
  <p><strong>General Linear Group</strong>: the set of all non-singular (non-zero determinant) $n\times n$ real matrices with the operation of matrix multiplication.</p>
</blockquote>

<p>We are interested in this group because some subgroups of this are useful to robotics. For example:</p>

<ul>
  <li>Orthogonal group $O(n)$, a set of $n\times n$ <strong>orthogonal</strong> matrices with $\det = \pm 1$</li>
  <li><strong>Special Orthogonal Group</strong> $SO(n)$, subgroup of $O(n)$ with $\det = +1$. Any matrix in $SO(n)$ will corresponds to a $n\times n$​ <strong>rotation</strong> matrices we saw before.</li>
  <li><strong>Special Euclidean Group</strong> $SE(n)$, a set of $(n+1)\times (n+1)$ homogeneous transformation matrices in $\mathbb{R}^n$​. The rigid-body transformations are a <em>subset</em> of this, since we also require no-stretching.</li>
</ul>

<h2 id="c-space-of-mobile-robots">C-Space of Mobile Robots</h2>

<blockquote>
  <p>Positions of robot = uniquely defined by a transformation matrix (plus a given original position)
<strong>Configuration</strong> of a robot: a complete specification of the position of every point of the system. We will use $q$ to denote a configuration.</p>
</blockquote>

<blockquote>
  <p><strong>Configuration Space</strong> (C-Space): space of all possible configurations of the robot. We will use $\mathcal{Q}$ to denote the C-space.</p>
</blockquote>

<blockquote>
  <p><strong>Degree of Freedom</strong> of a robot system is number of parameters needed to specify a configuration, or the dimension of the C-space.</p>
</blockquote>

<p><em>For example</em>, a circular, 2D robot with a known radius $r$ can be fully described using the location of its center. Therefore, a <strong>configuration</strong> looks like $q=(x,y)$, which has <strong>two degrees of freedom</strong>. The C-space has <strong>dimension 2</strong>, and is just $\R^2$ in this case.</p>

<p>We can also tie this back to the groups we discussed before. We can say <mark>single body robots can be described by $SE(2)$ or $SE(3)$</mark>. This is because any configuration of a single body robot can be described by a transformation matrix in $SE(2)$ or $SE(3)$​, and these group of matrices contain all possible translations and rotations in 2D or 3D space.</p>

<p>For example:</p>
<ul>
  <li>if the robot only translates, then often its C-space is just $\R^{2}$ or $\R^{3}$</li>
  <li>if the robot only rotates, then we can say its C-space is $SO(2)$ or $SO(3)$</li>
  <li>if we have multiple robots, then the full C-space is the <strong>Cartesian product</strong> of each body’s individual C-space</li>
</ul>

<p>We can also describe the degrees of freedom of those matrix groups, interpreted as the <strong>number of parameters</strong> needed to construct them:</p>

<ul>
  <li>$SO(2)$ and $SO(3)$ have dimension 1 and 3, respectively (for 3D, worst case you can have one rotation from each three axis)</li>
  <li>$SE(2)$ corresponds to $\R^2 \times SO(2)$, which has dimension $2+1=3$</li>
  <li>$SE(3)$ corresponds to $\R^3 \times SO(3)$, which has dimension $3+3=6$</li>
</ul>

<h3 id="unit-circle">Unit Circle</h3>

<p>Since $SO(2)$ has dimension 1, what’s the difference with $\R^1$? Realize that $SO(2)$ is uniquely parametrized by value $[0, 2\pi)$. To visualize this space, we can consider the <strong>points on a unit circle</strong>:</p>

\[\mathbb{S}^{1} = \{ (x,y) \in \R^2 | x^2 + y^2 = 1 \}\]

<p>and note that <mark>each point on the unit circle maps to a value in $[0, 2\pi)$</mark> (so its a good way to visualize it). More formally:</p>

<blockquote>
  <p><strong>Homeomorphism</strong>: $SO(2)$ and $\mathbb{S}^1$ are homeomorphic, since there exists a <strong>continuous bijection function $f:X\to Y$</strong></p>

  <ul>
    <li>i.e., so that you can visualize these two sets (of free variables) as the same thing</li>
  </ul>
</blockquote>

<p>This “visualization” tool comes in handy later when things get complicated.</p>

<h2 id="kinematic-chains">Kinematic Chains</h2>

<p>Can we describe the C-space of a manipulator? For a manipulator, each rigid body has a link, and links are connected by joints:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240126141028498.png" alt="image-20240126141028498" style="zoom: 25%;" /></p>

<p>What’s interesting now is that since <strong>each joint only has one degree of freedom, it severly restricts</strong> the degree of freedom of links and end effector. This means that two <strong>fully describe the C-space</strong> of this robot, we <strong>only have two degrees of freedom</strong>: $(\theta_1, \theta_2)$.</p>

<p>More formally, the C-space is (not $\R^2$):</p>

\[\mathbb{S}^1 \times \mathbb{S}^1\]

<p>How do you “visualize” this C-space? This is actually <mark>homeomorphic to the surface of a 2D torus $\mathbb{T}^2$</mark>.</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240126141906907.png" alt="image-20240126141906907" style="zoom: 50%;" /></p>

<p>where <mark>every point on the surface of the 2D torus corresponds to a unique angle configuration we have</mark>.</p>

<h2 id="manifolds">Manifolds</h2>

<p>Even though $\mathbb{S}^1$ and $\R$​ are not homeomorphic and topologically different, they <strong>are locally similar</strong>.</p>

<blockquote>
  <p><strong>Manifold</strong>: A subset $M \subseteq \R^m$ is a $n$-dimension manifold if <strong>each point in $M$ lies in a neighborhood</strong> that is homeomorphic <strong>to an open subset of $\R^n$</strong></p>

  <ul>
    <li>i.e., we can locally flatten each point in $M$, so that it is homeomorphic (can map) to $\R^n$</li>
    <li>e.g. a globe (Earth) is a manifold since the neighbor area we see are basically flat</li>
  </ul>

  <p>Practically, a valid manifold means you have a <strong>valid mapping</strong> $f:X\to Y$ with an <strong>inverse</strong> $f^{-1}:Y\to X$, where the space of $Y \in M$ and $X$ is in your original space.</p>
</blockquote>

<p>For example, $\mathbb{S}^1$ is a 1-dimensional manifold in $\R^2$​</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240126143121927.png" alt="image-20240126143121927" style="zoom: 33%;" /></p>

<ul>
  <li>
    <p>this is because we can have a mapping where blue and green does $(x,y) \to y$, and yellow and red does $(x,y)\to x$.</p>
  </li>
  <li>notice that the mapping is <strong>unique within the neighborhood</strong></li>
  <li>so “1-dimensional manifold in $\R^2$” <strong>means</strong> $\mathbb{S}^1$ lives in $\R^2$ as shown above, but we can flatten it in a way to describe it using only one continuous number (i.e., 1-dimensional manifold)</li>
</ul>

<p>For another example, the following are 2-dimensional manifolds in $\R^3$:</p>
<ul>
  <li>$\mathbb{S^2}$ the surface of a sphere</li>
  <li>$\mathbb{T^2} = \mathbb{S^1} \times \mathbb{S^1}$ the surface of a torus</li>
  <li>$\R \times \mathbb{S^1}$ infinite cylinder</li>
</ul>

<h2 id="matrix-lie-groups">Matrix Lie Groups</h2>

<blockquote>
  <p><strong>Lie Groups</strong>: groups that are also (differentiable) manifolds.</p>

  <ul>
    <li>this includes $SE(n)$​ and its subgroups, and most robot related C-spaces</li>
    <li>basically now, we are visualizing “matrix groups” as “manifolds”</li>
  </ul>
</blockquote>

<p>For example, a real $n\times n$ matrix is trivially homeomorphic to $\R^{n^2}$:</p>

\[A = \begin{bmatrix}
a &amp; b \\
c &amp; d
\end{bmatrix} \iff (a,b,c,d)\]

<p>where in this example, $SE(2)$ is homeomorphic to $\R^4$.</p>

<p>What about matrices in $SO(2)$​? Even though this is $\mathbb{S}^{1}$, we know we can flatten it to a 1-dimensional manifold in $\R^2$. So we can say $SO(2)$ is homeomorphic to $\R$. Another more direct way to think about this: <strong>$\mathbb{S}^{1}$ describes the points on a unit circle, which can be “flattened” into a manifold</strong>.</p>

<h2 id="obstacles-as-polygons">Obstacles as Polygons</h2>

<p>Real robot C-spaces are often not just an “open-world” $\mathcal{W}$, there may be obstacles $\mathcal{O}_i \in \mathcal{W}$.</p>

<blockquote>
  <p>A robot’s <strong>workspace</strong> is the subset two or three-dimensional Euclidean space $\mathcal{W}$ that it can reach.</p>
</blockquote>

<p>To efficiently represent this space, we will consider two tricks:</p>
<ul>
  <li>represent $\mathcal{O}$ using a combination of primitives (e.g., intersection of lines, planes)</li>
  <li>then we can directly “transform” these primitives into the C-space of the robot = robot’s <strong>free C-space</strong></li>
</ul>

<p>As a starting point, consider a simple 2D obstacle that we can represent with a finite set of vertices:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240126212827.png" style="zoom:100%;" /></p>

<p>We can describe using <mark>line equations + inequalities</mark>:</p>

\[O = H_{1} \cup H_{2} \cup ... \cup H_{m}\\
H_i = \{ (x,y) \in \mathcal{W} | f_i(x,y) \le 0 \}\]

<p>notice that a line equation is just $f_i(x,y) = ax + by + c = 0$, and we can use inequalities to describe the half-space of the line.</p>

<p>We can then describe a <strong>non-convex polygon</strong> by decomposing it into unions of convex polygons, and use set differences for holes.</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240126145546543.png" alt="image-20240126145546543" style="zoom:50%;" /></p>

<p>This idea is similar in 3D, where we just use polyhedra = using <mark>plane equations</mark> instead of line equations, and then consider the intersection of inequalities:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240126145727342.png" alt="image-20240126145727342" style="zoom:50%;" /></p>

<p>We can finally <mark>generalize this even further to non-linear primitives</mark>. For example, we can use polynomial equations to represent the following:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240126145856275.png" alt="image-20240126145856275" style="zoom:50%;" /></p>

<p>where the green area basically is the obstacle.</p>

<h3 id="c-space-obstacles">C-Space Obstacles</h3>

<p>Now we want to transform those obstacles <strong>into the C-space of the robot</strong>, i.e., we want to directly obtain a single, constrained C-space.</p>

<p>Let $\mathcal{A}$ be our robot, and let $q \in \mathcal{Q}$ denote the configuration of $\mathcal{A}$</p>

<blockquote>
  <p><strong>C-space obstacle region</strong>: is the region <mark>when the robot takes this configuration (i.e. transformation)</mark>, it <mark>collides</mark> with some obstacle.</p>

\[Q_{\mathrm{obs}} = \{ q \in \mathcal{Q}  | \mathcal{A}(q) \cap O \neq \empty \}\]

  <p><strong>Free C-space</strong>: when the robot will <mark>not collide</mark>:</p>

\[Q_{\mathrm{free}} = Q - Q_{\mathrm{obs}}\]

</blockquote>

<p>For example, for a 2D robot, you can imagine $q=(x_t,y_t, \theta)$, and $Q_{\mathrm{obs}}$ would be all the configurations (i.e., transformations) such that the robot will hit an obstacle after performing it.</p>

<p>What if you have multiple bodies? Then you also need to exclude <strong>collisions between these bodies</strong>. So $Q_{\mathrm{obs}}$ is:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240126151046216.png" alt="image-20240126151046216" style="zoom:50%;" /></p>

<hr />

<p><em>For example</em>, visualizing free C-space if your robot is just a point (has no rotation)</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240126151218525.png" alt="image-20240126151218525" style="zoom: 67%;" /></p>

<p>Again no rotation, but if we give it some volumes:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240126151351594.png" alt="image-20240126151351594" style="zoom:50%;" /></p>

<p>where notice that:</p>

<ul>
  <li>
    <p><strong>a coordinate $q$ in free C-space</strong> corresponds to a configuration (or transformation) such that <strong>$\mathcal{A}(q)$ does not hit an obstacle in the workspace</strong>.</p>
  </li>
  <li>
    <p>in the special case here we have only two degrees of freedom (no rotation), we only needed to <strong>grow boundaries of $Q_{\mathrm{obs}}$​</strong> by the radius of the robot to obtain $Q_{\mathrm{free}}$​.</p>
  </li>
  <li>
    <p>Things get more complicated when it goes to 3D.</p>
  </li>
</ul>

<h2 id="minkowski-difference">Minkowski Difference</h2>

<p>Since it gets complicated in 3D quickly, but is there a simple way to figure out the obstacle space? When the <strong>robot is a rigid body restricted to translation only</strong>, we can use</p>

<blockquote>
  <p><strong>Minkovski Differece</strong>: when $\mathcal{Q} = \R^{n}$, then $Q_{\mathrm{obs}}$ is the Minkowski difference:</p>

\[\mathcal{O} \ominus \mathcal{A}(0) = \{ o - a \in \R^n | o \in \mathcal{O}, a \in \mathcal{A}(0) \}\]

  <p>where $A(0)$ means the robot is at the origin, and $\ominus$ is the Minkowski difference operator. This is basically considering <mark>all points as vectors</mark>, and doing a <mark>vector minus</mark> for all possible points.</p>
</blockquote>

<p>Visually</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Example 1</th>
      <th style="text-align: center">Example 2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240126152230104.png" alt="image-20240126152230104" style="zoom:33%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240126152406089.png" alt="image-20240126152406089" style="zoom:30%;" /></td>
    </tr>
  </tbody>
</table>

<p>effectively we are obtaining the region by “sliding our robot” along the edge of the obstacles, therefore:</p>
<ul>
  <li>the vector minus is because we need to flip our robot to slide along the edge</li>
  <li>the Minkowski difference considered all vectors of the robot = the shape of the robot</li>
</ul>

<p>However, computationally this would need <strong>adding infinite number of vectors</strong>, so there are a few work-arounds</p>

<h3 id="convex-hulls">Convex Hulls</h3>

<p><mark>If we are dealing with convex polygons,</mark> it turns out adding/subtracting the <strong>vertices</strong> are sufficient.</p>

<p>The <strong>convex hull</strong> of the Minkowski differnce is the <strong>set of vertices</strong> of the C-shape obstacle region:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240202132151981.png" alt="image-20240202132151981" style="zoom: 50%;" /></p>

<p>note that we won’t need to know how to implement this in $\mathcal{O}(n \log n)$, as they are many existing algorithm implementations that does this efficiently.</p>

<h3 id="star-algorithm">Star Algorithm</h3>

<p><strong>Again, If both $\mathcal{A}$ and $\mathcal{O}$ are convex</strong>, we can compute $Q_{\mathrm{obs}}$​ by considering only <strong>vertex-edge contacts</strong>.</p>

<p>The key observation is that <mark>every edge of $\mathcal{C}_{obs}$ is a translated edge</mark> either from $\mathcal{A}$ or $\mathcal{O}$, In fact, <mark>every edge from $\mathcal{O}$ and $\mathcal{A}$ is used exactly once</mark> in the construction of $\mathcal{C}_{obs}$:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240126220451.png" style="zoom:20%;" /></p>

<p>where in (a) we color-coded a couple of examples, and (b) shows the final $\mathcal{C}<em>{obs}$. There is a translation of the edges, but that doesnt matter as we can construct <strong>if we know the order of edges</strong> to construct $\mathcal{C}</em>{obs}$ (then we can just glue them in order).</p>

<blockquote>
  <p><strong>Star Algorithm</strong>: the order of edges can be obtained by sorting:</p>
  <ol>
    <li>find the inward edge normals of $\mathcal{A}$</li>
    <li>find the outward edge normals of $\mathcal{O}$</li>
    <li>sort the edges by angle around $\mathcal{S}^1$</li>
    <li>Then, assemble by simply gluing edges in the order of the sorted list.</li>
  </ol>
</blockquote>

<p>For example, to obtain the $\mathcal{C}_{obs}$ above:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Algorithm</th>
      <th style="text-align: center">Glueing</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240126221207.png" style="zoom:100%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240126221214.png" style="zoom:100%;" /></td>
    </tr>
  </tbody>
</table>

<p>note that</p>

<ul>
  <li>
    <p>this assumes the “origin” of the robot is at the top left of the robot. If not, we can simply translate $\mathcal{C}_{obs}$ by the same amount</p>
  </li>
  <li>Star-algorithm is very fast: is linear in the number of edges of $\mathcal{A}$ and $\mathcal{O}$</li>
  <li>similar ideas for $\R^{3}$ based on enumerating contacts between <strong>convex polyhedra vertices</strong> and <strong>faces</strong> to obtain $\mathcal{C}_{obs}$</li>
</ul>

<h2 id="c-spaces-with-orientation">C-Spaces with Orientation</h2>

<p>If a robot can rotate, we can get a <strong>different C-space</strong> given an orientation. For example, given the same obstacle we can have different C-space:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240126153942725.png" alt="image-20240126153942725" style="zoom:30%;" /></p>

<p>Since now the <strong>different C-space is a function of angle</strong>, we can visualize it by treating $\theta$ as a vertical axis and <strong>stacking the C-spaces</strong>:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240126154020722.png" alt="image-20240126154020722" style="zoom:50%;" /></p>

<p>notice that already for a <strong>2D robot with rotation, the C-space is 3D and quite complex</strong>!</p>

<h2 id="c-space-with-manipulators">C-Space with Manipulators</h2>

<p>What about non-convex objects, such as using a manipulator? (obstacle is shown in blue)</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Manipulator</th>
      <th style="text-align: center">C-space</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240202132917802.png" alt="image-20240202132917802" style="zoom:33%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240202132905642.png" alt="image-20240202132905642" style="zoom:33%;" /></td>
    </tr>
  </tbody>
</table>

<p>It turns out this is <strong>extremly complicated</strong>, and currently we are still mainly using <strong>sampling based approaches</strong>. Note that:</p>

<ul>
  <li>the C-space is paramterized only by two variables $\alpha$ and $\beta$. So its dimension is a <strong>torus</strong> $=\mathbb{S}\times\mathbb{S}$</li>
  <li>visually it makes sense: only if $\alpha$ is large (e.g., $\ge 135 \degree$) the angle $\beta$ can rotate freely</li>
</ul>

<h1 id="kinematics">Kinematics</h1>

<p>Given a <mark>C-space</mark> and some points on it, how to do <strong>mathematically map it back to the real robot</strong> (i.e., <mark>workspace</mark>). For example, given the two angles, compute what the manipulator will actually look like.</p>

<blockquote>
  <p>A robot’s <strong>kinematics</strong> is a mapping from its C-space to its workspace.</p>
</blockquote>

<p>In this section, we will mostly focus on (fixed base) manipulators.</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240202133802240.png" alt="image-20240202133802240" style="zoom:33%;" /></p>

<p>note that:</p>

<ul>
  <li>
    <p>we will also assume a joint (the black dot) only has <strong>one degree of freedom</strong>. If we have $&gt;1$​, we can simply consider multiple joints and combine them.</p>
  </li>
  <li>
    <p>often $\theta_i$ is defined <mark>relatitve to the previous link</mark></p>
  </li>
  <li>
    <p>there are two types of joint: a rotational and a translational one</p>

    <p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240202133957292.png" alt="image-20240202133957292" style="zoom:50%;" /></p>
  </li>
</ul>

<blockquote>
  <p>Since the useful part is the <strong>end effector</strong>, we consider the <mark>workspace of a manipulator = points reachable by the end effector</mark></p>
</blockquote>

<p>For example, a planer RR arm (revolute + revolute) covers a workspace of an annulus in $\R^2$:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240202134435697.png" alt="image-20240202134435697" style="zoom:33%;" /></p>

<h2 id="forward-kinematics">Forward Kinematics</h2>

<blockquote>
  <p><strong>Forward kinematics</strong>: maps from its joint variables (e.g., angles) to the world position and orientation (pose) of its links</p>
</blockquote>

<p>For example, given two angles, we can compute the position $(x,y)$ of the end effector:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Visually</th>
      <th style="text-align: center">Mathematically</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240202134717936.png" alt="image-20240202134717936" style="zoom:50%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240202134733824.png" alt="image-20240202134733824" style="zoom:50%;" /></td>
    </tr>
  </tbody>
</table>

<p>where here we are mainly relying on <strong>geometry</strong>, so that:</p>

\[\begin{align*}
  x &amp;= l_1 \cos\theta_2 + l_2 \cos(\theta_1 + \theta_2) \\
  y &amp;= l_1 \sin\theta_2 + l_2 \sin(\theta_1 + \theta_2)
\end{align*}\]

<p>but this can quickly get <strong>very complicated</strong>. The trick is to use <mark>frame transformations matrices</mark>, where you will find that:</p>

<ul>
  <li>the <strong>position</strong> (i.e. $(x,y,z)$) of the end effector is exactly the <strong>last column vector of the matrix</strong></li>
  <li>the <strong>orientation</strong> of the end effector (i.e., if it is tilted, rotated) is found in the <strong>rotation submatrix</strong></li>
</ul>

<h3 id="2d-coordinate-frames">2D Coordinate Frames</h3>

<p>Consider the following idea:</p>
<ol>
  <li>label the <strong>body frames</strong> of each joints and end effector (red), and the <strong>fixed world frame</strong> as well (blue)</li>
  <li>then, figure out the <strong>transformation</strong> from the fixed world frame to the end effector frame</li>
  <li>since this transformation will tell you how to map anything from origin to the end effector, we automatically obtain the <strong>position</strong> and <strong>orientation</strong> of the end effector by <mark>reading off from the transformation matrix</mark></li>
</ol>

<p>Visually, we would first draw out the axes:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240202135002314.png" alt="image-20240202135002314" style="zoom:50%;" /></p>

<p>Then consider the transformations from one frame to another (which <em>conveniently will only be a single rotation and a translation</em>):</p>

\[T_{i}^{i-1} = \begin{bmatrix}
\cos\theta_i &amp; -\sin\theta_i &amp; l_{i-1} \\
\sin\theta_i &amp; \cos\theta_i &amp; 0 \\
0 &amp; 0 &amp; 1
\end{bmatrix}\]

<p>Since each frame is drawn <mark>relative to the previous frame</mark>, we can describe the final end effector’s body frame relative to the fixed frame using:</p>

\[T_{m+1}^0 = T_1^0 T_{2}^1 ... T^{m}_{m+1}\]

<p>and we would be able to read off the position and orientation of the end effector from $T_{m+1}^0$.</p>

<hr />

<p><em>For example</em>: consider a RRR arm, where we have three joint variables $\theta_1, \theta_2, \theta_3$ in C-space</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240202135803318.png" alt="image-20240202135803318" style="zoom:33%;" /></p>

<p>So then:</p>

<ul>
  <li>
    <p>frame 0 to 1 we only have rotation:</p>

\[T_1^0 = \begin{bmatrix}
\cos\theta_1 &amp; -\sin\theta_1 &amp; 0 \\
\sin\theta_1 &amp; \cos\theta_1 &amp; 0 \\
0 &amp; 0 &amp; 1
\end{bmatrix}\]
  </li>
  <li>
    <p>frame 1 to 2 and 2 to 3, we have rotation and translation:</p>

\[T_2^1 = \begin{bmatrix}
\cos\theta_2 &amp; -\sin\theta_2 &amp; l_1 \\
\sin\theta_2 &amp; \cos\theta_2 &amp; 0 \\
0 &amp; 0 &amp; 1
\end{bmatrix}, \quad
T_3^2 = \begin{bmatrix}
\cos\theta_3 &amp; -\sin\theta_3 &amp; l_2 \\
\sin\theta_3 &amp; \cos\theta_3 &amp; 0 \\
0 &amp; 0 &amp; 1
\end{bmatrix}\]
  </li>
  <li>
    <p>frame 3 and frame 4 we just have a single translation</p>

\[T_4^3 = \begin{bmatrix}
1 &amp; 0 &amp; l_3 \\
0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 1
\end{bmatrix}\]
  </li>
</ul>

<p>This results in</p>

\[T_4^0 = T_1^0 T_2^1 T_3^2 T_4^3 = \begin{bmatrix}
\cos(\theta_{1} + \theta_{2} + \theta_3) &amp; -\sin(\theta_{1} + \theta_{2} + \theta_3) &amp; l_1\cos\theta_1 + l_2\cos(\theta_1 + \theta_2) + l_3\cos(\theta_{1} + \theta_{2} + \theta_3) \\
\sin(\theta_{1} + \theta_{2} + \theta_3) &amp; \cos(\theta_{1} + \theta_{2} + \theta_3) &amp; l_1\sin\theta_1 + l_2\sin(\theta_1 + \theta_2) + l_3\sin(\theta_{1} + \theta_2 + \theta_3) \\
0 &amp; 0 &amp; 1
\end{bmatrix}\]

<p>which we will use a shorthand notation:</p>

\[T_4^0 = \begin{bmatrix}
c_{123} &amp; -s_{123} &amp; l_{1} c_1 + l_{2} c_{12} + l_{3} c_{123} \\
s_{123} &amp; c_{123} &amp; l_{1} s_1 + l_{2} s_{12} + l_{3} s_{123} \\
0 &amp; 0 &amp; 1
\end{bmatrix}\]

<p>How can we interpret this? Realize that:</p>
<ul>
  <li>
    <p>the last column describes the <strong>position</strong> of the end effector:</p>

\[(x,y) = (l_{1} c_1 + l_{2} c_{12} + l_{3} c_{123}, l_{1} s_1 + l_{2} s_{12} + l_{3} s_{123})\]
  </li>
  <li>
    <p>the upper left matrix describes the <strong>orientation</strong> of the end effector:</p>

\[\hat{x} = \begin{bmatrix}
c_{123} \\
s_{123} \\
\end{bmatrix}, \quad \hat{y} = \begin{bmatrix}
-s_{123} \\
c_{123} \\
\end{bmatrix}\]
  </li>
</ul>

<hr />

<p><em>For example</em>: RPR arm with $(\theta_1, d_2, \theta_3)$, so we also have translations in the middle:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240202141054119.png" alt="image-20240202141054119" style="zoom:33%;" /></p>

<p>Again, after drawing the frames, we consider:</p>
<ul>
  <li>
    <p>frame 0 to 1, we only have rotation</p>

\[T_1^0 = \begin{bmatrix}
\cos\theta_1 &amp; -\sin\theta_1 &amp; 0 \\
\sin\theta_1 &amp; \cos\theta_1 &amp; 0 \\
0 &amp; 0 &amp; 1
\end{bmatrix}\]
  </li>
  <li>
    <p>frame 1 to 2, we have only translation:</p>

\[T_2^1 = \begin{bmatrix}
1 &amp; 0 &amp; d_2 \\
0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 1
\end{bmatrix}\]
  </li>
  <li>
    <p>frame 2 to 3, we have rotation and translation:</p>

\[T_3^2 = \begin{bmatrix}
\cos\theta_3 &amp; -\sin\theta_3 &amp; l_2 \\
\sin\theta_3 &amp; \cos\theta_3 &amp; 0 \\
0 &amp; 0 &amp; 1
\end{bmatrix}\]
  </li>
  <li>
    <p>frame 3 to 4, we have only translation:</p>

\[T_4^3 = \begin{bmatrix}
1 &amp; 0 &amp; l_3 \\
0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 1
\end{bmatrix}\]

    <p>Hence altogether we have:</p>
  </li>
</ul>

\[T_4^0 = T_1^0 T_2^1 T_3^2 T_4^3 = \begin{bmatrix}
c_{13} &amp; -s_{13} &amp; (l_{2} + d_2)c_{1} + l_{3} c_{13} \\
s_{13} &amp; c_{13} &amp; (l_{2} + d_2)s_1 + l_{3} s_{13} \\
0 &amp; 0 &amp; 1
\end{bmatrix}\]

<p>where again, we can read of the actual position and orientation of the end effector from this matrix.</p>

<h3 id="cylindrical-arm">Cylindrical Arm</h3>

<p>Now here is a more complicated manipulator that can rotate along $z$-axis:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Cylindrical Manipulator</th>
      <th style="text-align: center">Annotated Body Frames</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240202141335562.png" alt="image-20240202141335562" style="zoom:33%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240202141347720.png" alt="image-20240202141347720" style="zoom:33%;" /></td>
    </tr>
  </tbody>
</table>

<p>So how do we obtain the position and orientation of the end effector?</p>

<ol>
  <li>frame 0 to 1 can rotate and move up and down. Specifically, we rotated $\theta_1$ by axis $z_0$, and translated along $z_0$ by $d_1$</li>
  <li>frame 1 to 2 can also rotate and move. Specifically, we rotated $- \pi / 2$ about axis $x_1$, and translated along $z_1$ by $d_2$</li>
  <li>frame 2 to 3 is the end effector, which translates along $z_2$ by $d_3$</li>
</ol>

<p>This results in:</p>

\[T_3^0 = \begin{bmatrix}
  c_1 &amp; 0 &amp; -s_1 &amp; -s_1 d_3 \\
  s_1 &amp; 0 &amp; c_1 &amp; c_1 d_3 \\
  0 &amp; -1 &amp; 0 &amp; d_1 + d_2 \\
  0 &amp; 0 &amp; 0 &amp; 1
\end{bmatrix}\]

<p>where again, the last column gives you the position of the end-effector, and orientation is given by the upper left matrix.</p>

<h2 id="inverse-kinematics">Inverse Kinematics</h2>

<p>Sometimes, you also want to do the reverse: <strong>given a position/orientation of the end-effector</strong>, find the <strong>joint configurations</strong> $q$ to achieve this.</p>

<blockquote>
  <p>The <strong>inverse kinematics</strong> problem is much harder since the FK are nonlinear!</p>
</blockquote>

<p>Why? For example:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240202142043654.png" alt="image-20240202142043654" style="zoom: 67%;" /></p>

<p>which is intrinsically because the <strong>transformation matrix</strong> is large in dimension (last row is skipped).</p>

<hr />

<p>For some <strong>simple</strong> case, we can solve it algebraically. Given $(x,y)$ here, solve for $\theta_1, \theta_2$:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240202142318774.png" alt="image-20240202142318774" style="zoom: 33%;" /></p>

<p>before we even try to solve this, <mark>notice a natural constraint</mark>:</p>

\[(l_1-l_2)^2 \le x^2 + y^2 \le (l_1+l_2)^2\]

<p>which is this annulus region we talked about before: the end effector cannot possibly be outside that space!</p>

<p>If this is an allowed position, we can solve it algebraically by:</p>

<ol>
  <li>first eliminating $\theta_1$:</li>
</ol>

\[x^2 + y^2 = l_1^2 + l_2^2 - 2l_1l_2\cos\theta_2\]

<ol>
  <li>then you will already find two solutions for $\theta_2$:</li>
</ol>

\[\theta_2 = \arccos \frac{x^2 + y^2 - l_1^2 -l_2^2}{2l_1l_2}\]

<ol>
  <li>and you can solve $\theta_1$ by plugging $\theta_2$​ in, and obtain:</li>
</ol>

\[\theta_1 = \arctan2(\sin \theta_1, \cos \theta_1)\]

<p>this makes physical sense as it corresponds to:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240202142648330.png" alt="image-20240202142648330" style="zoom: 33%;" /></p>

<blockquote>
  <p><strong>Note</strong>: $\arctan2$ function is different from the normal $\arctan$, where you can preserve sign information (because $\arctan(y/x)=\arctan(-y/-x)$). Visually, it looks like:</p>

  <p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/a/a8/Arctangent2.svg/220px-Arctangent2.svg.png" alt="img" /></p>

  <p>this is used mainly in <strong>programming</strong>, and many libraries provide this function.</p>
</blockquote>

<h2 id="robot-velocities">Robot Velocities</h2>

<p>The forward kinematics tells us the <strong>pose</strong> of the end effector (i.e., position and orientation). But our robot moves around:</p>

<blockquote>
  <p>The <strong>time derivative</strong> of the Forward Kinematics gives the <strong>velocity</strong> of the end effector.</p>

  <ul>
    <li>effectively, it helps us to compute $(\dot{x}, \dot{y}, \dot{z})$ from joint velocities $\dot{\mathbf{q}}$.</li>
    <li>this velocity information is also surprisingly helpful for us to solve some inverse kinematics problems (by gradient descent)</li>
  </ul>
</blockquote>

<p>We start with the end effectors position as a function of its configuration:</p>

\[x(\mathbf{q}), y(\mathbf{q}), z(\mathbf{q})\]

<p>we are interested in:</p>

\[\frac{d}{dt}(x(\mathbf{q}), y(\mathbf{q}), z(\mathbf{q}))\]

<p>using chain rules, this gives (assuming $\mathbf{q}\in \R^m$)</p>

\[\mathbf{v} = \frac{d}{dt} \begin{bmatrix} 
    x(\mathbf{q}) \\
    y(\mathbf{q}) \\
    z(\mathbf{q}) 
\end{bmatrix} = \begin{bmatrix} 
    \frac{\partial x}{\partial q_1} \frac{d q_1}{dt} + ... + \frac{\partial x}{\partial q_m} \frac{d q_m}{dt} \\
    \frac{\partial y}{\partial q_1} \frac{d q_1}{dt} + ... + \frac{\partial y}{\partial q_m} \frac{d q_m}{dt} \\
    \frac{\partial z}{\partial q_1} \frac{d q_1}{dt} + ... + \frac{\partial z}{\partial q_m} \frac{d q_m}{dt}
\end{bmatrix}
= \begin{bmatrix} 
    \frac{\partial x}{\partial q_1} &amp; ... &amp; \frac{\partial x}{\partial q_m} \\
    \frac{\partial y}{\partial q_1} &amp; ... &amp; \frac{\partial y}{\partial q_m} \\
    \frac{\partial z}{\partial q_1} &amp; ... &amp; \frac{\partial z}{\partial q_m} 
\end{bmatrix} \begin{bmatrix} 
    \frac{d q_1}{dt} \\
    \vdots \\
    \frac{d q_m}{dt} 
\end{bmatrix}
= J(\mathbf{q}) \dot{\mathbf{q}}\]

<p>so ultimately, velocity is some matrix (a Jacobian) times the <strong>joint velocity $\dot{\mathbf{q}}$​​</strong>. Later on you will also see that:</p>
<ul>
  <li>the $i$-th  <strong>column</strong> in the Jacobian is $\in \R^{3}$, which tells you the <strong>velocity direction</strong> of the end effector if you only moved that joint $q_i$</li>
  <li>so the velocity of the end effector is a <strong>linear function of the joint velocity</strong> $\dot{\mathbf{q}}$.</li>
</ul>

<hr />

<p><em>For example:</em> in an planar RR arm we have:</p>

\[\begin{bmatrix} 
    \dot{x} \\
    \dot{y}
\end{bmatrix}  = J(\theta_1, \theta_2) \begin{bmatrix} 
    \dot{\theta_1} \\
    \dot{\theta_2}
\end{bmatrix}\]

<p>where the jacobian is:</p>

\[J(\theta_1, \theta_2) = \begin{bmatrix} 
    -l_1 \sin\theta_1 - l_2 \sin(\theta_1 + \theta_2) &amp; -l_2 \sin(\theta_1 + \theta_2) \\
    l_1 \cos\theta_1 + l_2 \cos(\theta_1 + \theta_2) &amp; l_2 \cos(\theta_1 + \theta_2)
\end{bmatrix}
= \begin{bmatrix} 
    \vec{v}_1 &amp; \vec{v}_2 
\end{bmatrix}\]

<p>where notice that column vector is <strong>perpendicular</strong> from the effector to the joint. This means the <strong>direction of the velocity if you only move that joint</strong>.</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240202145040190.png" alt="image-20240202145040190" style="zoom:33%;" /></p>

<blockquote>
  <p>In general, this also means the <mark>column space</mark> of $J$​ is the set of <mark>all possible end effector velocities</mark>.</p>
</blockquote>

<h3 id="singular-configurations">Singular Configurations</h3>

<p>Typically, if your work space is $\R^n$, then your Jacobian could have $n$ independent columns (e.g., typically $n=3$).</p>

<blockquote>
  <p>Recall:</p>
  <ul>
    <li>the <strong>rank</strong> of a matrix is the number of linearly independent columns.</li>
    <li>the <strong>null space</strong> of a matrix $A$ is the set of all vectors $x$ such that $Ax=0$.</li>
    <li>if A has a non-trivial nullspace, it is <strong>not invertible and thus $\det A = 0$</strong>.</li>
  </ul>
</blockquote>

<blockquote>
  <p>It is possible for $J$ to have rank $&lt; n$ due to some special structure of the robot. If this happens, its called <strong>singular configurations</strong>.</p>
  <ul>
    <li>this means that there is some <strong>direction</strong> you cannot move the end effector, even if you moved all the joints.</li>
    <li>if $J$ is square, this also means <mark>it is non-invertible</mark> (also called being “singular”)</li>
    <li>finally, since its no longer full rank, there is a non-trivial <strong>null space</strong> of $J$​ = there will be certain <strong>non-zero joint velocities</strong> such that the <strong>end effector does not move</strong>.</li>
  </ul>
</blockquote>

<p><em>For example</em>, if for some reason your $\theta_2=0$​ is “stuck” and cant move for a while:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240202145552844.png" alt="image-20240202145552844" style="zoom: 40%;" /></p>

<p>then our Jacobian is</p>

\[J(\theta_1, 0) = \begin{bmatrix} 
    -l_2 \sin\theta_1 - l_2 \sin\theta_1 &amp; -l_2 \sin\theta_1 \\
    l_1 \cos\theta_1 + l_2 \cos\theta_1 &amp; l_2 \cos\theta_1
\end{bmatrix}\]

<p>Then notice that this has a null space:</p>

\[\text{Null}(J(\theta_1, 0)) = \text{Span}(-l_2, l_1+l_2)\]

<p>this means even if you moved the joints:</p>

\[\begin{bmatrix} 
    \dot{\theta_1} \\
    \dot{\theta_2}
\end{bmatrix} = \alpha  \begin{bmatrix}
    -l_2 \\
    l_1+l_2
\end{bmatrix}\]

<p>the end effector will <strong>not</strong> move.</p>

<hr />

<p><em>For example</em>: consider a cylindrical arm $\mathbf{q}=(\theta_1, d_2, d_3)$</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Visual</th>
      <th style="text-align: center">Jacobian</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240202150427866.png" alt="image-20240202150427866" style="zoom:33%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240202150438972.png" alt="image-20240202150438972" style="zoom:30%;" /></td>
    </tr>
  </tbody>
</table>

<p>first some sanity checks:</p>

<ul>
  <li>
    <p>the only way to give $z_0$ movement is in the second column, which corresponds to moving $d_2$​ = makes sense!</p>
  </li>
  <li>
    <p>to find singular configurations, we can solve for the nullspace or simply notice that $\det J = 0$. This gives us:</p>

\[0 = \det J = -d_3 \cos^2 \theta_1 - d_3 \sin^2 \theta_1 = -d_3\]

    <p>so if $d_3 = 0$, we will have a non-trival null space = singular configuration. In fact, if $d_3=0$, the end effector will lie on the $z_0$ axis, and actuating $\theta_1$ produces no <em>linear</em> velocity</p>
  </li>
</ul>

<hr />

<p><em>For example:</em> consider an anthropomorphic manipulator with $\theta_1, \theta_2, \theta_3$:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240202151501723.png" alt="image-20240202151501723" style="zoom:40%;" /></p>

<p>where if you look at the singular configurations, set $\det J = 0$ and you wil find:</p>

\[0 = \det J = a_2a_3 \sin\theta_{3} \cdot (a_{2} \cos\theta_{2} + a_{3} \cos\theta_{2}\cos\theta_{3})\]

<ul>
  <li>
    <p>so consider $\sin \theta_3 = 0$. This meaning multiples of $\pi$ gives you singular configurations = corresponding to your third joint being parallel to the second joint</p>
  </li>
  <li>
    <p>or $a_2\cos\theta_2 + a_3 \cos\theta_2\cos\theta_3 = 0$​​. This corresponds to</p>

    <p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240202151409202.png" alt="image-20240202151409202" style="zoom: 20%;" /></p>

    <p>again, the end effector has <strong>no linear velocity</strong> (its rotating, but not moving) if we move $\theta_1$</p>
  </li>
</ul>

<h2 id="numerical-inverse-kinematics">Numerical Inverse Kinematics</h2>

<blockquote>
  <p>Using a <strong>numerical</strong> approach to solve the Inverse Kinematics problem.</p>

  <ul>
    <li>a counterpart of our algebraic solutions in <a href="#Inverse_Kinematics">Inverse Kinematics</a></li>
    <li>drawback: can suffere from numerical instabilities, and require more computation</li>
  </ul>
</blockquote>

<p>Idea: suppose we want the end effector to be at position $(x^<em>, y^</em>, z^*)$, we can define an <strong>error function</strong> given its current position:</p>

\[MSE = \frac{1}{2}((x^*-x)^2 +(y^*-y)^2 + (z^*-z)^2)\]

<p>so our goal is simply to <strong>numerically find</strong> the $\mathbf{q}$ such that:</p>

\[\min_{\mathbf{q}} \frac{1}{2}((x^*-x)^2 +(y^*-y)^2 + (z^*-z)^2) = \min_{\mathbf{q}} \mathcal{L}\]

<p>so how do we find such $\mathbf{q}$ given this loss function? <strong>Gradient descent</strong>, which just takes a step using the partial derivatives</p>

\[\frac{\partial \mathcal{L}}{\partial \mathbf{q}} = \left [\frac{\partial \mathcal{L}}{\partial q_1}, \frac{\partial \mathcal{L}}{\partial q_2}, ..., \frac{\partial \mathcal{L}}{\partial q_m} \right ]\]

<p>and we update:</p>

\[\mathbf{q} \gets \mathbf{q} -\frac{\partial \mathcal{L}}{\partial \mathbf{q}}\]

<p>until convergence. But it turns out that we can write this gradient in <strong>another format</strong> that relates to what we discussed before:</p>

\[\begin{align*}
\frac{\partial \mathcal{L}}{\partial \mathbf{q}} 
&amp;= (-x^* - x(\mathbf{q})) \frac{\partial x }{\partial \mathbf{q}} - (y^* - y(\mathbf{q})) \frac{\partial y }{\partial \mathbf{q}} - (z^* - z(\mathbf{q})) \frac{\partial z }{\partial \mathbf{q}} \\
&amp;= - \begin{bmatrix} 
    \frac{\partial x}{\partial \mathbf{q}} &amp; \frac{\partial y}{\partial \mathbf{q}} &amp; \frac{\partial z}{\partial \mathbf{q}} 
\end{bmatrix} 
\begin{bmatrix} 
    x^* - x(\mathbf{q}) \\
    y^* - y(\mathbf{q}) \\
    z^* - z(\mathbf{q})
\end{bmatrix} \\
&amp;= -J(\mathbf{q})^T e(\mathbf{q})
\end{align*}\]

<p>so the <mark>gradient is just a negative Jacobian transpose times error vector</mark>! This again makes sense, since we just want to move in the direction to change $x,y,z$!</p>

<hr />

<p><em>For example</em>: given some initial configuration $\mathbf{q}$, desired position $\mathbf{p}$, step size $\alpha$, and an error threshold $\epsilon$:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240202153044747.png" alt="image-20240202153044747" style="zoom:50%;" /></p>

<p>Since this only uses first order gradient, we can get <strong>local minima</strong> when $J(\mathbf{q})^T e(\mathbf{q})=0$. This means that:</p>
<ul>
  <li>$e(\mathbf{q})$ is in the null space of $J(\mathbf{q})^T$.</li>
  <li>
    <p>Given a target position $(x^<em>, y^</em>, z^*)$, the entire thing is a function of $\mathbf{q}$. This means if you get into that $\mathbf{q}$ gradient descent will be <strong>stuck there</strong></p>
  </li>
  <li>This has a <mark>physical interpretation</mark>: these are the <mark>singular configurations</mark>!</li>
</ul>

<hr />

<p><em>For example,</em> we knew that $\theta_2$ fixed at $\theta_2=0$ gives a singular configuration. Then if we consider doing gradient descent at this configuration:</p>

\[J^{T}(\theta_1, 0) = \begin{bmatrix} 
    -(l_{1} + l_2) \sin \theta_{1} &amp; (l_{1} + l_2) \cos\theta_{1} \\
    -l_2 \sin\theta_{1} &amp; l_2 \cos\theta_{1} 
\end{bmatrix}\]

<p>Then if, given some target position $(x^<em>, y^</em>)$, we ended up with:</p>

\[e(\mathbf{q}) = \beta \begin{bmatrix} 
\cos\theta_1 \\
\sin\theta_1
\end{bmatrix}\]

<p>gradient descent will stop, and we are stuck. This visually corresponds to the case when:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240202213405.png" style="zoom:80%;" /></p>

<p>then given the star is your target position, but moving the joints in any direction away from $\theta_1, 0$ will increase the error function. So you are now stuck in a local minima.</p>

<h1 id="search-based-planning">Search-Based Planning</h1>

<p>Given a robot and a world $\mathcal{W}$, we want to move the robot from one place to another without colliding.</p>

<blockquote>
  <p><strong>Motion Plannning</strong>: find a path in configuration space $c: [0,1] \to Q_{\mathrm{free}}$  such that:</p>

\[c(0) = q_1, \quad c(1) = q_G\]

  <p>or report if no such path exists.</p>
  <ul>
    <li>so we are given initial and goal configuration $q_1$, $q_G$, and we want to find a path</li>
    <li>a path in the configuration space can then be easily translated to a path in the workspace -&gt; physically move!</li>
  </ul>
</blockquote>

<p>Visually:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240209131410953.png" alt="image-20240209131410953" style="zoom:33%;" /></p>

<p>There are many algorithms that can do this, and a good algorithm should satisfy:</p>

<ul>
  <li><strong>Completeness</strong>: Guarantee of finding a solution or reporting failure</li>
  <li><strong>Optimality</strong>: Path length, execution time, energy consumption of the robot, etc.</li>
  <li><strong>Efficiency</strong>: Algorithm runtime and memory complexity. This would also relate to C-space size; worst vs average case</li>
  <li><strong>Offline vs online</strong>: does planning occur in real-time, using sensor information?</li>
</ul>

<p>Types of algorithms</p>

<ul>
  <li><strong>Search-based</strong>: discrete C-space into graphs or grids, and then do planning</li>
  <li><strong>Combinatorial:</strong> plan using the full C-space by exploiting some geometry properties of the environment</li>
  <li><strong>Sampling -based</strong>: sample C-space to construct discrete representations</li>
</ul>

<p>both Search and Combinatorial methods yield completeness and optimality guarantees, but become expensive in high-dimensional space. Sampling-based methods are very efficient even in high-dimensional C-space, but weaker in completeness and optimality.</p>

<h2 id="grids-and-obstacles">Grids and Obstacles</h2>

<p><mark>Assuming</mark> we konw the full C-space already, and that its almost euclidean, we can <strong>discretize</strong> the C-space (given some resolution hyperparameter)</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Original</th>
      <th style="text-align: center">Discretized</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240209132426077.png" alt="image-20240209132426077" style="zoom:50%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240209132437133.png" alt="image-20240209132437133" style="zoom:50%;" /></td>
    </tr>
  </tbody>
</table>

<p>Then we can consider <strong>any cell that (partially) contain the obstacle</strong> to be out of bounds.</p>

<blockquote>
  <p>For search-based algorithms in this section, we first discretize them into grid, then convert the grids into <mark>graphs</mark>, and finally <mark>do planning on the graph</mark>.</p>
</blockquote>

<p>So we will almost always be working on the graph below (for this section)</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240209132602181.png" alt="image-20240209132602181" style="zoom:50%;" /></p>

<p>note that here we have a couple of “hyperparameters” to consider:</p>

<ul>
  <li>resolution of the grid (i.e., how many cells per unit)</li>
  <li>grid connectivity
    <ul>
      <li>use 4-point connectivity: robot only goes up, down, left, right</li>
      <li>use 8-point connectivity: The above, plus 4 diagonals</li>
    </ul>
  </li>
</ul>

<p>if we use high resolution + high connectivity, it could make the graph denser = more runtime to plan.</p>

<h2 id="search-trees">Search Trees</h2>

<p>Search algorithms in this section then typically follow the template:</p>

<ol>
  <li>traverses from the initial state and <strong>iteratively visit un-explored nodes</strong></li>
  <li><strong>mark visited nodes as explored</strong></li>
  <li>(different in different algorithms) consider <strong>which node to visit next</strong></li>
</ol>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240209132956470.png" alt="image-20240209132956470" style="zoom: 33%;" /></p>

<blockquote>
  <p>For all algorithms in this section, <mark>assume we know the entire region of interest</mark>. So then planning is done entirely offline without any interaction with the environment.</p>
</blockquote>

<p>Therefore, <strong>most search-based algorithms look like</strong>:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240209133455062.png" alt="image-20240209133455062" style="zoom:50%;" /></p>

<p>where:</p>

<ul>
  <li>$U(x)$ means all the transitions you can have at node $x$, i.e., edge to children nodes​</li>
  <li>$f(x,u)$​​ gives you the next state/node</li>
  <li>the $\text{resolve duplicate }x’$ means we might <em>update some statistics</em> about the graph or $x’$.</li>
  <li>difference between different search algorithms would come in $x \gets \text{Q.GetFirst()}$ and $\text{resolve duplicate }x’$​</li>
</ul>

<h3 id="dfs-and-bfs">DFS and BFS</h3>

<p>Both are very similar, with the mainly differ in $x \gets \text{Q.GetFirst()}$:</p>

<p><strong>Depth first search</strong>: expand the deepest state we have in $Q$ so far.</p>

<ul>
  <li><mark>not guaranteed</mark> to find a solution if state space is infinite</li>
  <li><mark>not guaranteed</mark> to find shallowest or cheapest solution</li>
  <li>but its space complexity is usually lower than other algorithms</li>
</ul>

<p><strong>Breadth first search</strong>: expand the shallowest state we have in $Q$​ so far (i.e., check each level of the tree before the next)</p>

<ul>
  <li><mark>guaranteed</mark> to return a shallowest solution, though it is <mark>not necessarily the lowest cost</mark> since each edge can have <strong>different costs</strong></li>
  <li>typically much more memory-intensive than DFS</li>
</ul>

<h3 id="dijkstras-algorithm">Dijkstra’s Algorithm</h3>

<p>We can generalize BFS with edge costs. This is basically Dijkstra’s algorithm.</p>

<blockquote>
  <p><strong>Dijkstra</strong>: nodes in $Q$​ are ordered by increasing values of cumulative cost from start node, i.e., check lowest cost node first! Essentially</p>

  <ul>
    <li>Priority function in 𝑄 is the <strong>cumulative</strong> cost of a state from initial</li>
    <li>Expanding the frontier = visit a new node and adding transition cost to parent cost</li>
  </ul>

  <p>Guaranteed to be optimal if there exists a finite cost path to reach $G$.</p>
</blockquote>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240209134553943.png" alt="image-20240209134553943" style="zoom: 50%;" /></p>

<p>But note that:</p>

<ul>
  <li>To guarantee cost optimality, we must keep track of <strong>path costs</strong></li>
  <li>It <em>may</em> not terminate (you can adversarially construct a graph to make this happen), but <strong>if cost is finite it will terminate</strong>.</li>
</ul>

<h3 id="navigation-functions">Navigation Functions</h3>

<p>If your edges are bi-directional and cost is the same for either direction, you can <strong>use Dijkstra to obtain “value functions”</strong> that looks like this:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Optimal Value Function</th>
      <th style="text-align: center">Optimal Policy</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240209190725.png" style="zoom:100%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240209140603002.png" alt="image-20240209140603002" style="zoom: 33%;" /></td>
    </tr>
  </tbody>
</table>

<p>How? Simply:</p>
<ol>
  <li>run Dijkstra starting from goal ($u_T$), terminate until all states visited</li>
  <li>now we have <strong>lowest costs from every state to a goal</strong>!</li>
</ol>

<p>This optimal value function is also called a <strong>navigation function $\phi$</strong> in robotics:</p>

\[\phi: \mathcal{Q} \to \R\]

<p>then given the <em>*optimal value function $V^</em>(s)$<em>*, we can easily extract the optimal policy $\pi^</em>$ for each node/state.</p>

<h3 id="wavefront-algorithm">Wavefront Algorithm</h3>

<p>If all edges have a cost of 1, we can modify BFS to obtain the same optimal value function by imaging waves:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240209191339.png" style="zoom:100%;" /></p>

<p>where we basically consider all elements expanded and labeled identically in each iteration.</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240209191426.png" style="zoom:100%;" /></p>

<p>If we want, we could also modify this to work with non-uniform costs, but then it would be more like Dijkstra’s algorithm.</p>

<h2 id="heuristics-functions">Heuristics Functions</h2>

<p>Since robotics has a lot to do with real-world scenarios, we often have heuristics: what is <em>very likely</em> a bad next state to explore. Specifically, we will see that <strong>(good) heuristics function can speed up algorithms significantly</strong>.</p>

<blockquote>
  <p><strong>Heuristic function $h(x)$</strong>: <mark>Estimated</mark> cost of cheapest path from $x$ to a goal state. An example would be euclidean distance.</p>
</blockquote>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240209141047483.png" alt="image-20240209141047483" style="zoom:50%;" /></p>

<blockquote>
  <p>A heuristic $h$ is <strong>admissable</strong> if $h(x) \le h^<em>(x)$ where $h^</em>(x)$ is the true cost from $x$ to goal.</p>

  <ul>
    <li>An example would again be using euclidean distance above</li>
    <li>very useful property = can <mark>guarantee A* search to return optimal solutions</mark></li>
  </ul>
</blockquote>

<p>Interestingly, if you consider grid navigation with all transitions have cost $1$:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240209141453011.png" alt="image-20240209141453011" style="zoom:67%;" /></p>

<ul>
  <li>if we have 4 point connectivitiy in this graph, then using both $L^1$ distance of $L^2$ distance are <strong>admissible</strong> heursitics</li>
  <li>if we have 8 point connectivity, then we need a $1/\sqrt{2}$ factor for $L^2$​ distance to be admissible.</li>
</ul>

<h3 id="a-search">A* Search</h3>

<blockquote>
  <p><em>*$A^{</em>}$ search<em>*: modify Dijkstra to evaluate each node based *on both cumulative cost and heuristic value</em>, so that Dijkstra’s cost function is now:</p>

\[f(n) = \mathrm{cost}(n)+ h(n)\]

  <p>such that nodes in the frontier $Q$ is sorted based on the modified cost $f$.</p>

  <p>But why does it matter? This is often more efficient than Dijkstra, as <mark>heuristic can “steer” the search to investigate more promising areas of the search space</mark>.</p>
</blockquote>

<p>For example:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240209142019186.png" alt="image-20240209142019186" style="zoom:50%;" /></p>

<p>where you see that the heuristics are <strong>pushing us away from trying non-promising area early</strong>.</p>

<h3 id="weighted-a-search">Weighted A* Search</h3>

<p>With robotics and real-time planning, <strong>time efficiency is often more important</strong> than optimality.</p>

<blockquote>
  <p><strong>Weighted $A^{*}$ Search</strong>: put a weight on the heuristics cost:</p>

\[f (n) = \mathrm{cost}(n) + \alpha h(n)\]

  <p>where this gives us:</p>

  <ul>
    <li>greedy best-first if $\alpha \to \infty$​</li>
    <li>if $\alpha = 1$ we get A* search, and if $\alpha = 0$ we get Dijkstra algorithm</li>
  </ul>
</blockquote>

<p>You can tune this $\alpha$ to <strong>expand less nodes to pop the goal out of the stack</strong> = faster.</p>

<p>However, the final solution <mark>may not be optimal</mark>: If optimal solution has cost $C^<em>$, weighted A</em> solution may cost up to $\alpha C^*$.</p>

<h1 id="dynamic-replanning">Dynamic Replanning</h1>

<p>What if our  <strong>C-space changes over time</strong>?</p>

<ul>
  <li>Costs or transitions may change after making a plan</li>
  <li>Robot may discover new information while executing a plan</li>
</ul>

<p>Note that the algorithms introduced before in <a href="#Search-Based-Planning">Search-Based Planning</a> do offline planning. Obviously you could just re-run the whole thing, but ths is <strong>very inefficient</strong> (e.g., changes are small). <mark>Can we reuse prior computations</mark> to make this more efficient?</p>

<h2 id="a-with-label-correction">A* with Label Correction</h2>

<p>One approach is to modify A* to keep track of previous results, and only recompute/expand some nodes when there are some <strong>inconsistencies</strong> between what I had before and what I have now.</p>

<blockquote>
  <p><strong>$A^{*}$ with label correction:</strong> for each node $n$, we store:</p>
  <ul>
    <li>the actual lowest cost $g(n)=\mathrm{cost}(n)$ to traverse from start to node $n$</li>
    <li><strong>another value $v(n)$</strong> to represent the <strong>previous value of $g(n)$</strong> = value of $g(n)$ when $n$​ was most recently expanded (use $\infty$ if no history)</li>
  </ul>

  <p>Then its basically the same as A* search, but we will <strong>only look into a node if $v(n) \neq g(n)$</strong>.</p>
</blockquote>

<p>This means that:</p>
<ul>
  <li>if you are running A* with label correction for the first time, everything is inconsistent, so it is equivalent to A* search</li>
  <li>if something changed and you run A* with label correction again, you will <strong>only recompute the nodes that are inconsistent (and the nodes affected by it)</strong>.</li>
</ul>

<p>This is achieved by the invariant:</p>

<blockquote>
  <p>At any given time, <mark>our frontier $Q$ only contains inconsistent nodes</mark> to explore/expand next.</p>
</blockquote>

<p>And the algorithms looks like:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240209194704.png" style="zoom:70%;" /></p>

<p>And once done, we <mark>store the computed $g,v$ values</mark> so that next time we can directly re-use them.</p>

<p>Note that the complicated “$g(n’)$ = min cost parent …” is to deal with the case that a node $n’$ might have multiple parent = to compute the actual shortest path to $n’$ we pick the cheapest parent.</p>

<hr />

<p>Let’s consider an example. Suppose we are in a fresh run and we have jsut expanded $S_2, S_1$. Since $S_2, S_1$ are just expanded, they are <strong>consistent</strong>, but not the other ones:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240209144519293.png" alt="image-20240209144519293" style="zoom:50%;" /></p>

<p>We then check $S_4$ and do:</p>
<ol>
  <li>mark it as consistent by setting $v(S_4) = g(S_4)$</li>
  <li>for each of $S_4$’s next state $n’$ = only $[S_3]$ in this case
    <ul>
      <li>set $\mathrm{cost}(n’) =$ cheapest parent cost + transition cost</li>
      <li>hence we set $g(S_3) = 2+3=5$</li>
      <li>check consistency $g(S_3) \overset{?}{=} v(S_3)$, and insert into open list if inconsistent</li>
    </ul>
  </li>
  <li>sort the open list $Q$ by $f(n) = \min{ g(n),v(n) } + h(n)$</li>
</ol>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240209144702227.png" alt="image-20240209144702227" style="zoom:50%;" /></p>

<p>Next, we repeat with the goal state being the first on the priority queue:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240209145135613.png" alt="image-20240209145135613" style="zoom:50%;" /></p>

<p>Then we are done because $f(\text{Q.peek()}) &gt; f(S_{\mathrm{goal}})$. But <mark>before we quit</mark>:</p>
<ul>
  <li>return the path found</li>
  <li>but also <mark>store all the statistics $g,v$ in memory</mark></li>
</ul>

<blockquote>
  <p>So when changes in the environment happens, we still re-compute from $S_{\mathrm{start}}$ but we only need to <strong>recompute nodes when we find inconsistencies</strong>.</p>
</blockquote>

<h2 id="lifelong-planning-a">Lifelong Planning A*</h2>

<p>To make the A* with label correction fully correct, it turns out we need to be <strong>slightly more careful</strong>. When there are changes in the environment, and we are inspecting node $n$, we may find:</p>

<ul>
  <li>the actual cost $g(n)$ is lower than the previous value $v(n)$ = <strong>overconsistent</strong></li>
  <li>or the actual cost $g(n)$ is higher than the previous value $v(n)$ = <strong>underconsistent</strong></li>
</ul>

<p>To be still optimal, we need to:</p>

<ul>
  <li>if we are overconsistent, we can repeat the same thing as A* with label correction by setting $v(n) = g(n)$ and <strong>recompute all children nodes</strong></li>
  <li>if we are underconsistent, we need to <mark>recompute $v(n)$ *and* all children nodes</mark></li>
  <li>and lastly, we need to consider a new end condition: we also <mark>require $v(goal) = g(goal)$ to terminate</mark></li>
</ul>

<p>Algorithm</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240209203936.png" style="zoom:70%;" /></p>

<p>and</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240209203830.png" style="zoom:70%;" /></p>

<hr />

<p>As an example, lets start off from our last example</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240209145135613.png" alt="image-20240209145135613" style="zoom:50%;" /></p>

<p>and suppose we changed an edge cost after our previous (stored) computation. If we run LSA* from $S_{\mathrm{start}}$, we will find our first inconsistency at $S_1$:</p>
<ol>
  <li>$v(S_1)=3$ was our previously computed cost</li>
  <li>recomputing $g(n)$ the actual cost, we get $g(S_1)=5$</li>
  <li>since the actual cost is higher, we are underconsistent and we need to recompute $v(S_1)$ and all children nodes</li>
  <li>set $v(S_1)=\infty$ and placed back to the queue</li>
  <li>(<code class="language-plaintext highlighter-rouge">updateNode</code>) check its children nodes, in this case $S_{\mathrm{goal}}$. It is again underconsistent, so $g \gets \infty$</li>
</ol>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Step 1 to 2</th>
      <th style="text-align: center">Step 3-5</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240209150352822.png" alt="image-20240209150352822" style="zoom:50%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240209150749077.png" alt="image-20240209150749077" style="zoom:50%;" /></td>
    </tr>
  </tbody>
</table>

<p>Now we expand $S_{\mathrm{goal}}$ and check if it is inconsistent. It is since $g$ was modified and became underconsistent, we need to <strong>compute $v(S_{\mathrm{goal}})$ and all children nodes again</strong>:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240209151123626.png" alt="image-20240209151123626" style="zoom:50%;" /></p>

<p>Next</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240209151143449.png" alt="image-20240209151143449" style="zoom:50%;" /></p>

<p>since $S_3$ is now over-consistent, we simply make it consistent and proceed</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240209151255613.png" alt="image-20240209151255613" style="zoom:50%;" /></p>

<p>Finally we have a consistent $S_{\mathrm{goal}}$ and we terminate</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240209151334533.png" alt="image-20240209151334533" style="zoom:50%;" /></p>

<p>As you may have noticed in this example:</p>
<ul>
  <li>whenever a node has <strong>underconsistency</strong>, we propagate $g \gets \infty$ for its children in a “DFS” like manner</li>
  <li>LPA* guarantees expanded nodes have non-decreasing $f$​ values over time to achieve optimality</li>
  <li>under-consistent nodes are expanded <strong>at most twice</strong> in LPA*</li>
  <li>we are only re-computing if needed</li>
</ul>

<h2 id="d-lite">D* Lite</h2>

<p>LPA* is still offline = we <strong>compute everything</strong> in our head when given the environment.</p>

<p>What if we want to <strong>execute while we are performing computation</strong>? (e.g., this may be useful when your robot does not have access to the full environment, but only what it sees right now)</p>

<blockquote>
  <p>Dynamic A* Lite (K&amp;L 2002): Similar to LPA* but</p>

  <ul>
    <li>we <strong>change start node to current node</strong> whenever we replan</li>
    <li>we run “backwards”: instead of searching from start state, <strong>search from goal state</strong> (which doesn’t change given the above condition)</li>
  </ul>
</blockquote>

<p>This is actually used in robotic systems, where we:</p>
<ol>
  <li>parse what our robot see</li>
  <li>run D* Lite (continuously) to find some actions to do and execute</li>
  <li>repeat</li>
</ol>

<h1 id="combinatorial-motion-planning">Combinatorial Motion Planning</h1>

<p>Last section we considered path search with graph search algorithms: 1) converting the world into a grid 2) convert the grid to a graph, and 3) do graph search.</p>

<p>Here we still use graph search algorithms, but we consider approaches to <strong>directly model the C-space as a graph</strong>. How do we do this?</p>

<blockquote>
  <p>In many motion planning problems, we can plan directly in the C-space by <strong>exploiting geometric properties and representation</strong>. Often by:</p>
  <ul>
    <li>limiting to special cases (e.g., 2D space), and assuming <strong>polygonal</strong> obstacles</li>
    <li>if the above holds, solutions are <strong>exact</strong> (c.f. grid approach) and <strong>complete</strong></li>
  </ul>
</blockquote>

<p>As we will focus on 2D euclidean space, polygonal obstacle regions, here is an example:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240216132046836.png" alt="image-20240216132046836" style="zoom:50%;" /></p>

<p>where we <strong>know the set of vertices of the obstacles</strong>. So we represent the C-space with:</p>

<ul>
  <li>a set of <strong>half-edges</strong>, i.e., defined by pairs of vertices</li>
  <li>Half-edges are oriented to run <strong>counterclockwise around an obstacle</strong></li>
  <li>holes in obstacles are ordered <strong>clockwise around holes</strong></li>
  <li>the non-obstacle region is the empty space we want to plan on</li>
</ul>

<h2 id="roadmaps">Roadmaps</h2>

<p>We can efficiently represent obstacle regions, but what about the free space (not using the grid approach)? What do we even want from such a representation?</p>

<blockquote>
  <p>We essentialy want a graph $\mathcal{G}$ that satisfies the following property:</p>
  <ul>
    <li>each vertex of $\mathcal{G}$ correspond to a point in $\mathcal{Q}_{\mathrm{free}}$</li>
    <li>each edge of $\mathcal{G}$ correspond to a continous path in $\mathcal{Q}_{\mathrm{free}}$</li>
  </ul>

  <p>As long we have these properties, graph search algorithms can be used to find a path in $\mathcal{Q}_{\mathrm{free}}$</p>
</blockquote>

<p>Furthermore:</p>

<blockquote>
  <p><strong>Swath</strong>: the set of points $\mathcal{S} \subset Q_{\mathrm{free}}$  reachable by some $\mathcal{G}$ you constructed.</p>
</blockquote>

<p>which is essentially a subspace of $\mathcal{Q}_{\mathrm{free}}$ that is considered by the graph. In this formulation, your graph <em>doesn’t need to reach all points</em>, but:</p>

<blockquote>
  <p><strong>Roadmaps</strong>: a graph $\mathcal{G}$ that satisfies the above property but is also:</p>
  <ul>
    <li><strong>accessible</strong>: there exists a path from any point in $q \in \mathcal{Q}_{\mathrm{free}}$ to some $s \in \mathcal{S}$</li>
    <li><strong>connected</strong>: if there exists a path $q_{1} \to q_{2} \in Q_{\mathrm{free}}$, a path $q_1\to s_{1} \in S$, and a path $q_{2} \to s_{2} \in S$, then your roadmap should have a path $s_1 \to s_2$</li>
  </ul>
</blockquote>

<p>Although the above seem to be less powerful in that it does not cover all space in $\mathcal{Q}_{\mathrm{free}}$, but it can happen in practice, for example:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240216182053.png" style="zoom:60%;" /></p>

<p>where the red edges are the road map $\mathcal{G}$:</p>
<ul>
  <li>given any two points in the free space (except for the hole)</li>
  <li>you can go from one point on to the “red highway”, and then to the other point</li>
</ul>

<p>And depending on if you just want “some path” or “the optimal path”, you can have different roadmaps.</p>

<h2 id="cell-decomposition">Cell Decomposition</h2>

<p>But how do we build such a roadmap?</p>

<blockquote>
  <p>One way here is to decompose free space into a union of cells, where cells are <strong>convex polygons</strong> instead of grids</p>
  <ul>
    <li>why convex polygons? If we have a convex polygon of free space, getting from any point to any other point is a simple <strong>straight</strong> line</li>
    <li>then, path finding becomes: find the best sequence of polygons to go through $\to$ travel within the polygons are straight lines</li>
  </ul>
</blockquote>

<p>Note that the grid approach can be also seen as a cell decomposition:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240216132659756.png" alt="image-20240216132659756" style="zoom:33%;" /></p>

<p>except that it does <strong>not exploit any information about the environment</strong>: in practice we need to <strong>remove those “off-limit” cells</strong> as long as there is partial collision.</p>

<p>So the real limitation we are trying to resolve is that:</p>

<blockquote>
  <p>Any grid search algorithm is only <strong>resolution-complete</strong> (I can come up with a very bad resolution where grid search will fail). Here we want to return a path as long as its feasible (irrespective of resolution)</p>
</blockquote>

<h3 id="vertical-decomposition">Vertical Decomposition</h3>

<p>Assuming the obstacles are <strong>polygonal</strong>, we can obtain convex polygon cells by <strong>drawing lines from each obstacle vertex</strong>:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240216133046866.png" alt="image-20240216133046866" style="zoom:60%;" /></p>

<blockquote>
  <p>Vertical cell decomposition: partitions free space into <strong>trapezoids</strong> (2-cells) and <strong>segments/lines</strong> (1-cells)</p>

  <ul>
    <li>construct by extending a segment upward and downward from every vertex until hitting $\mathcal{Q}_{\mathrm{obs}}$​</li>
    <li>we end up with 2-dimensional cell (trapezoid) and 1-dimensional cell (the segment/line we drew)</li>
  </ul>
</blockquote>

<p>Then we can <strong>construct a roadmap</strong> by considering the</p>
<ol>
  <li>consider the centroid of each cell (both 2-cell and 1-cell) as a vertex</li>
  <li>add an edge from each 2-cell vertex to its border 1-cell vertices</li>
</ol>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240216183239.png" style="zoom:100%;" /></p>

<p>How do we use this roadmap? Consider finding a feasible path from the red cross to the red square:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240216183510.png" style="zoom:50%;" /></p>

<ol>
  <li>find one way to get onto the “highway” from the red cross</li>
  <li>then find a way to get off the “highway” to the red square</li>
</ol>

<h3 id="line-sweep-algorithm">Line Sweep Algorithm</h3>

<p>Here we describe how to obtain the vertical decomposition:</p>

<blockquote>
  <p><strong>Line Sweep Algorithm</strong> imagining sweeping an infinite vertical line from left to right, but only focusing our attention when we are <mark>at obstacle vertices</mark>:</p>

  <ol>
    <li>initialization: index all obstacle <em>edges</em> (e.g., 0,1,2,3, …)</li>
    <li>sort all obstacle vertices with increasing $x$-coordinate</li>
    <li>for each vertex: consider an infinite line and record where it hit the obstacle and record in $L$</li>
    <li>make sure $L$ is sorted by index of intersected edges (to improve efficiency)</li>
  </ol>
</blockquote>

<p>Visually:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Grpah</th>
      <th style="text-align: center">Algorithm</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240216184137.png" style="zoom:60%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240216184147.png" style="zoom:60%;" /></td>
    </tr>
  </tbody>
</table>

<p>To be more exact, an efficient implementation of the algorithm needs to <strong>return us the trapezoidal regions</strong> at the end of the sweep. As a result, we need to consider the following cases:</p>

<ol>
  <li>when at a vertex $v$​​ which has edge <strong>on both left and right of the line/segment $c$</strong> we are sweeping:
<img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240216184532.png" style="zoom:80%;" />
then the algorithm
    <ul>
      <li>has the left edge $e$ is already in $L$</li>
      <li>remove $e$ and append $e’$</li>
      <li>add $c,e’,e’’$ and the next 1-cell to the trapezoidal region list</li>
    </ul>
  </li>
  <li>has <strong>both edges on the left of the line/segment</strong>:
<img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240216211028.png" style="zoom:100%;" />
then the algorithm:
    <ul>
      <li>remove $e,e’$ from the list (using $v$’s y-coordinate to locate them quickly in $L$, which is sorted)</li>
      <li>if obstacle is left of $v$, add one new trapezoidal region bounded by both $c$ and $c’$</li>
    </ul>
  </li>
  <li>when <strong>both obstacle edges are on the right of the line/segment</strong>
<img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240216211407.png" style="zoom:100%;" />
then  the algorithm:
    <ul>
      <li>add both edges to the list</li>
      <li>if obstacle is right of $v$, add two new trapezoidal regions bounded by $c$ and $c’$</li>
    </ul>
  </li>
</ol>

<p>note that since the intersected edges is sorted, finding the edge takes only $O(\log n)$ time (e.g., binary search). Since we then sort and process each vertex once, the total time is $O(n \log n)$​.</p>

<h3 id="adjacency-graph-and-path-finding">Adjacency Graph and Path Finding</h3>

<p>In summary, to do path finding you can:</p>
<ol>
  <li>do vertical decomposition</li>
  <li>construct a roadmap ($\mathcal{G}$) using centroids of the cells</li>
  <li>connect your start and end point to the roadmap</li>
  <li>run a graph search algorithm on $\mathcal{G}$</li>
</ol>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240216135412116.png" alt="image-20240216135412116" style="zoom:30%;" /></p>

<h3 id="morse-decomposition">Morse Decomposition</h3>

<blockquote>
  <p><strong>Morse Decomposition</strong>: but it turns out you can compute <strong>step 1 even more efficiently</strong> and a in more <strong>generic way</strong>: a cell decomposition consisting of vertices that changed <strong>connectivity</strong></p>
  <ul>
    <li>consider a line segment sweeping through</li>
    <li>if it encountered a vertex and the line segment splits into “two segments” merged into one, then we have a critical vertex</li>
  </ul>
</blockquote>

<p>Visually:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240216140041469.png" alt="image-20240216140041469" style="zoom:30%;" /></p>

<p>where the red line is not there because when sweeping from the critical point on its left, that segment still remains the same segment. Until we reach the region 5, where it merged with the upper segment = thats a critical vertex.</p>

<p>The upshot is that this produces fewer cells <strong>but is still complete</strong>.</p>

<blockquote>
  <p>However, <strong>cells themselves may not be convex anymore</strong> (so we might need to another decomposition + planning within those cells)</p>
</blockquote>

<p>But this is more general: if you consider different slicing functions:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Circular</th>
      <th style="text-align: center">Radial</th>
      <th style="text-align: center">Square</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240216213306.png" style="zoom:100%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240216213314.png" style="zoom:100%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240216213321.png" style="zoom:100%;" /></td>
    </tr>
  </tbody>
</table>

<p>This is useful for <strong>coverage tasks in reality</strong>, since some robots might prefer to move in a certain way (e.g., circular).</p>

<h2 id="visibility-graphs">Visibility Graphs</h2>

<p>The previous method aim to give you some path, but what if we want to get an <strong>optimal/shortest path</strong>?</p>

<p>Consider finding optimal path using roadmaps in the following graph:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240216142513052.png" alt="image-20240216142513052" style="zoom: 43%;" /></p>

<blockquote>
  <p>The observation is that shortest path will always include segments shown above: <strong>along the obstacle or straight lines connecting vertices.</strong></p>
</blockquote>

<blockquote>
  <p>A <strong>(reduced) visibility graph</strong> $\mathcal{G}$ is a roadmap using vertices of the C-space obstacles. Specifically:</p>
  <ul>
    <li>we consider <mark>obstacle vertices that are locally convex</mark> (interior angle less than $\pi$) as <strong>nodes</strong></li>
    <li>we consider obstacle edges + collision-free bi-tangent edges between these vertices as <strong>edges</strong></li>
  </ul>
</blockquote>

<p>So this roadmap above basically consists of:</p>

<ul>
  <li>obstacle vertices</li>
  <li>obstacle edges</li>
  <li>collision-free bi-tangent edges</li>
</ul>

<blockquote>
  <p><strong>Properties of Visibility Graph</strong>:</p>
  <ul>
    <li>$\mathcal{G}$ preserves accessibility if <strong>every point in $Q$ is within sight of a node</strong> $\mathcal{G}$</li>
    <li>$\mathcal{G}$ preserves connectivity if the graph is connected</li>
    <li>graph search on this will give you the <strong>shortest path</strong></li>
  </ul>
</blockquote>

<p>Visually, the optimal path search looks like:</p>

<table>
  <thead>
    <tr>
      <th>Given a start/end, connect to all possible vertices it can see</th>
      <th>Then just do a graph search algorithm</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240216143143762.png" alt="image-20240216143143762" style="zoom: 33%;" /></td>
      <td><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240216143154038.png" alt="image-20240216143154038" style="zoom: 33%;" /></td>
    </tr>
  </tbody>
</table>

<h3 id="efficiently-constructing-visibility-graph">Efficiently Constructing Visibility Graph</h3>

<p>How do we construct such visibility graph? The difficult part of this roadmap above is adding in the bi-tangent edges.</p>

<blockquote>
  <p>The idea is to do a <strong>rotational sweep</strong> from each given vertex.</p>

  <ol>
    <li>for each $v$, sort all vertices by increasing angle relative to $v$</li>
    <li>store a list of obstacle edges that intersected by the sweep line (sorted by which edge collide first with the sweep line)</li>
    <li>by <strong>how we are updating this list</strong>, we can efficiently find the bi-tangent edges</li>
  </ol>
</blockquote>

<p>So this gives:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240216143814290.png" alt="image-20240216143814290" /></p>

<p>where in the above image, we will be checking vertices in the order of $v_3,v_7,v_4, …$.</p>

<p><strong>On a high level</strong>, this algorithm does this:</p>

<ol>
  <li>
    <p>initialize and check all the obstacle <em>edges</em> we are intersecting in $S$ (i.e., $E_4, E_2, E_8, E_6$)</p>
  </li>
  <li>
    <p>at the next vertex (e.g., $v_3$​), we will</p>

    <ol>
      <li>check what edges its connected to, i.e., $E_2, E_3$</li>
      <li>if these edges were already in the list, <strong>delete them</strong> = we seen them before, we are exiting now (i.e., $E_2$)</li>
      <li>if these edges were not in the list, <strong>add them to the list</strong> (i.e., $E_3$​​)</li>
    </ol>
  </li>
  <li>
    <p>how do we know if the current vertex we are looking at is visible? You will need to do two checks</p>

    <ol>
      <li>make sure the segment between $v$ and $v_i$ <strong>does not intersect</strong> the first edge in list $S$
        <ul>
          <li>this can actually be done in $O(1)$ time:
<img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240216214956.png" style="zoom:100%;" /></li>
          <li>if there is an intersection, then two vertices of one segment lies on the opposite sides of the other segment</li>
          <li>
            <p>this translates to if $ccw(a,b,c)$ and $ccw(a,b,d)$ have different signs:</p>

\[ccw(p,q,r)  = \begin{vmatrix} 
      p_x - r_x &amp; p_y - r_y \\
      q_x - r_x &amp; q_y - r_y
 \end{vmatrix}\]
          </li>
        </ul>
      </li>
      <li>make sure the <strong>two edges at $v$</strong> are no the same side of the sweep line</li>
    </ol>

    <p>this can thus be done in $O(1)$ time.</p>
  </li>
</ol>

<h2 id="maximizing-clearance">Maximizing Clearance</h2>

<p>Visibility graph gives you shortest path, but they are close to the obstacle so they <strong>may not be safest route</strong>.</p>

<blockquote>
  <p>A <strong>maximum-clearance</strong> roadmap tries to <strong>stay as far as possible from $\mathcal{Q}_{obs}$</strong></p>
</blockquote>

<p>Starting from a simple case: How to maximize distances from a set of points? Consider drawing <strong>perpendicular bisectors between neighboring point pairs</strong>:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240216150136775.png" alt="image-20240216150136775" style="zoom: 33%;" /></p>

<p>from there:</p>

<ul>
  <li>green arrow = bisector <em>intersections</em> are equidistance from thre points</li>
  <li>other bisectors segments are equidistant from the closest two points</li>
</ul>

<p>But how do we generalize this to obstacle <em>regions</em>?</p>

<h3 id="generalized-voronoi-diagrams">Generalized Voronoi Diagrams</h3>

<p>To construct something like this, we need to consider accessing a distance/cost function, and consider three things:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240216150526663.png" alt="image-20240216150526663" style="zoom:50%;" /></p>

<p>where we consider:</p>
<ol>
  <li><strong>Generalized Voronoi region</strong> $F_i$: the set of coordinates/points where they are <strong>closer to obstacle $i$​ than any other obstacles in the diagram</strong> (the boundary of the environment is also treated as an obstacle)</li>
  <li><strong>GVD edges</strong>: set of the above points where they are equidistant from two obstacles</li>
  <li><strong>GVD</strong>: set of the above edges</li>
</ol>

<h3 id="deformation-retracts">Deformation Retracts</h3>

<blockquote>
  <p>Here, we show that GVD are also valid <strong>roadmaps</strong> being accessible and connected. The trick is to show that $\exists$ some function that maps from any point in the free space to the GVD.</p>
</blockquote>

<p>Claim 1: Given any point in the free space, we can move to the GVD by <strong>increasing distance away from the <em>nearest</em> obstacle</strong></p>

<p>Proof:</p>
<ol>
  <li>given a distance function $d(q)$ and an initial position $q$</li>
  <li>
    <p>a path $c$ to GVD from $q$ satisfies:</p>

\[\frac{dc}{dt} = \nabla d(c(t)), \quad c(0) = q\]

    <p>where we are imaging $c(t)$ being a path parameterized by $t$ that moves from $q$ to GVD.</p>
  </li>
</ol>

<p>So we can numerically find GVD by doing gradient ascent, until being equidistance from at least one other obstacle.</p>

<blockquote>
  <p><strong>Deformation Retraction</strong>: a function such that give any position in free space at $t=0$, it needs to spit out a path that moves it to GVD at $t=1$:</p>

\[h: \mathcal{Q}_{\mathrm{free}} \times [0,1] \to \mathcal{Q}_{\mathrm{free}}\]

  <p>such that:</p>
  <ul>
    <li>$h(q,0) = q, \forall q \in \mathcal{Q}_{\mathrm{free}}$</li>
    <li>$h(q,1) \in \mathrm{GVD}$</li>
    <li>$h(q,t)$ is continuous in $t$</li>
    <li>$h(g,t) = g, \forall g\in \mathrm{GVD}$, i.e., it stays on the GVD</li>
  </ul>
</blockquote>

<p>Using the two above properties/definitions, this means GVDs is a <strong>deformation retract of $\mathcal{Q}_{\mathrm{free}}$</strong>. Visually, all free points (blue) goes to the GVD:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240216220813.png" style="zoom:20%;" /></p>

<blockquote>
  <p>Therefore, a <strong>deformation retract</strong> is a roadmap, which satisfies <strong>accessibility and connectivity</strong>. In fact, the function $h$ above directly describes how to get to the GVD from any point in the free space.</p>
</blockquote>

<h3 id="constructing-gvds">Constructing GVDs</h3>

<p>So how do you construct GVDs? This is actually a highly studied problem in computation geometry.</p>

<p>A basic implementation considers the following three cases:</p>

<ul>
  <li>being equidistance for edge-edge pairs</li>
  <li>being equidistance for edge-vertex pairs</li>
  <li>being equidistance for vertex-vertex pairs</li>
</ul>

<p>and they you need to <strong>generate an equidistant curve (yellow) for each of the above cases and stitching them together</strong>:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240216152526191.png" alt="image-20240216152526191" style="zoom:50%;" /></p>

<p>basic implementation will take $O(n^{4})$ time.</p>

<p>Some famous algorithms for constructing GVDs are:</p>

<ul>
  <li>Point approximations: Discretize obstacle boundaries into finite sets of points, then find all possible perpendicular bisectors and intersections</li>
  <li>Fortune’s algorithm: Push a sweep line through the space and trace out equidistant edges from points already seen</li>
  <li>Divide and conquer: Recursively divide points into sets of two, build separate GVDs and then merge them together</li>
</ul>

<h3 id="brushfire-algorithm">Brushfire Algorithm</h3>

<p>But under some special cases, we can actually compute GVDs more efficiently:</p>

<blockquote>
  <p>If we have a <strong>grid</strong> environment, we can actually <strong>efficiently compute GVD</strong> using the wavefront algorithm.</p>
</blockquote>

<blockquote>
  <p><strong>Brushfire Algorithm</strong>: if we are in a grid world, we can <strong>imagine the <em>cells on the obstacle’s boundary</em> expanding</strong> until wavefronts collided each other</p>

  <ol>
    <li>if a square was just now expanded but another wavefront want to expand it next, it is GVD cell (the 2-cells in the example below)</li>
    <li>if both wave fronts want to expend it, it is GVD cell (the 3-cells in the example below)</li>
  </ol>
</blockquote>

<p>So the algorithm is simply:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240216153205015.png" alt="image-20240216153205015" style="zoom:50%;" /></p>

<p>Visually, we basically get the yellow cells being the GVD:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Step 0</th>
      <th style="text-align: center">Step 1</th>
      <th style="text-align: center">Step 2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240216221231.png" style="zoom:100%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240216221241.png" style="zoom:100%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240216221249.png" style="zoom:100%;" /></td>
    </tr>
  </tbody>
</table>

<p>note that visually you may feel like some cells are not really “GVD”, but this is basically because you are approximating the space via discretized cells. In practice, we just imagine we have a “<strong>thick GVD line</strong>”.</p>

<p>In a more complicated case:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Step 1</th>
      <th style="text-align: center">Step 2</th>
      <th style="text-align: center">Step 3</th>
      <th style="text-align: center">Step 4</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240216221708.png" style="zoom:100%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240216221715.png" style="zoom:100%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240216221723.png" style="zoom:100%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240216221730.png" style="zoom:100%;" /></td>
    </tr>
  </tbody>
</table>

<h1 id="probabilistic-roadmaps">Probabilistic Roadmaps</h1>

<p>The previous section does planning in the workspace. This is often <strong>low dimensional, mostly polynomial space</strong>:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240223211908.png" style="zoom:100%;" /></p>

<p>In reality, we might need to <strong>directly plan in the configuration space of the robot</strong> (e.g. with many joints) = find a path in a high dimensional space, and the space might not even be Euclidean. In general:</p>

<ul>
  <li>
    <p>Planning in high-dimensional and/or non-Euclidean spaces is hard</p>
  </li>
  <li>
    <p>Constructing high-dimensional and/or non-Euclidean spaces is hard</p>
  </li>
</ul>

<blockquote>
  <p><strong>But the idea is appealing</strong>: Maybe we construct a <strong>roadmap</strong> in the <strong>configuration space</strong>, by sampling some conllision-free configurations and connecting them</p>

  <ul>
    <li>in high dimensional space, directly figuring out the free $C_{\mathrm{free}}$ is hard = cannot easily use methods in the previous section</li>
    <li>since we will be using sampling methods, they have weaker optimality and completeness guarantees</li>
    <li>but it turns that that they are very practical for real robotic problems (many robot joints, complicated obstacles)</li>
  </ul>
</blockquote>

<h2 id="sampling-based-methods">Sampling Based Methods</h2>

<p>While <mark>it is hard to compute obstacles' boundaries in high-dimensional space, it is easy to check if a sampled point is in collision or not</mark>. So the idea is to:</p>

<blockquote>
  <p><strong>Probabilistic roadmaps</strong> (PRM) attempt to build a roadmap in the C-space <strong>by sampling nodes coarsely and sampling edges finely</strong> in the configuration space, and add these nodes/edges to the roadmap if they are collision-free</p>
</blockquote>

<p>Since sampling methods can be stochastic, we consider propoerties such as</p>

<ul>
  <li><strong>Resolution completeness</strong>: If a solution exists, guaranteed to find it through <em>deterministic</em> (e.g., grid) sampling given some sampling resolution</li>
  <li><strong>Probabilistic completeness</strong>: Guaranteed to find solution if you have enough samples (i.e., high resolution)</li>
</ul>

<p>So how do you construct such a PRM? On a high level:</p>

<ol>
  <li><strong>Randomly generate</strong> robot <strong>configurations</strong> (e.g., from a uniform distribution) and add as nodes to the roadmap if collision-free
    <ul>
      <li>can also be generated deterministically, or with some heuristics</li>
    </ul>
  </li>
  <li>Attempt to <strong>connect nodes to nearby nodes</strong> with local paths (e.g., segments), which is controlled/generated by a <em>local planner</em>
    <ul>
      <li>the local planner is often also a sampling method, that randomly considers edges and see if it is collision free</li>
    </ul>
  </li>
  <li>to do search, add initial and goal configurations to the roadmap and connect them using the local planner</li>
  <li>perform graph search as usual = since now we have a roadmap graph</li>
</ol>

<p>So implementation wise</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240223132550316.png" alt="image-20240223132550316" style="zoom:50%;" /></p>

<p>In this algorithm</p>

<ul>
  <li>We are given or can generate a sequence of sampled vertices $\alpha$​ (<mark>note that this sequence can be infinite</mark>)</li>
  <li>We find existing <mark>vertices in the neighborhood of $\alpha(i)$</mark> and consider potential edges
    <ul>
      <li>simple version: add if collision-free, discard if not</li>
      <li>more complicated version: we may <em>also</em> want to minimize the connectivity while keeping the same number of connected components = have a sparser graph so that planning is a bit easier</li>
    </ul>
  </li>
</ul>

<blockquote>
  <p>Note that similar to the previous motion planning sections, we will <strong>not return optimal paths</strong>, but will try to <strong>return feasible path whenever the task is solvable</strong>.</p>
</blockquote>

<p>Visually, probabilistic roadmap looks like:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240223132748829.png" alt="image-20240223132748829" style="zoom:40%;" /></p>

<blockquote>
  <p>Notice that, because we could have only little samples, there can be <strong>multiple disconnected components</strong>. Therefore we may say “no path exists” if your initial and goal state are in different (disconnected) components.</p>
</blockquote>

<p>There are many possible fixes, which we will discuss later. But at this point, you may question:</p>

<ul>
  <li>How do we sample configurations?</li>
  <li>Do you really use uniform random sampling? If not, what kind of bias, if any, should we use?</li>
  <li>How do define a “neighborhood” of a vertex?</li>
  <li>How to efficiently perform collision checking given a configuration?</li>
</ul>

<h3 id="distance-metrics">Distance Metrics</h3>

<p>Since we needed to search in a neighborhood, we first need a distance metric:</p>

<blockquote>
  <p>A <strong>metric space</strong> is a set $X$ with a metric $d: X \times X \to \R$ satisfying the following:</p>

  <ul>
    <li>non-negativity: $d(a,b) \ge 0$</li>
    <li>reflexivity: $d(a,b) = 0 \iff a=b$</li>
    <li>symmetry: $d(a,b) = d(b,a)$</li>
    <li>triangle inequality: $d(x,z) \le d(x,y) + d(y,z)$</li>
  </ul>
</blockquote>

<p>some useful <strong>properties</strong> of metric space include:</p>

<ul>
  <li>a subset of a metric space $X$ is also a metric (sub)space, if you use the same metric as $X$​</li>
  <li>if you have a vector space, you can simply use norm $\vert \vert x\vert \vert$ as the metric to obtain a metric space: $d(x,y) = \vert \vert  x -y \vert \vert$</li>
  <li>
    <p>$L_p$ metrics is a valid metric if you <strong>consider euclidean spaces</strong></p>

\[d(x,x') = ||x - x'||_p = \left(\sum_{i=1}^n |x_i - x_i'|^p \right)^{1/p}\]

    <p>and a max norm.</p>

\[d(x,x') = ||x - x'||_\infty = \max_i |x_i - x_i'|\]
  </li>
</ul>

<p>But what about non-euclidiean space such as $\mathbf{S}^1$​​? For example:</p>

\[d \left(\theta_{1} = 0 , \theta_{2} = \frac{\pi}{2} \right) = ?\]

<p>one approach is to consider $\theta \in [0, 2\pi]$, using $L_2$ is probably still a valid metric. But the problem is that it would say $d(0, 2\pi) = 2\pi$, although intuitively it should be zero.</p>

<p>Therefore, one approach we often do is to:</p>
<ol>
  <li><strong>first embed this to a euclidean metric</strong></li>
  <li>then consider using $L_p$ distance</li>
</ol>

<p>For instance, a striaght-forward method is to consider the following embedding in $\R^{2}$ space:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240223220003.png" style="zoom:100%;" /></p>

<p>Then simply:</p>

\[d \left(\theta_{1} = 0 , \theta_{2} = \frac{\pi}{2} \right) = \left\| (1,0) - (0,1) \right\|_p\]

<p>would work. (however, this embedding method often distorts the actual distance between angles, which in this case is curved).</p>

<blockquote>
  <p>Finally, another useful property of metric space is that, if $(X,d_x)$ and $(Y,d_y)$ are metric spaces, then:</p>
  <ul>
    <li>consider $Z = X \times Y$</li>
    <li>coefficient $c_1, c_{2} &gt; 0$</li>
    <li>
      <p>define distance:</p>

\[d(z, z') = d((x_1,y_1), (x_2,y_2)) = c_1 d_x(x_1,x_2) + c_2 d_y(y_1,y_2)\]
    </li>
  </ul>

  <p>then $(Z, d)$ is also a metric space</p>
</blockquote>

<p>This is very useful, because our robot has each joint in $SE(2)$. This means:</p>

\[d(q, q') = c_{1} \left\| (x,y) - (x',y')  \right\| + c_{2} d_\theta(\theta, \theta')\]

<p>given some valid $c_1, c_2$​, is also a metric space. In practice, <strong>weights</strong> $c_1, c_2$ need to be carefully chosen to ensure the relative importance of translation/rotation is balanced.</p>

<h3 id="pseudometrics">Pseudometrics</h3>

<blockquote>
  <p>Sometimes (in practice) it is sufficient to define functions that <strong>behave almost like metrics</strong> but violate one (or more) of the metric properties</p>
</blockquote>

<p>For example, you can measure <strong>distance in robot’s configuration as the physical distance in their actual workspace</strong>:</p>

\[d(q_1, q_2) = d(\mathrm{FK}(q_1), \mathrm{FK}({q_2}))\]

<p>this is <em>not a metric</em>, because it violates reflexitivity: $d(q_1, q_2)=0$ could happen even for $q_1 \neq q_2$.</p>

<p>But why would maintaining some of the metric properties be useful? For example:</p>

<ul>
  <li>consider <strong>computing the neighborhood during the PRM algorithm</strong></li>
  <li>using this metric, you could end up with two <em>very different configurations $q_1,q_2$</em> that have <em>zero distance</em>. This is therefore considered “neighbors” by your metric, even though the two <em>configurations</em> is far from each other.</li>
</ul>

<h3 id="k-d-trees">$k$-D Trees</h3>

<p>Before finally diving into the neighborhood computation algorithm, we need to learn about some <strong>efficient data structures</strong> to find nearest neighbor fast. An naive approach would require $O(n^{2})$ time to figure out the nearest neighbor for each vertex.</p>

<blockquote>
  <p>Idea: construct <strong>binary tree to partition space into “halves”</strong>, and then during search we can quickly cut down the search space by halves each time</p>
</blockquote>

<p>Practically, you would need to sort the points along each dimension, and then each split means: 1) traverse tio left child if the point is left/below the current node, 2) traverse to right child if the point is right/above the current node:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Input 2D space</th>
      <th style="text-align: center">$k$-D tree</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240223141013213.png" alt="image-20240223141013213" style="zoom:50%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240223141021987.png" alt="image-20240223141021987" style="zoom:40%;" /></td>
    </tr>
  </tbody>
</table>

<p>For example, if we have a target point $x$ that sits right next to node 14, then the search process would be:</p>
<ol>
  <li>start at root node 7. According to the left image, node 7 partitions the space into left and right</li>
  <li>since $x$ is on the right side we, we go to the right child = node 8</li>
  <li>node 8 splits the space into above and below</li>
  <li>since $x$ is above, we go to the right child = node 11</li>
  <li>…</li>
  <li>finally, we reach node 14</li>
</ol>

<blockquote>
  <p>In a nutshell: $k$-D tree sorts and stores $k$-dimensional points in a binary tree, where each node corresponds to the median point along a dimension. This will take $O(kn \log n)$ time to construct.</p>
</blockquote>

<ul>
  <li>if we are dealing with $k=3$ dimensions, then this tree would split by “planes” instead of a “lines” as shown above</li>
  <li>with the PRM algorithm, $k$ would represent the dimension of your C-space</li>
</ul>

<p>But what if we consider the following case:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Input 2D space</th>
      <th style="text-align: center">$k$-D tree</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240223221609.png" style="zoom:100%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240223141021987.png" alt="image-20240223141021987" style="zoom:40%;" /></td>
    </tr>
  </tbody>
</table>

<p>Then naively our search sequence would be $7 \to 8 \to 11 \to 14$. But we can see that the nearest neighbor is actually 12!</p>

<blockquote>
  <p>If our target point $x$ is closer to a <em>boundary</em> than the current nearest neighbot, then it means there <em>could be nodes on the other side</em> of the boundary that is closer (e.g., imagine there was a node right on the boundary).</p>

  <ul>
    <li>basically, at every <strong>parent</strong> (that has both children) we need to ask this question</li>
    <li>if the answer is yes, then during backtracking we need to <strong>consider searching the other side</strong></li>
  </ul>
</blockquote>

<p>Therefore, we also need to consider <strong>unwinding recursion</strong> and move back up the parent while doing checks to be completely correct:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Step 1</th>
      <th style="text-align: center">Step 2</th>
      <th style="text-align: center">Step 3</th>
      <th style="text-align: center">Step 4</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240223222200.png" style="zoom:100%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240223222226.png" style="zoom:100%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240223222310.png" style="zoom:100%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240223222330.png" style="zoom:100%;" /></td>
    </tr>
  </tbody>
</table>

<p>where:</p>
<ol>
  <li>we start at node 7, and do a normal search to end at node 14. This is the current neighest neighbor.</li>
  <li>we backtrack to the first parent node that has a child = node 8. Since the distance to the boundary of node 8 is closer than the distance to the current NN (node 14), we search the other side of node 8 = node 12. <strong>This is closer!</strong>
<img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240223222814.png" style="zoom:60%;" /></li>
  <li>we backtrack to node 10. This time, the distance to the boundary of node 10 is not closer than the current NN (node 12). This means we don’t need to search the other side of node 10</li>
  <li>we backtrack to node 7. Similar to above, we don’t need to search the other side of node 7 since its distance to the boundary is further.</li>
  <li>return node 12</li>
</ol>

<p>In total, the average runtime for search is $O(\log n)$!</p>

<h3 id="vertex-neighborhood">Vertex Neighborhood</h3>

<p>So how can we use the $k$-D tree to obtain <em>neighborhood</em> of a vertex? We can:</p>

<ul>
  <li><strong>find nearest $k$</strong> instead of the top-1 nearest (by additionally keeping a priority queue during the search)</li>
  <li>find nearest $k$ component: first find $k$​-nearest nearest components, and then for each component find the nearest node</li>
  <li><strong>radius</strong>: take all points within a ball of a set radius centered at $x$</li>
  <li><strong>Visibility</strong>: Take all points that are visible from $x$ (analogous to the <a href="#Visibility Graphs">Visibility Graphs</a>)</li>
</ul>

<p>Here we expand on the visibility idea: <strong>can construct small roadmaps (little number of vertices) that still sufficiently cover the C-space</strong>:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Need Neighborhood graph of $q$</th>
      <th style="text-align: center">Example Output</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240223145519189.png" alt="image-20240223145519189" style="zoom:50%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240223145536821.png" alt="image-20240223145536821" style="zoom:50%;" /></td>
    </tr>
  </tbody>
</table>

<p>why is this useful: reduce connectivity again to cover large C-space with low number of nodes/edges. How does this work?</p>

<blockquote>
  <p>Idea: Given a vertex, its nerighbor vertex set is divided into <strong>guards and connectors</strong>:</p>
  <ul>
    <li>a guard veretx is not allowed to see any other vertex in the neighborhood</li>
    <li>a connector vertex must connect at least two guards</li>
  </ul>

  <p>after this definition of vertices, we can have a very space graph by:</p>
  <ul>
    <li>a new vertex is considered if it’s a guard or</li>
    <li>a new vertex is considered if it’s a connector and it connects guards in different components</li>
    <li>otherwise, discard this vertex</li>
  </ul>
</blockquote>

<p>This can clean up the neighbor set to make our edge connections/final graph a lot sparser, while still covering the C-space.</p>

<h2 id="collision-detection-with-sampling-methods">Collision Detection with Sampling Methods</h2>

<p>Now we have methods to sample and find candidate vertices for connections. How do we check if a node/edge is collision free?</p>

<p>If we are considering collision detection in workspace (with arbitrary complex obstacles):</p>

<ul>
  <li>
    <p>map the obstacles (with complicated shape) to workspace, and consider <strong>simple bounding regions</strong></p>

    <p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240223145825169.png" alt="image-20240223145825169" style="zoom:50%;" /></p>

    <p>but of course, these are over-conservative.</p>
  </li>
  <li>
    <p>then, the idea is then to consider:</p>
    <ul>
      <li>if no collision in bounding regions = no collision</li>
      <li>if there is, draw more fine-grained regions and repeat upto some iterations</li>
    </ul>

    <p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240223150006061.png" alt="image-20240223150006061" style="zoom:50%;" /></p>

    <p>some version of this is probably used in <code class="language-plaintext highlighter-rouge">pybullet</code></p>
  </li>
</ul>

<blockquote>
  <p>But the problem is we are planning in the high dimensional <strong>configuration</strong> space + the robot/obstacles are of <strong>complex</strong> shapes (e.g., highly non-convex)</p>
</blockquote>

<p>Is there a simple approach to do collision detection? Some intuitive approach include:</p>

<h3 id="local-planner-and-path-collision-detection">Local Planner and Path Collision Detection</h3>

<blockquote>
  <p>But in most C-space environments, we do <strong>NOT have a closed expression for the position of the obstacles</strong>. However, we can efficiently compute <strong>if a point is inside an obstacle</strong>.</p>
</blockquote>

<p>So how does a local planner decide if an <strong>edge</strong> would collide with obstacles?</p>

<blockquote>
  <p>Again, very <strong>simple</strong> ideas include:</p>

  <ul>
    <li>draw only straight lines and check for collisions by sampling.
      <ul>
        <li>this very faster but succeed less.</li>
        <li>to be more successful you may require denser sampling nodes.</li>
      </ul>
    </li>
    <li>Slower, better planners might consider things like “curved paths”, etc.</li>
  </ul>
</blockquote>

<p>Visually: you basically do this given that you want to (try to) connect $q$ and $q’$:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240223151016093.png" alt="image-20240223151016093" style="zoom:50%;" /></p>

<p>so obviously some design choice is:</p>

<ul>
  <li>step size: too small and each check will be slow, too large and we may miss collisions</li>
  <li>can change step size to be adaptive, etc.</li>
</ul>

<h2 id="sampling-strategies">Sampling Strategies</h2>

<p>Finally, how do we sample configurations (not too many and not too few) to construct roadmaps? Before, we kind of assumes we will be doing <strong>uniform sampling</strong>. For example, after collision detection of the nodes we could get to:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240223132748829.png" alt="image-20240223132748829" style="zoom:40%;" /></p>

<blockquote>
  <p>but the <strong>runtime and success rate of entire PRM procedure will have high variance</strong>.</p>
</blockquote>

<p>More specialized sampling methods (e.g., using some heuristics) may be better in certain adversarial environments</p>

<h3 id="dispersion-sampling">Dispersion Sampling</h3>

<p>This is actually a <em>deterministic sampling algorithm</em></p>

<blockquote>
  <p>Idea: place more samples to <strong>shrink the size of the largest uncovered area</strong></p>
</blockquote>

<p>To do this, we first need to measure “the size of uncovered area”</p>

<blockquote>
  <p>The <strong>dispersion</strong> of set of samples $P$ is:</p>

\[\delta(P) = \sup_{x \in X} \min_{p \in P} d(x,p)\]

  <p>so what is this? This basically gives me <strong>the maximum distance to its nearest neighbor</strong></p>
  <ul>
    <li>imagine computing the distance of some coordinate $x$ to its nearest neighbor</li>
    <li>then re-position your $x$ to maximize the above</li>
  </ul>
</blockquote>

<p>Visually you would need to place your $x$ to be the center of the following yellow regions:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240223151817865.png" alt="image-20240223151817865" style="zoom:33%;" /></p>

<p>In fact, by this definition, <strong>distributing samples in a uniform grid minimizes dispersion</strong>. But that requires pre-defining how many grids to use.</p>

<p>So the proposed method is really aiming to achieve this while <strong>allowing you to continuously generate more samples</strong></p>

<ul>
  <li>because each new sample is added to minimize dispersion, this is <mark>resolution complete</mark></li>
  <li>again, this can be done <mark>deterministically</mark></li>
</ul>

<p>Examples of algorithms that does this include</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Halton Sequence</th>
      <th style="text-align: center">Hammersley Sequence</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240223152225042.png" alt="image-20240223152225042" style="zoom:50%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240223152232235.png" alt="image-20240223152232235" style="zoom:50%;" /></td>
    </tr>
  </tbody>
</table>

<h3 id="connection-sampling">Connection Sampling</h3>

<p>Previous methods are all “unbiased”: they do not really care about (e.g., the obstacles in) the environment. This can be a problem if we have <strong>narrow regions that is crowded with obstacles = likely to get disconnected components</strong>.</p>

<blockquote>
  <p>Idea: increase/generate more vertex samples <strong>near vertices that have weak roadmap connectivity</strong></p>
</blockquote>

<p>So we can selectively <strong>sample near such vertices</strong> to increase the density of the roadmap and try to increase roadmap connectivity:</p>

<ul>
  <li>assign probabilities to each vertex based on heuristics like <strong>vertex degree</strong> (relative to rest of graph) or rate of failed edge connections</li>
  <li>when sampling, pick an existing vertex according to these probabilities and then sample in a neighborhood around it</li>
</ul>

<h3 id="obprm">OBPRM</h3>

<p>A prime example that modifies the sampling procedure above and have a good practical performance is OBPRM</p>

<blockquote>
  <p>Idea: when you sampled $\alpha(i)$ that has a collision, instead of discarding it, <strong>sample some nodes in random directions from $\alpha(i)$</strong>. So its <mark>biased to sample near boundary of the obstacles</mark>.</p>
</blockquote>

<p>Visually</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240223152809472.png" alt="image-20240223152809472" style="zoom:50%;" /></p>

<p>So that the roadmap at the end will look like this:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240223152920858.png" alt="image-20240223152920858" style="zoom:50%;" /></p>

<p>where for the PRM roadmap we were using the algorithm described in <a href="#Sampling-Based-Methods">Sampling Based Methods</a> and used uniform sampling.</p>

<h3 id="other-sampling-strategies">Other Sampling Strategies</h3>

<p>Some other algorithms that was useful from research:</p>

<ul>
  <li>
    <p><strong>GVD Sampling:</strong> We could could have a bias to get samples <strong>away</strong> from obstacles.</p>

    <ul>
      <li>We can approximate <a href="#Generalized-Voronoi-Diagrams">GVD</a> by sampling uniformly, but perturb them to increase their distance away from obstacles</li>
      <li>to do the above we need to map back to constructing GVD in the workspace</li>
    </ul>
  </li>
  <li>
    <p><strong>Gaussian sampler</strong>: Generate $q_1$ via uniform sampling, $q_2$ from a Gaussian distribution centered at $q_2$</p>

    <ul>
      <li>Discard both if both are free or in collision; otherwise, keep the free one</li>
    </ul>
  </li>
  <li>
    <p><strong>Bridge test sampling</strong>: Generate $q_1$ and $q_2$​ via uniform sampling, and if both in collision, consider their midpoint; keep if free</p>

    <p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240223153239740.png" alt="image-20240223153239740" style="zoom:50%;" /></p>
  </li>
</ul>

<h2 id="postprocessing-queries">Postprocessing Queries</h2>

<p>Given a query/solution that is already found, we can <strong>postprocess it</strong> to find some shortcuts so that the <strong>resultant path is further optimized</strong></p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240223153638914.png" alt="image-20240223153638914" style="zoom: 50%;" /></p>

<p>On a high level, you can</p>

<ol>
  <li>Find a node $q_0$ closest to start that can connect directly to the goal</li>
  <li>Then find a node $q_1$ closest to start that can connect directly to $q_0$</li>
  <li>… repeat until start is directly connected to the shorter path</li>
</ol>

<h1 id="single-query-planners">Single-Query Planners</h1>

<p>For PRMs, our goal was to construct a <strong>representation of the free C-space</strong> that can be used for planning. Specifically, they are <strong>usable</strong>: once constructed, you can use them for multiple queries of different start/goal pairs.</p>

<blockquote>
  <p>Here, we diiscuss <strong>single-query planners</strong> that are designed to solve a <strong>single query</strong> (start/goal pair) as efficiently as possibl, i.e., in the C-space, find me a path from $q_{\mathrm{start}}$ to $q_{\mathrm{goal}}$.</p>
</blockquote>

<p>As you will see, these algorithms will be:</p>
<ul>
  <li>again sampling based, but will have bias (towards reaching the goal state) and <strong>exploration</strong> (to avoid local minima) stages</li>
  <li>is in practice more <strong>efficient</strong> to run than PRMs</li>
</ul>

<h2 id="grid-based-roadmap">Grid-Based Roadmap</h2>

<p>The first (not-very single-query-related) idea is to use a <strong>grid-based roadmap</strong>. The implementation, however, can be done in a single-query manner.</p>

<blockquote>
  <p><strong>Simple Grid-based Roadmap</strong>: given a start $q_I$ and end $q_G$ configuration, overlay a grid (ignoring the obstacles for now). Then, you can either remove obstacles after that, or you can <strong>check on-the-fly of planning if the vertices are in collision</strong>.</p>
</blockquote>

<p>for collision-check, alike <a href="#Probabilistic-Roadmaps">PRMs</a> we will a run local planner (e.g., sample along the line and check for collision) at the neighbor vertices that you would traverse next.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Lay a grid</th>
      <th style="text-align: center">Remove Collisions</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240301131934975.png" alt="image-20240301131934975" style="zoom:50%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240301131954796.png" alt="image-20240301131954796" style="zoom:50%;" /></td>
    </tr>
  </tbody>
</table>

<p>Problem with this approach:</p>

<ul>
  <li><strong>curse of dimensionality</strong>: this doesn’t scale well when you increase dimension. To keep dispersion, increasing one dimension = square the number of samples (we will cover much more efficient single-query approaches soon)</li>
  <li>is <strong>resolution-complete</strong>: depends on resolutions to be able to find the solutions</li>
</ul>

<p>Practial stitches to the resoluion problem?</p>

<ul>
  <li>just increase resolution and do again: expensive</li>
  <li>itereatively increase resolution between search processes
    <ol>
      <li>Add new samples to the grid one (or a few) at a time</li>
      <li>check if the initial and goal state are in the same component (if so, done). This can be done efficiently using union-find.</li>
    </ol>
  </li>
</ul>

<h2 id="potential-functions">Potential Functions</h2>

<p>Besides thinking about how to construct vertices and edges efficiently in high-dimension, another concern is the <strong>cost of the search</strong> after you laid out the plan.</p>

<blockquote>
  <p>Searching for the path itself can be very expensive in high-dimensional spaces. <strong>Potential functions</strong> generalize heuristics (see <a href="#A*-Search">A* Search</a>), can be used to guide the search</p>
</blockquote>

<p>for example, yuo can imaging having:</p>
<ul>
  <li>e.g., an attractive force = distance towards the goal</li>
  <li>e.g., a repulsive force = distance away obstacles</li>
</ul>

<p>but note that in C-space we often don’t know the layout, <strong>this heuristics is often just your guess.</strong> But how will this relate to the roadmap?</p>

<blockquote>
  <p>A peak at single-query algorithms we will see: they will consider efficient sampling based approach to explore/map out the C-space, but also <strong>guided by some cost/distance function</strong> to eventually find the path connecting the start and goal state.</p>
</blockquote>

<p>From the above, you might wonder: why do we need to have exploration if I have a potential function? Suppose your guessed a potential/cost functino being the straight line distance between start and goal state:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Unforseen Boundary</th>
      <th style="text-align: center">Narrow Passages</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240301133533895.png" alt="image-20240301133533895" style="zoom:50%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240301133543226.png" alt="image-20240301133543226" style="zoom:50%;" /></td>
    </tr>
  </tbody>
</table>

<p>where:</p>

<ul>
  <li>for the first case, really <strong>“random” exploration</strong> may be required for the search algorithm</li>
  <li>for the second case, you might need to <em>also search from the goal state</em> to be lucky</li>
</ul>

<p>In general: finding a good potential function would require a lot of trial and errors.</p>

<h3 id="randomized-potential-fields">Randomized Potential Fields</h3>

<p>If we really want to use potential fields methods, there are some ways to get out of local minima. Normally, your algorithm would simply try to explore by steping in the direction to <strong>decrease potential</strong> (and eventually get stuck at a local minima).</p>

<blockquote>
  <p>One simple idea to add some exploration and get out of the local minima: execute a random walk</p>
</blockquote>

<p>implementation-wise: perturb each coordinate by some random direction, check if potential is decreased (if not, repeat this random process for a couple of iterations)</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240301222654.png" style="zoom:50%;" /></p>

<p>note that a backtracking step may also be used to limit the number of unsuccessful random walks.</p>

<h2 id="tree-based-planners">Tree-Based Planners</h2>

<p>Finally, we discuss the most practical single-query planners: tree-based planners.</p>

<blockquote>
  <p>Idea: we grow a tree by sampling (sampling vertices and connecting them), such that:</p>
  <ul>
    <li>we bias the sampling process of roadmap construction = prioritize exploring only the C-space regions that <strong>relevant to the query</strong></li>
    <li>eventually it will reach the goal state = done!</li>
  </ul>
</blockquote>

<p>On a high level, these algorithms</p>
<ul>
  <li>are very similar steps to <a href="#Dijkstra's-Algorithm">Dijkstra’s Algorithm</a> and <a href="#A*-Search">A* Search</a>, with the main difference is they know the full graph in advance, but here we sample new vertices on-the-fly</li>
  <li>each step  here consists of sampling a new vertex (expansion), running a local planner and inserting an edge if valid, and checking for a solution (goal test)</li>
</ul>

<h3 id="expansive-space-trees">Expansive-Space Trees</h3>

<blockquote>
  <p><strong>EST algorithm</strong>: initial trees $T_{init}$ and $T_{goal}$ at the start/goal and alternatively grow trees from both sides.</p>

  <ol>
    <li>initialize two trees</li>
    <li>pick an existing node $q$ according to some distribution $\pi_T$</li>
    <li>sample a new node $q_{rand}$ near $q$ (expansion)</li>
    <li>if local planner say we can connect them, add $q_{rand}$ to the tree</li>
    <li>since we have two trees, we need to interleave some merge attemtps</li>
    <li>repeat from step 2 alternatively from both trees</li>
  </ol>
</blockquote>

<p>Notice that this is <strong>much more biased than general PRM</strong>: we only sample near the current vertex and biased towards the goal/start state (by the distribution and by the merging process)</p>

<p>Visually, after selecting $q$ we basically do:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240301135228646.png" alt="image-20240301135228646" style="zoom: 33%;" /></p>

<p>in more details:</p>

<ul>
  <li>
    <p>how do we merge? simply treat one node in a tree (e.g., $T_{init}$) as the sampled $q_{rand}$ for the other tree (e.g., $T_{goal}$)</p>

    <ul>
      <li>so we interleave some merge attemptes with the tree growth</li>
      <li>eventually merge will success when the trees are close enough</li>
      <li>once succeeded, we are done</li>
    </ul>
  </li>
  <li>
    <p>what should $\pi_T$ be = used to choose <strong>which node to expand next</strong>?</p>

    <ul>
      <li>if we want to have some exploration, this should be higher in sparser regions = reflect neighborhood density</li>
      <li>so this can be done in many ways, such as:
        <ul>
          <li>inversely proportional to the number of nodes near $q$</li>
          <li>can also use other heuristics such as distance, out degree, etc.</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<blockquote>
  <p>Drawback of EST:</p>
  <ul>
    <li>we need continuously update $\pi_T$ as we expand new nodes = can be expensive.</li>
    <li>It is also very sensitive to how you defined $\pi_T$ and other parameters such as how often do you merge</li>
  </ul>
</blockquote>

<h3 id="rapidly-exploring-random-trees">Rapidly-Exploring Random Trees</h3>

<p>Much more practical to uset than EST is the RRT algorithm.</p>

<blockquote>
  <p><strong>Rapidly exploring random tree (RRT)</strong>: instead of growing the tree blindly, we can <strong>sample $q_{rand}$ anywhere</strong> in the C-space, and <strong>“connect” them to an existing tree node $q_{near}$</strong> that’s closest to $q_{rand}$.</p>

  <ul>
    <li>don’t need this sampling distribution $\pi_T$ to choose which node to expand</li>
    <li>eventually, the “connect” part will lead the trees to merge</li>
  </ul>
</blockquote>

<p>This algoritm also</p>

<ul>
  <li>guarantees a dense covering</li>
  <li>Samples may be randomly or deterministically generated</li>
  <li>can work by either grow one tree from $q_I$, or two trees from both $q_I$ and $q_G$ (bi-directional trees)</li>
</ul>

<p>A bit more details of how the algorithm work</p>

<ol>
  <li>sample a random node $q_{rand}$ (randomly or deterministically)</li>
  <li>figure out the closest tree node $q_{near}$</li>
  <li>add a new node $q_{new}$ (i.e., expansion) by taking <strong>a step size distance away</strong> from $q_{near}$ in the direction of $q_{rand}$​
    <ul>
      <li>if there is a collision, do not add and repeat from step 1</li>
      <li>if no collision from $q_{near}$ to $q_{new}$, add</li>
    </ul>
  </li>
  <li>discard $q_{rand}$, and repeat from step 1</li>
</ol>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240301140810987.png" alt="image-20240301140810987" /></p>

<h4 id="greedy-extend-rrt">Greedy Extend RRT</h4>

<p>While you can simply pick a small constant step size, another small change is to do this <strong>automatically and greedily</strong>.</p>

<blockquote>
  <p>Idea: start with one small step. If it worked, increase one step and check again. Return when we have a collision.</p>
</blockquote>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240301140958347.png" alt="image-20240301140958347" style="zoom:40%;" /></p>

<p>This can be used to <strong>reduce number of vertices</strong> = discard all intermediate nodes generated during this greedy extend.</p>

<h4 id="other-extend-variations">Other Extend Variations</h4>

<p>However having fewer nodes might not be always the best <em>in this case</em> = may make it <mark>more difficult to connect new nodes to the (sparse) tree</mark></p>

<blockquote>
  <p>Idea: If we have long edges, $q_{rand}$ may be closer to an edge than a node. Then we can still connect the node, but also add a new node to the edge.</p>
</blockquote>

<ul>
  <li>this requires more computation = need to compute distance from a point to an edge in a high-dimensional space</li>
  <li>we add one new node to the existing edge and split the edge into two</li>
</ul>

<p>So visually, you would have computed and created a new red vertex:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240301141559865.png" alt="image-20240301141559865" style="zoom:40%;" /></p>

<h4 id="adding-sampling-bias">Adding Sampling Bias</h4>

<p>Another modification that we can do to improve the algorithm is to add some <strong>sampling bias</strong>. Rather than sampling uniformly, to stick to our single-query idea, we can <strong>bias the sampling of $q_{ran}$</strong></p>

<blockquote>
  <p>Idea: with a small probability $\epsilon$, set $q_{rand}:=q_{goal}$ as if its our new sample. Otherwise, $q_{rand}$ is uniformly sampled.</p>
</blockquote>

<p>note that</p>

<ul>
  <li>if we started with a single tree,  this also <strong>ensures that we will connect $q_{goal}$ to our current ree</strong></li>
  <li>why can’t we just do $q_{rand}:=q_{goal}$​ all the time? then there is no exploration = get stuck in local minima</li>
  <li>so basically <strong>$\epsilon$​​ controls exploration</strong></li>
</ul>

<h4 id="merging-rrt-trees">Merging RRT Trees</h4>

<p>Finally, if we chose to grow two trees, how do we merge? Merging RRTs proceeds <strong>similarly</strong> to merging <a href="#Expansive-Space-Trees">ESTs</a>.</p>

<p>After growing trees for a set time, we run the merge algorithm with an upper bound on number of tries:</p>
<ol>
  <li>suppose we expanded $T_1$ randomly and added a node $q_{new}$.</li>
  <li>attempt to expand $T_2$ by adding treating $q_{new}$ as its $q_{rand}$</li>
  <li>if fails, repat from step 1 but swap the roles of $T_1$ and $T_2$</li>
  <li>if step 3 failed too many times, go back to growing trees</li>
</ol>

<p>So you basically will run this once in a while when growing your tree.</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240301144108105.png" alt="image-20240301144108105" style="zoom:38%;" /></p>

<p>Visually you will get this green path when the two tress are close enough</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240301144243278.png" alt="image-20240301144243278" style="zoom:50%;" /></p>

<h4 id="rrt-visualizations">RRT Visualizations</h4>

<p>Now we have a complete description of the algorithm, some visualizations:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">RRT Example in 2D (bi-directional trees)</th>
      <th style="text-align: center">RRT Example in C-space</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="https://lavalle.pl/rrt/point1.jpg" alt="img" style="zoom:50%;" /></td>
      <td style="text-align: center"><img src="https://lavalle.pl/rrt/chain_movie.gif" alt="img" style="zoom:100%;" /></td>
    </tr>
  </tbody>
</table>

<p>(credit: <a href="https://lavalle.pl/rrt/gallery.html">RRT Page: Photo and Animation Gallery (lavalle.pl)</a>)</p>

<h4 id="rrt-limiting-behavior">RRT Limiting Behavior</h4>

<p>In the limit of running for infinite number of iterations, it can be proven that <strong>we can cover all places in the C-space</strong>. Visually:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240301144355284.png" alt="image-20240301144355284" style="zoom:50%;" /></p>

<p>Specifically, the original paper proved that, <strong>if a path from $q_{init}$ to $q_{goal}$ exists</strong> in the free C-space:</p>

<ul>
  <li>the <strong>expected</strong> number of iteration needs to find a path can be <strong>upperbounded</strong></li>
  <li>the probability that RRT fails to find the path <strong>decreases exponentially with the number of iterations</strong></li>
  <li>therefore, RRT is <mark>probabilisitically complete</mark>: in the limit that there are infinitely many nodes, the probability that a tree rooted at $q_I$ contains $q_{G}$ approaches to 1.</li>
</ul>

<h2 id="growing-more-than-two-trees">Growing More than Two Trees</h2>

<p>We can also have <strong>(more) new trees grown</strong> in arbitrary or difficult parts of the C-space! This may be appealing for some reasons:</p>
<ul>
  <li>each tree can be computed in parallel = <strong>faster</strong> computation</li>
  <li>instead of connecting to some start/goal state, we can just connect the trees = a <strong>more general roadmap</strong></li>
</ul>

<blockquote>
  <p>Some key steps you will need to do:</p>
  <ul>
    <li>uniformly sample the C-space and <strong>grow trees</strong> with EST, RRT, or any variation of the two strategies</li>
    <li>merge neartest tree <strong>neighrbos</strong> = can define distance as distance between representative nodes (e.g., centrooid)</li>
  </ul>
</blockquote>

<h3 id="sampling-based-roadmap-of-trees">Sampling-Based Roadmap of Trees</h3>

<p>One example algorithm that does this is the Sampling-Based Roadmap of Trees (SRT). This can also be seen as an integration of both RRT and PRM, since you end up having many clusters of trees:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240301145542354.png" alt="image-20240301145542354" style="zoom:50%;" /></p>

<p>implementation-wise:</p>
<ul>
  <li>to <strong>connect to neighbor trees</strong> together
    <ul>
      <li>try one pair of nodes fro meach tree, and use a local planner to connect them</li>
      <li>if tailed, use RRT/EST merge algorithms (which can also grow the tree a bit)</li>
    </ul>
  </li>
  <li><strong>given some initial/end state</strong>, we can
    <ul>
      <li>directly connect them to the roadmap, if they are close enough to some tree</li>
      <li>if not, can also grow trees from them</li>
    </ul>
  </li>
</ul>

<blockquote>
  <p>Note: this is more like a PRM - a multiple-query graph. In practice, if your goal is to get a <a href="#Probabilistic-Roadmaps">PRM</a>, then you should use traditional PRM algorithms, and use this unless you failed.</p>
</blockquote>

<h2 id="optimality-for-rrt">Optimality for RRT</h2>

<p>The <a href="#Rapidly-Exploring-Random-Trees">RRT</a> algorithms does not have optimality, as we only aimed to find some feasible path. However, it turns out that we can modify them to <strong>achieve asymptotic optimality.</strong></p>

<blockquote>
  <p>But of course, optimality = <mark>assumes there is a distance/cost metric already given</mark>.</p>
</blockquote>

<h3 id="rapidly-exploring-random-graph">Rapidly-Exploring Random Graph</h3>

<p>One modification is to:</p>

<ul>
  <li>connetc all nearest neighbors in the tree to $q_{new}$​</li>
  <li>since this produces cycles = no longer trees but graphs</li>
  <li>but is proved <strong>asymptotically</strong> optimal = RRG will contain optimal path for sufficiently large node neighborhoods</li>
</ul>

<h3 id="rrt">RRT*</h3>

<p>As seen in many examples, RRTs can grow many good nodes, but the edges are “not optimal”.</p>

<blockquote>
  <p>RRT* Idea: we grow $q_{rand}$ nodes the same way as RRT, but carefuly <strong>consider which node $q_{rand}$ should connect to</strong>.</p>
</blockquote>

<p>More specifically:</p>
<ol>
  <li>for a $q_{new}$ we just added, first connect it with <strong>all neighbors</strong> (no longer a tree as we can have cycles)</li>
  <li><strong>prune</strong> the edges so that
    <ul>
      <li>ensure every node in the neighborhood of $q_{new}$ has its previous parent having the cheapet cost to start</li>
      <li>only keep the edge to the cheaper parent</li>
      <li>stop until you get a tree structure</li>
    </ul>
  </li>
</ol>

<p>As a result, existing nodes may change parents as tree grows outward. To compare</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240301150440308.png" alt="image-20240301150440308" style="zoom: 33%;" /></p>

<p>where:</p>

<ul>
  <li>first row RRT considers random nodes and connects them = edges are in random directions</li>
  <li>second row RRT*: nodes are also random, <strong>but edges are pruned to be optimal</strong> w.r.t. the cost function (same function used for optimality)</li>
</ul>

<h2 id="differential-constraints">Differential Constraints</h2>

<p>So far we have really only considered path or kinematic planning: just give me a path.</p>

<blockquote>
  <p>The full motion planning problem also considers <strong>how</strong> the paths are followed = practical robot systems have <strong>physical constraints</strong></p>
</blockquote>

<p>Often theses are written down as <strong>differential constraints</strong>:</p>
<ul>
  <li>constraints on velocities, directions of motion, etc.</li>
  <li>so written as differential equations, e.g., $\dot{x}=f(x,u)$ where $x$ is the state (e.g., current position), and $u$ is an action (e.g., control the velocity forward)</li>
</ul>

<blockquote>
  <p>So “solving the motion planning problem” becomes: return an <strong>action trajectory $\tilde{u}$</strong> such that the correspdoning state $\tilde{x}$ trajectory satisifes the constraints.</p>
</blockquote>

<p>Can we not directly plan in the action space and do some fixes to satisfy the constraint? Not with the algorithsm discussed so far, as they consider each state being <strong>independent</strong> of each other!</p>
<ul>
  <li>the short answer is: we can plan in the $x$-state space, but each vertex is a $u$ that satisfies the constraints. Then, given a path from start to end, we can <mark>extract the sequence of $u$ from the $x$-path</mark>.</li>
  <li>but before we discuss how this works, first let’s understand what kind of constraints we will have</li>
</ul>

<hr />

<p><strong>For example: consider a simple car</strong> that has two actions: forward velocity $u_s$ and steering angle $u_\phi$. Since cars cannot do sharp turns, we constraint the velocity to be:</p>

\[\dot{x} = u_s \cos\theta\\
\dot{y} = u_s \sin \theta\\
\dot{\theta} = \frac{u_s}{L} \tan u_\phi\]

<p>state space is $(x,y,\theta)$, and action space is $u_s, u_\phi$.</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240301152023936.png" alt="image-20240301152023936" style="zoom:33%;" /></p>

<p><strong>Another common example: differential drive</strong> is</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240301233734.png" style="zoom:100%;" /></p>

<p>which has constraint of:</p>

\[\dot{x} = \frac{r}{2}(u_l + u_r) \cos\theta \\
\dot{y} = \frac{r}{2}(u_l + u_r) \sin\theta \\
\dot{\theta} = \frac{r}{L}(u_r - u_l)\]

<hr />

<p>So how do you do planning with this constraints?</p>

<ul>
  <li>this becomes a nightmare for combinatorial approaches</li>
  <li>but turns out that <strong>sampling based approaches is more or less okay</strong> (as briefly hinted above)</li>
</ul>

<h3 id="kinodynamic-planning">Kinodynamic Planning</h3>

<blockquote>
  <p>Idea: we plan in the $x$-state space, but <strong>each pair of vertex is connected by an action $u$ that satisfies the constraints</strong>. Then, we can extract the sequence of $u$ from the $x$-path.</p>
</blockquote>

<p>So basically we consider</p>

<ol>
  <li>
    <p>Kinodynamic RRT first samples $x_{rand}$ and finds $x_{new}$ as before</p>
  </li>
  <li>
    <p>instead of directly do a strght line connect, the local planner will need to draw a path that solves the differential constraint between the two samples</p>

    <table>
      <thead>
        <tr>
          <th style="text-align: center">Before</th>
          <th style="text-align: center">Here</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240301234251.png" style="zoom:11%;" /></td>
          <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240301234304.png" style="zoom:11%;" /></td>
        </tr>
      </tbody>
    </table>

    <p>where $u$ is in the action space.</p>
  </li>
  <li>
    <p>one we found a $x$-path, we can then extract $\tilde{u}$ as a sequence of $u$-edges.</p>
  </li>
</ol>

<p>Visually, if we only want to <strong>plot the full $x$-path</strong>, you will need to integrate over $u$ for each edge to obtain figures like below:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics/image-20240301152620765.png" alt="image-20240301152620765" style="zoom: 50%;" /></p>]]></content><author><name></name></author><category term="2024@Columbia" /><summary type="html"><![CDATA[Table of Contents:]]></summary></entry><entry><title type="html">COMS4733 Computational Aspects of Robotics part2</title><link href="/lectures/2024@columbia/COMS4733_Computational_Aspects_of_Robotics_part2.html/" rel="alternate" type="text/html" title="COMS4733 Computational Aspects of Robotics part2" /><published>2024-06-02T00:00:00+00:00</published><updated>2024-06-02T00:00:00+00:00</updated><id>/lectures/2024@columbia/COMS4733_Computational_Aspects_of_Robotics_part2</id><content type="html" xml:base="/lectures/2024@columbia/COMS4733_Computational_Aspects_of_Robotics_part2.html/"><![CDATA[<p>[toc]</p>

<h1 id="probabilistic-models-and-localization">Probabilistic Models and Localization</h1>

<p>The problem is that in reality, we can have inaccuraries of</p>

<ul>
  <li>dynamic and unstructured environments</li>
  <li>noisy sensors and actuators</li>
  <li>inaccurate models</li>
</ul>

<p>etc. So the goal of this section is to <strong>bring probability (e.g., confidence) into robotic modeling and algorithms</strong></p>

<h2 id="probability-and-statistics-refreshers">Probability and Statistics Refreshers</h2>

<p>We denote a random variable as $X: \Omega \to \R$  map sample space outcome (e.g., dice number) to real values (e.g., 4). We then have</p>

<ul>
  <li>in a discrete case, we have <strong>PMF</strong> $f_X(a) = \Pr(X=a)$ is the actually probability</li>
  <li>in a continous case, we have <strong>PDF</strong>, $\Pr(a \le X \le b) = \int_b^a f_X(x)dx$​ is probability</li>
</ul>

<p>For multiple random variables, we have a random <strong>vector</strong> $\mathbf{X} = [X_1, …, X_n]$. This then have:</p>

<ul>
  <li>
    <p>a joint PMF being simply:</p>

\[f_X(x_1, ..., x_n) = \Pr(X_1 = x_1, ..., X_n = x_n)\]

    <p>which again describes an actual probability,</p>
  </li>
  <li>
    <p>a joint PDF being:</p>

\[\Pr(a_1 \le x_1 \le b_1, ..., a_n \le x_n \le b_n) = \int_{a_1}^{b_1}\dots\int_{a_n}^{b_n}f_X(x_1, ..., x_n) dx_n...dx_1\]
  </li>
  <li>
    <p>a marginal distribution then considers either:</p>

\[f_X(x) = \sum_y f_{X,Y}(x,y)\]

    <p>for a continuous case</p>

\[f_X(x) = \int f_{X,Y}(x,y)dy\]
  </li>
</ul>

<hr />

<p>Important examples: <strong>Multivariate Gaussian</strong>. A n-vector $X$</p>

\[X \sim N( \mathbf{\mu}, \Sigma), \quad \text{where } X,\mu \in \R^n, \Sigma \in \R^{n \times n}\]

<p>this is defined by</p>

\[f_X(x) = \frac{1}{\sqrt{(2\pi)^n |\Sigma|}} \exp\left( -\frac{1}{2}(\mathbf{x} - \mathbf{\mu})^T  \Sigma^{-1} (\mathbf{x} - \mathbf{\mu}) \right)\]

<p>visually for a 2D multivariate Gaussian:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240322133258919.png" alt="image-20240322133258919" style="zoom:33%;" /></p>

<p>some key properties:</p>

<ul>
  <li><strong>linear combinations of elements of $X$​ is also a Gaussian</strong>.</li>
  <li>$\sqrt{(\mathbf{x} - \mu)^T \Sigma^{-1} (\mathbf{x} - \mu)}$ is the <strong>Mahalanobis distance between $\mathbf{x}$ and mean $\mathbf{\mu}$</strong></li>
</ul>

<h3 id="conditional-distributions-and-independence">Conditional Distributions and Independence</h3>

<p>For <strong>conditional</strong> distribution</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Discrete</th>
      <th style="text-align: center">Continous</th>
      <th> </th>
      <th> </th>
      <th> </th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">$$\Pr(x</td>
      <td style="text-align: center">y) = \frac{\Pr(x,y)}{\Pr(y)}$$</td>
      <td>$$f_{X</td>
      <td>Y}(x</td>
      <td>y) = \frac{f_{X,Y}(x,y)}{f_{Y}(y)}$$</td>
    </tr>
  </tbody>
</table>

<blockquote>
  <p>For two RV to be <strong>independent</strong>, then:</p>

\[f_{X,Y}(x,y) = f_X(x)f_Y(y),\quad \forall x,y\]

  <p>which is equivalent of saying $f_{X\vert Y}(x\vert y) = f_X(x)$: knowing $y$ tells us <mark>nothing extra about what $x$ could be.</mark></p>
</blockquote>

<p>As an example, consider a bivariate uniform distribution: one everywhere inside a box:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240322134701370.png" alt="image-20240322134701370" style="zoom:33%;" /></p>

<p>where you can check that $f_{X_1, X_2}(x_1, x_2) = f_{X_1}(x_1)f_{X_2}(x_2)$ everywhere, and that knowing $y=0.3$ or $y=0.5$ tells you nothing about $f_X(x)$.</p>

<hr />

<p>In reality, independence is hard to observe. A looser version of independence is <strong>conditional independence</strong></p>

<blockquote>
  <p><strong>Conditional Independence</strong>: given <em>a RV’s value</em> $Z=z$, then:</p>

\[f_{X,Y|z}(x,y|z) = f_{X|z}(x|z)f_{Y|z}(y|z)\]

  <p>we say $X,Y$ is conditional independent given $Z=z$.</p>
</blockquote>

<p>Note that <strong>absolute independence may not infer conditional independence:</strong></p>

<ul>
  <li>$f_{X,Y\vert z}(x,y) = f_{X\vert z}(x)f_{Y\vert z}(y) \centernot\implies f_{X,Y}(x,y) = f_X(x)f_Y(y)$​ because $z$ may contain important information</li>
  <li>$f_{X,Y}(x,y) = f_X(x)f_Y(y)\centernot\implies f_{X,Y\vert z}(x,y) = f_{X\vert z}(x)f_{Y\vert z}(y)$ because knowing something about $z$ might break independence</li>
</ul>

<h3 id="expectation-and-variance">Expectation and Variance</h3>

<p>Obviously:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Discrete</th>
      <th style="text-align: center">Continous</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">$\mathbb{E}[X] = \sum_i x_i f_X[x_i]$</td>
      <td style="text-align: center">$\mathbb{E}[X] = \int x f_X(x)dx$</td>
    </tr>
  </tbody>
</table>

<p>A function $g(X)$ of a random variable is also a random variable. So then you could also consider the expectation of $g(X)$ as:</p>

\[\mathbb{E}[g(X)] = \int g(x)f_X(x)dx\]

<p>an exercise: the <strong>linearity property</strong> of expectation</p>

\[\begin{align*}
\mathbb{E}[aX + bY] 
&amp;= \iint (ax+by)f_{X,Y}(x,y) dxdy \\
&amp;= \iint ax f_{x,y}(x,y)dxdy + \iint by f_{x,y}(x,y)dxdy\\
&amp;= a\int xf_X(x)dx + b\int y f_Y(y) dy \\
&amp;= a \mathbb{E}[X] + b \mathbb{E}[Y]
\end{align*}\]

<blockquote>
  <p>Then the <strong>variance</strong> is like a “second moment” but:</p>

\[\text{Var}[X] = \mathbb{E}[ (X - \mu)^2]\]

</blockquote>

<p>is like measuring the <strong>dispersion</strong> of an RV’s value from the mean. We can then also show using linearity of expectation:</p>

\[\begin{align*}
\mathbb{E}[(X-\mu)^2]
&amp;= \mathbb{E}[X^2 - 2 \mu X + \mu^2]\\
&amp;= \mathbb{E}[X^2] - 2\mu \mathbb{E}[X] + \mu^2 \\
&amp;= \mathbb{E}[X^2] - \mu^2
\end{align*}\]

<p>some important <strong>properties of variance</strong>. (prove them as an exercise)</p>

<ul>
  <li>
    <p>$\text{Var}[X+Y] = \text{Var[X]} + \text{Var}[Y] + 2\text{Cov}[X,Y]$, i.e., there is a “cross-term”:</p>

\[\text{Cov}[X_i,X_j] \equiv \mathbb{E}[ (X_i - \bar{X}_i) (X_j - \bar{X}_j) ] = \mathbb{E}[ X_iX_j] - \bar{X}_i\bar{X}_j\]

    <p>is like how the two RV interacts with each other. So if two variables are <em>independent of each other</em>, then:</p>

\[\text{Cov}[X_i, X_j] = \mathbb{E}[X_iX_j] - \bar{X_i}\bar{X_j} = \bar{X_i}\bar{X_j}-\bar{X_i}\bar{X_j}=0\]
  </li>
  <li>
    <p>$\text{Var}[aX] = a^2\text{Var[X]}$ has the scalar squared.</p>
  </li>
</ul>

<p>Finally, what if $X$ is a vector? Then</p>

<blockquote>
  <p><strong>Covariance for a $n$-vector $\mathbf{X}$</strong> is then:</p>

\[P_X \equiv \mathbb{E}[(\mathbf{X}- \bar{\mathbf{X}})(\mathbf{X}- \bar{\mathbf{X}})^T] = \mathbb{E}[\mathbf{X}\mathbf{X}^T] - \bar{\mathbf{X}}\bar{\mathbf{X}}^T\]

  <p>visually,</p>

\[P_x = \begin{bmatrix}
\text{Var}[X_1] &amp; \text{Cov}[X_1, X_2] &amp; \dots &amp; \text{Cov}[X_1, X_n]\\
\vdots &amp; \text{Var}[X_2] &amp; \dots &amp; \vdots\\
\vdots &amp; \dots &amp; \ddots &amp; \vdots\\
\text{Cov}[X_n, X_1] &amp; \text{Cov}[X_n, X_2] &amp; \dots &amp; \text{Var}[X_n]\\
\end{bmatrix}\]

  <p>which is also <strong>symmetric, positive semi-definite matrix</strong> (i.e., $x^TP_xx \ge 0, \forall x$.)</p>
</blockquote>

<p>As an example, consider. a bivariate distribution</p>

\[f_{X_1, X_2}(x_1, x_2) = \begin{cases}
x_1 + x_2, &amp; 0 \le x_1 \le 1, 0 \le x_2 \le 1\\
0, &amp; \text{otherwise}
\end{cases}\]

<p>visually</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240322142409514.png" alt="image-20240322142409514" style="zoom: 25%;" /></p>

<p>We can then compute:</p>

<ul>
  <li>
    <p>marginal of $f_{X_1}$:</p>

\[f_{X_1}(x_1) = \begin{cases}
\int_{0}^1 x_1 + x_2 dx_2 = x_1 + \frac{1}{2}, &amp; 0 \le x_1 \le 1\\
0, &amp; \text{otherwise}
\end{cases}\]
  </li>
  <li>
    <p>conditional given $x_1=1$:</p>

\[f_{X_2 | X_1}(x_2 | X_1=1) = \begin{cases}
\frac{f_{X_1,X_2}(1,x_2)}{f_{X_1}(1)} = \frac{1+x_2}{3/2} = \frac{2}{3}(1+x_2), &amp; 0 \le x \le 1\\
\text{undefined}, &amp; \text{otherwise}
\end{cases}\]
  </li>
  <li>
    <p>expectations, which is symmetrical in this case</p>

\[\mathbb{E}[X_1] = \mathbb{E}[X_2] = \int_{0}^1\int_0^1 x_1 (x_1+x_2)dx_1dx_2 = \frac{7}{12}\]
  </li>
  <li>
    <p>variance, again symmetrical:</p>

\[\text{Var}[X_1] = \text{Var}[X_2] = \int_{0}^1\int_0^1 x_1^2 (x_1+x_2)dx_1dx_2 - \bar{X}_1^2 = \frac{11}{144}\]
  </li>
  <li>
    <p>covariance matrix: we know that the diagonal are the variances of individual element, we only need to find the covariances:</p>

\[\text{Cov}[X_1, X_2] = \int_0^1\int_0^1 x_1x_2(x_1+x_2)dx_1dx_2 - \bar{X}_1\bar{X}_2 = -\frac{1}{144}\]

    <p>its negative but its slightly harder to see why (a negative covariance means if $X_1$ goes up, $X_2$ has to go down). To see it mathematically you will need to compare $f_{X_2 \vert  X_1}(x_2 \vert  X_1=1)$ and $f_{X_2 \vert  X_1}(x_2 \vert  X_1=0)$. But the goal is to find covariance matrix:</p>

\[P = \frac{1}{144}\begin{bmatrix}
11 &amp; -1 \\
-1 &amp; 11
\end{bmatrix}\]
  </li>
</ul>

<h2 id="state-and-belief-distributions">State and Belief Distributions</h2>

<p>Since we might have uncertainty about <strong>both robot and environment</strong>, we can consider</p>

<blockquote>
  <p>A <strong>state</strong> including all aspects of the robot and the environment at a point in time.</p>
</blockquote>

<p>Since we have uncertainty in states, we consider</p>

<blockquote>
  <p>A <strong>belief (posterior) distribution</strong> over all possible state hypothesis:</p>

\[B(\mathbf{x}_{k}) = \Pr[ \mathbf{x}_{k} | \mathbf{z}_{1:k}, \mathbf{u}_{1:k}]\]

  <p>where:</p>

  <ul>
    <li>$\mathbf{x}_k$: state vector at step $k$​, models what the “actual world state” is</li>
    <li>$\mathbf{z}<em>{1:k}$, $\mathbf{u}</em>{1:k}$: set of <strong>measurement (what you saw via sensors)</strong> and <strong>control vectors (what you did)</strong> from step 1 to step $k$​</li>
  </ul>
</blockquote>

<blockquote>
  <p>For this section, you can just <mark>imagine $B(\mathbf{x}_{k})$ as a distribution that can be computed exactly by</mark>:</p>

  <ol>
    <li>
      <p>given the previous belief state $\mathbf{x}_{k-1}$​</p>
    </li>
    <li>
      <p>give some action $\mathbf{u}_k$, then you can either or do both:</p>

      <ul>
        <li>directly figure out where your next state by <em>computing</em> from a <strong>transition model</strong> (called motion model) $\Pr[\mathbf{x}<em>k\vert \mathbf{x}</em>{k-1},\mathbf{u}_k]$</li>
        <li><em>fix</em> your next state belief with a measurement from your <strong>measurement model</strong> $\Pr[\mathbf{z}_k \vert  \mathbf{x}_k , \mathbf{u}_k]$​</li>
      </ul>

      <p>the former is like blind-folded predicting where the car is at after you hit the brake, and the later is that you fix your estimate of your car’s state after opening your eyes for 1s.</p>
    </li>
  </ol>
</blockquote>

<p>In practice, we might also consider modeling the next state before making a measurement $z$:</p>

\[B'(\mathbf{x}_{k}) = \Pr[ \mathbf{x}_{k} | \mathbf{z}_{1:k-1}, \mathbf{u}_{1:k}]\]

<p>either way, problem now is <mark>how do we update belief</mark> using transition model or measurement model?</p>

<h3 id="probabilistic-models">Probabilistic Models</h3>

<p>To be exact, you would have:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">(Transition) Motion Model</th>
      <th style="text-align: center">Measurement Model</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">$\Pr[ \mathbf{x}<em>{k} \vert  \mathbf{x}</em>{1:k-1}, \mathbf{z}<em>{1:k-1}, \mathbf{u}</em>{1:k}]$</td>
      <td style="text-align: center">$\Pr[ \mathbf{z}<em>{k} \vert  \mathbf{x}</em>{1:k-1}, \mathbf{z}<em>{1:k-1}, \mathbf{u}</em>{1:k}]$</td>
    </tr>
  </tbody>
</table>

<p>But this is very computationally heavy because these sequences can be long/high-dimension. Therefore, we often consider using <strong>Markov assumption and conditional independence</strong> to instead use</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240322145458273.png" alt="image-20240322145458273" style="zoom: 50%;" /></p>

<p>where:</p>

<ul>
  <li>
    <p>the latter is much simpler, but of course has a <strong>computation and accuracy trade-off</strong>.</p>
  </li>
  <li>
    <p>and again, knowing either of the two (especially the first one) will be <strong>very useful to update your belief estimates</strong></p>
  </li>
</ul>

<h3 id="motion-models">Motion Models</h3>

<p>A motion model basically is a transition model that can be applied to update your belief distribution:</p>

<blockquote>
  <p>If we have a belief distribution over $\mathbf{x}<em>{k-1}$, the motion model $\Pr[ \mathbf{x}</em>{k} \vert  \mathbf{x}<em>{k-1}, \mathbf{u}</em>{k}]$ describes <strong>how you should then update your belief distribution</strong> given an action $\mathbf{u}_k$.</p>
</blockquote>

<p>For example, even given a simple motion, you might have a <strong>distribution</strong> of where your robot is actually at.</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240322150012147.png" alt="image-20240322150012147" style="zoom:50%;" /></p>

<h4 id="velocity-motion-model">Velocity Motion Model</h4>

<p>One way to describe how this transition works is by <strong>velocity vectors</strong>. Given <strong>velocity controls</strong>, e.g., $\mathbf{u} = (w, \vec{v})$ in the following example</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240322184944696.png" alt="image-20240322184944696" style="zoom:50%;" /></p>

<p>you can then model the transition function as:</p>

\[\begin{bmatrix}
x_k \\
y_k \\
\theta_k
\end{bmatrix} = 
\begin{bmatrix}
x_{k-1} \\
y_{k-1} \\
\theta_{k-1}
\end{bmatrix} + \underbrace{\Delta t
\begin{bmatrix}
v_k \cos \theta_{k-1} \\
v_k \sin \theta_{k-1} \\
\omega_k \\
\end{bmatrix} + \mathbf{w}_k}_{\text{your model's design}}\]

<p>where the probabilistic part comes in by how we model the <strong>error vector $\mathbf{w}_k$</strong>. If we have no prior about it:</p>

<ul>
  <li>
    <p>a multivariate Gaussian with zero mean vector, but <strong>some non-zero covariance</strong> (which you need to define)</p>
  </li>
  <li>
    <p>then how you design this covariance matrix changes what the state distribution looks like:</p>

    <p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240322150827838.png" alt="image-20240322150827838" style="zoom:33%;" /></p>
  </li>
  <li>
    <p>or if you really have no idea, <strong>this can also be estimated by some machine learning model + some data</strong></p>
  </li>
</ul>

<h4 id="odometry-motion-model">Odometry Motion Model</h4>

<p>Another common motion model is based on <strong>odometry measurment</strong>, typically when you have wheel encoder.</p>

<p>Given three “controls” $\delta_{rot1}$,  $\delta_{trans}$,  $\delta_{rot2}$ being initial rotation, translation, and final rotation:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240322185721093.png" alt="image-20240322185721093" style="zoom:33%;" /></p>

<p>You can then model transition being</p>

\[\begin{bmatrix}
x_k \\
y_k \\
\theta_k
\end{bmatrix} = 
\begin{bmatrix}
x_{k-1} \\
y_{k-1} \\
\theta_{k-1}
\end{bmatrix} + 
\begin{bmatrix}
\hat{\delta}_{trans} \cos(\theta_{k-1} + \hat{\delta}_{rot1}) \\
\hat{\delta}_{trans} \sin(\theta_{k-1} + \hat{\delta}_{rot1}) \\
\hat{\delta}_{rot1} + \hat{\delta}_{rot2}
\end{bmatrix}\]

<p>where $\hat{\delta}$ are the true rotation/translation <strong>+ some noise vector</strong>.</p>

<h2 id="measurement-models">Measurement Models</h2>

<p>Measurement models describe how sensor measurements are generated. These can <strong>also have noises</strong> due to stuff like misreadings, unexpected objects, etc. Therefore, the goal is how to represent the “real measurement” (i.e. what you really saw) probabilistically!</p>

<h3 id="maps-and-range-finders">Maps and Range Finders</h3>

<p>In this section, we have measurements are often described relative to some <strong>map</strong></p>

<blockquote>
  <p>A <strong>map</strong> is an environment where you basically <mark>know a priori</mark> where is the obstacles/the free space of the robot.</p>
</blockquote>

<p>One simple way to obtain measurement in this case is using <strong>range finders</strong></p>

<blockquote>
  <p>A <strong>range finder</strong> measure range and/or bearing to fixed landmarks (or obstacles) in the environment.</p>
</blockquote>

<p>For example, the map and beams shot out by some range finder is shown below:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240322190614043.png" alt="image-20240322190614043" style="zoom:50%;" /></p>

<p>so how would you model measurements in this case?</p>

<h3 id="landmark-measurement-model">Landmark Measurement Model</h3>

<blockquote>
  <p>Then, we can model “measurements” as the <strong>position of the obstacles given the location of the current robot</strong>. This is also called a <strong>landmark measurement model</strong>.</p>
</blockquote>

<p>note that here we ignored measurements that we could “collect from the range finder” here. In practice, you could <strong>combine</strong> the results from this measurement model with actual measurements.</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240322153237887.png" alt="image-20240322153237887" style="zoom:50%;" /></p>

<p>Then the <strong>measurement model for each landmark $j$</strong>​ at step $k$ of the robot is given by</p>

\[\mathbf{z}_{j,k} = \begin{bmatrix}
r_{j,k}\\
\phi_{j,k}
\end{bmatrix}
= \begin{bmatrix}
\sqrt{(m_{j,x} - x_k)^2 + (m_{j,x} - y_k)^2}\\
\text{atan2}(m_{j,y} - y_k, m_{j,x} - x_k) - \theta_k
\end{bmatrix}
+ \mathbf{v}_k\]

<p>so your full measurement would just be:</p>

\[\mathbf{z}_k = \{ \mathbf{z}_{1, k}, \mathbf{z}_{2, k}, ...,\mathbf{z}_{n, k} \}\]

<p>where:</p>

<ul>
  <li>
    <p>the $-\theta_k$​ appears is because the robot has its own orientation</p>
  </li>
  <li>
    <p>$\mathbf{v}_k$ will be <strong>measuring the error</strong></p>
  </li>
</ul>

<h2 id="localization">Localization</h2>

<p>Finally, to figure out measurement above, you <strong>first need to figure out where the robot is relative to the map</strong>.</p>

<blockquote>
  <p><strong>Localization</strong> is the problem of determining a mobile robot’s pose (position and orientation) or its coordinate transformation relative to a known map</p>
</blockquote>

<p>An example of a hard global localization problem: <strong>kidnapped robot problem</strong> (your robot suddenly transported to a new location). This task can be used as a measure of how good your localization algorithm is.</p>

<p>In general, an example of localization would look like:</p>

<ol>
  <li>
    <p>consider a 1-D robot, where you <strong>don’t really know where your robot</strong> is, <mark>except that its near a door</mark>.</p>
  </li>
  <li>
    <p>At the beginning, since you have no idea where you are, <strong>your initial belief state estimate would be uniform</strong>:</p>

    <p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240323171447699.png" alt="image-20240323171447699" style="zoom: 50%;" /></p>
  </li>
  <li>
    <p>But you can <strong>measure the location of the door as a function of $x$​</strong> (i.e., with a <em>measurement mode</em>l). Since you see three doors, you can then update your estimate being your robot near any of one of the three door:</p>

    <p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240323171640912.png" alt="image-20240323171640912" style="zoom:50%;" /></p>
  </li>
  <li>
    <p>Then, let’s say you moved your robot a bit. You can then <strong>update your belief again using a motion/transition model</strong>:</p>

    <p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240323171814155.png" alt="image-20240323171814155" style="zoom: 60%;" /></p>
  </li>
  <li>
    <p>After that, say you make another measurement and found that you are <em>still at a door</em>. Then you have quite some good estimate of where your robot is:</p>

    <p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240323171945857.png" alt="image-20240323171945857" style="zoom: 60%;" /></p>
  </li>
  <li>
    <p>Lastly, if you move your robot again, your belief state estimate would be more confident:</p>

    <p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240323172027860.png" alt="image-20240323172027860" style="zoom:60%;" /></p>
  </li>
</ol>

<h1 id="bayes-filters-and-grid-localization">Bayes Filters and Grid Localization</h1>

<p>Now, we can <strong>formally define how to get from</strong>:</p>

\[B(\mathbf{x}_k) = p( \mathbf{x}_k|\mathbf{z}_{1:k},\mathbf{u}_{1:k} ) \to B(\mathbf{x}_{k+1})= p( \mathbf{x}_{k+1}|\mathbf{z}_{1:k+1},\mathbf{u}_{1:k+1} )\]

<p>with a bit more detail, we will see this being:</p>
<ul>
  <li>given some movement $\mathbf{u}<em>{k+1}$, use motion model to predict the next state $B(\mathbf{x}</em>{k}) \to B’(\mathbf{x}_{k+1})$</li>
  <li>given some measurement $\mathbf{z}<em>{k+1}$, use measurement model to predict the next state $B’(\mathbf{x}</em>{k+1}) \to B(\mathbf{x}_{k+1})$</li>
</ul>

<h2 id="bayesian-inference">Bayesian Inference</h2>

<p>Recall that bayes theorem shows:</p>

\[p(x_i | x_j) = \frac{p(x_j | x_i)p(x_i)}{p(x_j)}\]

<p>the practical usage of this is basically in inferences:</p>

\[\text{posterior} = \frac{\text{likelihood} \times \text{prior}}{\text{normalization constant}}\]

<p>and that this <strong>holds with multiple terms</strong></p>

\[p(x_i | x_j, y_1, ..., y_m) = \frac{p(x_j|x_i, y_1,..,y_m)p(x_i| y_1,..,y_m)}{p(x_j|y_1,..,y_m)}\]

<p>where basically the original equation holds if we condition every term additionally on $y_1,..,y_m$.</p>

<p>So how can we use it?</p>

<h2 id="bayes-filter">Bayes Filter</h2>

<p>Consider a simplified case we we have a prior belief $B=p(\mathbf{x}<em>{k-1})$ and a transition model $p(\mathbf{x}</em>{k}\vert \mathbf{x}_{k-1})$, <mark>assuming no control</mark>:</p>

\[p(\mathbf{x}_{k}) = \int p(\mathbf{x}_{k}|\mathbf{x}_{k-1}) p(\mathbf{x}_{k-1}) d\mathbf{x}_{k-1}\]

<p>but now suppose we <strong>observed something</strong>, i.e. have a measurement model $p(\mathbf{z}<em>{k}\vert \mathbf{x}</em>{k})$</p>

\[p(\mathbf{x}_{k}|\mathbf{z}_{k}) = \frac{p(\mathbf{z}_{k}|\mathbf{x}_{k})p(\mathbf{x}_{k})}{p(\mathbf{z}_{k})} = \eta^{-1}p(\mathbf{z}_{k}|\mathbf{x}_{k})p(\mathbf{x}_{k})\]

<p>where here is where the bayes theorem come in:</p>

<ul>
  <li>$\eta$​​ can be computed <em>afterwards to normalize everything to 1.0</em></li>
  <li>$p(\mathbf{x}_{k})$​ is computed from the previous step.</li>
</ul>

<p>This means to get <mark>actually get from $B(\mathbf{x}_k) \to B(\mathbf{x}_{k+1})$</mark> we will take two steps:</p>

<ul>
  <li><strong>motion prediction</strong>: given that we took an action:
    <ol>
      <li>previous belief $B(\mathbf{x}<em>{k-1} ) = p(\mathbf{x}</em>{k-1}\vert \mathbf{z}<em>{1:k-1},\mathbf{u}</em>{1:k-1})$</li>
      <li>given an action the robot took $\mathbf{u}_k$</li>
      <li>we want to compute a motion model update for the belief states $B’(\mathbf{x}<em>{k} ) = p(\mathbf{x}</em>{k-1}\vert \mathbf{z}<em>{1:k-1},\mathbf{u}</em>{1:k})$ ​</li>
    </ol>

    <p>to be more specific, we show that:</p>

    <p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240329132838175.png" alt="image-20240329132838175" style="zoom:50%;" /></p>

    <p>where this basically says:</p>

\[B'(\mathbf{x}_{k}) = \int \underbrace{p(\mathbf{x}_{k}|\mathbf{x}_{k-1}, \mathbf{u}_{k})}_{\text{motion model}} B(\mathbf{x}_{k-1}) d\mathbf{x}_{k-1}\]
  </li>
  <li><strong>obversation update</strong>: we then make a measurement and further refine our belief state estimate:
    <ol>
      <li>given $B’(\mathbf{x}<em>{k} ) = p(\mathbf{x}</em>{k-1}\vert \mathbf{z}<em>{1:k-1},\mathbf{u}</em>{1:k})$</li>
      <li>given an observation $\mathbf{z}_k$</li>
      <li>we want to compute a measurement model update/final update for the belief states $B(\mathbf{x}<em>{k} ) = p(\mathbf{x}</em>{k}\vert \mathbf{z}<em>{1:k},\mathbf{u}</em>{1:k})$ ​</li>
    </ol>

    <p>to be more specific, we show that:</p>

    <p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240329133639556.png" alt="image-20240329133639556" style="zoom:50%;" /></p>

    <p>where in the first equality, we split $\mathbf{z}<em>{1:k} = \mathbf{z}</em>{k}, \mathbf{z}_{1:k-1}$ and this bayes theorem is apparent. This therefore says</p>

\[B(\mathbf{x}_{k}) = \eta^{-1} \underbrace{p(\mathbf{z}_{k}|\mathbf{x}_{k}, \mathbf{u}_{k})}_{\text{measurement model}} B'(\mathbf{x}_{k})\]

    <p>and depending on how your insert your assumption, you measurement model could even be:</p>

\[p(\mathbf{z}_{k}|\mathbf{x}_{k}, \mathbf{u}_{k}) \iff p(\mathbf{z}_{k}|\mathbf{x}_{k})\]
  </li>
</ul>

<p>Visually, its like we are doing an HMM update</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240329133018891.png" alt="image-20240329133018891" style="zoom:40%;" /></p>

<p>This means, in summary:</p>

<blockquote>
  <p><strong>Bayes Filter</strong>: the exact computation of $B(\mathbf{x}_{k})$ where:</p>
  <ol>
    <li>given a prior belief $B(\mathbf{x}<em>{k-1})$= $p(\mathbf{x}</em>{k-1}\vert \mathbf{z}<em>{1:k-1},\mathbf{u}</em>{1:k-1})$</li>
    <li>given a robot motion $\mathbf{u}_k$, update the belief:</li>
  </ol>

\[B'(\mathbf{x}_{k}) = \int p(\mathbf{x}_{k}|\mathbf{x}_{k-1}, \mathbf{u}_{k}) B(\mathbf{x}_{k-1}) d\mathbf{x}_{k-1}\]

  <ol>
    <li>given a measurement $\mathbf{z}_k$, update the belief:</li>
  </ol>

\[B(\mathbf{x}_{k}) = \eta^{-1} p(\mathbf{z}_{k}|\mathbf{x}_{k}, \mathbf{u}_{k}) B'(\mathbf{x}_{k})\]

  <p>where sometimes you could also see $p(\mathbf{z}<em>{k}\vert \mathbf{x}</em>{k}, \mathbf{u}<em>{k}) \iff p(\mathbf{z}</em>{k}\vert \mathbf{x}_{k})$ being interchangeable.</p>
</blockquote>

<p>For example, suppose we have a 1D robot that moves between $[0,1]$ and we have a prior belief:</p>

\[B(x_{k-1}) = 2x_{k-1}, \quad 0 \le x_{k-1} \le 1\]

<p>Visually, this means the we think the robot is</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240330123630.png" style="zoom:12%;" />
Then:</p>

<ul>
  <li>
    <p><strong>motion model update</strong>: let a motion model be given, being:</p>

\[p(x_{k} | x_{k-1}) = \frac{x_{k-1} + x_k}{x_{k-1} + 0.5},\quad 0 \le x_k \le 1\]

    <p>plugging in the equation, we get:</p>

\[B'(x_k) = \int_0^{1} \frac{x_{k-1} + x_k}{x_{k-1} + 0.5} 2x_{k-1} dx_{k-1} = x_{k} (2 - \ln 3) + 0.5 \ln 3,\quad 0 \le x_k \le 1\]

    <p>where:</p>
    <ul>
      <li>the information of how the robot moved is <strong>embedded in the motion model/transition model</strong></li>
      <li>this motion model says: given the robot moved a bit, I can estimate the chances that now I am in a position $x_k$ given I was previously at $x_{k-1}$.</li>
      <li>therefore, to visualize the motion model, it will be a 2D surface.</li>
    </ul>

    <p>but this $B’$ can be visualized as:</p>

    <p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240330123605.png" style="zoom:12%;" /></p>

    <p>which indicates the movement is probably to the left.</p>
  </li>
  <li>
    <p><strong>measurement model update</strong>: let a measurement model be given, being:</p>

\[p(z_k | x_k) = 1, \quad 0.5 \le x_k \le 1\]

    <p>plugging in the equation, we get:</p>

\[B(x_k) = \eta^{-1} p(z_k | x_k) B'(x_k) = \eta^{-1} (x_k (2 - \ln 3) + 0.5 \ln 3), \quad 0.5 \le x_k \le 1\]

    <p>where:</p>
    <ul>
      <li>again, the information of what you measured is <strong>embedded in the measurement model</strong></li>
      <li>this essentially measures the <strong>likelihood</strong> of the robot being at $x_k$ given what you just observed.</li>
    </ul>

    <p>this final $B$ can be visualized as:</p>

    <p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240330124033.png" style="zoom:12%;" /></p>
  </li>
</ul>

<p>This gives me a full updated $B(x_k)$​​ after a movement and a measurement.</p>

<h2 id="histogram-filters">Histogram Filters</h2>

<blockquote>
  <p>Idea: this integration over motion model would be computationally expensive and near intractable at high dimensional space. But we can <strong>discretize over the state space</strong> (e.g., grid state space) and do sum instead.</p>
</blockquote>

<p>so we can have:</p>

<ul>
  <li>chunk a continuous space into grid regions $x_i$</li>
  <li>every position in a grid region $x_i$ will have the same probability $p_i$ (e.g. probability of the mean coordinate $\hat{x}_i$)</li>
</ul>

<p>Visually, the red dots are the representative state $\hat{x}_i$ we use for $p_i$</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240330124350.png" style="zoom:15%;" /></p>

<p>Then we have
<img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240329135913594.png" alt="image-20240329135913594" style="zoom:50%;" /></p>

<p>where the $\vert x_{i,k}\vert$ describes the <strong>volume of that grid region $x_i$​</strong>. The transition/motion model is then:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240330124546.png" style="zoom:15%;" /></p>

<p>For example:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Continuous Transformations</th>
      <th style="text-align: center">Discrete Transformations</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240329140305980.png" alt="image-20240329140305980" style="zoom:50%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240329140327366.png" alt="image-20240329140327366" style="zoom:50%;" /></td>
    </tr>
  </tbody>
</table>

<p>More concretely, consider discretizing our example in the previous section. Let’s still have $B(x_{k-1}) = 2x_{k-1}$ into two bins:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240329140524718.png" alt="image-20240329140524718" style="zoom:50%;" /></p>

<p>so basically we have two representative points: $x_1=0.25,x_2=0.75$. Then our <strong>discretized motion model</strong> looks like</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Full Motion Model</th>
      <th style="text-align: center">Discretized (NxN matrix)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240329141017820.png" alt="image-20240329141017820" style="zoom:50%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240329140701469.png" alt="image-20240329140701469" style="zoom: 67%;" /></td>
    </tr>
  </tbody>
</table>

<p>Hence our belief update $B’(x_k)$ becomes <strong>a discrete sum</strong>:</p>

\[B'(\mathbf{x}_{k}) = \sum_{\mathbf{x}_{k-1}} p(\mathbf{x}_{k}|\mathbf{x}_{k-1}) B(\mathbf{x}_{k-1})\]

<p>So we get:</p>

\[B'(x_k) = \begin{bmatrix} 
  B'(x_k=0.25) \\
  B'(x_k=0.75) 
\end{bmatrix} = 
\begin{bmatrix} 
    0.34 (0.5) + 0.4 (1.5) \\
    0.66 (0.5) + 0.6(1.5)
\end{bmatrix} =
\begin{bmatrix} 
    0.77 \\
    1.23
\end{bmatrix}\]

<p>and finally applying the measurement model $p(z_k\vert x_k)=1$ for $0.5\le x_k\le1$:</p>

\[B(x_k) = \eta^{-1} p(z_k|x_k)B'(x_k) = \eta^{-1} \begin{bmatrix} 
    0.0 \\
    1.23 
\end{bmatrix} = 
\begin{bmatrix} 
    0.0 \\
    2.0 
\end{bmatrix}\]

<p>which zeroed out the first cell entirely.</p>

<blockquote>
  <p><strong>Histogram Filter</strong>: the approximate computation of $B(\mathbf{x}_{k})$ where after we discretized all states:</p>
  <ol>
    <li>given a discretized belief $B(\hat{\mathbf{x}}<em>{k-1})$= $p(\hat{\mathbf{x}}</em>{k-1}\vert \mathbf{z}<em>{1:k-1},\mathbf{u}</em>{1:k-1})$</li>
    <li>given a robot motion $\mathbf{u}_k$, update the belief:</li>
  </ol>

\[B'(\hat{\mathbf{x}}_{k}) = \sum_{\hat{\mathbf{x}}_{k-1}} p(\hat{\mathbf{x}}_{k}|\hat{\mathbf{x}}_{k-1}, \mathbf{u}_{k}) B(\hat{\mathbf{x}}_{k-1})\]

  <ol>
    <li>given a measurement $\mathbf{z}_k$, update the belief:</li>
  </ol>

\[B(\hat{\mathbf{x}}_{k}) = \eta^{-1} p(\mathbf{z}_{k}|\hat{\mathbf{x}}_{k}, \mathbf{u}_{k}) B'(\hat{\mathbf{x}}_{k})\]

  <p>where $p(\hat{\mathbf{x}}<em>{k}\vert \hat{\mathbf{x}}</em>{k-1}, \mathbf{u}<em>{k})$ and $p(\mathbf{z}</em>{k}\vert \hat{\mathbf{x}}<em>{k}, \mathbf{u}</em>{k})$ are the <strong>discretized motion and measurement models</strong> (i.e., they becomes a $N \times N$ matrix instead of a continuous function, if you have $N$ discretized states)</p>
</blockquote>

<h3 id="grid-localization">Grid Localization</h3>

<p>As a visual example, we can apply this discretization method to the <a href="#Localization">Localization</a> problem. The difference is that <mark>here we discretized the states</mark> but assume that the measurement/motion model given was still at full resolution (i.e., continuous).</p>

<p>Given the first measurement:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240329141940504.png" alt="image-20240329141940504" style="zoom:50%;" /></p>

<p>after taking an action (to the right) and another measurement</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240329142009602.png" alt="image-20240329142009602" style="zoom:50%;" /></p>

<h3 id="grid-resolution">Grid Resolution</h3>

<blockquote>
  <p>One problem of discretizatoin is that you lose information <strong>within a cell</strong>. So there is now a trade-off.</p>
</blockquote>

<p>A few practical solutions to mitigate this:</p>

<ul>
  <li><strong>Topological grid:</strong> Regions are defined based on features and “significant” locations in the environment</li>
  <li><strong>Metric grid</strong>: Regions are fine-grained cells of uniform size</li>
</ul>

<p>Of course, we can plot the errors as a function of grid size (higher size = coarser)</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240329142616638.png" alt="image-20240329142616638" style="zoom: 33%;" /></p>

<p>But other interesting methods include:</p>

<ul>
  <li>Increase the amount of <strong>noise that is assumed by the model</strong>. This is a bit counter-intuitive:
    <ul>
      <li>With coarse resolutions, the motion and measurement models may <strong>vary</strong> a lot within grid cells</li>
      <li>so we now model that variation by making the models <strong>less accurate</strong></li>
    </ul>
  </li>
  <li>tricks to <strong>make computation faster</strong>:
    <ul>
      <li>ensor subsampling (e.g., using a subset of measurements)</li>
      <li>delayed motion updates</li>
    </ul>
  </li>
</ul>

<h3 id="dynamic-decomposition">Dynamic Decomposition</h3>

<p>In practice, robot will not move very far within a short number of steps. So we will uslaly see zero probability (white) in most parts.</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240329142944496.png" alt="image-20240329142944496" style="zoom: 33%;" /></p>

<blockquote>
  <p>Idea: a dynamic decomposition then <strong>varies resolution</strong> in different regions</p>

  <ul>
    <li>merge regions with similar or low probabilities</li>
    <li>split regions where probability is higher for better representation</li>
  </ul>
</blockquote>

<p>Visually:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240329143115940.png" alt="image-20240329143115940" style="zoom: 33%;" /></p>

<h1 id="particle-filters-and-mc-localization">Particle Filters and MC Localization</h1>

<p>Instead of grids to do discretization, we can <strong>use random samples</strong> (I.e., particles)</p>

<h2 id="particle-filters">Particle Filters</h2>

<p>Alike using grid to represent distributions, you can just use particles to also do <strong>discretization</strong></p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240329144423516.png" alt="image-20240329144423516" style="zoom:40%;" /></p>

<p>BUt why would this be useful? Consider you have:</p>

<ul>
  <li>a prior belief $B(\mathbf{x}_0)$</li>
  <li>consider $M$ state particles (i.e., “clones” of your robot) being $(\mathbf{x}^1_0, \mathbf{x}^2_0, …, \mathbf{x}^M_0)$</li>
</ul>

<p>Then, finding $B(\mathbf{x}_1)$ means:</p>

<blockquote>
  <p><strong>Particle Filter</strong>: estimate $B(\mathbf{x}_{k+1})$ by imaging clones/hypothesis of your robot sampled from $B(\mathbf{x}_k)$, then do the motion/measurement model update <strong>to each of these particles</strong>.</p>

  <p>For each timestep $k$:</p>
  <ol>
    <li>for each particle $j$:
      <ul>
        <li><strong>motion update</strong>: sample new particle $\mathbf{x}^j_{k+1}$ from $p(\mathbf{x}_{k+1}\vert \mathbf{x}^j_k, \mathbf{u}_k)$</li>
        <li><strong>measurement update</strong>: adjust the weight of the particle $w^j_{k+1} = p(\mathbf{z}<em>{k+1}\vert \mathbf{x}^j</em>{k+1})$</li>
      </ul>
    </li>
    <li><strong>resample</strong> particles from the distribution of the weights $(w_{k+1}^{1}, w_{k+1}^{2}, …, w_{k+1}^{M})$</li>
  </ol>

\[B(\mathbf{x}_{k+1}) = \text{density of the resampled particles}\]

  <p>implementation-wise this is basically <strong>sampling particles with repetition at $\mathbf{x}^j_{k+1}$ again, but with new weights</strong></p>
</blockquote>

<h3 id="monte-carlo-localization">Monte Carlo Localization</h3>

<p>An example of usage of particle filters is do localization. Since essentially this distribution is like <strong>the evolution of each particle</strong>, this is also called <strong>Monte Carlo Localization</strong>.</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240329145308301.png" alt="image-20240329145308301" style="zoom:50%;" /></p>

<p>now, each particle has a <strong>weight defined by the measurement model</strong> (the second row).</p>

<h3 id="motion-model-sampling">Motion Model Sampling</h3>

<blockquote>
  <p>Recall that the motion model defines a <strong>probability distribution</strong> to transform from one state to another. So how do we model <strong>each particle’s next state</strong>?</p>
</blockquote>

<p>In the view that each particle is a “clone” of the robot, <strong>motion model update</strong> is like <mark>applying the motion model on that particle plus some noise</mark>. For example:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240329145602442.png" alt="image-20240329145602442" style="zoom: 50%;" /></p>

<p>but in general, if your motion model is some crazy weird distribution, you can do <strong>rejection sampling</strong> to have <strong>new samples at a likely part of this distribution</strong></p>

<blockquote>
  <p><strong>Rejection Sampling</strong> as a way to apply motion model to particles. Given a particle $\mathbf{x}_{k-1}^{j}$ and a motion $\mathbf{u}_k$:</p>

  <ol>
    <li>Sample one new particle $\mathbf{x}<em>{k}$ on the support (non-zero region) of the motion model $p(\mathbf{x}</em>{k}\vert \mathbf{x}_{k-1}^{j}, \mathbf{u}_k)$</li>
    <li>Uniformly sampling $c$ between $0$ and $\max p(\mathbf{x}<em>{k}\vert \mathbf{x}</em>{k-1}^{j}, \mathbf{u}_k)$</li>
    <li>if this particle has probability $p(\mathbf{x}<em>{k}\vert \mathbf{x}</em>{k-1}^{j}, \mathbf{u}_k) &gt; c$, then accept this particle as the new state. Otherwise, reject it and repeat the process.</li>
  </ol>

  <p>the idea is that you are <strong>sampling from the motion model</strong> but <strong>rejecting samples that are unlikely</strong>.</p>
</blockquote>

<p>Visually, suppose $f(x)$ is your motion model given your previous particle, and you sampled $x$ for the first time, and $x’$ the next:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240330131713.png" style="zoom:100%;" /></p>

<p>So you basically got $x’$ as your particle’s next state.</p>

<h3 id="measurement-model-likelihood">Measurement Model LIkelihood</h3>

<blockquote>
  <p>Recall that measurement model defines a <strong>probability distribution</strong> to get a measurement given the state. So how do we model <strong>each particle’s new probability/likelihood/weight</strong> given some measurement?</p>
</blockquote>

<p>Consider an example where measurements are from range finders:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240322153237887.png" alt="image-20240322153237887" style="zoom:50%;" /></p>

<p>where the <strong>measurement model for each landmark</strong> $l$​ at step $k$ of the robot is given by</p>

\[\mathbf{z}_{l,k} = \begin{bmatrix}
r_{l,k}\\
\phi_{l,k}
\end{bmatrix}
= \begin{bmatrix}
\sqrt{(m_{l,x} - x_k)^2 + (m_{l,x} - y_k)^2}\\
\text{atan2}(m_{l,y} - y_k, m_{l,x} - x_k) - \theta_k
\end{bmatrix}
+ \mathbf{v}_k\]

<p>Then, we can use this to specify <strong>the probability of a particle seeing the measurements</strong> as a normal distribution:</p>

\[\mathcal{N}(\mathbf{z}_k, R)\]

<p>given some specified covariance matrix $R$. Visually, say for particle $j$, it should see obstacle $l$ at $r=\hat{r}<em>l^{j}$ (computed using the $r</em>{l,k}$ equation):</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240330133105.png" style="zoom:20%;" /></p>

<p>This means you can then compute the <strong>likelihood of seeing the measurement</strong> by indexing the actual measurement $\mathbf{z}_k$ from the above probability distribution. This is <mark>used as the likelihood/weight of this particle</mark>.</p>

<h3 id="importance-sampling-and-resampling-new-particles">Importance Sampling and Resampling New Particles</h3>

<blockquote>
  <p>Recall that the final step of the particle filter is to <strong>resample new particles</strong> from the existing particles but with these weights from the measurement model. Why and how do we do this?</p>
</blockquote>

<p>First, we discuss why.</p>

<p>Recall the goal of particle filters is to <strong>approximate the true distribution</strong> $B(\mathbf{x}_k)$ with particles. But our initial particles are <strong>sampled from a distribution $B’(\mathbf{x}_k)$</strong> that is <strong>different</strong> from the true distribution. As you may have guessed, this means to <strong>mimic</strong> these particles to be sampled from the true distribution, we need to do importance sampling:</p>

<ol>
  <li>
    <p>suppose we sampled particles from $g$, but we wanted to sample from $f$:</p>

    <p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240330134248.png" style="zoom:60%;" /></p>
  </li>
  <li>
    <p>(see the RL notes for proof) you can show that for any function $h(x)$:</p>

\[\mathbb{E}_{x \sim f}[h(x)] = \mathbb{E}_{x \sim g}\left[\frac{f(x)}{g(x)}h(x)\right]\]

    <p>so that you can <strong>adjust the weights of the particles</strong> to be from the true distribution.</p>

    <p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240330134415.png" style="zoom:60%;" /></p>

    <p>and these importance weights corresponds to the <strong>weight computed from the measurement model</strong>.</p>
  </li>
  <li>
    <p>Therefore, to mimic the true distribution, we finally <strong>resample</strong> particles from the distribution of the weights $(w_{k+1}^{1}, w_{k+1}^{2}, …, w_{k+1}^{M})$ for each particle. (This means that we <mark>won't have new states, but just redistribute them with repetition</mark> to better represent the true distribution)</p>
  </li>
</ol>

<p>Implementation-wise, to resample new particles:</p>

<ul>
  <li>
    <p>the resampling weights are the $p(z_k \vert  x_k^j)$ being the likelihood of seeing $z_k$ if the robot is at this particle</p>
  </li>
  <li>
    <p>the resampling step <strong>aims to change the distribution from $B’(x_k)$ to $B(x_k)$ by</strong>:</p>

    <ul>
      <li>
        <p>changes the weight of the particles</p>

        <p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240329152105788.png" alt="image-20240329152105788" style="zoom:50%;" /></p>
      </li>
      <li>
        <p>resample (with repetition) from the distribution above</p>
      </li>
    </ul>
  </li>
</ul>

<h3 id="example-particle-filter-updates">Example: Particle Filter Updates</h3>

<p>Consider a uniform unitialization of particle filters:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240329152237912.png" alt="image-20240329152237912" style="zoom:50%;" /></p>

<p>Given some oberservation, many of these particles (hypothesis) disappear:</p>

<table>
  <thead>
    <tr>
      <th>Less lucky</th>
      <th>If you are lucky</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240329152337479.png" alt="image-20240329152337479" style="zoom:50%;" /></td>
      <td><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240329152318904.png" alt="image-20240329152318904" style="zoom:50%;" /></td>
    </tr>
  </tbody>
</table>

<p>More visually (see <a href="https://amrl.cs.utexas.edu/interactive-particle-filters/">Interactive Robotics Algorithms (utexas.edu)</a> for more examples)</p>

<ul>
  <li>without measurement and only uses motion model = over time error accumulates and particles spread out</li>
</ul>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Step 0</th>
      <th style="text-align: center">Step 100</th>
      <th style="text-align: center">Step 200</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240330134929.png" style="zoom:100%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240330134939.png" style="zoom:100%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240330134949.png" style="zoom:100%;" /></td>
    </tr>
  </tbody>
</table>

<ul>
  <li>with measurement weights = density will be more certain as the robot moves around</li>
</ul>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Step 0</th>
      <th style="text-align: center">Step 100</th>
      <th style="text-align: center">Step 200</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240330134959.png" style="zoom:100%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240330135007.png" style="zoom:100%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240330135014.png" style="zoom:100%;" /></td>
    </tr>
  </tbody>
</table>

<h2 id="sampling-variance">Sampling Variance</h2>

<p>Pros for particle filters</p>

<ul>
  <li>Easy to implement, accuracy increase with number of particles</li>
  <li>Nonparametric: can easily represent complex distributions</li>
</ul>

<p>Cons:</p>

<ul>
  <li>need enough particles: too few samples gives strong biases</li>
  <li>you may have a <strong>high sampling variance</strong> (estimated distribution may be very difference across runs)</li>
</ul>

<h3 id="reducing-variance">Reducing Variance</h3>

<p>You can deal with bias by adding particles, but what about variance?</p>

<ul>
  <li>
    <p><strong>reduce the frequency of resampling</strong> (more deterministic)</p>

    <ul>
      <li>For example, we should not resample if we know that state is static</li>
      <li>or determine when to resample can be based on variance of likelihood weights
        <ul>
          <li>When weight variance is low and weights have similar values, not needed</li>
          <li>When weight variance is high and weights have very different values, resampling can shift particles away from low weight regions</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>Low-Variance Sampling</strong>: Common random number or correlated sampling are sampling methods that are <mark>near deterministic</mark>.</p>

    <ul>
      <li>
        <p>e.g.,: sample the first particle with $\text{rand}(0, M^{-1})$, and the rest $M-1$ samples <strong>deterministically</strong> at intervals of $M^{-1}$</p>
      </li>
      <li>
        <p>visually, the particle picked is actually <strong>still obeying the probability distribution</strong> (small bins have no arrows!)</p>

        <p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240329153432345.png" alt="image-20240329153432345" style="zoom:50%;" /></p>
      </li>
    </ul>
  </li>
</ul>

<h3 id="particle-deprivation">Particle Deprivation</h3>

<p>Since your particles are eventually converging (not sampling at new locations), this may be problematic. In fact, <strong>because re-sampling is a random process</strong>. Suppose you have a robot where it didn’t move and <strong>all measurements are identical</strong>. Then you would see:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Initial</th>
      <th style="text-align: center">Over time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240329153718304.png" alt="image-20240329153718304" style="zoom:50%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240329153725341.png" alt="image-20240329153725341" style="zoom:60%;" /></td>
    </tr>
  </tbody>
</table>

<p>so due to randomness:</p>

<ul>
  <li>resampling will eventually cause all particles to converge toward one of the states. But this is wrong—we should still have a uniform belief!</li>
  <li>in fact, it will <strong>also happen to the kidnapped robot problem</strong>. (particle filter is unable to correct itself when the robot’s state has changed drastically, see next section for an example)</li>
</ul>

<h3 id="distribution-mismatch">Distribution Mismatch</h3>

<p>Your samples might not <strong>really match the real distribution</strong> if your target distribution is <strong>very different</strong>. For example, the actual distribution may look like the dark line</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240329154222419.png" alt="image-20240329154222419" style="zoom: 33%;" /></p>

<p>then no matter how you do importance sampling adjustment, there is no hope. To address this issue we can consider <strong>Random Particle Injection</strong>.</p>

<blockquote>
  <p><strong>Random Particle Injection</strong>: to address distribution mismatch, we can <strong>randomly inject new particles</strong> at each iteration.</p>

  <p>At each iteration of the particle filter:</p>

  <ol>
    <li>additionally compute two <strong>moving averages</strong> of the particles: one with a short window $w_s$ and one with a long window $w_l$</li>
    <li>modify the resampling prodcedure to:
      <ul>
        <li>only with probability $\min(1, \frac{w_s}{w_l})$ resample the particles</li>
        <li>otherwise replace the particle with a completely random one</li>
      </ul>
    </li>
  </ol>
</blockquote>

<p>The intuition is that when $w_{s} \ll w_l$, it means that the particles are <strong>converging</strong> and we should <strong>inject new randomness</strong> (alike exploration v.s. exploitation in RL).</p>

<h1 id="kalman-filters">Kalman Filters</h1>

<p>State estimation of continuous distributions and in continuous spaces is generally non-trivial.</p>

<p>Previous section introduced non-parametric methods to estimate $B(\mathbf{x})$ as a distribution. In this section, we show that if you go for <strong>parametric methods</strong> (e.g. assume its Gaussian or mixture of Gaussian), then in practice the computation for state estimation becomes much easier (<strong>only need to consider how the parameters of your distribution change</strong>).</p>

<h2 id="gaussian-filters">Gaussian Filters</h2>

<p>Since we only need the mean and variance for Gaussian, this can be very parameter-efficient.</p>

\[\text{provide mean and covariance matrix}: \mathbf{x}_k, P_k\]

<p>then you get an entire distribution:</p>

\[B(\mathbf{x}_k) \gets \mathcal{N}(\mathbf{x}_k, P_k) = \frac{1}{(2\pi)^{n/2} \text{det}(P_k)^{1/2}} \exp\left(-\frac{1}{2}(\mathbf{x}_k - \hat{\mathbf{x}}_k)^T P_k^{-1} (\mathbf{x}_k - \hat{\mathbf{x}}_k)\right)\]

<p>in the case of a single Gaussian, its not so suitable for problems that have multiple hypotheses (e.g., you have two strong prior guesses of where the robot is). However, we will later show that it can be easily extended to <strong>mixture of Gaussian</strong>.</p>

<h3 id="discrete-time-linear-systems">Discrete-Time Linear Systems</h3>

<p>We then <mark>further assume</mark> that state transformations are <mark>linear transformations</mark>:</p>

\[\begin{cases}
  \mathbf{x}_k = F_k \mathbf{x}_{k-1} + G_k \mathbf{u}_k + \mathbf{w}_k, &amp; \text{motion model}\\
  \mathbf{z}_k = H_k \mathbf{x}_k + \mathbf{v}_k, &amp; \text{measurement model}
\end{cases}\]

<p>where you have:</p>
<ul>
  <li>$\mathbf{x} \in \mathbb{R}^n$ is the state, $\mathbf{u} \in \mathbb{R}^m$ is the control input, and $\mathbf{z} \in \mathbb{R}^p$ is the measurement</li>
  <li>$F_k$ can be interpreted as a state transition matrix, $G_k$ is the control-input matrix, $H_k$ is the measurement matrix</li>
  <li>$\mathbf{w}_k$ and $\mathbf{v}_k$ are the process and measurement <strong>noise</strong>, respectively</li>
</ul>

<p>But why would we be considering linear systems?</p>

<blockquote>
  <p>In this section, we will (first) focus on linear systems + Gaussian distributions. This is because <strong>affine transformations of Gaussian distributions are also Gaussian</strong>.</p>
</blockquote>

<p>This means that if your prior belief is Gaussian, then the update after applying the motion model and measurement model will also be Gaussian.</p>

<blockquote>
  <p>At this point you might already be suspicious: Gaussian + affine transformations. Is it practical? The quick peek is that later we will:</p>
  <ul>
    <li>for non-linear transformations, approximate with taylor expansions = linearization</li>
    <li>for non-Gaussian distributions, approximate with mixtures of Gaussian</li>
  </ul>
</blockquote>

<h2 id="kalman-filter-derivation">Kalman Filter Derivation</h2>

<blockquote>
  <p>For discrete-time linear dynamical systems with independent, additive Gaussian noise, the <mark>Kalman filter</mark> is an optimal, recursive, and closed-form estimator.</p>
  <ul>
    <li>i.e., you can update your belief distribution exactly (as they are parametric)</li>
    <li>i.e., the update can be summarized in closed-form equations with matrix operations</li>
  </ul>
</blockquote>

<p>On a high level, the sequence of updates we will do is the same as before:</p>

<ol>
  <li>
    <p><strong>Prediction step</strong>: given a prior, make update from motion model</p>

    <p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240405132908573.png" alt="image-20240405132908573" style="zoom:50%;" /></p>
  </li>
  <li>
    <p><strong>Update step</strong>: then given measurement model/measurements, refine the belief</p>

    <p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240405133026287.png" alt="image-20240405133026287" style="zoom:50%;" /></p>
  </li>
  <li>
    <p><strong>Repeat</strong>: then repeat the process</p>

    <p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240405132929413.png" alt="image-20240405132929413" style="zoom:50%;" /></p>
  </li>
</ol>

<p>The only difference from previous methods is that <mark>here everything is Gaussian</mark>. What does this mean? For example, if your robot moves to the right:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240405133206197.png" alt="image-20240405133206197" style="zoom:50%;" /></p>

<p>Practically you are just shifting your mean and variance:</p>
<ul>
  <li>your mean will shift to the right according to the motion model</li>
  <li>your variance <mark>variance/uncertainty</mark> will increase (i.e., particles spread out as in <a href="#Particle-Filters">Particle Filters</a>) if you haven’t seen any measurements</li>
</ul>

<h3 id="prediction-step">Prediction Step</h3>

<p>So how do we update according to the motion model? Suppose we are given a prior Gaussian with known $\hat{\mathbf{x}}<em>{k-1\vert k-1}$ and $P</em>{k-1\vert k-1}$  (e.g., computed from previous iteration):</p>

\[\mathbf{x}_{k-1} \sim \mathcal{N}( \hat{\mathbf{x}}_{k-1|k-1}, P_{k-1|k-1})\]

<p>You now want to do a motion update to figure out your new belief state:</p>

\[\mathbf{x}_{k}' \sim \mathcal{N}( \hat{\mathbf{x}}_{k|k-1}, P_{k|k-1})\]

<p>This turns out to be easy because:</p>
<ol>
  <li>
    <p>if we consider the motion model to be <strong>linear</strong>:</p>

\[\mathbf{x}_{k}' = F_{k} \mathbf{x}_{k-1} + G_{k} \mathbf{u}_{k} + \mathbf{w}_{k}, \text{ where } \mathbf{w}_{k} \sim N(0, Q_k)\]
  </li>
  <li>
    <p>then you can derive the new mean and covariance from applying this affine transformation:</p>

\[\begin{cases}
 \hat{\mathbf{x}}_{k|k-1} = F_k \hat{\mathbf{x}}_{k-1|k-1} + G_k \mathbf{u}_{k}, &amp; \text{new mean}\\
 P_{k|k-1}=F_kP_{k-1|k-1}F_k^T + Q_k, &amp; \text{new variance}
 \end{cases}\]

    <p>essentially</p>

    <ul>
      <li>the variance is now “squared”, which intutively corresponds to squring a random variable by $x \to ax$ will square its variance $\sigma^2 \to a^2\sigma^2$​.</li>
      <li>the mean is just the linear transformation of the previous mean</li>
    </ul>
  </li>
</ol>

<hr />

<p><em>Proof of the covariance update:</em> starting from the definition of covariance matrix:</p>

\[\begin{align*}
  P_{k|k-1} 
  &amp;= \mathbb{E}[(F_{k} \mathbf{x}_{k-1} + G_{k} \mathbf{u}_{k} + \mathbf{w}_{k})(F_{k} \mathbf{x}_{k-1} + G_{k} \mathbf{u}_{k} + \mathbf{w}_{k})^{T}] - \hat{\mathbf{x}}_{k|k-1} \hat{\mathbf{x}}_{k|k-1}^{T}\\
  &amp;= F_{k}( \mathbb{E}( \mathbf{x}_{k-1} \mathbf{x}_{k-1}^{T}) - \hat{\mathbf{x}}_{k-1|k-1} \hat{\mathbf{x}}_{k-1|k-1}^{T}) F_{k}^{T} + \mathbb{E}(\mathbf{w}_{k} \mathbf{w}_{k}^{T}) \\
  &amp;= F_{k} P_{k-1|k-1} F_{k}^{T} + Q_{k}
\end{align*}\]

<p>where many cross terms disappear in line 2 because $\mathbf{x}<em>{k-1}$ and noise $\mathbf{w}_k$ are independent, hence $\text{Cov}(x</em>{k-1},w_k)=0$.</p>

<hr />

<p>Visually, the mean basically moves exactly like the motion model $F_k$, and then shift the covariance:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Mean Transformation</th>
      <th style="text-align: center">Covariance Transformation</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240405134437106.png" alt="image-20240405134437106" style="zoom: 50%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240405134445744.png" alt="image-20240405134445744" style="zoom: 50%;" /></td>
    </tr>
  </tbody>
</table>

<h3 id="update-step">Update Step</h3>

<p>Now we have a measurement, and we want to further refine our belief state estimate:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Belief (Orange) and Measurement (Gray)</th>
      <th style="text-align: center">Belief after Update (Green)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240405134643724.png" alt="image-20240405134643724" style="zoom:50%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240405134716912.png" alt="image-20240405134716912" style="zoom: 50%;" /></td>
    </tr>
  </tbody>
</table>

<p>so how does it work? This is slightly more complicated.</p>

<ol>
  <li>
    <p>Recall that given a measurement model, the <strong>belief state update is given by Bayes’ Theorem</strong>:</p>

\[B(\mathbf{x}_k) = \eta^{-1} p(\mathbf{z}_k|\mathbf{x}_k) B'(\mathbf{x}_k)\]
  </li>
  <li>
    <p>We already have the prior belief after motion model:</p>

\[\mathbf{x}_{k}' \sim \mathcal{N}(\hat{\mathbf{x}}_{k|k-1}, P_{k|k-1})\]

    <p>and we assumed that transformation is linear:</p>

\[\mathbf{z}_k = H_k \mathbf{x}_k + \mathbf{v}_k, \text{ where } \mathbf{v}_k \sim \mathcal{N}(0, R_k)\]
  </li>
  <li>
    <p>Then we can first show that given:</p>

\[\mathbf{z}_k|\mathbf{x}_k' \sim \mathcal{N}(H_k \mathbf{x}_{k}', R_k) = p(\mathbf{z}_k|\mathbf{x}_k')\]

    <p>and finally, because the product of Gaussian is also Gaussian, we can show that the after applying the bayes theorem, the new belief state is also Gaussian:</p>

\[\begin{cases}
 \hat{\mathbf{x}}_{k|k} = \hat{\mathbf{x}}_{k|k-1} + K_{k} \tilde{\mathbf{y}}_k, &amp; \text{new mean}\\
 P_{k|k} = (I - K_k H_k) P_{k|k-1}, &amp; \text{new variance} 
\end{cases}\]

    <p>where the additional variables are:</p>
    <ul>
      <li>$\tilde{\mathbf{y}}<em>k = \mathbf{z}_k - H_k \hat{\mathbf{x}}</em>{k\vert k-1}$ is the <strong>error vector</strong> or the <strong>innovation</strong></li>
      <li>$K_k = P_{k\vert k-1} H_k^{T}S_k^{-1}$ is the <strong>Kalman gain</strong></li>
      <li>$S_k = H_k P_{k\vert k-1} H_k^{T} + R_k$ is the <strong>innovation covariance</strong></li>
    </ul>

    <p>and notice that the only things we need are $P_{k\vert k-1}, P_{k\vert k-1}$ which we know from the previous step, and the constants $H_k, R_k$ from the measurement model.</p>
  </li>
</ol>

<hr />

<p><em>Proof of the mean and variance update</em>: the trick is that because we know the result is a Gaussian, we just have to match the terms:</p>

\[B(\mathbf{x}_k) \propto p(\mathbf{z}_k|\mathbf{x}_k) B'(\mathbf{x}_k) = \exp(- \frac{1}{2} f(\mathbf{x}_k)) \propto \mathcal{N}(\hat{\mathbf{x}}_{k|k}, P_{k|k})\]

<p>Therefore, moving from the LHS we have:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240406151356.png" style="zoom:80%;" /></p>

<p>the RHS then is:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240406151459.png" style="zoom:80%;" /></p>

<p>Therefore the green and blue terms have to match, ending up:</p>

\[\begin{cases}
P_{k|k}^{-1} = H_k^TR_{k}^{-1}H_k + P_{k|k-1}^{-1}, &amp; \text{new variance}\\
\hat{\mathbf{x}}_{k|k} = P_{k|k} H_k^T R_k^{-1}(z_k - H_k \hat{\mathbf{x}}_{k|k-1}) + \hat{\mathbf{x}}_{k|k-1}, &amp; \text{new mean}
\end{cases}\]

<p>To simply them, we can show that:</p>
<ul>
  <li>
    <p>using the matrix inversion lemma:</p>

\[P_{k|k} = (I - K_k H_k) P_{k|k-1}\]

    <p>where $K_k = P_{k\vert k-1} H_k^{T}(H_k P_{k\vert k-1} H_k^{T} + R_k)^{-1}$ is the <strong>Kalman gain</strong>.</p>
  </li>
  <li>
    <p>and the new mean is just a scaled version of the error vector:</p>

\[\hat{\mathbf{x}}_{k|k} = \hat{\mathbf{x}}_{k|k-1} + K_{k} \tilde{\mathbf{y}}_k\]

    <p>where $\tilde{\mathbf{y}}<em>k = \mathbf{z}_k - H_k \hat{\mathbf{x}}</em>{k\vert k-1}$ is the <strong>error vector</strong>, or also called the <strong>innovation</strong>.</p>
  </li>
</ul>

<blockquote>
  <p><strong>Kalman Gain</strong>: is a matrix $K_k \in \R^{n \times p}$ governs the amount of correction applied to the belief state</p>
</blockquote>

<p>To visualize this, consider we are in the 1D case, such that $K = PH / (H^2P+R)$​. Then given that:</p>

\[P_{k|k} = (I - K_kH_k) P_{k|k-1}\]

<ul>
  <li>if $P_{k\vert k-1}$ is small, then $K$ is mostly determined by $R$ (the uncertainty from measurement). So the new uncertainty $P_{k\vert k}$ is mostly determined by your measurement.</li>
  <li>if $P_{k\vert k-1}$ is large (previous belief state has large uncertainty), then $K \approx 1/H$​. So new uncertainty is near zero, meaning you just trust the measurement model instead of the previous belief.</li>
</ul>

<p>Visually:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240405141241443.png" alt="image-20240405141241443" style="zoom:50%;" /></p>

<h3 id="summary-kalman-filter">Summary: Kalman Filter</h3>

<p>So in summary, given the previous estimate $\hat{\mathbf{x}}<em>{k-1\vert k-1}$ and $P</em>{k-1\vert k-1}$, the update steps for the mean and covariances look like:</p>

<ol>
  <li>
    <p>Apply motion model:</p>

\[\begin{cases}
 \hat{\mathbf{x}}_{k|k-1} = F_k \hat{\mathbf{x}}_{k-1|k-1} + G_k \mathbf{u}_{k}, &amp; \text{new mean}\\
 P_{k|k-1}=F_kP_{k-1|k-1}F_k^T + Q_k, &amp; \text{new variance}
 \end{cases}\]
  </li>
  <li>
    <p>Apply measurement model:</p>

\[\begin{cases}
   \hat{\mathbf{x}}_{k|k} = \hat{\mathbf{x}}_{k|k-1} + K_{k} \tilde{\mathbf{y}}_k, &amp; \text{new mean}\\
   P_{k|k} = (I - K_k H_k) P_{k|k-1}, &amp; \text{new variance}
 \end{cases}\]

    <p>where you have:</p>
    <ul>
      <li>$\tilde{\mathbf{y}}<em>k = \mathbf{z}_k - H_k \hat{\mathbf{x}}</em>{k\vert k-1}$</li>
      <li>$K_k = P_{k\vert k-1} H_k^{T}S_k^{-1}$</li>
      <li>$S_k = H_k P_{k\vert k-1} H_k^{T} + R_k$</li>
    </ul>
  </li>
</ol>

<hr />

<p><em>For example,</em> consider a 1D robot with mass $m$ moving in a straight line. Let it have state $\mathbf{x}_k = (x_k, v_k)$ for $x_k$ is the 1D coordinate of the robot. Let the control be the <em>force</em> you applied $u_k$.</p>

<p>Then the motion model is <em>physically</em> modeled by:</p>

\[\mathbf{x}_k = \begin{bmatrix} 
  x_k\\
  v_k 
\end{bmatrix} = \begin{bmatrix} 
  x_{k-1} + v_{k-1} \Delta t \\
  v_{k-1} + \frac{u_k}{m} \Delta t
\end{bmatrix} = \begin{bmatrix} 
  1 &amp; \Delta t\\
  0 &amp; 1 
\end{bmatrix} \mathbf{x}_{k-1} + \begin{bmatrix} 
  0\\
  \frac{\Delta t}{m} 
\end{bmatrix} \mathbf{u}_k + \mathbf{w}_k
\iff F_k \mathbf{x}_{k-1} + G_k \mathbf{u}_k + \mathbf{w}_k\]

<p>which is actually a <strong>linear model</strong> and $\mathbf{w}_k$ be a noise vector. Furthermore, let’s suppose we have a sensor being velocity measurement:</p>

\[\mathbf{z}_k = [0,1]\mathbf{x}_k + \mathbf{v}_k \iff H_k \mathbf{x}_k + \mathbf{v}_k\]

<p>which is also a linear model on $\mathbf{x}_k$. Then you can apply the Kalman filter to update the belief state.</p>

<ol>
  <li>
    <p>Let’s first provide some parameters:</p>

\[m = 1, \Delta t = 0.5, R_{k} = 0.5, Q_{k} = \begin{bmatrix} 
    0.2 &amp; 0.05 \\
     0.05 &amp; 0.1 
\end{bmatrix}\]

    <p>and that the initial belief state is:</p>

\[B(\mathbf{x}_0) \sim \mathcal{N}(\begin{bmatrix} 2 \\ 4 \end{bmatrix}, \begin{bmatrix} 1.0 &amp; 0 \\ 0 &amp; 2.0 \end{bmatrix})\]

    <p>meaning that we have a strong hypothesis the initial state is at $(x_0=2, v_0=4)$.</p>
  </li>
  <li>
    <p>suppose we provided a control of $u_1 = 0$. <strong>Then the prediction step would be</strong>:</p>

\[\hat{x}_{k|k-1} = F_k \hat{x}_{k-1|k-1} + G_k u_k = \begin{bmatrix} 
   4 \\
   4 
\end{bmatrix}\]

    <p>and the new variance would be:</p>

\[P_{k|k-1} = F_k P_{k-1|k-1} F_k^T + Q_k = \begin{bmatrix} 
     1.7 &amp; 1.05 \\
     1.05 &amp; 2.1
 \end{bmatrix}\]

    <p>this means that the position uncertainty has now increased (the diagonal), and position/velocity is correlated.</p>
  </li>
  <li>
    <p>Suppose we measured $z_k=0.9$ being our actual velocity. <strong>Then we update:</strong></p>

\[\tilde{y}_k = z_k - H_k \hat{x}_{k|k-1} = 0.9 - 4 = -3.1\]

    <p>and the Kalman gain would be:</p>

\[K_k = P_{k|k-1} H_k^{T}S_k^{-1} = \begin{bmatrix} 
     0.404 \\
     0.808
 \end{bmatrix}\]

    <p>this means that we will scale our update on velocity more than position. The new mean would be:</p>

\[\hat{\mathbf{x}}_{k|k} = \hat{\mathbf{x}}_{k|k-1} + K_{k} \tilde{\mathbf{y}}_k = \begin{bmatrix} 
    2.748 \\
    1.495
 \end{bmatrix}\]

    <p>and the new variance would be:</p>

\[P_{k|k} = (I - K_k H_k) P_{k|k-1} = \begin{bmatrix} 
     1.276 &amp; 0.202 \\
     0.202 &amp; 0.403
 \end{bmatrix}\]

    <p>notice that the uncertainty in position and velocity has decreased (diagonal) compared to our covariance in the prediction step.</p>
  </li>
</ol>

<p>Visually, each update is doing:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Prediction Step</th>
      <th style="text-align: center">Update Step</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240406154412.png" style="zoom:50%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240406154431.png" style="zoom:70%;" /></td>
    </tr>
  </tbody>
</table>

<h1 id="extended-kalman-filter-and-localization">Extended Kalman Filter and Localization</h1>

<p>The above were always taking about linear transformations. But in practice the relationships/transformations may be non-linear</p>

\[\mathbf{x}_k = f(\mathbf{x}_{k-1}, \mathbf{u}_{k}) + \mathbf{w}_k, \quad \mathbf{z}_k = h(\mathbf{x}_k) + \mathbf{v}_k\]

<blockquote>
  <p>Idea: <strong>approximate it with linearization</strong>. For each update step, we can compute the Taylor expansion of the function, take the linear term, and then apply the Kalman filter.</p>
</blockquote>

<h2 id="linearization">Linearization</h2>

<p>The most straightforward method is to consider <strong>Taylor expansion</strong>:</p>

\[\mathbf{g}(\mathbf{x}) = \mathbf{g}(\mathbf{\mu}) + \frac{\partial \mathbf{g}}{\partial \mathbf{x}}(\mathbf{\mu})(\mathbf{x} - \mathbf{\mu}) + \mathbf{O}(\|\mathbf{x} - \mathbf{\mu}\|^2)\]

<p>where $\frac{\partial \mathbf{g}}{\partial \mathbf{x}}(\mathbf{\mu})$ is the <strong>Jacobian</strong> of the function at $\mathbf{\mu}$.</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240405144517784.png" alt="image-20240405144517784" style="zoom:50%;" /></p>

<p>Therefore, given any non-linear function $\mathbf{x}<em>k = f(\mathbf{x}</em>{k-1}, \mathbf{u}_{k}) + \mathbf{w}_k$, we can:</p>

<ol>
  <li>
    <p>compute the Jacobian to be the linear transformation matrix evaluated at the <strong>mean of the distribution</strong>:</p>

\[F_k = \frac{\partial f}{\partial x}(\hat{\mathbf{x}}_{k-1|k-1}, \mathbf{u}_k)\]

    <p>so that the linearized model is, using Taylor expansion:</p>

\[\mathbf{x}_k = f(\hat{\mathbf{x}}_{k-1|k-1}, \mathbf{u}_k) + F_{k} \cdot (\mathbf{x}_{k-1} - \hat{\mathbf{x}}_{k-1|k-1}) + \mathbf{w}_k\]

    <p>note that $f(\hat{\mathbf{x}}_{k-1\vert k-1})$ is a constant you can compute at each update step.</p>
  </li>
  <li>
    <p>we can similarly apply linearization to the measurement model, with mean computed from the previous step $\hat{\mathbf{x}}_{k\vert k-1}$:</p>

\[H_k = \frac{\partial h}{\partial x}(\hat{\mathbf{x}}_{k|k-1})\]

    <p>so that the linearized model is:</p>

\[\mathbf{z}_k = h(\hat{\mathbf{x}}_{k|k-1}) + H_k \cdot (\mathbf{x}_k - \hat{\mathbf{x}}_{k|k-1}) + \mathbf{v}_k\]
  </li>
  <li>
    <p>now all transformations are linear, we can <strong>reapply the Kalman filter</strong> to update the belief state, but the equations become a little different than before.</p>
  </li>
</ol>

<h2 id="extended-kalman-filter-derivations">Extended Kalman Filter Derivations</h2>

<p>Now, we derive the case of Kalman filters under which we use a linearized version of non-linear functions.</p>

<h3 id="extended-prediction-step">Extended Prediction Step</h3>

<p>Now our motion model becomes:</p>

\[\mathbf{x}_k = f(\hat{\mathbf{x}}_{k-1|k-1}, \mathbf{u}_k) + F_k \cdot (\mathbf{x}_{k-1} - \hat{\mathbf{x}}_{k-1|k-1}) + \mathbf{w}_k\]

<p>and given the previous belief parameters $\hat{\mathbf{x}}<em>{k-1\vert k-1}, P</em>{k-1\vert k-1}$, we want to find out what’s the new mean and variance:</p>

\[\mathbf{x}_k' \sim \mathcal{N}(\hat{\mathbf{x}}_{k|k-1}, P_{k|k-1})\]

<p>It turns out that in this case, you will get:</p>

\[\begin{cases}
\hat{\mathbf{x}}_{k|k-1} = f(\hat{\mathbf{x}}_{k-1|k-1}, \mathbf{u}_k), &amp; \text{new mean}\\
P_{k|k-1} = F_k P_{k-1|k-1} F_k^T + Q_k, &amp; \text{new variance}
\end{cases}\]

<blockquote>
  <p>Therefore the new mean is just the <strong>non-linear function evaluated at the previous mean</strong>, and the new variance is the same equation but with <strong>the linearized approximation matrix $F_k$</strong>.</p>
</blockquote>

<h3 id="extended-update-step">Extended Update Step</h3>

<p>Now our measurement model becomes:</p>

\[\mathbf{z}_k = h(\hat{\mathbf{x}}_{k|k-1}) + H_k \cdot (\mathbf{x}_k - \hat{\mathbf{x}}_{k|k-1}) + \mathbf{v}_k\]

<p>then you can do the same thing to find what’s the new mean and covariance if you do the same procedure as before:</p>

\[B(x_k) \propto p(\mathbf{z}_k|\mathbf{x}_k) B'(\mathbf{x}_k) = \exp(- \frac{1}{2} f(\mathbf{x}_k)) \propto \mathcal{N}(\hat{\mathbf{x}}_{k|k}, P_{k|k})\]

<p>matching the terms that the final distribution is Gaussian, you will get:
and you will find that:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240406160244.png" style="zoom:80%;" /></p>

<p>Hence we get exactly the same as before</p>

\[\begin{cases}
\hat{\mathbf{x}}_{k|k} = \hat{\mathbf{x}}_{k|k-1} + K_{k} \tilde{\mathbf{y}}_k, &amp; \text{new mean}\\
P_{k|k} = (I - K_k H_k) P_{k|k-1}, &amp; \text{new variance}
\end{cases}\]

<p>except that:</p>
<ul>
  <li>$\tilde{\mathbf{y}}<em>k = \mathbf{z}_k - h(\hat{\mathbf{x}}</em>{k\vert k-1})$ is the <strong>innovation</strong> using the <mark>non-linear function</mark></li>
  <li>$K_k = P_{k\vert k-1} H_k^{T}S_k^{-1}$ is the <strong>Kalman gain</strong> using the <mark>linearized approximation</mark></li>
  <li>$S_k = H_k P_{k\vert k-1} H_k^{T} + R_k$ is the <strong>innovation covariance</strong> using the <mark>linearized approximation</mark></li>
</ul>

<h3 id="summary-of-extended-kalman-filter">Summary of Extended Kalman Filter</h3>

<p>In summary, given a prior belief state $\hat{\mathbf{x}}<em>{k-1\vert k-1}, P</em>{k-1\vert k-1}$, the update steps for the mean and covariances look like:</p>

<ol>
  <li>
    <p>Prediction step with motion model:</p>

\[\begin{cases}
   \hat{\mathbf{x}}_{k|k-1} = f(\hat{\mathbf{x}}_{k-1|k-1}, \mathbf{u}_k), &amp; \text{nonlinear}\\
   P_{k|k-1} = F_k P_{k-1|k-1} F_k^T + Q_k, &amp; \text{linear with Jacobian}
   \end{cases}\]
  </li>
  <li>
    <p>Update step with measurement model:</p>

\[\begin{cases}
   \hat{\mathbf{x}}_{k|k} = \hat{\mathbf{x}}_{k|k-1} + K_{k} \tilde{\mathbf{y}}_k, &amp; \text{nonlinear}\\
   P_{k|k} = (I - K_k H_k) P_{k|k-1}, &amp; \text{linear with Jacobian}
   \end{cases}\]

    <p>where you have:</p>
    <ul>
      <li>$\tilde{\mathbf{y}}<em>k = \mathbf{z}_k - h(\hat{\mathbf{x}}</em>{k\vert k-1})$</li>
      <li>$K_k = P_{k\vert k-1} H_k^{T}S_k^{-1}$</li>
      <li>$S_k = H_k P_{k\vert k-1} H_k^{T} + R_k$</li>
    </ul>
  </li>
</ol>

<p>In practice:</p>

<ul>
  <li>Just as efficient as regular KF, relatively robust in many real problems</li>
  <li>Less robust when uncertainty is high or models are locally very nonlinear</li>
</ul>

<h3 id="ekf-problem-cases">EKF Problem Cases</h3>

<blockquote>
  <p>Key problem: linearization is evaluated at the mean of the distribution.</p>
</blockquote>

<p>Intuitively, if your belief distribution is very narrow, then linearization near the mean would probably be fine:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240406161236.png" style="zoom:80%;" /></p>

<p>But if your belief distribution is spread out, then the linearization gives a lot of errors at the tails</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240406161425.png" style="zoom:80%;" /></p>

<p>Alternatively, if your function is not very linear away from the point of linearization</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240406161536.png" style="zoom:80%;" /></p>

<h3 id="ekf-localization">EKF Localization</h3>

<p>For example, consider a 1D robot where we had a good initial belief</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240405150549520.png" alt="image-20240405150549520" style="zoom:50%;" /></p>

<p>Then let’s apply a motion model moving to the right, but with increased uncertainty</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240405150621971.png" alt="image-20240405150621971" style="zoom:50%;" /></p>

<p>But then if you apply the measurement now:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240405150652159.png" alt="image-20240405150652159" style="zoom:50%;" /></p>

<p>and finally, if you moved again:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240405150708793.png" alt="image-20240405150708793" style="zoom:50%;" /></p>

<h2 id="motion-model-linearization-example">Motion Model Linearization Example</h2>

<p>Now, let’s consider a planar mobile robot in SE(2):</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Robot</th>
      <th style="text-align: center">Motion Model</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240405150825700.png" alt="image-20240405150825700" style="zoom:50%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240406161838.png" style="zoom:60%;" /></td>
    </tr>
  </tbody>
</table>

<p>where obviously the motion model is non-linear as it involves sin and cosine of the angle. So you can linearize it by taking the Jacobian:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240405151109417.png" alt="image-20240405151109417" style="zoom:50%;" /></p>

<p>and then you can apply the EKF update steps as before.</p>

<h2 id="measurement-model-linearization-example">Measurement Model Linearization Example</h2>

<p>Now, le’s consider a measurement model being the range finder given a map:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Visual</th>
      <th style="text-align: center">Measurement Model</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240406162211.png" style="zoom:100%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240406162216.png" style="zoom:60%;" /></td>
    </tr>
  </tbody>
</table>

<p>Again, it’s a non-linear function, so we need to linearize it by taking the Jacobian:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240405151502288.png" alt="image-20240405151502288" style="zoom: 50%;" /></p>

<p>where we are looking at the $j$-th landmark at the $k$-th time step.</p>

<blockquote>
  <p>Problem: if there are $l$ land marks, the Jacobian will be very large and expensive to compute. Also the covariance matrix will $2l \times 2l$, and computing its inverse is expensive in EKF.</p>
</blockquote>

<p>one common trick is to assume that the landmarks are independent, so that the updates for each landmark can be computed independently. With $l$ landmarks, we will get:</p>

<ol>
  <li>
    <p>first initialize:</p>

\[\hat{\mathbf{x}}_{k|k} \gets \hat{\mathbf{x}}_{k|k-1}, \quad P_{k|k} \gets P_{k|k-1}\]
  </li>
  <li>
    <p>then for each landmark, compute independently:</p>

\[\begin{cases}
 \hat{\mathbf{x}}_{k|k} = \hat{\mathbf{x}}_{k|k} + K_{j,k} \tilde{\mathbf{y}}_{j,k}, &amp; \text{new mean}\\
 P_{k|k} = (I - K_{j,k} H_{j,k}) P_{k|k}, &amp; \text{new variance}
 \end{cases}\]

    <p>where:</p>
    <ul>
      <li>$\tilde{\mathbf{y}}<em>{j,k} = \mathbf{z}</em>{j,k} - h_{j,k}(\hat{\mathbf{x}}_{k\vert k})$</li>
      <li>$K_{j,k} = P_{k\vert k} H_{j,k}^{T}S_{j,k}^{-1}$</li>
      <li>$S_{j,k} = H_{j,k} P_{k\vert k} H_{j,k}^{T} + R_{j,k}$</li>
    </ul>

    <p>and now $S^{-1}_{j,k}$ shown above is much easier to compute.</p>
  </li>
</ol>

<hr />

<p><em>As an example</em>, consider white circles as the landmarks, and the solid line being the actual movement. The dashed line is what the robot thinks it’s moving. The light gray is belief after motion model updates</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240405152129176.png" alt="image-20240405152129176" style="zoom:50%;" /></p>

<p>And if you increase uncertainty in real measurement (e.g., sensor errors)</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240405152222862.png" alt="image-20240405152222862" style="zoom:50%;" /></p>

<h2 id="data-association">Data Association</h2>

<p>Another practical problem is that, given $l$ measurements, we need to know which landmark it corresponds to in order to do the above computation. In practice, we need to estimate it since we don’t know the true correspondence.</p>

<blockquote>
  <p>Idea: use maximum likelihood. For each landmark given the current (mean) position, we can estimate the likelihood of an measurement being the landmark $l$ and then <strong>choose the one with the highest likelihood</strong>.</p>
</blockquote>

<p>So then this will need to be implemented as a separate sub-rountine in the EKF algorithm:</p>
<ol>
  <li>
    <p>given a measurement $\mathbf{z}_k$, compute the likelihood of each landmark $l$’s expected measurement:</p>

\[\mathcal{N}(h_j(\hat{\mathbf{x}}_{k|k}), S_{j,k})\]
  </li>
  <li>
    <p>associate $z_{i,k}$ with the landmark $j$ that maximizes the likelihood</p>
  </li>
</ol>

<p>and more tricks to clean this up include</p>

<ul>
  <li>may first <em>filter out landmarks that are very unlikely</em> or similar to each other</li>
  <li>may add a <em>mutual exclusion constraint</em> to prevent a landmark from being associated with multiple measurements</li>
</ul>

<h2 id="multi-hypothesis-tracking">Multi-Hypothesis Tracking</h2>

<p>Previously we assumed that Kalman filters work with belief = unimodal Gaussian. This is quite restrictive, but</p>

<blockquote>
  <p><strong>Idea</strong>: Instead of one Gaussian, our belief can be written as a <strong>mixture of Gaussians</strong></p>
</blockquote>

<p>Then what happens in KF? It can be still extended, with:</p>

<ul>
  <li>apply KF to each of the Gaussian</li>
  <li>add a few correction terms (details omitted)</li>
</ul>

<p>This could be useful for:</p>

<ul>
  <li>initial robot belief is uncertain: it might be at 2 different places with high prob.</li>
  <li>In the extreme case, this can solve the data association problem by creating a mixture component for every possible feature-measurement correspondence!</li>
</ul>

<p>in practice maintaining all the Gaussians is expensive, so  a simple fix would be that we simply prune the components down to a fixed number after each filter update</p>

<h2 id="other-considerations-for-kalman-filters">Other Considerations for Kalman Filters</h2>

<p>A few differenes:</p>

<ul>
  <li>in <a href="#Particle-Filters">Particle Filters</a> <strong>obstacle regions</strong> are automatically avoided. EKFs cannot represent spatial constraints</li>
  <li><strong>too many measurement features</strong> increase computation and possibility of mixing up features (e.g., the data association problem); too few may be insufficient for good estimation</li>
  <li>EKFs cannot incorporate <strong>negative information</strong>, e.g. absence of a feature: I don’t see a door X, therefore I cannot be at location Y.</li>
</ul>

<h1 id="simultaneous-localization-and-mapping">Simultaneous Localization and Mapping</h1>

<p>Previsouly we discussed localization methods <strong>assuming we know the map/obstacles in advance</strong>. In this section, we will:</p>
<ul>
  <li>discuss how to perform mapping (by itself) assuming we know the robot’s state/measurements (localization)</li>
  <li>discuss how to perform localization and mapping simultaneously</li>
</ul>

<table>
  <tbody>
    <tr>
      <td>So we can consider The posterior over all maps given data is Pr(𝒎</td>
      <td>𝒙1:𝑘 , 𝒛1:𝑘 ) and independence</td>
    </tr>
  </tbody>
</table>

<h2 id="occupancy-grid-mapping">Occupancy Grid Mapping</h2>

<p>A popular method to represent the map is to use an <strong>occupancy grid</strong>: the map becomes a grid world, and you want to know whether <strong>each cell is occupied by an obstacle or not</strong>.</p>

<blockquote>
  <p>Mathematically, we want to model:</p>

\[\Pr(\mathbf{m} | \mathbf{x}_{1:k}, \mathbf{z}_{1:k})\]

  <p>where here we <strong>can assume that the history of robot states and measurements are given</strong>. $m$ would be like a vector of the size of the number of grids, modeling the probability of each cell being occupied.</p>
</blockquote>

<h3 id="bayes-filter-for-mapping">Bayes Filter for Mapping</h3>

<p>The above is difficult to even represent if you have a large map. Therefore, one assumption we can make is to <strong>assume each grid/cell’s occupancy is independent of others</strong>:</p>

\[\Pr(\mathbf{m} | \mathbf{x}_{1:k}, \mathbf{z}_{1:k}) = \prod_{i} \Pr(m_i | \mathbf{x}_{1:k}, \mathbf{z}_{1:k})\]

<p>so we can model <mark>the belief distribution of each grid cell independently</mark>. So how do we do not?</p>

<blockquote>
  <p>Recall that <a href="#Bayes-Filter">Bayes filter</a> is a recursive way to update the belief state given the previous estimates:</p>

\[\Pr( m_i | \mathbf{x}_{1:k}, \mathbf{z}_{1:k}) \gets \text{previous estimate } \Pr(m_i | \mathbf{x}_{1:k-1}, \mathbf{z}_{1:k-1})\]

</blockquote>

<p>Foolowing conditional independence between the latest observation $\mathbf{z}<em>k$ and the history $\mathbf{x}</em>{1:k-1},\mathbf{z}_{1:k-1}$ given the robot’s current state $\mathbf{x}_k$, we can write the above as:</p>

\[\begin{align*}
  \Pr(m_i | \mathbf{x}_{1:k}, \mathbf{z}_{1:k}) 
  &amp;= \eta \Pr(\mathbf{z}_k | m_i, \mathbf{x}_{1:k}, \mathbf{z}_{1:k-1}) \Pr(m_i | \mathbf{x}_{1:k}, \mathbf{z}_{1:k-1}) \\
  &amp;= \eta \Pr(\mathbf{z}_k | m_i, \mathbf{x}_k) \Pr(m_i | \mathbf{x}_{1:k}, \mathbf{z}_{1:k-1})\\
  &amp;= \eta \frac{\Pr( m_{i} |  \mathbf{x}_{k}, \mathbf{z}_{k}) \Pr(\mathbf{z}_k | \mathbf{x}_k )}{\Pr( m_i | \mathbf{x}_k)} \Pr(m_i | \mathbf{x}_{1:k}, \mathbf{z}_{1:k-1})\\
  &amp;= \eta \frac{\Pr( m_{i} |  \mathbf{x}_{k}, \mathbf{z}_{k}) \Pr(\mathbf{z}_k | \mathbf{x}_k )}{\Pr( m_i )} \Pr(m_i | \mathbf{x}_{1:k}, \mathbf{z}_{1:k-1})
\end{align*}\]

<p>where the second equality used conditional independence mentioned above, and the last equality used the independence of $m_i$ and $\mathbf{x}_k$ (dependent only if we have an observation $\mathbf{z}_k$).</p>

<h3 id="log-odds">Log Odds</h3>

<p>However, the above is computationally not efficient because:</p>

<ul>
  <li>computing the joint $\Pr(\mathbf{m} \vert  \mathbf{x}<em>{1:k}, \mathbf{z}</em>{1:k})$ would end up multiplying a lot of probabilities</li>
  <li>there are three probabilities to compute for each cell $\Pr(m_i \vert  \mathbf{x}<em>{1:k}, \mathbf{z}</em>{1:k})$</li>
</ul>

<p>One trick to solve both issue would be using the <strong>log odds</strong> instead.</p>

<p>Consider the probability of observing an event $x$ as $\Pr(X)$, then define:</p>

\[l(x) = \text{log odds} = \log \frac{\Pr(X)}{1 - \Pr(X)} = \log \frac{\Pr(X)}{\Pr(\bar{X})}\]

<p>Visually, it would look like</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240412211921.png" style="zoom:50%;" /></p>

<p>This is useful because the log odd of $\Pr(m_i \vert  \mathbf{x}<em>{1:k}, \mathbf{z}</em>{1:k})$ then becomes:</p>

\[\begin{align*}
  l_{i,1:k}
  &amp;= \log \frac{\Pr(m_i | \mathbf{x}_{1:k}, \mathbf{z}_{1:k})}{1 - \Pr(m_i | \mathbf{x}_{1:k}, \mathbf{z}_{1:k})}\\
  &amp;= \log \frac{\Pr(m_i | \mathbf{x}_{1:k-1}, \mathbf{z}_{1:k-1})}{1 - \Pr(m_i | \mathbf{x}_{1:k-1}, \mathbf{z}_{1:k-1})} \frac{\Pr( m_{i} |  \mathbf{x}_{k}, \mathbf{z}_{k})}{ 1- \Pr( m_{i} |  \mathbf{x}_{k}, \mathbf{z}_{k}) } \frac{ 1 - \Pr( m_i )}{\Pr( m_i )}\\
  &amp;\equiv l_{i,1:k-1} + l_{i,k} - l_{i}
\end{align*}\]

<p>so that:</p>
<ul>
  <li>the term $\Pr(\mathbf{z}_k \vert  \mathbf{x}_k )$ is cancelled as we compute the ratio</li>
  <li>adding log odds is numerically stable</li>
  <li>you have basically the “next log odd = previous log odd + log odd of $m_i$ given current measurement/states - log odd of prior”</li>
</ul>

<p>The only challenge left is <strong>how do we model $l_{i,k}$?</strong></p>

<h3 id="inverse-sensor-model">Inverse Sensor Model</h3>

<blockquote>
  <p>It turns out that $l_{i,k} = \log \frac{\Pr( m_{i} \vert   \mathbf{x}<em>{k}, \mathbf{z}</em>{k})}{ 1- \Pr( m_{i} \vert   \mathbf{x}<em>{k}, \mathbf{z}</em>{k}) }$ is also called a n <mark>inverse sensor model</mark> and there is no single best way to do this yet. The popular approach (next section) is do learn this from a machine learning model.</p>
</blockquote>

<p>In some special case, however, there are methods that can estimate this. Consider we are using a beam sensor like this:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240412133900842.png" alt="image-20240412133900842" style="zoom:50%;" /></p>

<p>where $r_k$ is the distance from robot to the dark square. Then we can model this log odds by:</p>
<ol>
  <li>decrease log odds of cell closer than $r_k$ as they are likely free</li>
  <li>increase log odds of cell physically around $r_k$ as they are likely occupied</li>
  <li>no change for other cells</li>
</ol>

<p>again, this is empirical, but works quite well. Implementation-wise, one can first consider a mixture of zero-mean gaussian over $\theta$ and a decreasing linear function of $r_k$ to capture uncertainty in both range and bearing</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240412134519021.png" alt="image-20240412134519021" style="zoom:30%;" /></p>

<p>Then, given a measurement $z$ being the distance to the obstacle, we can update the distribution with a piecewise function on the left:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240412134342538.png" alt="image-20240412134342538" style="zoom: 67%;" /></p>

<p>where $d_1, d_3$ are hyperparameters. A full mapping run using the above technique would look like:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Process</th>
      <th style="text-align: center">Mapped</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240412134717105.png" alt="image-20240412134717105" style="zoom: 50%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240412134736661.png" alt="image-20240412134736661" style="zoom:67%;" /></td>
    </tr>
  </tbody>
</table>

<h3 id="learning-inverse-sensor-models">Learning Inverse Sensor Models</h3>

<p>But again, there is no closed-form solution to derive $\Pr( m_{i} \vert   \mathbf{x}<em>{k}, \mathbf{z}</em>{k})$, an inverse model, given the forward model $\Pr( \mathbf{z}<em>{k} \vert   \mathbf{x}</em>{k}, m_{i} )$ using Bayes.</p>

<p>So other pratical yet pretty good trick is to <strong>learn a model using supervised learning</strong>:</p>
<ol>
  <li>generate training data ${(\mathbf{x}_k, \mathbf{z}_k, m_i)}$ by sampling from known maps, robot states, and measurements</li>
  <li>train a model to predict $m_i$ given $\mathbf{x}_k, \mathbf{z}_k$ using a neural network or other machine learning models</li>
</ol>

<h3 id="independence-assumption">Independence Assumption</h3>

<p>Finally, another problem of our current method is that we are assuming the occupancy of each cell is independent of each other. This is may not be true in practice:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240412135440538.png" alt="image-20240412135440538" style="zoom:50%;" /></p>

<p>where in the above example, certain cells (e.g., the conflict shown above) depends on knowing its immediate neighbor being an obstacle.</p>

<p>In practice, this can be somewhat alleviated by:</p>

<ul>
  <li>narrower beam sensors like lidar can help alleviate this issue</li>
  <li>or somehow learn this as well from machine learning models (above)</li>
</ul>

<h2 id="slam">SLAM</h2>

<p>Finally, here we discuss how to do <strong>localization and mapping simultaneously</strong>. The idea is to include the map as part of the state vector, and make corresponding modifications to the <a href="#Extended-Kalman-Filter-and-Localization">EKF</a> or <a href="#Particle-Filters">Particle Filter</a> algorithm.</p>

<h3 id="ekf-slam">EKF-SLAM</h3>

<p>Suppose we know that our map consists of $N$ landmarks, but we are not sure where they are ($N$ can increase as the algorithm goes).</p>

<blockquote>
  <p>Then we can <strong>model state $\mathbf{x}$ = robot state + landmark location</strong>. This means that we consider:</p>

\[\mathbf{x} = (x,y,\theta, m_{1x},m_{1y}, ...,m_{Nx},m_{Ny}) \in \R^{3+2N}\]

  <p>for a robot in 2D space, and then apply the EKF algorithm as before (with some modifications below)</p>
</blockquote>

<p>First, we note that <strong>our covariance matrix</strong> becomes $P \in \R^{(3+2N)\times (3+2N)}$</p>

\[P = \begin{bmatrix}
P_{xx} &amp; P_{xm}\\
P_{mx} &amp; P_{mm}
\end{bmatrix}\]

<p>where $P_{xx} \in \R^{3\times 3}$ is the covariance of the robot state, $P_{mm} \in \R^{2N\times 2N}$ is the covariance of the landmarks, and $P_{xm} \in \R^{3\times 2N}$ is the cross-covariance between the robot state and the landmarks.</p>

<p><strong>Algorithmically:</strong></p>

<ol>
  <li>
    <p>we can <mark>initialize</mark> with 1) robot initial position and landmark being uncorrelated, and 2) infinite variance for the landmarks since we have no idea where they are:</p>

\[P_{xx,0} = \mathbf{0}^{3\times 3}, \quad P_{mm,0} = \infty \times \mathbf{I}^{2N\times 2N}, \quad P_{xm,0} = \mathbf{0}^{3\times 2N}\]

    <p>and some robot state guess $\mathbf{x}<em>0$ and landmark guess $\mathbf{m}</em>{0}$.</p>

    <p>Note that we can <strong>also add landmarks as we go</strong> (e.g., if our data association model found some landmark estimate to be extremely low = likely a new landmark, or there is a signature we can use to check if its a existing landmark). In this case, we can <strong>add terms to the covariance/mean</strong> with a non-zero initialization:</p>

\[\begin{bmatrix} 
    \hat{m}_{jx} \\
   \hat{m}_{jy} 
\end{bmatrix} = \begin{bmatrix} 
    \hat{x} \\
   \hat{y}
 \end{bmatrix} + \begin{bmatrix} 
     r_j \cos(\hat{\theta} + \phi_j) \\
     r_j \sin(\hat{\theta} + \phi_j)
 \end{bmatrix}\]
  </li>
  <li>
    <p><mark>predict step</mark> given some movement/motion model (e.g., a vecolity model)</p>

    <p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240412140854365.png" alt="image-20240412140854365" style="zoom: 67%;" /></p>

    <p>where we <strong>do not update the landmarks position</strong> since they don’t move. We can then linearize this and show that</p>

    <p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240412140915812.png" alt="image-20240412140915812" style="zoom: 50%;" /></p>

    <p>then we <strong>apply the same prediction step to both the covariance and the mean</strong>. Note that given the nature of obstacles not moving, $P_{mm}$ will remain unchanged while $P_{xx}$ and $P_{xm}$ will change in this step.</p>
  </li>
  <li>
    <p><mark>update step</mark> then you can compute your observation $z$​ but with <strong>landmark location (you estimated) from previous step</strong></p>

    <p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240412141702727.png" alt="image-20240412141702727" style="zoom:60%;" /></p>

    <p>and again, we need to linearize the above ($h(\cdot)$) using the Jacobian <strong>$H_{i,j}$</strong> evaluted at the <strong>estimated state/landmark location</strong>:</p>

    <p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240412142035377.png" alt="image-20240412142035377" style="zoom:50%;" /></p>

    <p>This would give a $2 \times (3+2N)$ matrix $H_k$. Since landmarks do not affect each other, we will only have two additional non-zero columns for each landmark $j$. With this, we can apply the same measurement step from EKF to both covariance and mean updates.</p>
  </li>
</ol>

<blockquote>
  <p>In summary, <strong>EKF-SLAM equations are near identical to the regular EKF algorithm</strong>:</p>
  <ol>
    <li>
      <p>predict step considers:</p>

\[\begin{cases}
\hat{\mathbf{x}}_{k|k-1} = f(\hat{\mathbf{x}}_{k-1|k-1}, \mathbf{u}_k), &amp; \text{nonlinear}\\
P_{k|k-1} = F_k P_{k-1|k-1} F_k^T + Q_k, &amp; \text{linear with Jacobian}
\end{cases}\]

      <p>Note that given the nature of obstacles not moving, $P_{mm}$ will remain unchanged while $P_{xx}$ and $P_{xm}$ will change in this step.</p>
    </li>
    <li>
      <p>update step considers:</p>

\[\begin{cases}
\hat{\mathbf{x}}_{k|k} = \hat{\mathbf{x}}_{k|k-1} + K_{k} \tilde{\mathbf{y}}_k, &amp; \text{nonlinear}\\
P_{k|k} = (I - K_k H_k) P_{k|k-1}, &amp; \text{linear with Jacobian}
\end{cases}\]

      <p>where you have:</p>
      <ul>
        <li>$\tilde{\mathbf{y}}<em>k = \mathbf{z}_k - h(\hat{\mathbf{x}}</em>{k\vert k-1}, \hat{m}_{k-1})$ depends on your estimate of the landmark</li>
        <li>$K_k = P_{k\vert k-1} H_k^{T}S_k^{-1}$</li>
        <li>$S_k = H_k P_{k\vert k-1} H_k^{T} + R_k$</li>
      </ul>
    </li>
  </ol>

  <p>note that although $H_k$ is sparse, the Kalman gain $K_k \in \R^{3 \times (3+2N)}$ is generally <strong>dense</strong>. This is because it incorporates correlations/updates between landmarks that were previously seen.</p>
</blockquote>

<p><em>For example</em>, if we have two landmarks, then $F_k \in \R^{(3 + 2\times 2)\times (3 + 2\times 2)}$ matrix</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240412142353734.png" alt="image-20240412142353734" style="zoom:67%;" /></p>

<p>where we dropped the $k$ subscript in $H=[H_1, H_2]^{T}$ for each landmark to save space. Notice that the <strong>last four columns in $H$</strong> is <strong>block diagonal</strong>: this is because the $x,y$​​ for a landmark is independent of the other landmarks.</p>

<blockquote>
  <p><strong>Note</strong> in this section it seems that mapping is not very hard: this is because we have simplified the map to simply be the location of obstacles. In practice, if you need Occupany Grid, then you really need <a href="#Occupancy-Grid-Mapping">Occupancy Grid Mapping</a>.</p>
</blockquote>

<h3 id="ekf-slam-example">EKF-SLAM Example</h3>

<p>Visually, let the red small dots be the actual landmarks, and gray dots be the actual robot’s path. Then our estimate of mean and variance may look like:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240412144643066.png" alt="image-20240412144643066" style="zoom:50%;" /></p>

<p>note that:</p>

<ul>
  <li>in the beginning, as the robot moves and sees new landmarks, its own uncertainty grows. Landmark uncertainties also grow since they depend on robot uncertainty</li>
  <li>but uncerintaty of landmarks are correlated: once we have a low uncertainty for a landmark (<mark>in (d) as we saw the top left landmark again</mark>), the uncertainty of the other ones decrease as it indicates our estimate of landmarks were likely all correct.</li>
  <li>With sufficient observations, the individual variances (uncertainties) of both robot state and landmarks converge toward a lower bound = becomes certain of its position and the landmarks</li>
</ul>

<p>Problems with EKF-SLAM:</p>

<ul>
  <li>Complexity of each EKF iteration is quadratic in the number of landmarks = cannot handle very large maps</li>
  <li>Cannot take advantage of sparsity, as all landmarks eventually become fully correlated</li>
  <li>Still subject to the usual limitations of EKFs (nonlinearity, high uncertainty)</li>
  <li><strong>data association</strong> problem becomes more critical in this case</li>
</ul>

<h3 id="particle-filters-for-slam">Particle Filters for SLAM</h3>

<p>Recall that in <a href="#Particle-Filters">Particle Filters</a>, we had each particle representing a clone of the robot. Consider a simple idea similar to EKF SLAM, where now <strong>each particle represent the robot + a map configuration</strong>.</p>

<p>The problem with naively doing the above is its cloning the map too much.</p>

<ul>
  <li>in EKF, we have one distribution over the robot state</li>
  <li>in particle filter, each particle itself is certain of its robot state, but the distribution is recovered by the distribution of the particles.</li>
</ul>

<blockquote>
  <p>Therefore, the key idea is to assume each particle has no uncertainties about its state, and hence the partcle can <strong>itself solve its own mapping problem</strong>.</p>
</blockquote>

<h4 id="rao-blackwellization">Rao-Blackwellization</h4>

<p>The key idea is implemented with factoring the state distribution $\mathbf{x}=[\mathbf{x}_{1:k}, \mathbf{m}]$ into two parts:</p>

\[\begin{align*}
  \Pr(\mathbf{x}_{1:k}, \mathbf{m} | \mathbf{z}_{1:k}, \mathbf{u}_{1:k}) 
  &amp;= \Pr(\mathbf{x}_{1:k} | \mathbf{z}_{1:k}, \mathbf{u}_{1:k}) \Pr(\mathbf{m} | \mathbf{x}_{1:k}, \mathbf{z}_{1:k}, \mathbf{u}_{1:k})\\
  &amp;= \Pr(\mathbf{x}_{1:k} | \mathbf{z}_{1:k}, \mathbf{u}_{1:k}) \Pr(\mathbf{m} | \mathbf{x}_{1:k}, \mathbf{z}_{1:k})\\
  &amp;= \Pr(\mathbf{x}_{1:k} | \mathbf{z}_{1:k}, \mathbf{u}_{1:k}) \prod_{i} \Pr(m_i | \mathbf{x}_{1:k}, \mathbf{z}_{1:k})
\end{align*}\]

<p>where the last equality is because the map is independent of the control sequence $\mathbf{u}_{1:k}$​​. Then</p>
<ul>
  <li>the term $\Pr(\mathbf{x}<em>{1:k} \vert  \mathbf{z}</em>{1:k}, \mathbf{u}_{1:k})$ can be represented <strong>purely by the density distribution of our partciles</strong></li>
  <li>the term $\Pr(m_i \vert  \mathbf{x}<em>{1:k}, \mathbf{z}</em>{1:k})$ is simply the <strong>individual landmark estimate given a robot state/measurement</strong>.</li>
</ul>

<h4 id="fastslam">FastSLAM</h4>

<p>Using the above factorization, we can do</p>

<blockquote>
  <p>FastSLAM: Use normal <strong>particle filter for the robot state</strong>, and then for each particle, <strong>use EKF to model each of the landmarks</strong>.</p>
</blockquote>

<p>This means that given $M$ particles, we will consider tracking:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240412150656337.png" alt="image-20240412150656337" style="zoom:50%;" /></p>

<p>where:</p>
<ul>
  <li>for each particle, we track its trajectory and <strong>its own estimate of landmark’s mean and variance</strong>:</li>
  <li>each <strong>landmark’s mean and covariance is also modelled independently</strong> in this algorithm: much easier to compute as its simply $\R^{2 \times 2}$ for each landmark!</li>
  <li>this results in 1 filter (normal particle filter) of the robot’s state (the above), and $MN$ filters for landmarks (one EKF filter for each particle and each landmark).</li>
</ul>

<p>Overall, the algorithm is similar to the normal particle filter:&gt;</p>

<blockquote>
  <p>In summary, <strong>FastSLAM equations are near identical to the regular particle filter algorithm</strong>:</p>

  <p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240412151059796.png" alt="image-20240412151059796" style="zoom:50%;" /></p>

  <p>The only difference is that we will be using EKF to model the landmarks, and the re-weighing operation will depend on our estimate of the landmarks.</p>
</blockquote>

<h4 id="fastslam-updating-landmarks">FastSLAM: updating landmarks</h4>

<p>For each landmark, consider a Gaussian distribution for each landmarks’ position. Then we can model this using <strong>mean and covariance matrices</strong>. Specifically, we can show that for landmark $j$ with a measurement $z_{j,k}$, we can update our estimate with:</p>

\[\Pr(m_{j,k} | \mathbf{x}_{1:k}, \mathbf{z}_{1:k}) \propto \Pr(\mathbf{z}_{j,k} | m_{j,k}, \mathbf{x}_{k}) \Pr(m_{j,k} | \mathbf{x}_{1:k-1}, \mathbf{z}_{1:k-1})\]

<p>which can then be derived using EKK update steps! THis means we can do linearized models and update the <strong>mean and covariance with for each landmark $j$</strong> with:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240412151305172.png" alt="image-20240412151305172" style="zoom:50%;" /></p>

<h4 id="fastslam-weighing">FastSLAM: Weighing</h4>

<p>Finally, we want to re-weight each particle with the likelihood of seeing the measurement $z_k$ given the particle’s estimate of the map and its current position:</p>

\[w = \Pr(\mathbf{z}_k | \mathbf{x}_k, \mathbf{m}_k) = \prod_{j} \Pr(\mathbf{z}_{j,k} | m_{j,k}, \mathbf{x}_k)\]

<p>Then each of the weight can be obtained by modeling a Gaussian</p>

\[w_{j} = \frac{1}{\sqrt{(2\pi)^2 |S_{j,k}|}} \exp\left(-\frac{1}{2} (\mathbf{z}_{j,k} - h_{j,k}(\mathbf{x}_k, m_{j,k}))^T S_{j,k}^{-1} (\mathbf{z}_{j,k} - h_{j,k}(\mathbf{x}_k, m_{j,k}))\right)\]

<p>where $S_{j,k} = H_{j,k} P_{j\vert k-1} H_{j,k}^{T} + R_{j,k}$.</p>

<h4 id="fastslam-example">FastSLAM: Example</h4>

<p>Consider the case of using $N=3$ particles, and there are 2 landmarks. Initially:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240412151706187.png" alt="image-20240412151706187" style="zoom:50%;" /></p>

<p>Let the green dots be the actual measurement made, and each particle can compute independently covariance updates of landmarks</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240412151810218.png" alt="image-20240412151810218" style="zoom:50%;" /></p>

<p>finally, reweight and resample</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240412152013476.png" alt="image-20240412152013476" style="zoom:50%;" /></p>

<p>An example in real life:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240412152036133.png" alt="image-20240412152036133" style="zoom:67%;" /></p>

<p>With an animated example:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Beginning</th>
      <th style="text-align: center">More Obstacles Seen</th>
      <th style="text-align: center">Loop Closure</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240412152546622.png" alt="image-20240412152546622" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240412152558255.png" alt="image-20240412152558255" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240412152602430.png" alt="image-20240412152602430" /></td>
    </tr>
  </tbody>
</table>

<h2 id="comparing-slam-algorithms">Comparing SLAM Algorithms</h2>

<p>In practice you need to do <strong>data associations</strong> yourselves.</p>

<ul>
  <li>With EKF-SLAM, we can only compute a single association per measurement</li>
  <li>With FastSLAM, <em>each particle can compute its “best” correspondence for the same measurement</em>, e.g. using maximum likelihood (actually an advantage)</li>
</ul>

<p>With map updates:</p>

<ul>
  <li>With EKF-SLAM, you update a single map update</li>
  <li>With FastSLAM, <em>each particles can maintain their own maps</em> by adding or removing landmarks when necessary</li>
</ul>

<p>For both SLAM, <strong>convergence occur when loop is closed</strong></p>

<ul>
  <li>
    <p>particle filters face the problem of <em>particle deprivation</em>: before loop is closed, you <em>need to maintain particle diversity</em> otherwise estimate could converge to a wrong estimate = bias</p>

    <p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240412153317139.png" alt="image-20240412153317139" style="zoom:50%;" /></p>
  </li>
  <li>
    <p>resampling particles = as particles are resampled, we lose most of the estimated histories</p>

    <ul>
      <li>in an extreme case, particle filters <em>might not even be able to close the loop</em>: suppose you just observed obstacle $m_j$ but also lost all particles that saw it before</li>
      <li>this is less of a problem for EKF-SLAM, since all historical correlations are tracked</li>
    </ul>
  </li>
</ul>

<p>Some fixes for FastSLAM:</p>

<ul>
  <li>simply have more or insert random particles to alleviate deprivation</li>
  <li>In FastSLAM 2.0, they use a proposal distribution that takes into account both motion and measurements</li>
</ul>

<h1 id="robot-perception-and-vision">Robot Perception and Vision</h1>

<p>Implementation-wise, previous sections were considering algorithms that runs on “already processed data”, i.e., observations as simple numbers/vectors. However, in practice, robots need to <strong>perceive the world</strong> using sensors, and <strong>interpret the data</strong> to make decisions.</p>

<p>Modern robots have access to a wide variety of different sensors:</p>

<ul>
  <li><strong>Proprioceptive</strong> sensors measure <em>internal</em> state, e.g. motor speed, joint angles</li>
  <li><strong>Exteroceptive</strong> sensors acquire <em>external</em> environment information, e.g. distance  measurements, light intensity</li>
</ul>

<p>Examples include</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240419131825512.png" alt="image-20240419131825512" style="zoom:50%;" /></p>

<p>In later subsections, we will instead focus on <strong>vision sensors/models</strong> that takes in camera input and returns measurements. This means:</p>

<blockquote>
  <p>Vision-type sensors have two key ingredients:</p>

  <ul>
    <li><strong>Digital cameras</strong> (e.g., color, depth, stereo) are sensors that capture light and transform them to <em>digital images</em></li>
    <li><strong>Computer vision</strong> is concerned with acquiring, processing, and understanding those <em>digital images</em> in order to extract symbolic <strong>information</strong></li>
  </ul>
</blockquote>

<p>This means that we will be tranforming our “mapping” or “pose estimation” tasks to become:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240419132055981.png" alt="image-20240419132055981" style="zoom:50%;" /></p>

<h2 id="image-representation-and-filtering">Image Representation and Filtering</h2>

<p>This section assumes you are familiar with basic CV approaches.</p>

<ul>
  <li>
    <p>images are most often represented as a grid of pixel values $I(x,y)$</p>

    <ul>
      <li>brightness adjustment $I(x,y)+\beta$</li>
      <li>contrast adjustment: $\alpha I(x,y)$</li>
    </ul>
  </li>
  <li>
    <p>another way to processes those images is <strong>filtering</strong></p>

    <ul>
      <li>
        <p><strong>Spatial filters</strong> transform images using functions on <strong>pixel neighborhoods</strong> (i.e. <mark>convolution</mark>)</p>

\[I'(x,y) = F*I = \sum_{i=-M}^{M}\sum_{j=-N}^N F(i,j)I(x+i, y+j)\]

        <p>where $F$ is a <mark>kernel</mark> with shape $(2M+1)\times (2N+1)$. Usually this kernel is a square:</p>

        <p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240419132712033.png" alt="image-20240419132712033" style="zoom:50%;" /></p>
      </li>
      <li>
        <p>examples of simple filters include:</p>

        <ul>
          <li>
            <p>moving average filter:</p>

\[B = \frac{1}{9}\begin{bmatrix}
1 &amp; 1 &amp; 1\\
1 &amp; 1 &amp; 1\\
1 &amp; 1 &amp; 1
\end{bmatrix}\]

            <p>this will basically blur an image</p>

            <p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240419133001062.png" alt="image-20240419133001062" style="zoom:50%;" /></p>
          </li>
          <li>
            <p>sharpening filter:</p>

\[S = \begin{bmatrix}
0 &amp; 0 &amp; 0\\
0 &amp; 2 &amp; 0\\
0 &amp; 0 &amp; 0
\end{bmatrix}\]

            <p>this will sharpen the image</p>

            <p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240419133220965.png" alt="image-20240419133220965" style="zoom:50%;" /></p>
          </li>
          <li>
            <p>Gaussian filters; also achieves blurring, but weights are defined proportional to a Gaussian centered at each pixel</p>

            <p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240419133308087.png" alt="image-20240419133308087" style="zoom:50%;" /></p>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p>But recall that the goal is to <strong>understand what is in the image</strong>. This then includes:</p>

<ul>
  <li>
    <p><strong>edge detection</strong>: when intensities are changing in a certain direction, it is “and edge”.</p>

    <table>
      <thead>
        <tr>
          <th style="text-align: center">Sobel detector</th>
          <th style="text-align: center">Result</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240419133919913.png" alt="image-20240419133919913" style="zoom:50%;" /></td>
          <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240419133905024.png" alt="image-20240419133905024" style="zoom:50%;" /></td>
        </tr>
      </tbody>
    </table>

    <p>There is also <strong>Canny detector</strong> is a multi-stage algorithm involving Gaussian smoothing and thresholding</p>

    <p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240419134049478.png" alt="image-20240419134049478" /></p>
  </li>
  <li>
    <p><strong>corner detection</strong>: a point with large changes in intensity in <em>all</em> directions. In general, corners can be more directly used for <em>3D reconstruction</em> and panorama stitching</p>

    <p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240419134253442.png" alt="image-20240419134253442" style="zoom:50%;" /></p>

    <p>More generally, <mark>image descriptors</mark> are features that can be compared <strong>across images</strong>, useful for object detection and matching</p>

    <p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240419134430408.png" alt="image-20240419134430408" style="zoom:50%;" /></p>

    <p>there are many existing detection algorithms to do the above, e.g., SIFT (scale-invariant feature transform)</p>
  </li>
</ul>

<h2 id="point-cloud-registration">Point-Cloud Registration</h2>

<p>Suppose we have two point clouds, and we want to want to <strong>find a spatial transformation that aligns them</strong>. This task can be useful for:</p>
<ul>
  <li>finding globally consistent model</li>
  <li>3D reconstruction and pose estimation</li>
  <li>data association in SLAM (see <a href="#ICP">ICP</a> later)</li>
</ul>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240419134734358.png" alt="image-20240419134734358" style="zoom:67%;" /></p>

<blockquote>
  <p>Since it is to figure out a transformation, this can be formulated mathematically as <strong>minimizing an error between one set of points and a transformation of the other set</strong></p>
</blockquote>

<p>And it turns out that if this transformation is a <em>rotation followed by a translation,</em> then there is a closed-form solution.</p>

<ol>
  <li>
    <p>given two set of points $X= {x_1, …, x_n}$ and $P={p_1, …, p_n}$ and suppose they are <strong>associated already $(x_i, p_i)$</strong></p>
  </li>
  <li>
    <p>we can consider a transformation such that the following is minimized:</p>

\[E(R, \mathbf{t}) = \sum_{i=1}^{n} || \mathbf{x}_i - (R\mathbf{p}_i + \mathbf{t}) ||^2\]
  </li>
  <li>
    <p>then there is a closed formed solution:</p>
    <ol>
      <li>
        <p>first re-center the data by:</p>

\[X' = X - \mu_x, \quad P' = P - \mu_p\]
      </li>
      <li>
        <p>then compute a outer product matrix:</p>

\[W = \sum_{i=1}^{n} \mathbf{x}_i \mathbf{p}_i^T\]

        <p>and perform SVD on $W = U \Sigma V^T$.</p>
      </li>
      <li>
        <p>then the optimal solution is given by:</p>

\[R^* = UV^T, \quad \mathbf{t}^* = \mu_x - R^* \mu_p\]

        <p>which would minimize the error $E(R, \mathbf{t})$.</p>
      </li>
    </ol>
  </li>
</ol>

<p>But then how do we find the data association with this?</p>

<h3 id="icp">ICP</h3>

<blockquote>
  <p>One simple algorithm is just iteratively: estimate an association, compute the best solution and its error, provide a better estimate, and repeat.</p>
</blockquote>

<p>And this leads us to ICP:</p>

<blockquote>
  <p>Iterative closest point (ICP): Iterate between estimating the correspondences by finding closest points and solving the least squares problem</p>
</blockquote>

<p>but of course, this method:</p>
<ul>
  <li>can be computationally intensive, especially with correspondence estimation</li>
  <li>Convergence depends on the initial guess and <em>presence of noise and outliers</em></li>
  <li>Will generally converge to a local optimum, no guarantee of global optimal</li>
</ul>

<h3 id="icp-improvements">ICP Improvements</h3>

<p>Several lines of improvements on its efficiency and robustness:</p>

<ul>
  <li><strong>use $k$-d tree</strong> to increase the efficiency of finding closes points</li>
  <li>apply <strong>variable weighting</strong> to different pairs of points, e.g. lower weights to pairs that are very far apart or deemed less informative</li>
  <li><strong>detecting outliers</strong> and ignore them in computations (see next section)</li>
</ul>

<h3 id="random-sample-consensus">Random Sample Consensus</h3>

<p>In general, detecting outlier data and removing them from your method is useful both in ICP and other CV problems. One common method is RANSAC:</p>

<blockquote>
  <p>RANSAC: Iterative algorithm for parameter estimation and outlier detection</p>
</blockquote>

<p>The general approach is to:</p>

<ol>
  <li>randomly subsample from the full dataset</li>
  <li>fit a model (e.g., a line shown in green below)</li>
  <li>test <em>all</em> the data using the model to determine a consensus set (data that is consistent with this line) under some threshold</li>
  <li>repeat, and <strong>keep the model that has the largest consensus set.</strong></li>
</ol>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240419140558202.png" alt="image-20240419140558202" style="zoom:50%;" /></p>

<p>Since each of this loop is independent, one can compute this in parallel.</p>

<h1 id="convolutional-neural-networks">Convolutional Neural Networks</h1>

<p>This section assumes you are familiar with basic CV approaches. So we will skip through the basics, and only keep some relevant information here.</p>

<p>Since images are large in dimension, CNN based approaches are very parameter efficient:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240419150554080.png" alt="image-20240419150554080" style="zoom:67%;" /></p>

<p>The set of outputs from all filters make up a new image called an <strong>activation map</strong>. This means you can:</p>

<ol>
  <li>
    <p>each CNN can apply more than 1 kernel. Since the above applied one kernel and obtained an output of $(1, W,H)$ matrix, using $N$ kernels in a layer gives you back matrices of $(N, W, H)$.</p>
  </li>
  <li>
    <p>then you can just stack those CNN layers, and learned features typically progress from more primitive (edges/corners) to more high-level</p>

    <p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240419151232308.png" alt="image-20240419151232308" style="zoom:50%;" /></p>

    <p>to achieve this, typically the the receptive field (i.e., size of kernel) of a filter also increases with each layer</p>
  </li>
</ol>

<p>And other common layers used in CNN today include:</p>

<ul>
  <li>
    <p><strong>Pooling layers</strong>: downsample and shrink the image. This can also be useful to prevent overfitting. This can implemented similarly to filters</p>

    <p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240419151647556.png" alt="image-20240419151647556" style="zoom: 33%;" /></p>
  </li>
  <li>
    <p><strong>Nonlinear activations</strong>: since convolution is still a linear operation, we still need nonlinear activation functions (e.g., RELU, GeLU, etc) to achieve better performance</p>
  </li>
</ul>

<p>Finally, the actual “classification task” is done by a few layers of FFNN:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240419152215639.png" alt="image-20240419152215639" style="zoom:50%;" /></p>

<p>So in this view, CNN are mostly used to perform feature extraction efficiently, and the last regular FFNN layers + softmax performs the actual classification.</p>

<h1 id="reinforcement-learning">Reinforcement Learning</h1>

<p>With both increasing computational power and complexity of robots, it is often desirable to learn models <strong>from data</strong> rather than derive them <strong>analytically</strong>. The idea is therefore to do RL from data.</p>

<p>But of course, <strong>data</strong> cannot solve everything:</p>

<ul>
  <li>Curse of dimensionality—robots can be <em>very high-dimensional systems</em></li>
  <li>We often only see data from a <em>small part of the C- or state space</em>
    <ul>
      <li>Probabilistic learning methods can help robot to infer missing information</li>
    </ul>
  </li>
  <li>Real robots may also need to also consider effects such as <em>friction</em></li>
  <li>To ensure sufficient richness in your data, may need <em>lots of exploration, artificial noise</em> while collecting data</li>
</ul>

<p>Additionally, <strong>learning algorithms</strong> may also need to consider, given the data:</p>

<ul>
  <li>there is often massive amounts of data coming through sensors -&gt; need to discern what is useful</li>
  <li>need fast, real-time planning/execution algorithms</li>
  <li>May want to incorporate prior knowledge, active learning by interacting with humans for data labeling</li>
  <li>real life are non-stationary systems: Time-dependent dynamics, changing environments</li>
</ul>

<h2 id="rl-basics">RL Basics</h2>

<p>We will go through RL quickly, assuming you are already familiar with most RL concepts. The key difference between SFT and RL is that the latter is learning through interaction/experience, whereas the former is fully offline.</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240426132750707.png" alt="image-20240426132750707" style="zoom: 33%;" /></p>

<p>Example RL tasks in robotics look like:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240426133124913.png" alt="image-20240426133124913" style="zoom: 50%;" /></p>

<h2 id="example-grid-world">Example: Grid World</h2>

<p>Consider the following setup</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240426134228685.png" alt="image-20240426134228685" style="zoom: 50%;" /></p>

<p>where:</p>

<ul>
  <li>
    <p><strong>States and actions:</strong> Agent can choose to move in one of four cardinal directions from a given state, except at terminal states</p>
  </li>
  <li>
    <p><strong>Transition function</strong> (motion model) $\Pr[s’\vert s,a]$: Probability distribution of successor states, given starting state and action. For example, it may be non-deterministic:</p>

    <p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240426134422646.png" alt="image-20240426134422646" style="zoom: 25%;" /></p>
  </li>
  <li>
    <p><strong>Reward function</strong>: $\pm1$ for terminal states; constant living reward (e.g., $0$) for all other transitions</p>
  </li>
</ul>

<p>And then you can define <strong>value functions and action value functions</strong> as:</p>

\[V^\pi(s) = \mathbb{E}_{\pi}\left[\sum_{t=0} \gamma^t r_t | s_0=s \right], \quad Q^\pi(s,a) = \mathbb{E}_{\pi}\left[\sum_{t=0} \gamma^t r_t | s_0=s, a_0=a \right]\]

<p>where $\gamma\in(0,1]$ can be used to: 1) avoid infinite value functions if all rewards are positive, and 2) models how human may not lookahead to much.</p>

<p>In the case of a grid world, we can directly <strong>find the optimal value function $V^<em>,Q^</em>$</strong>, and hence <strong>extract the optimal policy $\pi^*$​</strong>. The idea is to use Bellman’s optimality equation and iteratively run:</p>

\[Q(s,a) \gets \mathbb{E}_{s'}[R(s,a) + \gamma \max_{a'}Q(s',a')]\]

<p>visually, applying the equation above will <strong>change the values near the terminal states with non-zero reward first</strong>, and then slowly propagate to all the remaining states. Finally, after this converged to $Q^<em>$, we can extract $\pi^</em> = \arg\max_a Q^*(s,a)$​.</p>

<p>For DL methods, this will become:</p>

<ol>
  <li>sampling $(s,a,r)$​ observations</li>
  <li>update the $Q$ network using the equation above</li>
  <li>balance exploration-exploitation to select next action to do (typically $\epsilon$-greedy)
    <ul>
      <li>want to balance exploration with exploitation to avoid pure random walks</li>
    </ul>
  </li>
</ol>

<h2 id="deep-q-network">Deep Q-Network</h2>

<p>The idea is to use ConvNet + RL to play games like Atari. This can be done by modeling the ConvNet as $Q_\theta$ and:</p>

<ol>
  <li>
    <p>consider a loss function as:</p>

\[L_i(\theta_i) = \mathbb{E}[ (y_i - Q_{\theta_i}(s_t, a_t))^2]\]

    <p>for your network at the $i$-th iteration. Since there is no label/ground truth $Q^*$, you can use</p>

\[y_i = \mathbb{E}_{s'}[r + \gamma \max_a Q_{\theta_{i-1}}(s_{t+1},a)]\]

    <p>note that this is also an <strong>unbiased estimator</strong> of the optimal $Q^*$, if the above $Q_\theta$ has loss converges to zero.</p>
  </li>
  <li>
    <p>play the game while training your model with the loss above.</p>
  </li>
</ol>

<p>The general policy-iteration paradigm for DL therefore looks like:</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240426142646063.png" alt="image-20240426142646063" style="zoom:67%;" /></p>

<h1 id="imitation-learning">Imitation Learning</h1>

<p>Many specialized tasks (especially those pertaining to humans) are difficult to define, program, and generalize from scratch. The idea is then to start with imitation learning, before considering RL.</p>

<p>On this approach. there can be <strong>many different ways of obtaining demonstration data</strong></p>

<ul>
  <li>
    <p><strong>Kinesthetic teaching</strong>: Physical guidance of the robot.</p>

    <ul>
      <li>
        <p>i.e., actually forcing the robot (e.g., arms) to do stuff</p>

        <p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240426150527819.png" alt="image-20240426150527819" style="zoom:33%;" /></p>
      </li>
      <li>
        <p>No explicit physical correspondence is needed</p>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>Teleoperation</strong>: User has same perception as the robot.</p>

    <p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240426150555146.png" alt="image-20240426150555146" style="zoom:33%;" /></p>

    <ul>
      <li>Can train robots from a distance or remotely</li>
      <li>Difficult to perform low-level motion demonstrations</li>
    </ul>
  </li>
  <li>
    <p><strong>Imitation</strong>: Directly recording human motions</p>
    <ul>
      <li>Use of motion tracking systems, e.g. vision or wearable motion sensors</li>
      <li>Need to solve human-robot correspondences</li>
    </ul>
  </li>
</ul>

<p>With these data (typically ~hundreds of demonstrations)</p>

<blockquote>
  <p>Typically we learn <em>either policies, rewards/costs, or plans</em> from these demonstrations.</p>

  <ul>
    <li>note that if we try to learn underlying models or reward functions instead, this goes into the framework of <em>inverse reinforcement learning</em>. One motivation for this is that for some tasks,  the reward ($R^<em>$) is often more succinct and robust than optimal policy ($\pi^</em>$)</li>
    <li>if learning complex tasks, we try to break down them down into a sequence of sub-tasks or primitive actions—a plan</li>
    <li>Training a mapping going directly from raw pixels or <strong>observations to commands</strong> or actions is also known as <strong>end-to-end learning</strong></li>
  </ul>
</blockquote>

<p>For example</p>

<p><img src="/lectures/images/2024-06-02-COMS4733_Computational_Aspects_of_Robotics_part2/image-20240426151230376.png" alt="image-20240426151230376" style="zoom: 37%;" /></p>

<h2 id="challenges-of-real-world-rl">Challenges of Real World RL</h2>

<p>Practical challenges:</p>

<ul>
  <li>Discretization of continuous state and action spaces dramatically increases their dimensionality</li>
  <li>Real-world samples can be unreliable, <strong>expensive</strong>, and slow</li>
  <li>Robots must explore <strong>safely</strong>.</li>
  <li>Small modeling errors can lead to <strong>large error accumulation</strong>s in unstable tasks</li>
  <li><strong>Simulation bias</strong>—well-trained sim models may translate poorly to real systems</li>
</ul>]]></content><author><name></name></author><category term="2024@Columbia" /><summary type="html"><![CDATA[[toc]]]></summary></entry><entry><title type="html">COMS6998 Spoken Language Processing</title><link href="/lectures/2024@columbia/COMS6998_Spoken_Language_Processing.html/" rel="alternate" type="text/html" title="COMS6998 Spoken Language Processing" /><published>2024-06-02T00:00:00+00:00</published><updated>2024-06-02T00:00:00+00:00</updated><id>/lectures/2024@columbia/COMS6998_Spoken_Language_Processing</id><content type="html" xml:base="/lectures/2024@columbia/COMS6998_Spoken_Language_Processing.html/"><![CDATA[<h1 id="logistics-and-introduction">Logistics and Introduction</h1>

<p><strong>Syllabus</strong>:</p>

<ul>
  <li>Mainly its weekly reading + posts</li>
  <li>5% class participation (attendance at EoClass), 20% weekly post, and 75% from three HWs</li>
  <li>See for details <a href="https://www.cs.columbia.edu/~julia/courses/CS6998-24/syllabus24.html">cs.columbia.edu/~julia/courses/CS6998-24/syllabus24.html</a></li>
  <li>TA office hours:
    <ul>
      <li>Ziwei (Sara): CESPR714 M3-4pm</li>
      <li>Debasmirta: CESPR 714  TH2-4pm</li>
      <li>Yu-Wen Chen: Zoom FR 2-4pm</li>
    </ul>
  </li>
  <li>a very useful reference I found: <a href="https://speechprocessingbook.aalto.fi/index.html">Introduction to Speech Processing — Introduction to Speech Processing (aalto.fi)</a></li>
  <li>a very useful Praat scripting reference: <a href="https://www.fon.hum.uva.nl/praat/manual/Sound.html">Sound (uva.nl)</a></li>
  <li></li>
</ul>

<p><strong>Introduction</strong></p>

<ul>
  <li>
    <p>Spoken language processing = not only <strong>what</strong> you say, but also <strong>how</strong> you say it.</p>
  </li>
  <li>
    <p><strong>intonation contour</strong>: notice the difference between</p>

    <ul>
      <li>You’re going. (statement)</li>
      <li>You’re going? (question)</li>
    </ul>

    <p>and the fact that you can convey the two meaning <em>without explicitly saying it ends with <code class="language-plaintext highlighter-rouge">.</code> or <code class="language-plaintext highlighter-rouge">?</code></em></p>
  </li>
  <li>
    <p>by just listening to <em>how</em> a person is saying things, you can learn about his/hers personality, mental health, etc.</p>
  </li>
  <li>
    <p>current and past challenges in spoken language processing:</p>

    <ul>
      <li>e.g., “Do you live at <u>288 110th</u> street?” is different from just pronouncing the numbers as-is</li>
      <li>e.g., “They <u>city hall</u> <u>parking lot</u> was <u>chock full of cars</u>.” notice where <em>pause</em> are inserted between phrases.</li>
    </ul>
  </li>
</ul>

<h1 id="from-sounds-to-language">From Sounds to Language</h1>

<blockquote>
  <p><strong>Linguistic sounds</strong>: how are sounds produced, and what sounds are <em>shared by languages X and Y</em>?</p>
</blockquote>

<p>Motivation:</p>

<ul>
  <li>sometimes <em>sounds</em> you produce can affect your <em>thinking</em>. e.g. <code class="language-plaintext highlighter-rouge">ou</code> sounds “bigger and more expensive “ than <code class="language-plaintext highlighter-rouge">ee</code>. As a result, you <em>may</em> think “$2.33” sounds like a better deal than “$2.22”.</li>
  <li>sometimes how your lips <em>visually</em> move can affect what you think he/she is <em>saying</em>. e.g., the The McGurk Effect.</li>
</ul>

<p>Specifically, we will study in this section</p>

<ul>
  <li><strong>Auditory phonetics</strong>: the <strong>perception</strong> of speech sounds</li>
  <li><strong>Articulatory phonetics</strong>: the <strong>articulation</strong> of speech sounds</li>
  <li><strong>Acoustic phonetics</strong>: the <strong>acoustic</strong> features of speech sounds</li>
</ul>

<blockquote>
  <p>Some definitions</p>

  <ul>
    <li><strong>Phonemes</strong>: perceptually distinct units of sound</li>
    <li><strong>Phones</strong>: the phonetic representation of the phoneme we produce when we speak</li>
    <li><strong>Allophones</strong>: different ways of saying things but has the same meaning</li>
    <li><strong>Orthographic Representation</strong>: how to “spell” a sound. For example “sea, see, scene, receive, thief” all had [i] in it.
      <ul>
        <li>so a single sound may be represented differently in orthography = is orthography a good choice for English?</li>
      </ul>
    </li>
    <li><strong>Phonetic Symbol Sets</strong>: use things like International Phonetic Alphabet (IPA) to represent sounds = has a single character for each unique sound.
      <ul>
        <li>IPA as you have guessed, is quite large</li>
        <li>for example, “Xiao” would be “[ɕi̯ɑʊ̯]”</li>
      </ul>
    </li>
  </ul>
</blockquote>

<h2 id="articulatory-phonetics">Articulatory Phonetics</h2>

<p>How do you produce sounds? Each language is different, but typically multiple parts of your body:</p>

<p><img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240123165438730.png" alt="image-20240123165438730" style="zoom:33%;" /></p>

<p>In English, we further have:</p>

<ul>
  <li>Consonants: voiced or voiceless, but often with restriction/blockage of air flow</li>
  <li>Vowels: generally voiced with little restrictions. Variations in different vowels caused by factors such as ‘height of tongue’, ‘roundness of lips’</li>
</ul>

<p>More specifcally, <strong>vowels</strong> can be categorized into</p>

<p><img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240123165816669.png" alt="image-20240123165816669" style="zoom:33%;" /></p>

<p>For example:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">High Front or Back for [iy] and [uw]</th>
      <th>Low Front or Back [ae] and [aa]</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240123165851618.png" alt="image-20240123165851618" style="zoom:33%;" /></td>
      <td><img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240123165910451.png" alt="image-20240123165910451" style="zoom:33%;" /></td>
    </tr>
  </tbody>
</table>

<p>For <strong>consonants</strong>, two things define its type: <strong>place of articulation</strong> and <strong>manner of articulation</strong></p>

<p><img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240123170944935.png" alt="image-20240123170944935" style="zoom:33%;" /></p>

<blockquote>
  <p><strong>Coarticulation</strong>: one challenge is that things can be different depending on its phonetic context - a major issue in ASR</p>

  <ul>
    <li>e.g. place of articulation moves forward in “eight” v.s. “eighth”, due to different <em>adjacent</em> sounds</li>
  </ul>
</blockquote>

<h2 id="representations-of-sounds">Representations of Sounds</h2>

<p>We have ways to <strong>represent</strong> sounds (e.g., IPA) and to classify similar sounds. This is important, because it relates to how systems such as ASR, TTS (speech synthesis), Speech Pathology, Language/Speaker ID.</p>

<p>So how do we recognize sounds automatically?</p>

<ul>
  <li>
    <p>e.g., <em>use the relationship between representation and acoustics to identify speech automatically?</em></p>

    <p><img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240123172729045.png" alt="image-20240123172729045" style="zoom:33%;" /></p>

    <p>notice that vowels (purple) have higher amplitudes, and also note that these “shape” will <strong>change</strong> depending on what is pronounced before them.</p>
  </li>
  <li>
    <p>and interestingly, people (Nima Mesgarani) show that you could directly produce speech using brain signals</p>

    <p><img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240123173147396.png" alt="image-20240123173147396" style="zoom: 50%;" /></p>

    <p>i.e., think it in your brain and we can identify what you were thinking! (combining speech synthesis and brain interface!)</p>
  </li>
</ul>

<h2 id="reading-notes-for-lecture-1">Reading notes for Lecture 1</h2>

<p><strong>Key notes</strong> from <a href="http://www.cs.columbia.edu/~julia/courses/CS6998-23/28-Sounds2Language.pdf">Jurafsky &amp; Martin Chapter 28 (Chapters 1-3)</a></p>

<ul>
  <li>
    <p>earliest writing systems we know of (Sumerian, Chinese, Mayan) were mainly <strong>logographic</strong>: one symbol representing a whole word. But</p>

    <ul>
      <li>some symbols were also used to represent the <em>sounds</em> that made up words</li>
    </ul>
  </li>
  <li>
    <p>the idea that the spoken word is composed of <strong>smaller units of speech</strong> underlies algorithms for both <strong>speech recognition</strong> (transcribing waveforms into text) and <strong>text-to-speech</strong> (converting text into waveforms)</p>

    <ul>
      <li>but the difficulty is that a single letter (e.g., <code class="language-plaintext highlighter-rouge">p</code>) can represent very different sounds in different contexts</li>
    </ul>
  </li>
  <li>
    <p><strong>Phonetics</strong>: the study of the speech sounds</p>
  </li>
  <li>
    <p>We will represent the pronunciation of a word as a string of <strong>phones</strong> (see the transcription part). Examples look like</p>

    <p><img src=".//lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240120140432680.png" alt="image-20240120140432680" style="zoom:50%;" /></p>

    <p>where the standard representation is using the  International Phonetic Alphabet (IPA) symbols, but here we use the ARPAbet as it uses ACSII.</p>
  </li>
  <li>
    <p><strong>Articulatory phonetics</strong>: how these “phones” are pronounced by various organs in the mouth, throat, and nose</p>

    <p><img src=".//lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240120144029140.png" alt="image-20240120144029140" style="zoom:50%;" /></p>

    <ul>
      <li><strong>Consonants</strong> are made by restriction or blocking of the airflow in some way, and can be voiced or unvoiced</li>
      <li><strong>Vowels</strong> have less obstruction, are usually voiced, and are generally louder and longer-lasting than consonants.</li>
    </ul>
  </li>
  <li>
    <p>More specifics about consonants:</p>

    <ul>
      <li>
        <p>can group consonants into their <strong>point of maximum restriction</strong>, their place of articulation</p>
      </li>
      <li>
        <p>Consonants are also distinguished by <strong>how the restriction</strong> in airflow is made, for example, by a complete stoppage of air or by a partial blockage</p>

        <p><img src=".//lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240120145253251.png" alt="image-20240120145253251" style="zoom:50%;" /></p>

        <p>and the combination of how and where is usually sufficient to uniquely identify a consonant.</p>
      </li>
    </ul>
  </li>
  <li>
    <p>More specifics about vowels:</p>

    <ul>
      <li>
        <p>The three most relevant parameters for vowels are what is called vowel <strong>height</strong>, which correlates roughly with the height of the highest part of the tongue</p>

        <ul>
          <li>vowel frontness or backness, indicating whether this high point is toward the <strong>front</strong> or back <strong>of</strong> the oral tract and</li>
          <li>whether the shape of the lips is <strong>rounded</strong> or not</li>
        </ul>

        <p><img src=".//lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240120145634803.png" alt="image-20240120145634803" style="zoom:50%;" /></p>
      </li>
    </ul>
  </li>
  <li>
    <p>Consonants and vowels combine to make a <strong>syllable</strong></p>

    <ul>
      <li>
        <p>yes, there are rules of what constitutes a syllable, although practically everybody knows by trying to pronounce them</p>

        <p><img src=".//lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240120145952247.png" alt="image-20240120145952247" style="zoom:50%;" /></p>

        <p>where:</p>

        <ul>
          <li>initial consonants, if any, are called the <strong>onset</strong></li>
          <li>The rime, or rhyme, is the <strong>nucleus</strong> (vowel at the core of a syllable) plus <strong>coda</strong> (optional consonant following the nucleus)</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>Prosody</strong> is the study of the <strong>intonational and rhythmic aspects</strong> of language, and in particular the use of F0, energy, and duration to convey pragmatic, affective, or conversation-interactional meanings. On a high level:</p>

    <ul>
      <li>energy as the acoustic quality that we perceive as <strong>loudness</strong></li>
      <li>F0 as the <strong>frequency</strong> of the sound that is produced</li>
      <li>acoustic quality is what we hear as the <strong>pitch</strong> of an utterance.</li>
    </ul>

    <p>this is heavily used to <mark>convey affective meanings like happiness, surprise, or anger</mark>. For example, speakers make a word or syllable more <strong>salient</strong> in English by <em>saying it louder, saying it slower</em> (so it has a longer duration), or by <em>varying F0 during the word</em>, making it higher or more variable</p>
  </li>
  <li>
    <p>Prosodic Prominence: Accent, Stress and Schwa</p>

    <ul>
      <li>
        <p>Words or syllables that are prominent are said to bear (be associated with) a <strong>pitch accent</strong> (e.g., the underlined words below):</p>

        <p>“I’m a little <u>surprised</u> to hear it <u>characterized</u> as <u>happy</u>.”</p>
      </li>
      <li>
        <p>syllable that has <strong>lexical stress</strong> is the one that will be louder or longer if the word is accented. For example, the word <em>surprised</em> is stressed on its second syllable, not its first</p>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>Prosodic Structure</strong>: some words seem to group naturally together, while some words seem to have a noticeable break or disjuncture between them.</p>

    <ul>
      <li>an example we have seen earlier “They <u>city hall</u> <u>parking lot</u> was <u>chock full of cars</u>.”</li>
      <li>Automatically predicting prosodic boundaries can be important for tasks like TTS</li>
    </ul>
  </li>
  <li>
    <p>The <strong>tune</strong> of an utterance is the <strong>rise and fall of its F0</strong> over time.</p>
  </li>
  <li>
    <p>A very obvious example of tune is the difference between statements and yes-no questions in English</p>

    <table>
      <thead>
        <tr>
          <th style="text-align: center">a final F0 rise</th>
          <th style="text-align: center">a final drop in F0 (also called a final fall)</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td style="text-align: center"><img src=".//lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240120152033782.png" alt="image-20240120152033782" /></td>
          <td style="text-align: center"><img src=".//lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240120152134689.png" alt="image-20240120152134689" /></td>
        </tr>
      </tbody>
    </table>
  </li>
</ul>

<h1 id="acoustics-of-speech">Acoustics of Speech</h1>

<p>How do we automatically distinguish one pheome from speech, even if they sound similar. For example, how do we distinguish between “kill him” v.s. “bill him” <strong>only using sound</strong> (e.g., using spectrograms, see <a href="#Reading Notes for Lecture 2">Reading notes</a>)</p>

<p><img src=".//lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240127142226286.png" alt="image-20240127142226286" style="zoom:67%;" /></p>

<p><strong>Sound production</strong>:</p>

<ul>
  <li><strong>signal to noise ration (SNR)</strong>: sound produced might not always be people’s speech</li>
  <li><strong>harmonic to noise ratio (HNR)</strong>: ratio between periodic and a-periodic speech components. In particular, speech waveform that show <em>repeating patterns over time in distorted or unnatural speech</em></li>
</ul>

<p>What do we need to capture good speech data?</p>

<ul>
  <li>good recording conditions (quite space)</li>
  <li>close-talking microphone (right next to the bottom left of your lips)</li>
  <li>a good microphone that can capture at least 2 samples per cycle (to figure out the frequency)
    <ul>
      <li><strong>human</strong> hearing can <strong>discern up to 20k</strong>, but for studying speech, <strong>typically 16k-22k sampling rate</strong> is enough</li>
      <li>this probably also relates to how humans acuity is lower at higher frequency</li>
    </ul>
  </li>
</ul>

<p>Sampling errors:</p>

<ul>
  <li><strong>aliasing</strong>: different signals can become <em>indistinguishable</em> from one another <em>when they are sampled</em>
    <ul>
      <li>e.g., often happens when sound $&gt;$ nyquitst frequency, or when you <strong>quantized</strong> too much</li>
      <li>e.g., solutions include simply increase your sampling rate (or called <strong>resolution</strong>), or buy larger storage to store more bits per sample</li>
    </ul>
  </li>
  <li>speech file formats: mostly <code class="language-plaintext highlighter-rouge">wav</code>, and a useful tool is <code class="language-plaintext highlighter-rouge">SoX</code> (sound eXchange) that can convert between many formats</li>
</ul>

<p>Frequency:</p>

<ul>
  <li>
    <p><strong>pitch track</strong>: plotting F0 over time</p>

    <p><img src=".//lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240127134621161.png" alt="image-20240127134621161" style="zoom: 67%;" /></p>
  </li>
  <li>
    <p>how exactly is F0 determined? by definition: <mark>F0 approximate frequency of the (quasi-)periodic structure of voiced speech signals</mark>. This means if you <strong>zoom into any segment of speech wave</strong>, you will see some periodic pattern (originates from our vocal cord):</p>

    <p><img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240130175949133.png" alt="image-20240130175949133" style="zoom:77%;" /></p>

    <p>for exmaple, the F0 above is $F_0 = 1/0.01 \approx 100 \mathrm{Hz}$, where $T\approx 10\mathrm{ms}$ above. Of course, since these are produced by an organ, it’s not exactly periodic and have fluctuations. Specifically, the amount of variation in period length and amplitude are known respectively as <strong>jitter</strong> and <strong>shimmer</strong>.</p>
  </li>
  <li>
    <p>there are <strong>softwares that can automatically plot these</strong>, e.g. <code class="language-plaintext highlighter-rouge">Praat</code></p>

    <ul>
      <li>but note that it can contain errors, such as <strong>pitch doubling or halving</strong> (i.e., looks very high or low in the diagram, but we don’t perceive it as high)</li>
    </ul>

    <p><img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240213162658508.png" alt="image-20240213162658508" style="zoom:50%;" /></p>
  </li>
  <li>
    <p>difference between pitch and F0? Pitch is how human <em>perceives</em> the F0, and humans has lower acuity at higher frequency</p>

    <ul>
      <li>hence there is stuff like the <strong>mel scale</strong> to measure <strong>frequency</strong> (see <a href="#Reading Notes for Lecture 2">Reading notes</a>)</li>
      <li>the <strong>dB</strong> scale mostly measure **amplitude **(e.g., whisper is about 10dB, normal conversation is about 50-70dB)</li>
    </ul>
  </li>
</ul>

<p>How is HNR useful?</p>

<ul>
  <li>lower HNR indicates more noise in signal, often <strong>perceived as hoarseness and roughness</strong> (emotionally-wise)</li>
  <li>can also be used to discern pathological voice disorders</li>
</ul>

<p>More on <strong>visualizing waveform</strong>:</p>

<ul>
  <li>
    <p>fricative v.s. vowel, the latter more clearly articulated</p>

    <p><img src=".//lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240203222406009.png" alt="image-20240203222406009" style="zoom:50%;" /></p>
  </li>
  <li>
    <p>and we can also use libraries to get the <strong>spectrogram</strong> of a waveform (by doing Fourier transforms) and analyze from there, i.e. <mark>using the formants</mark> (see <a href="#Reading Notes for Lecture 2">Reading notes</a>)</p>

    <p><img src=".//lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240127142226286.png" alt="image-20240127142226286" style="zoom: 67%;" /></p>

    <p>but again, these formants will <strong>change</strong> <em>depending on the consonant contexts</em>.</p>
  </li>
  <li>
    <p>What’s the connection between the fundamental frequency $F_0$, and the formants $F_1, F_2, …$? if we consider a <strong>spectrum of a speech segment</strong> (i.e., the frequency-amplitude space after Fourier transform):</p>

    <p><img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240130181052358.png" alt="image-20240130181052358" style="zoom:77%;" /></p>

    <p>notice that <mark>F1, F2, ... are the frequencies of the amplitude peaks</mark> (i.e., the dark spots in the <strong>spectrogram</strong>), and they are all <strong>integer multiples of F0</strong>, which can be found by counting how frequent things peak here.</p>
  </li>
  <li>
    <p>useful library here include <code class="language-plaintext highlighter-rouge">MFCC</code> and <code class="language-plaintext highlighter-rouge">Praat</code>, which can basically give you every quantity mentioned above automatically</p>
  </li>
</ul>

<h2 id="reading-notes-for-lecture-2">Reading Notes for Lecture 2</h2>

<ul>
  <li>
    <p>acoustic analysis is going again back to sine and cosine functions:</p>

\[y = A * \sin(2\pi ft) = A * \sin(2\pi t / T)\]

    <p>and <strong>sound waves</strong> are basically the above due to the change in air pressure = compression and rarefaction of air molecules in a plane wave. For example:</p>

    <p><img src=".//lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240127133206320.png" alt="image-20240127133206320" style="zoom: 67%;" /></p>

    <p>how is this produced in reality? It’s an <strong>analog-to-digital conversion</strong> where:</p>

    <ol>
      <li>we <strong>sample</strong> `$\to$ sampling frequency. To accurately measure a wave, we must have at least two samples <em>in each cycle</em>.
        <ul>
          <li>this means the <strong>maximum measurable frequency</strong> is <strong>half</strong> of the sampling rate. For human speech, we would need 20,000 Hz sampling rate = measure <em>20,000 amplitudes per second</em></li>
        </ul>
      </li>
      <li>we <strong>quantize</strong> real value measurements into integers
        <ul>
          <li>for easier storage, we sometimes also compress them, e.g., using $\mu$​-law which is a log compression algorithm.</li>
        </ul>
      </li>
    </ol>
  </li>
  <li>
    <p>tie this back to articulatory phonetics:</p>

    <ul>
      <li>the frequency we record <strong>come from vibration of our vocal folds</strong></li>
      <li>so e<strong>ach major peak</strong> in Figure 28.9 corresponds to <strong>an opening of the vocal folds</strong></li>
    </ul>

    <p>then basically we are recording frequency of vocal folds vibration , which is called <mark>fundamental frequency</mark> of a wave form, often abbreviated as <mark>F0</mark>:</p>

    <p><img src=".//lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240127134621161.png" alt="image-20240127134621161" style="zoom: 67%;" /></p>

    <p>for example, in the middle plot above we show the <strong>F0 over time in a pitch track</strong> = plotting the frequency as a function of time.</p>
  </li>
  <li>
    <p>Similarly we can also plot (average) amplitude variation over time. But since directly averaging them you would get near zero everywhere, people typically use 1) <strong>root mean square amplitude</strong> 2) normalize it to <strong>human auditory threshold</strong>, measured in dB.</p>

\[\mathrm{Intensity} = 10 \log_{10} \frac{1}{NP_0} \sum_{i=1}^N x_i^2\]

    <p>visually:</p>

    <p><img src=".//lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240127135541495.png" alt="image-20240127135541495" style="zoom: 67%;" /></p>
  </li>
  <li>
    <p>human perceived <strong>pitch</strong> relates to <strong>frequency</strong>, but the difference is that:</p>

    <ul>
      <li>human hearings has different acuities for different frequencies</li>
      <li>mostly linear for low frequency below 1000Hz (can accurately distinguish), but logarithmically for high frequency.</li>
    </ul>

    <p>as a result, there is also a <mark>mel scale</mark>, where a unit of pitch is defined such that pair of sounds which are <mark>perceptually equidistant</mark> in pitch are separated by an equal number of mels.</p>
  </li>
  <li>
    <p>human perceived <strong>loudness</strong> corelates to <strong>power</strong>, but again</p>

    <ul>
      <li>humans have a greater resolution in the lower-power range</li>
    </ul>
  </li>
  <li>
    <p>phones can often be <strong>visually found by inspecting its waveform</strong>:</p>

    <p><img src=".//lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240127140724880.png" alt="image-20240127140724880" style="zoom:67%;" /></p>

    <p>notice that <mark>vowels are often voiced = have regular peaks in amplitudes</mark>.</p>
  </li>
  <li>
    <p>an alternative representation of the above is to use <mark>Fourier analysis</mark> to decompose a wave at any time using <strong>frequencies and amplitudes</strong> of the composite waves:</p>

    <table>
      <thead>
        <tr>
          <th style="text-align: center">Original Wave</th>
          <th style="text-align: center">Fourier Decomposition</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td style="text-align: center"><img src=".//lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240127141129784.png" alt="image-20240127141129784" /></td>
          <td style="text-align: center"><img src=".//lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240127141135949.png" alt="image-20240127141135949" /></td>
        </tr>
      </tbody>
    </table>

    <p>recall that since Fourier analysis can break <em>any smooth function $f(t)$</em> into a sum of sine/cosine waves:</p>

    <table>
      <thead>
        <tr>
          <th style="text-align: center">Original Wave</th>
          <th style="text-align: center">Fourier Decomposition</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td style="text-align: center"><img src=".//lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240127141424118.png" alt="image-20240127141424118" /></td>
          <td style="text-align: center"><img src=".//lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240127141430862.png" alt="image-20240127141430862" />1</td>
        </tr>
      </tbody>
    </table>

    <p>but why is this decomposition useful? It turns out <strong>peaks</strong> (e.g. around 930, 1860, and 3020Hz) are <mark>=characteristics of different phones</mark>.</p>
  </li>
  <li>
    <p>a yet another way of representing sound is using <strong>spectrograms</strong> (inspired by the finding above). In a spectrogram, we can plot all time, frequency, and amplitude by using a <strong>dark points to signify high amplitude</strong>:</p>

    <p><img src=".//lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240127142226286.png" alt="image-20240127142226286" style="zoom:67%;" /></p>

    <p>this is useful because:</p>

    <ul>
      <li>let each horizontal dark bar (or spectral peak) be called a <strong>formant</strong></li>
      <li>then F1 (first formant) of the first vowel (left) is at about 470Hz, much lower than the other two (at about 800 Hz)</li>
      <li>so again, since <strong>different vowel have different formants at characteristics places</strong> = spectrum can distinguish vowels from each other (typically just using F1 and F2 suffices)</li>
    </ul>
  </li>
  <li>
    <p>there are many online phonetic resources where we can use for computation work, here a few is highlighted</p>

    <ul>
      <li>online <strong>pronunciation dictionaries</strong> such as LDC</li>
      <li><strong>phonetically annotated corpus</strong>, a collection of waveforms hand-labeled with the corresponding string of phones</li>
    </ul>
  </li>
</ul>

<h1 id="tools-for-speech-analysis">Tools for Speech Analysis</h1>

<p><strong>Praat</strong>: a general purpose speech tool for</p>

<ul>
  <li>editing, segmentation and labeling sounds</li>
  <li>can also create plots!</li>
</ul>

<p>Assuming you have already gone through the tutorials (record, analysis, and save). By default, viewing a sound file should also give you a spectrogram</p>

<p><img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240206162945328.png" alt="image-20240206162945328" style="zoom:33%;" /></p>

<p>and basically from the top menu bar, you can analyze information such as “maximum pitch”.</p>

<p><strong>By comparing the analysis between different files</strong>, you could find:</p>

<ul>
  <li>maximum pitch of male voice is much lower than that of females</li>
  <li>intensity for whispering is lower than not whispering</li>
  <li>F0 contour rises at the end for yes or no question</li>
  <li>etc.</li>
</ul>

<p><strong>You can also manipulate your sound</strong> using the <code class="language-plaintext highlighter-rouge">manipulation</code> option from the objects window. <em>For example</em>, changing the pitch and duration (speed) of the last part of the “My mama lives in Memphis”:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Getting the manipulation object</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240218140822702.png" alt="image-20240218140822702" style="zoom: 50%;" /></td>
    </tr>
  </tbody>
</table>

<p>Then simply drag and move manipulatable dots using or you can add them (using the menu bar on top)</p>

<table>
  <thead>
    <tr>
      <th>Normal Sound</th>
      <th>Manipulating to get a Y and N question</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240206174144135.png" alt="image-20240206174144135" /></td>
      <td><img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240206174048019.png" alt="image-20240206174048019" /></td>
    </tr>
  </tbody>
</table>

<p>For more details, refer to Week 4 on this syllabus: <a href="https://www.cs.columbia.edu/~julia/courses/CS6998-24/syllabus24.html">cs.columbia.edu/~julia/courses/CS6998-24/syllabus24.html</a></p>

<h2 id="scripting-in-praat">Scripting in Praat</h2>

<p>The main reference is <a href="https://www.fon.hum.uva.nl/praat/manual/Sound.html">Sound (uva.nl)</a>, but some generic note is you can “translate” clicking in Praat to scripting by, for example:</p>

<p>Obtain mean intensity:</p>

<ol>
  <li>
    <p>Get an intensity object:</p>

    <p><img src=".//lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240217172854231.png" alt="image-20240217172854231" style="zoom:50%;" /></p>
  </li>
  <li>
    <p>query for intensity min:</p>

    <table>
      <thead>
        <tr>
          <th style="text-align: center">Query Command</th>
          <th style="text-align: center">Setting/Arguments</th>
          <th style="text-align: center">Results</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td style="text-align: center"><img src=".//lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240217173020439.png" alt="image-20240217173020439" style="zoom: 80%;" /></td>
          <td style="text-align: center"><img src=".//lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240217173033062.png" alt="image-20240217173033062" /></td>
          <td style="text-align: center"><img src=".//lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240217173038158.png" alt="image-20240217173038158" /></td>
        </tr>
      </tbody>
    </table>
  </li>
</ol>

<p>The above would translate to the following commands in <code class="language-plaintext highlighter-rouge">python</code>. Note that the arguments to the <code class="language-plaintext highlighter-rouge">call</code> function are basically the <strong>same ones you see in the <code class="language-plaintext highlighter-rouge">Settings</code> pop up window above.</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">parselmouth</span>
<span class="kn">from</span> <span class="nn">parselmouth.praat</span> <span class="kn">import</span> <span class="n">call</span>

<span class="k">def</span> <span class="nf">extract_features_from_file</span><span class="p">(</span><span class="n">wav_file_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">transcriptions</span><span class="p">:</span> <span class="n">Dict</span><span class="p">):</span>
    <span class="n">sound_obj</span> <span class="o">=</span> <span class="n">parselmouth</span><span class="p">.</span><span class="n">Sound</span><span class="p">(</span><span class="n">wav_file_path</span><span class="p">)</span>
    <span class="n">data_dict</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="c1">### intensity analysis
</span>    <span class="n">intensity_obj</span> <span class="o">=</span> <span class="n">call</span><span class="p">(</span><span class="n">sound_obj</span><span class="p">,</span> <span class="s">"To Intensity"</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="s">"yes"</span><span class="p">)</span>
    <span class="n">mean_intensity</span> <span class="o">=</span> <span class="n">call</span><span class="p">(</span><span class="n">intensity_obj</span><span class="p">,</span> <span class="s">"Get mean"</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="s">"energy"</span><span class="p">)</span>
    <span class="n">max_intensity</span> <span class="o">=</span> <span class="n">call</span><span class="p">(</span><span class="n">intensity_obj</span><span class="p">,</span> <span class="s">"Get maximum"</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="s">"Parabolic"</span><span class="p">)</span>
    <span class="n">min_intensity</span> <span class="o">=</span> <span class="n">call</span><span class="p">(</span><span class="n">intensity_obj</span><span class="p">,</span> <span class="s">"Get minimum"</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="s">"Parabolic"</span><span class="p">)</span>
    <span class="n">stdev_intensity</span> <span class="o">=</span> <span class="n">call</span><span class="p">(</span><span class="n">intensity_obj</span><span class="p">,</span> <span class="s">"Get standard deviation"</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">data_dict</span><span class="p">[</span><span class="s">"Mean Intensity"</span><span class="p">]</span> <span class="o">=</span> <span class="n">mean_intensity</span>
    <span class="n">data_dict</span><span class="p">[</span><span class="s">"Max Intensity"</span><span class="p">]</span> <span class="o">=</span> <span class="n">max_intensity</span>
    <span class="n">data_dict</span><span class="p">[</span><span class="s">"Min Intensity"</span><span class="p">]</span> <span class="o">=</span> <span class="n">min_intensity</span>
    <span class="n">data_dict</span><span class="p">[</span><span class="s">"Sd Intensity"</span><span class="p">]</span> <span class="o">=</span> <span class="n">stdev_intensity</span>
    
    <span class="c1"># other code omitted
</span></code></pre></div></div>

<h1 id="analyzing-speech-prosody">Analyzing Speech Prosody</h1>

<blockquote>
  <p>Prosody is the study of the elements of speech that aren’t phonetic segments (e.g. vowels and consonants) and is concerned with <strong>the way speech sounds</strong>.</p>
</blockquote>

<p>Differences in <strong>how people produce a speech</strong> influence how we <strong>interpret it</strong> (i.e., semantic meanings). Therefore, building a good <strong>prosodic model</strong> can be very useful for:</p>

<ul>
  <li>improving text-to-speech synthesis</li>
  <li>improve speech recognition and understanding</li>
  <li>etc.</li>
</ul>

<p>Some <strong>challenges</strong> in building a good prosodic model:</p>

<ul>
  <li>
    <p>naively <strong>using a pitch contour directly</strong> = people could have spoke in different pitches = <strong>difficult to represent similarities between contours</strong></p>

    <p><img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240213161904138.png" alt="image-20240213161904138" style="zoom:33%;" /></p>
  </li>
  <li>
    <p>how about just annotating them with <strong>arrows and capital letters</strong>?</p>

    <p><img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240213161949795.png" alt="image-20240213161949795" style="zoom:33%;" /></p>

    <p>but this is too generic: it doesn’t capture full contours or type of pitch accents</p>
  </li>
</ul>

<p>before we go to modern systems such as TOBI, we need to discusst some definitions</p>

<blockquote>
  <p>Recall that:</p>

  <ul>
    <li><strong>Prominence/Pitch Accent</strong>: making a word or syllable “stand out”</li>
    <li><strong>Perceived Disjuncture</strong>: pauses during the speech, for instance used to <strong>structure information</strong> (e.g., group words into regions)</li>
  </ul>
</blockquote>

<h2 id="tone-sequence-models">Tone Sequence Models</h2>

<p>How we annotate prosody today:</p>

<table>
  <thead>
    <tr>
      <th>British School</th>
      <th>American School (we will focus on this)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240213163203512.png" alt="image-20240213163203512" style="zoom:50%;" /></td>
      <td><img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240213163314057.png" alt="image-20240213163314057" style="zoom:50%;" /></td>
    </tr>
  </tbody>
</table>

<blockquote>
  <p>On a high level, the American school consider:</p>

  <ul>
    <li><mark>accents</mark> (if a particular word is prominent)</li>
    <li><mark>boundary tones</mark> (if the entire phrase is prominent)</li>
    <li><mark>phrase accents</mark> (if part of a phrase is prominent)</li>
    <li>and different ways to pause (<mark>break index</mark>), etc.</li>
  </ul>
</blockquote>

<p>The American school became popular since the 1980 thesis from Pierrehumbert, where <strong>how human produces speech = transitions in the state diagram below</strong>:</p>

<p><img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240213163716721.png" alt="image-20240213163716721" style="zoom:50%;" /></p>

<p>In the 1991-94, <mark>there comes the TOBI system</mark> that combined the above and other prior work with the goal of</p>

<ul>
  <li>Devise common labeling scheme for Standard American English that is robust and reliable</li>
  <li>Promote collection of large, prosodically labeled, <strong>shareable</strong> corpora</li>
</ul>

<blockquote>
  <p>In TOBI, prosody is</p>

  <ul>
    <li>inherently <mark>categorical</mark> in labeling prosody</li>
    <li>basically describes <strong>high (H)</strong> and <strong>low (L)</strong> toes associated with events such as pitch accents, phrase accents, and boundary tones</li>
    <li><strong>break indices</strong> to describe when you pause, and the degree/length of the pause</li>
  </ul>
</blockquote>

<p>On a high level, TOBI annotates the F0 contour with four tiers:</p>

<ol>
  <li><strong>orthographic</strong>: annotate the actual words that are said</li>
  <li><strong>break-index:</strong> pauses and how long is the pause</li>
  <li><strong>Tonal Tier</strong>: all accents (prominence)  including pitch accents, phrase accents, boundary tones</li>
  <li><strong>Miscellaneous Tie</strong>r:  disfluencies, laughter, etc.</li>
</ol>

<h3 id="tobi-pitch-accent-types">TOBI Pitch Accent Types</h3>

<p>Words can be accented/deaccented in different ways</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Accent Contour</th>
      <th style="text-align: center">Meaning</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240213164608183.png" alt="image-20240213164608183" style="zoom: 33%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240213164643303.png" alt="image-20240213164643303" style="zoom: 33%;" /></td>
    </tr>
  </tbody>
</table>

<p>An example</p>

<p><img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240213164957991.png" alt="image-20240213164957991" style="zoom:50%;" /></p>

<h3 id="prosodic-phrase-and-phrase-ending-in-tobi">Prosodic Phrase and Phrase Ending in TOBI</h3>

<p>Combined we can describe an entire phrase -&gt; combined we can describe accents in an entire sentence.</p>

<p>For instance, the rows indicates the <strong>accent to start something</strong>, and columns indicate <strong>accent in the middle/ending</strong>.</p>

<p><img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240213170115673.png" alt="image-20240213170115673" style="zoom: 33%;" /></p>

<p><img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240213170125037.png" alt="image-20240213170125037" style="zoom: 33%;" /></p>

<p>Examples include</p>

<ul>
  <li>(H*; L-L%) “I (up) like you (down)”</li>
  <li>(L*; L-L%) “Amelia.”</li>
  <li>(L* + H;  L - H%) “A (low) me (high) li (low) a (up)”</li>
</ul>

<p>A full example with a sentence (note that <mark>no label for a word = deaccented/no accent</mark>)</p>

<p><img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240213170426348.png" alt="image-20240213170426348" style="zoom:50%;" /></p>

<blockquote>
  <p>Although it might seem “subjective” to decide when there is an accent and how its accented, but it turns out:</p>

  <ul>
    <li>88% agreement on presence/absence of tonal category</li>
    <li>81% agreement on category label</li>
    <li>91% agreement on break indices to within 1 level</li>
  </ul>

  <p>so <strong>after some training this should be pretty robust/intuitive!</strong></p>
</blockquote>

<h2 id="autobi">AuTOBI</h2>

<p>Somebody also built a way to <strong>automatically</strong> annotate a voice track with TOBI. Basically it identifies pitch accents and boundaries with high accuracy using many acoustic-prosodic features.</p>

<p><strong>Input you will give:</strong></p>

<ul>
  <li>Time-aligned word boundaries (human or automatically done)</li>
  <li>a <code class="language-plaintext highlighter-rouge">.wav</code> file of the speech</li>
  <li>some previously trained AuToBI models (e.g. for different language, trained on different corpus)</li>
</ul>

<p><strong>Output</strong></p>

<ul>
  <li>TOBI tones and break indicies</li>
  <li>confidence scores as well</li>
</ul>

<p>An example</p>

<p><img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240213171728296.png" alt="image-20240213171728296" style="zoom: 33%;" /></p>

<h2 id="other-prosodic-models">Other Prosodic Models</h2>

<p>There are <strong>many other ways to model prosody and analyze them</strong>.</p>

<ul>
  <li>many models are developed for database retrieval, phonological analysis and text-to-speech synthesis</li>
  <li>How can we extract information from large speech corpora that go beyond pitch, intensity, speaking rate?</li>
  <li>How can we analyze the way subjects convey different kinds of information?</li>
  <li>etc.</li>
</ul>

<h2 id="reading-notes-for-lecture-4">Reading Notes for Lecture 4</h2>

<h3 id="analyzing-speech-prosody-1">Analyzing Speech Prosody</h3>

<p>See PDF at <a href="https://www.cs.columbia.edu/~julia/papers/conv.pdf">conv.dvi (columbia.edu)</a></p>

<blockquote>
  <p>The <strong>TOBI (Tones and Break Indices) annotation system</strong> is a tool used for marking intonation and prosodic structure in spoken language. TOBI provides a <mark>standardized</mark> way to annotate speech, facilitating the study of how intonation patterns affect meaning, signal sentence structure, and express speaker attitudes.</p>
</blockquote>

<p>It consists of four tiers for <mark>labeling the F0 contour</mark> of a speech:</p>

<ol>
  <li>
    <p>an orthographic tier</p>

    <ul>
      <li>an orthographic word = one standalone English word</li>
      <li>transcription of orthographic words done at the <strong>final segment of the word</strong> = the right edge</li>
      <li>some considerations here include: whether or not to annotate pauses such as “er”,  “mm”, “uh”, etc.</li>
    </ul>
  </li>
  <li>
    <p>a tone tier: we mark two type of events</p>

    <ul>
      <li>pitch events associated with <strong>intonational boundaries</strong> (phrasal tones)
        <ul>
          <li>assigned at every intermediate phrase</li>
          <li>L- or H- <strong>phrase accent</strong>, which occurs at an intermediate phrase boundary</li>
          <li>L% or H% <strong>boundary tone</strong></li>
          <li>%H high <strong>initial boundary tone</strong> = phrase that begins relative high in the speaker’s pitch range</li>
          <li>example include “H-H%” in a yes-no question, and “L-L%” for a full intonation phrase with a L accent ending its final phrase and a L% boundary tone falling to a point low in pitch</li>
        </ul>
      </li>
      <li>pitch events associated with <strong>accented syllabus</strong> (pitch accent)
        <ul>
          <li>marked at every <strong>accented syllable</strong></li>
          <li>H* peak accent = high pitch range for the speaker</li>
          <li>L* low accent</li>
          <li>L*+H scooped accent = low taget on the accented syllable immediately followed by a sharp rise</li>
          <li>L+H* rising peak  accent = a high peak target on the accented syllable preceded by a sharp rise from a valley</li>
          <li>H+!H* a clear step down onto the accented syllable…</li>
        </ul>
      </li>
      <li>examples include:</li>
    </ul>

    <table>
      <thead>
        <tr>
          <th style="text-align: center">low boundary tone</th>
          <th style="text-align: center">yes-no question</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240211203311541.png" alt="image-20240211203311541" style="zoom: 67%;" /></td>
          <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240211203518456.png" alt="image-20240211203518456" style="zoom: 67%;" /></td>
        </tr>
      </tbody>
    </table>

    <p>other variants of <strong>phrasal</strong> accents are shown in</p>

    <p><img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240211203838494.png" alt="image-20240211203838494" /></p>

    <p>examples of <strong>syllable</strong> accents:</p>

    <p><img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240211203906834.png" alt="image-20240211203906834" /></p>
  </li>
  <li>
    <p>a break-index tier</p>

    <ul>
      <li>break indices are to be marked at the right edges of words transcribed in the Orthographic tier. All junctures have an explicity break index value.</li>
      <li><strong>break-index values</strong> include:
        <ul>
          <li>“0” for clear phonetic marks of clitic groups (e.g., “0” between “Did” and “you” indicating palatalization)</li>
          <li>“1” for most phrase-medial word boundaries (e.g., a mere word boundary between “you” and “want”)</li>
          <li>“2” strong disjuncture due to a pause</li>
          <li>“3” intermediate intonation phrase boundary: “a single phrase tone affecting the region from the last pitch accent to the boundary”</li>
          <li>“4” full intonation phrase boundary (e.g., “4” at the end of a sentence.)</li>
        </ul>
      </li>
      <li>(in practice, its frequently “0” = no juncture, “1” normal pauses between words. See section <a href="#Tone-Sequence-Models">Tone Sequence Models</a> for more example)</li>
      <li>if you are uncertain, use “-“ (e.g., “2-“ means uncertainty between “2” and “1”)</li>
      <li><strong>disfluencies</strong> are indicated by “p”, meaning an audible hesitation. (e.g., “3p”)</li>
    </ul>
  </li>
  <li>
    <p>a miscellaneous tier, used for <strong>comments or markings of laughter, disfluencies, etc.</strong></p>

    <ul>
      <li>
        <p>labels should be applied at the <em>temporal beginnings and endings by</em>:</p>

        <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>event&lt; ... event&gt;
</code></pre></div>        </div>

        <p>for example, a period of laughter plus speech (<code class="language-plaintext highlighter-rouge">...</code>) looks like:</p>

        <pre><code class="language-wave">laughter&lt; ... laughter&gt;
</code></pre>
      </li>
    </ul>
  </li>
</ol>

<h3 id="pragmatics-and-prosody">Pragmatics and Prosody</h3>

<p><strong>Variation in prosody (i.e., intonation)</strong> can influence the interpretation of languages. This section discusses aspects of prosodic variation (e.g., when and where intonation changes) and pragmatic meaning that have been explored by researchers.</p>

<p>To achieve this, <strong>many conventions for describing prosodic variation</strong> has been developed = can easily compare across researchers</p>

<ul>
  <li><strong>continuous descriptions</strong> focus on describing the F0 contour</li>
  <li><strong>categorical systems</strong> describes prosodic events as tokens from a given inventory of prosodic phenomena. Example include <strong>TOBI</strong>.</li>
</ul>

<p>TOBI annotations often have some interpretations:</p>

<ul>
  <li>H* accents of an <strong>accented (prominent) word</strong> in a declarative sentence = the accented item is <mark>new information</mark></li>
  <li>L+H* accents can be used to produce a sense of <mark>contrast</mark></li>
  <li>and more</li>
</ul>

<p>research on the <strong>prosody-syntax interface</strong> = can these two affect each other?</p>

<ul>
  <li>
    <p>how prosodic phrases divide an utterance into meaningful chunks? Can this aid syntactic parsing?</p>
  </li>
  <li>
    <p>useful in resolving syntactic disambiguation, such as:</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>VP-attachment: Anna frightened the woman | with the gun (Anna held the gun)
NP-attachment: Anna frightened | the woman with the gun (the woman held the gun)
</code></pre></div>    </div>

    <p>While prosodic variation can disambiguate syntactically ambiguous utterances,  <strong>evidence that it does so reliably is mixed</strong>.  Speakers often  manage to convey the distinctions illustrated above without employing particular prosodic means.</p>
  </li>
  <li>
    <p>this relationship exists in many languages</p>
  </li>
</ul>

<p><strong>Prosodic</strong> prominence and phrasing can also influence the <strong>semantic interpretation</strong> of  utterances.</p>

<ul>
  <li>
    <p>signal <mark>focus</mark>, define the scope of <mark>negation</mark>, quantification, and  modals, and influence the interpretation of presupposition</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>DOGS must be carried
dogs must be CARRIED
</code></pre></div>    </div>

    <p>being a sign on a British train in 1967 confused people that every trainer should have a dog and carry them.</p>
  </li>
  <li>
    <p><strong>reference resolution</strong> = pronouns may be interpreted differently depending upon whether they are prominent  or not, in varying contexts. For instance:</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>John called Bill a Republican and then he insulted him
John called Bill a Republican and then HE insulted HIM
</code></pre></div>    </div>

    <p>With both deaccented, the likely referent of he is John and him is Bill, but if both are accented, the preferred referents of each are switched.</p>
  </li>
</ul>

<p><strong>Prosodic</strong> can indicate some <strong>discourse phenomena</strong> (i.e., extract meta information from a conversation)</p>

<ul>
  <li>
    <p><strong>information</strong> - such as focus of attention, <mark>topic/comment</mark>, theme/rheme, given/new - is  often correlated with <strong>variation in accent or phrasing</strong></p>
  </li>
  <li>
    <p>signaling <strong>focus of attention and contrast</strong>: not only that prosodic prominence can signal focus but that inappropriate deaccenting of items in focal contexts or accenting of items in non-focal contexts show differences  in brain activity in ERP experiments with Dutch speakers.</p>
  </li>
  <li>
    <p>conveying information about <strong>discourse topic</strong>: in task-oriented monologues, speakers referred to local topics with deaccented pronominal expressions, and accented, full NPs otherwise</p>
  </li>
  <li>
    <p>distinguishing <strong>new/old</strong> information: an expression may be prosodically marked as given (i.e., old information) by deaccenting</p>
  </li>
  <li>
    <p>convery <strong>discourse structure</strong> by varying pitch range, pausal duration between phrases, and speaking rate. For instance,  it has been found that phrases beginning <em>new topics are begun in a wider pitch range</em>, are preceded by a longer  pause, and are louder and slower than other phrases;</p>
  </li>
  <li>
    <p>there is considerable evidence that <strong>full intonational</strong> contours can, in the appropriate context, <strong>signal syntactic mood, speech act, belief, or emotion</strong></p>

    <ul>
      <li>For example, the L*H L-H% contour may convey uncertainty</li>
    </ul>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>A: Did you feed the animals?
B: I fed the L<span class="k">*</span>+H GOLDFISH L-H% <span class="o">(</span>is that what you meant?<span class="o">)</span>
</code></pre></div>    </div>
  </li>
</ul>

<p>See PDF as <a href="https://www.cs.columbia.edu/~julia/papers/Chapter_28.pdf">cs.columbia.edu/~julia/papers/Chapter_28.pdf</a></p>

<h1 id="text-to-speech-analysis">Text-To-Speech Analysis</h1>

<blockquote>
  <p><strong>Requirements</strong> for a TTS system:</p>

  <ul>
    <li>
      <p>Front End: pronounciation modeling; text normalization; intonation</p>
    </li>
    <li>
      <p>Backend: waveform production</p>
    </li>
  </ul>
</blockquote>

<p>For example:</p>

<p><img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240220163039713.png" alt="image-20240220163039713" style="zoom:50%;" /></p>

<p>And there are many <strong>issues</strong> and <strong>challenges</strong>:</p>

<ul>
  <li><strong>disambiguation</strong> in context: “bass”, “reading” (e.g., “Reading is the place he hated most” is pronounced as “reding”)
    <ul>
      <li>this can be done with Letter-to-Sound Rules or even Pronunciation Dictionary</li>
      <li>or learn from data</li>
    </ul>
  </li>
  <li><strong>text normalization</strong> issues: “The <u>NAACP</u> just elected a new president.” is pronounced as “N double A CP”</li>
  <li>sentence and phrase <strong>break</strong>. You think you can just use punctuations, but what about “234-5682”?
    <ul>
      <li>traditional: hand-built rules</li>
      <li>current approach: machine learning on large labeled corpus</li>
    </ul>
  </li>
  <li>assigning pitch contours: in reality no one knows how to assign complex varieties of how human talks
    <ul>
      <li>e.g., with just “.”’ = declarative contour, wh-question v.s. “?” = yes-no-question contour is doable now</li>
      <li>but in reality people can put accent everywhere</li>
    </ul>
  </li>
</ul>

<h2 id="more-on-waveform-generation">More on Waveform Generation</h2>

<p>They are many types of approaches today:</p>

<ul>
  <li>(early days) Articulatory Synthesis: Model the actual movements of articulators and acoustics of vocal tract</li>
  <li>(early days) Formant Synthesis: Start with acoustics, create rules/filters to create each formant (i.e., produce formants for each group)
    <ul>
      <li>the DECtalk system that Stephen Hawking use</li>
    </ul>
  </li>
  <li><strong>Concatenative Synthesis</strong>: Diphone or Unit Selection using databases to store speech segments (i.e., select from database + glue the waveforms)
    <ul>
      <li>this is actually used a lot in commercial products until late 1990s</li>
      <li>directly using this produces a speech that is <em>not very smooth</em>. How do we do post-processing on the output?</li>
    </ul>
  </li>
  <li><strong>Parametric Synthesis:</strong> ML-based learning methods
    <ul>
      <li>used by SIRI in early days</li>
    </ul>
  </li>
  <li><strong>End2End Models</strong></li>
</ul>

<h3 id="concatenative-sythesis">Concatenative Sythesis</h3>

<p>There are two ways to do this:</p>

<ul>
  <li><strong>diphone synthesis</strong>: every sound/unit is a diphone (two phones)
    <ul>
      <li>all you need is a collection of recording for all possible diphones</li>
      <li>then you just fetch the diphones and concatenate them to produce speech</li>
      <li>intelligible, but not very natural/continuous</li>
    </ul>
  </li>
  <li><strong>unit selection synthesis</strong>: use larger units than diphone
    <ul>
      <li>not only diphone, but also record common ones and common phrases</li>
      <li>use dynamic programming to search to find best <em>sequence</em> of units, and then concatenate them</li>
      <li>better than diphone synthesis since you are <em>joining less disjunct chunks</em></li>
    </ul>
  </li>
</ul>

<p>Visually, diphone synthesis could cut at <code class="language-plaintext highlighter-rouge">eh</code> and join things:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Example Diphone 1</th>
      <th style="text-align: center">Example Diphone 1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240220165911759.png" alt="image-20240220165911759" style="zoom: 67%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240220165917452.png" alt="image-20240220165917452" style="zoom: 67%;" /></td>
    </tr>
  </tbody>
</table>

<p>For unit synthesis, the challenge is how to find the unit that <strong>best</strong> matches the desired synthesis specification. What does best mean here?</p>

<ul>
  <li><strong>Target cost:</strong> Find closest match in terms of
    <ul>
      <li>Phonetic context</li>
      <li>F0, stress, phrase position</li>
    </ul>
  </li>
  <li><strong>Join cost:</strong> Find best join with neighboring units
    <ul>
      <li>Matching formants + other spectral characteristics</li>
      <li>Matching energy</li>
      <li>Matching F0</li>
    </ul>
  </li>
</ul>

<p>and more. The end goal is to get a better <strong>prosody selection</strong>. However, this is good only when the database is large and diverse enough:</p>

<ul>
  <li>This has bad performance <strong>when no good match in database</strong></li>
  <li>Hard to control the overall prosody/vary speaker identity</li>
</ul>

<h3 id="parametric-synthesis">Parametric Synthesis</h3>

<p>The idea is to use ML to generate acoustic features:</p>

<ul>
  <li><strong>Hidden Markov Model Synthesis</strong> (good in the early days)
    <ul>
      <li>predict the acoustic property of each phone in each context</li>
      <li>a best non-neural parametric system</li>
    </ul>
  </li>
  <li><strong>Neural Net Synthesis</strong> (many modern TTS systems)
    <ul>
      <li>can capture more complex relationships</li>
      <li>began to overcome naturalness issues</li>
    </ul>
  </li>
</ul>

<p>An example of NN systhesis approach:<strong>Merlin and Neural Net Synthesis</strong>: use NN to predict acoustic <strong>features</strong>, and use a backend to generate waveforms</p>

<p><img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240220171014666.png" alt="image-20240220171014666" /></p>

<ul>
  <li>features for each phone include: “Current phone; Surrounding phones;  Position in syllable/word/sentence; Stress; …”</li>
  <li>so this NN is only doing the frontend. It is not an end-to-end model.</li>
</ul>

<p>Problem: not end-to-end means error can accumulate!</p>

<h3 id="end-to-end-models">End-to-End Models</h3>

<p>Directly generate waveforms from text:</p>

<ul>
  <li>
    <p>even more natural, and used in <strong>many TTS systems today</strong></p>
  </li>
  <li>
    <p>but also require a lot of training data</p>
  </li>
  <li>
    <p>examples include WaveNet (based on CNN), Tacrotron (based on Transformer)</p>

    <p><img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240220171506518.png" alt="image-20240220171506518" style="zoom:77%;" /></p>
  </li>
</ul>

<p>But why was Tacrotron so good?</p>

<ul>
  <li>Autoregression is very useful: each new waveform is <strong>conditioned on previous context</strong></li>
  <li>Neural nets are mostly better at learning <strong>contextual</strong> features</li>
  <li>Attention mechanism: Only minor improvements</li>
</ul>

<p><strong>Problems</strong> with this approach:</p>

<ul>
  <li>losing low-level control as we let the model do everything</li>
  <li>need large data and large model</li>
</ul>

<h2 id="producing-trustworthy-voices">Producing Trustworthy Voices</h2>

<p>The second part of the lecture was about <strong>how to produce</strong> trustworthy speech, and <strong>how human perceive</strong> trustworthiness in speech.</p>

<p>Some studies that does this include <strong>synthesizing speech + putting online survey to have people rate them</strong></p>

<ul>
  <li>use STRAIGHT toolkit in Matlab, which allows you to manipulate sound</li>
  <li>specifically considered speech stimulus in 5 parameters:
    <ul>
      <li>F0, frequency, spectro-temporal density, aperiodicity</li>
    </ul>
  </li>
  <li>manipulate and combine parameters</li>
  <li><em>only focus on the producing the word: “hello”</em></li>
</ul>

<p>Some interesting results found were:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Overall Features</th>
      <th style="text-align: center">Red is rated as more trustworthy</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240220172408514.png" alt="image-20240220172408514" style="zoom: 23%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240220172905460.png" alt="image-20240220172905460" style="zoom: 33%;" /></td>
    </tr>
  </tbody>
</table>

<p>The more latest approach is that you can SOTA TTS model (<a href="https://docs.aws.amazon.com/polly/latest/dg/what-is.html">Amazon Polly</a>) + voice manipulation (<a href="https://docs.aws.amazon.com/polly/latest/dg/ssml.html">Generating Speech from SSML Documents</a>) and meausure <strong>longer speeches</strong>:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">High level features</th>
      <th style="text-align: center">Lower level features</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240220174128354.png" alt="image-20240220174128354" style="zoom:40%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240220174317228.png" alt="image-20240220174317228" style="zoom:23%;" /></td>
    </tr>
  </tbody>
</table>

<p>where here, they found that trustworthiness (first column) <strong>correlates with mostly positive traits</strong> such as “engaging and lively”, and that <strong>speaking at a lower rate</strong> can make you sound more trustworthy.</p>

<h1 id="speech-recognition">Speech Recognition</h1>

<p>The task of automatic speech recognition is to map waveform to texts</p>

<table>
  <thead>
    <tr>
      <th>Wave form Input</th>
      <th>Text Output</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240224140654.png" style="zoom:70%;" /></td>
      <td><img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240224140700.png" style="zoom:70%;" /></td>
    </tr>
  </tbody>
</table>

<blockquote>
  <p>Multilingual modeling for SR today = how can you take a model that is strong in one language/resource, and <strong>share/transfer these representations</strong> to other tasks and languages?</p>
</blockquote>

<p>Some challenges in this area:</p>

<ul>
  <li><strong>code switching</strong>: speaker switches between languages within a single utterance (phrase)
    <ul>
      <li>relates to language identification task (LID) mentioned below (<a href="#Reading_Notes_for_Lecture 6">Reading Notes for Lecture 6</a>)</li>
      <li>need to cater to different dialects as well</li>
    </ul>
  </li>
  <li><strong>ambiguity in transcription</strong>: there may be more than one way to write the same said phrase in some languages = can artificially inflate WER.
    <ul>
      <li>need to differentiate modeling error (actual errors) and render error (wrong language due to code switching)</li>
      <li>some attempts: map all the transcribed words and reference into a single language space</li>
    </ul>
  </li>
</ul>

<p>Code-switching has been a “pain” and yet so practical that there are many attempts includeing</p>

<ul>
  <li>
    <p><strong>data</strong> augmentation: synthesize code-switching utterances</p>

    <ul>
      <li>
        <p>some great datasets to begin with <a href="https://arxiv.org/abs/2205.12446">FLEURS: Few-shot Learning Evaluation of Universal Representations of Speech (arxiv.org)</a></p>
      </li>
      <li>
        <p>pretraining with <strong>unlabled speech</strong>, as well as incorporating multimodal data (primarily <strong>unspoken speech</strong> = text) <a href="https://arxiv.org/abs/2303.01037">Google USM: Scaling Automatic Speech Recognition Beyond 100 Languages (arxiv.org)</a></p>

        <p><img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240227170409941.png" alt="image-20240227170409941" style="zoom: 33%;" /></p>

        <p>where <mark>BEST-RQ</mark> means BERT-based Speech pre-Training with Random Projection Quantizer. The idea is to predict random numbers that correspond to the masked waveform section, as long as the masked-to-random-number-mapping is consistent across different speech segments</p>

        <p><img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240227170831831.png" alt="image-20240227170831831" style="zoom: 33%;" /></p>
      </li>
      <li>
        <p>in fact, the idea of modality matching (from non-speech domains) to improve speech models has been quite popular <a href="https://arxiv.org/abs/2204.03409">MAESTRO: Matched Speech Text Representations through Modality Matching (arxiv.org)</a></p>
      </li>
    </ul>
  </li>
  <li>
    <p>other <strong>training</strong> techniques: constraint the representations of same word different language to be close together</p>
  </li>
  <li>
    <p>other <strong>modeling</strong> techniques:</p>

    <ul>
      <li>mixture of expert. For each language cluster (e.g., english, spanish, german, etc as one cluster, and Japanese, Chinese, Korean, … in the second cluster, etc.) train a model.</li>
      <li>language-agnostic approach: transliterate all languages into the same script (e.g. Latin), do inference, and translate back</li>
      <li>language-dependent approach: just model everything end-to-end</li>
    </ul>
  </li>
</ul>

<p>Some key findings:</p>

<ul>
  <li>shared model representation useful for different languages</li>
  <li>shared data modalities useful for improving ASR and TTS tasks (since these two tasks are like “inverse” of each other!)</li>
</ul>

<p>How does different kind of data affect the different abilities.</p>

<h2 id="reading-notes-for-lecture-6">Reading Notes for Lecture 6</h2>

<ul>
  <li>modern ASR tasks vary in different dimensions in practice
    <ul>
      <li>vocabulary size: standard system involve vocabularies up to 60,000 words</li>
      <li>recognizing <strong>read speech</strong> (e.g., audio books) is different from <strong>conversational speech</strong></li>
      <li>whether its recorded in a quiet room or in a noisy environment</li>
      <li>speaker identity: dialects, languages, etc.
to illustrate the difficulties, modern ASR systems already have a very low word error rate for read speech, but can still have high errors for conversational speech:</li>
    </ul>

    <p><img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240224142650.png" style="zoom:60%;" /></p>
  </li>
  <li>examples of modern large scale speech datasets include
    <ul>
      <li><strong>LibriSpeech</strong>: 1000 hours of read English speech</li>
      <li><strong>Switchboard</strong>: 2430 conversations averaging 6 minutes each</li>
      <li>etc.</li>
    </ul>
  </li>
  <li>so how do we do ASR?
    <ol>
      <li><strong>feature extraction: log mel spectrum</strong>. First we want to transform the waveform into a <strong>sequence of acoustic feature vectors</strong>.
        <ul>
          <li>first we slice the waveform into <strong>frames</strong> (e.g., periods of 25ms)</li>
          <li>you may naively use a rectangular window, but in practice people use <strong>Hamming window</strong> since the former will create problems with Fourier transform</li>
        </ul>

        <table>
          <thead>
            <tr>
              <th>Framing</th>
              <th>Hemming Window vs Rec Window</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td><img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240224143212.png" style="zoom:60%;" /></td>
              <td><img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240224143404.png" style="zoom:60%;" /></td>
            </tr>
          </tbody>
        </table>
      </li>
      <li>extract <strong>spectral information using Discrete Fourier Transform</strong> (DFT)
        <ul>
          <li>take each of the windowed signal, and transform it to obtain a spectrum of frequencies:
<img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240224143639.png" style="zoom:60%;" /></li>
          <li>this is useful because it tells us approximately the <strong>anergy at each frequency band</strong></li>
        </ul>
      </li>
      <li>since human hearing is less sensitive at high frequencies, we can use <strong>mel scale</strong> to transform the spectrum into a mel spectrum
        <ul>
          <li>this is done by using a <strong>mel filter bank</strong> to transform the spectrum into a mel spectrum</li>
          <li>then you take the log</li>
        </ul>
      </li>
      <li>finally, this sequence of <strong>log mel spectral features</strong> are used as input to the ASR system</li>
    </ol>
  </li>
  <li>what <strong>model architectures for ASR?</strong>
    <ul>
      <li>typical encoder-decoder models (e.g. with transformers)</li>
      <li>for example, the system below takes in a sequence of $t$ acoustic feature vectors $f_1, …, f_t$, each being a 10ms frame. Then, the output will be a sequence of letters/word pieces (done by a decoder)
<img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240224144222.png" style="zoom:60%;" /></li>
      <li>however, as shown above a single, 5 characters long word might have 200 acoustic frames, often there is a <strong>special compression stage to shorten the feature sequence</strong>, denoted as <strong>subsampling</strong> above.</li>
      <li>another common practice is to augment the system with an LLM. Since large scale pretraining ASR data is much smaller than pure text, people do 1) use ASR to produce many candidate sequences, and 2) use LLM to rescore them.</li>
    </ul>
  </li>
  <li>besides encoder-decoder, another very important algorithm and loss function is called <strong>Connectionist Temporal Classification (CTC)</strong>
    <ul>
      <li>
        <p>idea: output a <strong>single character for every frame of the input</strong>, but <strong>post-process them afterwards</strong> by collapsing identical letters. An naive example:
<img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240224144839.png" style="zoom:70%;" /></p>

        <p>where the intent was to say “dinner”, but a naive de-dup algorithm would produce “diner”.</p>
      </li>
      <li>
        <p>the smart part of CTC is to <strong>add a special blank token</strong>:
<img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240224145024.png" style="zoom:70%;" /></p>
      </li>
      <li>
        <p>but note that this algorithm means there can be many different alignments that produce the same output. This will also be used to formalize how we algorithmically compute the <strong>loss function/inference</strong> for CTC.
<img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240224145240.png" style="zoom:100%;" /></p>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>CTC inference</strong>: first we find the best alignment by assuming that each frame is independent to each other (notice that this is different from LM):</p>

\[P_{\mathrm{CTC}}(A|X) = \prod_{t=1}^{T} P(a_t|X)\]

    <p>where $A = { a_1, …, a_n}$  is an alignment for the input $X$ and output $Y$. Based on this formulation, the best alignment will be:</p>

\[a_{t} = \arg \max_{a_t} P(a_t|X)\]

    <p>at the end of the day this can be implementing with a traditional encoder LM:
<img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240224145631.png" style="zoom:70%;" /></p>
    <ul>
      <li>but this has a problem: the most likely alignment is not necessarily the most likely output sequence.</li>
      <li>
        <p>in fact, the most probable output sequence is the <strong>highest sum</strong> over probability of all possible alignments:</p>

\[P_{\mathrm{CTC}}(Y|X) = \sum_{A \in \mathcal{A}(X, Y)} P(A|X) = \sum_{A \in \mathcal{A}(X, Y)} \prod_{t=1}^{T} P(a_t|X)\]

        <p>so it is actually:</p>

\[\hat{Y} = \arg \max_{Y} P_{\mathrm{CTC}}(Y|X)\]

        <p>which is very expensive to do, and in practice this is approximated using <strong>Viterbi beam search</strong>.</p>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>CTC loss function</strong> using the above, we can formalize a loss function as:</p>

\[\mathcal{L}_{\mathrm{CTC}}(X, Y) = - \log P_{\mathrm{CTC}}(Y|X)\]

    <p>but since  $P_{\mathrm{CTC}}(Y\vert X)$ is expensive as it needs all alignments, we can approximate it with the <strong>forward-backward algorithm</strong>.</p>

    <p>In reality, people often combine this with the traditional LM loss, and you end up with a <strong>CTC+LM loss</strong> and an model training that looks like:
<img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240224150317.png" style="zoom:70%;" /></p>
  </li>
  <li><strong>ASR Evaluation: word error rate</strong>:  how much the word string returned by the recognizer (the hypothesized word string) differs from a reference transcription
    <ol>
      <li>first, compute the minimum edit distance between the two strings</li>
      <li>
        <p>compute word error rate as:</p>

\[\text{Word Error Rate} = 100 \times \frac{\text{Insertions} + \text{Substitutions} + \text{Deletions}}{\text{Total Words in Ground Truth}}\]

        <p>for example, the following made 6, 3, 1 errors in insertion, substitution, and deletion, and the total number of words in the ground truth is 13, so the WER is 76.9%:
 <img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240224150724.png" style="zoom:70%;" /></p>
      </li>
    </ol>
  </li>
  <li><strong>other speech tasks</strong> beyond ASR and TTS include:
    <ul>
      <li>wake word detection: e.g., “Hey Siri”, but you want to maintain privacy</li>
      <li>speech translation (ST): conversational spoken phrases are <em>instantly translated and spoken aloud in a second language</em></li>
      <li>speaker identification: e.g., “who is speaking?”</li>
      <li>speaker diarization: e.g., “who is speaking when?”</li>
    </ul>
  </li>
</ul>

<p>Twenty-Five Years of Evolution in Speech and Language Processing</p>
<ul>
  <li>overview of the Speech Language Processing field
    <ul>
      <li>speech coding task: compress speech signals for efficient transmission</li>
      <li>ASR and TTS: mostly <strong>data-driven</strong> today</li>
      <li>speech enhancement and separation: remove noise from speech</li>
    </ul>
  </li>
  <li>main driving forces in SLP over the last decade
    <ul>
      <li>big data: it was estimated that 2.5 quintillion bytes of data would be created every day in 2022</li>
      <li>big, pretrained models: transformer-based models gathered a lot of attention, and self- or semi-self supervised methods used to pretrain many speech models.</li>
    </ul>
  </li>
  <li>major technical breakthroughs
    <ul>
      <li>ASR: encoder-decoder models, CTC, and attempts at self-supervised learning methods for speech models</li>
      <li>TTS: a combination of WaveNet-based vocoder and encoder-decoder models achieved near-human-level synthetic speech, and recently some non-autoregressive models have been proposed to show better performance</li>
    </ul>
  </li>
  <li>current and future trend:
<img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240224154155.png" style="zoom:100%;" /></li>
</ul>

<h1 id="spoken-dialogue-systems">Spoken Dialogue Systems</h1>

<p>some downstream research and applications in spoken dialogue systems</p>

<h2 id="empathetic-conversations-in-dialogue-systems">Empathetic Conversations in Dialogue Systems</h2>

<p>What is emphay</p>

<ul>
  <li><strong>cognitive emphasis:</strong> “perspective-taking” or being to put yourself into someone else’s place (useful skill for managers)</li>
  <li><strong>emotional empathy:</strong> being able to feel other peoples emotions (e.g., you get sad if your friend is sad)</li>
  <li><strong>compassionate empathy:</strong> feeling someone’s pain and taking action to help mitigate their problems</li>
</ul>

<p>Why is this useful?</p>

<ul>
  <li>empathetic robots = encourage users to <em>like</em> the agents more</li>
  <li>think the agents are <em>more intelligent</em> = more willing to take their advice</li>
  <li>help establish social bonds, promote or diffuse conflict, persuade, succeed in negotiations, etc.</li>
  <li>etc.</li>
</ul>

<p>some models used:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">speechT5</code>, <code class="language-plaintext highlighter-rouge">OpenAI TTS</code>, <code class="language-plaintext highlighter-rouge">ElevenLabs</code>, <code class="language-plaintext highlighter-rouge">Suno/Bark</code>, meta’s <code class="language-plaintext highlighter-rouge">AudioBox</code> for text to speech</li>
  <li><code class="language-plaintext highlighter-rouge">MetaVoice</code>: voice cloning (speak things in some speaker’s style)</li>
  <li><code class="language-plaintext highlighter-rouge">wave2vec</code> for intermediate representation used for classification task (e.g., emotion classification)</li>
  <li><code class="language-plaintext highlighter-rouge">whisper</code> for speech to text</li>
</ul>

<h2 id="reading-notes-for-lecture-7">Reading Notes for Lecture 7</h2>

<p><strong>Chatbots &amp; Dialogue Systems</strong> from the textbook</p>

<ul>
  <li>
    <p>Properties of Human Conversation</p>

    <ul>
      <li>each utterance in a dialogue is a kind of action being performed by the speaker = <strong>dialogue acts</strong></li>
      <li>Speakers do this by <strong>grounding</strong> each other’s utterances.</li>
      <li>have structures such as Q and A, sub-dialogues, and clarification questions</li>
      <li>speakers take turn to have conversational <strong>initiative</strong></li>
      <li><strong>conversational implicature</strong>: speaker seems to expect the hearer to draw certain inferences; in other words, the speaker is communicating more information than seems to be present in the uttered words</li>
    </ul>
  </li>
  <li>
    <p>chatbots</p>

    <ul>
      <li>
        <p>ELIZA and PARRY: rule based systems</p>
      </li>
      <li>
        <p>GUS: Simple Frame-based Dialogue Systems serving as a prototype for task-based dialogue.</p>

        <ul>
          <li>
            <p><strong>frames</strong>. A frame is a kind of knowledge structure representing the kinds of intentions the system can extract. Basically a collection of key, value pairs, constituting a <strong>domain ontology</strong>.</p>

            <p><img src=".//lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240302134352784.png" alt="image-20240302134352784" style="zoom:50%;" /></p>
          </li>
          <li>
            <p>so the goal was to get these <strong>slots filled</strong> by asking the relevant questions. Some challenges: an utterance may touch multiple slots.</p>
          </li>
          <li>
            <p><strong>domain/intent classification</strong>, and <strong>extractive</strong> slot filling</p>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><strong>RASwDA: Re-Aligned Switchboard Dialog Act Corpus for Dialog Act Prediction in Conversations</strong></p>

<ul>
  <li>
    <p>The Switchboard Dialog Act (SwDA) corpus has been widely used for dialog act prediction and generation tasks. However, due to misalignment between the text and speech data in this corpus, models incorporating prosodic information have shown poor performance.</p>

    <ul>
      <li>this transcripts and speech was originally aligned using a GMM-HMM speech recognition system.</li>
      <li>However, these alignment results are <strong>unreliable</strong>, making it extremely difficult to use both speech and text data to accurately predict or generate DAs.</li>
      <li>for example, they have found 27 conversations in which speakers were recorded on the wrong channel, resulting in incorrect speaker identifications</li>
    </ul>
  </li>
  <li>
    <p>In this paper, they report the <strong>misalignment issues present in the SwDA corpu</strong>s caused by previous automatic alignment methods and introduce a re-aligned, improved version called RASwDA</p>

    <ul>
      <li>there are large scale text data annotated with DA, but only a few have been transcribed in speech.</li>
    </ul>
  </li>
  <li>
    <p>To <strong>produce high-quality alignments</strong> between the audio and transcripts of SwDA, we employ a two-step process.</p>

    <ol>
      <li>obtain the text grid of each speech file. Since both transcripts and speech spectrogram is there, they then used <code class="language-plaintext highlighter-rouge">aeneas</code> library to do <strong>automatic alignment</strong></li>
      <li>we <strong>manually correct</strong> the TextGrids produced both from the NXT-format Switchboard Corpus alignments and the aeneas forced alignments</li>
    </ol>

    <p>with this re-aligned corpus, they show that you can have a higher DA classification performance after training.</p>
  </li>
</ul>

<p><strong>Nora the Empathetic Psychologist</strong></p>

<ul>
  <li>
    <p>Nora is a new dialog system that mimics a conversation with a psychologist by screening for stress, anxiety, and depression as she <strong>understands, emphasizes, and adapts to the user</strong>.</p>

    <ul>
      <li>capable of recognizing stress, emotions, personality, and sentiment from speech</li>
      <li>included an <strong>emotional intelligence (EI)</strong> module is incorporated to enable emotion understanding, empathy, and adaptation to users</li>
    </ul>
  </li>
  <li>
    <p>system design</p>

    <p><img src=".//lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240302142555591.png" alt="image-20240302142555591" style="zoom:50%;" /></p>

    <ul>
      <li>empathetic dialog system that <strong>takes audio and facial image</strong> of the user as input, and basically consists of a) <strong>ASR and TTS</strong> modules from prior work, 2) <strong>empathic module</strong>, and 3) a <strong>mixed-initiative (text) dialogue system</strong></li>
      <li>the key new component is this emphathic module, which consists of four submodules
        <ul>
          <li><strong>stress detection from audio</strong>: detect stress from spoken utterances by training on Natural Stress Emotion corpus</li>
          <li><strong>Automatic emotion detection from audio</strong>: another CNN trained with emotion detection dset (6 labels)</li>
          <li>sentiment analysis</li>
          <li>personality analysis</li>
        </ul>
      </li>
      <li>most models are trained by processing wave spectrograms using CNNs.</li>
    </ul>
  </li>
</ul>

<h1 id="speech-analysis-emotion-detection-and-solicitation">Speech Analysis: Emotion Detection and Solicitation</h1>

<p>Downstream application of speech analysis.</p>

<h2 id="emotion-and-sentiment-detection">Emotion and Sentiment Detection</h2>

<ul>
  <li>
    <p>has many downstream tasks,</p>
  </li>
  <li>
    <p>some <strong>findings and prior work</strong> in emotional recognition</p>

    <p><img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240319164728759.png" alt="image-20240319164728759" style="zoom: 15%;" /></p>

    <p>lexical feature is important:</p>

    <p><img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240319164800173.png" alt="image-20240319164800173" style="zoom: 15%;" /></p>

    <p>CNN is strong enough to learn from raw spectrogram and understand emotions</p>

    <p><img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240319164838619.png" alt="image-20240319164838619" style="zoom:15%;" /></p>

    <p>transformers + multimodal data are great as well</p>

    <p><img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240319164921928.png" alt="image-20240319164921928" style="zoom:15%;" /></p>
  </li>
</ul>

<h2 id="emotion-elicitation">Emotion Elicitation</h2>

<h2 id="reading-notes-for-lecture-8">Reading Notes for Lecture 8</h2>

<p><strong>Predicting Arousal and Valence from Waveforms and Spectrograms using Deep Neural Networks</strong></p>

<ul>
  <li>
    <p>task: Automatic recognition of <strong>spontaneous emotion in conversational speech</strong></p>

    <ul>
      <li>
        <p>idea: by exploiting waveforms and spectrograms as input, and use CNN to capture spectral information with Bi-LSTM to capture temporal information</p>
      </li>
      <li>
        <p>instead of classifying into a few emotion cases, map it into a <strong>continuous multi-dimensional space</strong> (valence-arousal)</p>

        <p><img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240319162037906.png" alt="image-20240319162037906" style="zoom:43%;" /></p>
      </li>
      <li>
        <p>significantly outperforms model using hand-engineered features</p>
      </li>
    </ul>
  </li>
  <li>
    <p>datasets include</p>

    <ul>
      <li><strong>SEMAINE</strong> database: The user’s emotion is annotated by 6-8 annotators for <strong>arousal and valence at 20ms intervals</strong></li>
      <li>RECOLA database: Conversations were annotated for <strong>arousal and valence at 40ms intervals</strong> by 6 annotators; scores range from -1 to 1 with 2 decimal places</li>
    </ul>
  </li>
  <li>
    <p>proposed model architecture: output of CNN layers are then <strong>concatenated together for BiLSTM.</strong></p>

    <p><img src=".//lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240308171402780.png" alt="image-20240308171402780" style="zoom:67%;" /></p>

    <p>but since things are continuous, what does the input really look like?</p>

    <ul>
      <li>waveform: we <strong>normalize</strong> waveform signals on the conversation level with zero mean and unit variance to reduce the inter-speaker difference. Then we <strong>re-sample</strong> the speech to 16kHz sampling rate, and <strong>segment the conversation into 6s segments</strong></li>
      <li>spectrogram: a <strong>40-dimensional mel-scale log filter bank</strong> as the spectrogram features. Similar with our preprocessing of waveforms, we first perform normalization and segmentation.</li>
    </ul>
  </li>
  <li>
    <p>how do you then measure performance? MSE from the ground truth:</p>

    <table>
      <thead>
        <tr>
          <th style="text-align: center">Arousal</th>
          <th style="text-align: center">Valence</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td style="text-align: center"><img src=".//lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240308172409502.png" alt="image-20240308172409502" style="zoom:50%;" /></td>
          <td style="text-align: center"><img src=".//lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240308172431642.png" alt="image-20240308172431642" style="zoom:50%;" /></td>
        </tr>
      </tbody>
    </table>
  </li>
</ul>

<p><strong>Emotions and Types of Emotional Responses</strong></p>

<ul>
  <li>Understanding emotions can help us navigate life with greater ease and stability.</li>
  <li>what are emotions?
    <ul>
      <li>emotions are <strong>complex psychological states</strong> that involve three distinct components: a <strong>subjective</strong> experience, a <strong>physiological</strong> response, and a <strong>behavioral or expressive</strong> response.</li>
      <li>Subjective Experience: experiencing emotion can be highly <strong>subjective</strong> = what you feel internally differs</li>
      <li>Physiological response: e.g., your stomach lurch from anxiety or your heart palpate with fear, you’ve already experienced the strong physiological reactions that can occur with emotions
        <ul>
          <li>early research believes these are mostly due to the sympathetic nervous system, a branch of the <a href="https://www.verywellmind.com/what-is-the-autonomic-nervous-system-2794823">autonomic nervous system</a>.</li>
          <li>but recent research has targeted the <strong>brain’s</strong> role in emotions. Brain scans have shown that the amygdala, part of the limbic system, plays an important role in emotion and fear in particular.</li>
        </ul>
      </li>
      <li>Behavioral response: the actual expression of emotion.
        <ul>
          <li>ability to accurately <strong>understand</strong> these expressions is tied to what psychologists call <a href="https://www.verywellmind.com/what-is-emotional-intelligence-2795423">emotional intelligence</a></li>
          <li><strong>sociocultral</strong> norms also play a role: Western cultures tend to value and promote high-arousal emotions (fear, excitement, distress) whereas Eastern cultures typically value and prefer low-arousal emotions (calmness, serenity, peace).</li>
        </ul>
      </li>
      <li>“evolutionary theory of emotion”: emotions are <strong>adaptive to our environment and improve our chances of survival</strong></li>
    </ul>
  </li>
  <li>what kind of emotions do we have?
    <ul>
      <li>Paul Ekman defined six basic emotions universal throughout human cultures: <strong>fear, disgust, anger, surprise, joy, and sadness.</strong></li>
      <li>Robert Plutchik defined <strong>wheel of emotions</strong>: how different emotions can be combined or mixed together</li>
    </ul>
  </li>
  <li>primary vs secondary emotion
    <ul>
      <li><strong>Primary emotions</strong> are the emotions that humans experience universally (e.g., happiness, sadness, fear, disgust, anger, and surprise)</li>
      <li>Sometimes, we have <strong>secondary</strong> emotions <strong>in response to our primary emotions</strong> (i.e., “I’m frustrated that I’m so sad”).</li>
    </ul>
  </li>
  <li>emotions, feelings, and moods
    <ul>
      <li>Emotions are reactions to stimuli, but <strong>feelings</strong> are what we experience as <strong>a result of emotions.</strong> Emotions are also likely to have a definite and identifiable cause. Feelings are influenced by our perception of the situation</li>
      <li>A <strong>mood</strong> can be described as a temporary emotional state. For example, you might find yourself feeling gloomy for several days without any clear, identifiable reason.</li>
    </ul>
  </li>
</ul>

<p><strong>Eliciting Rich Positive Emotions in Dialogue Generation</strong></p>

<ul>
  <li>task: <strong>evoking positive emotion</strong> state in human users in open-domain dialogue
    <ul>
      <li>prior work simply aim to “elicit positive emotions”. here they consider <strong>more fine-grained emotions</strong> such as “Hopeful”, “Joy” and “Surprise”.</li>
      <li>idea: represent the elicited emotions <strong>using latent variables</strong> in order to take full advantage of the <strong>large-scale unannotated datasets</strong></li>
    </ul>
  </li>
  <li>
    <p>prior work: EmpDG</p>

    <ul>
      <li>EmpDG extracts <strong>implicit information from the next utterance</strong> as feedback for semantic and emotional guidance of targeted response. These are then used to enhance the base generator model</li>
      <li>problem? the extracted feedback can be <strong>sparse and noisy</strong>, which introduces uncertainty in empathetic generation</li>
    </ul>

    <p><img src=".//lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240308215626148.png" alt="image-20240308215626148" style="zoom:67%;" /></p>
  </li>
  <li>this work then trains a CVAE network using some pretrained emotion classifier in a GAN-like setting.</li>
</ul>

<h1 id="speech-analysis-entrainment-and-code-switching">Speech Analysis: Entrainment and Code Switching</h1>

<p><strong>Entrainment</strong>: speakers start to mimic each other’s speaking style as conversation continues.</p>

<p><strong>Code-switching</strong>: a person changing languages or dialects throughout a single conversation and sometimes even over the course of a single sentence.</p>

<p>Some findings on <strong>conversation with code-switching</strong>:</p>

<ul>
  <li>lexical entrainment exists: similar vocabularies</li>
  <li>acoustic-prosodic entrainment: correlations on stuff like intensity, HNR, etc.</li>
  <li>code-switching behavior entrainment:
    <ul>
      <li>turn-level synchrony: if I switch language after one turn, the other is likely to switch as well</li>
      <li>amount of code-switching: if I switch language very often, the other will switch often as well</li>
    </ul>
  </li>
</ul>

<h1 id="speech-analysis-personality-and-mental-state">Speech Analysis: Personality and Mental State</h1>

<p>aaa</p>

<h2 id="reading-notes-for-lecture-10">Reading Notes for Lecture 10</h2>

<p><strong>Predicting the Big 5 personality traits from digital footprints on social media: A meta-analysis</strong></p>

<ul>
  <li>You can use <strong>social medai content to predict user personailtiy</strong>, and these predictions can then be used for a variety of purposes, including tailoring online services to improve user experience. Specifically, this paper considers
    <ul>
      <li>meta-analyses to determine the <strong>predictive power of digital footprints</strong> collected from social media over Big 5 personality traits.</li>
      <li>impact of <strong>different types of digital footprints</strong> on prediction accuracy</li>
    </ul>
  </li>
  <li>digital footprints: <strong>information shared by users</strong> on their social media profiles - e.g., personal information about age, gender orientation, place of residence, as well shared texts, pictures, and videos</li>
  <li><strong>Big 5 traits</strong> have been shown to be significantly associated with users’ behaviors on social media. For example, individuals with high extraversion have been characterized by higher levels of activity on social media</li>
  <li>Some interesting results
    <ul>
      <li>Results of univariate regressions showed <strong>significant effects for use of multiple types of digital footprints</strong>, demographics, and activity statistics. For each trait except agreeableness, results showed an increase in strength of association</li>
      <li>The use of <strong>demographic statistics</strong> was associated with a significant increase in correlation strength between digital footprints and both agreeableness (β = 0.25, R2 = 0.19), and neuroticism (β = 0.25, p &lt; 0.05, R2 = 0.19)</li>
    </ul>
  </li>
</ul>

<p><strong>Multimodal Deep Learning for Mental Disorders Prediction from Audio Speech Samples</strong></p>

<ul>
  <li>
    <p>Key features of <strong>mental illnesses are reflected in speech.</strong> This paper then aims to design DNN to <mark>extract salient features from speech</mark> that can be used for mental disorder prediction.</p>
  </li>
  <li>
    <p>HIgh level approach: combine audio+text embeddings and do prediction</p>

    <p><img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240330151424401.png" alt="image-20240330151424401" style="zoom:50%;" /></p>

    <p>the key insight to our model is that depending on the encoded information in textual and acoustic modalities, the <strong>relative importance of their associated learned embeddings may differ</strong> in the bimodal feature fusion layer.</p>

    <ul>
      <li>textual feature representation layer uses <strong>1) segment-level features extraction</strong> to learn fine-grained textual embeddings for every segment, and <strong>2) emotion-specific representation of text segment</strong> which extracts emotion information contained in every segment. These two are then concatenated as a single text feature</li>
      <li>audio feature extraction module also uses: <strong>1) segment-level acoustic features</strong> extraction to learn audio embeddings for every segment, and <strong>2) emotion-specific representation</strong> of audio segment</li>
    </ul>
  </li>
</ul>

<p>**Speech Processing Approach for Diagnosing Dementia in an Early Stage **</p>

<ul>
  <li>
    <p>Our hypothesis is that any disease that <strong>affects particular brain  regions involved in speech production</strong> and processing will also  leave <strong>detectable finger prints in the speech</strong>. This paper, in particular, aims to detect <strong>Alzheimer’s disease</strong></p>
  </li>
  <li>
    <p>dataset</p>

    <ul>
      <li>standard protocol for collecting speech samples for aphasia  work is to ask volunteers to <strong>describe what they see in a picture</strong></li>
      <li>features: from speech to
        <ul>
          <li>acoustic feature extraction using pitch, energy, and voice activity detector</li>
          <li>linguistic feature extraction using POS tags, syntactic complexity, LIWC, and syntactic density.</li>
        </ul>
      </li>
      <li>the pen-and-paper test for this before was the MMSE  score.
        <ul>
          <li>MMSE scores greater than or equal to 24 points  (out of 30) indicates a normal cognition.</li>
          <li>Below this, scores can  indicate severe (≤9 points), moderate (10–18 points) or mild  (19–23 points) cognitive impairment</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>goal, develop a system that is <strong>fully automatic</strong> (without assessing the MMSE test)</p>

    <ul>
      <li>
        <p>with MMSE, the accuracy achieved was  94.4% using only five features, one of which was the MMSE  score. The five features selected (in order of importance) were  MMSE score, race, fraction of pauses greater than 10sec,  fraction of speech length that was pause and LIWC.</p>
      </li>
      <li>
        <p>without MMSE, In order to achieve the 91.7% accuracy, 12 features  were needed:</p>

        <p><img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240330155905878.png" alt="image-20240330155905878" style="zoom:67%;" /></p>
      </li>
    </ul>
  </li>
</ul>

<h1 id="speech-analysis-sarcasm-simile-and-metaphor-wordseye">Speech Analysis: Sarcasm, Simile and Metaphor; WordsEye</h1>

<p><u>$R^3$: Reverse, Retrieve, and Rank for Sarcasm Generation with Commonsense Knowledge</u></p>

<ul>
  <li>
    <p>generating sarcasm is challenge: there is <strong>no parallel corpus of non-sarcastic to sarcastic text</strong></p>
  </li>
  <li>
    <p>even if we have this data, <strong>generating novel sarcasm would be issue</strong></p>
  </li>
  <li>
    <p>approach: $R^3$ reversal, retrieve, and re-rank</p>

    <ul>
      <li>
        <p>motivating example:</p>

        <ul>
          <li><strong>reverse</strong> valence “Zero visibility in fog makes driving difficult” $\to$​ “Zero visibility in fog makes driving easy”</li>
          <li><strong>retrieve</strong> common sense and append: “Zero visibility in fog makes driving easy” $\to$ “Zero visibility in fog makes driving easy. It is advisable to insure your …”</li>
          <li><strong>re-rank</strong> to get more semantic incongruity: “Zero visibility in fog makes driving easy” $\to$​ “Zero visibility in fog makes driving easy. Suffered three three bones in the accident.”</li>
        </ul>
      </li>
      <li>
        <p><strong>approach</strong>:</p>

        <ul>
          <li>
            <p>reversal can be simply done with wordnet</p>
          </li>
          <li>
            <p>retrieve common sense?</p>

            <ol>
              <li>use COMET which is GPT-2 tuned on ConceptNet (a knowledge graph)</li>
              <li>input words without stopwords: “zero, visibility, fogs, drive, easy”</li>
              <li><strong>COMET output</strong>: “accident”</li>
              <li>retrieve sentences that contains accident from a database: got many</li>
              <li>re-rank by Roberta tuned on MNLI, i.e., <strong>the less it entails, the more incongruity it has</strong> = the better.</li>
            </ol>

            <p>note that this entire process is purely unsupervised = generating sarcasm without any training/parallel corpus.</p>
          </li>
        </ul>
      </li>
      <li>
        <p><strong>testing</strong>: against SOTA and against human annotators</p>
      </li>
    </ul>
  </li>
</ul>

<p>Metaphor generation: again hard since there is no parallel corpus.</p>

<ul>
  <li>
    <p>here, the proposed method is an unsupervised way to <strong>create parallel corpus</strong></p>
  </li>
  <li>
    <p>approach</p>
    <ol>
      <li>first taking sentences from a poetry dataset, and then find ones that has <strong>metaphoric verbs</strong>, $v$ (have existing models to do it)</li>
      <li>pick words replacing $v$ that are consistent according to COMET’s “relates to” and is <strong>literal</strong></li>
      <li>training: train the model to input sentence from step 2, and output step 1</li>
    </ol>
  </li>
</ul>

<p>Simile generation:</p>

<ul>
  <li>before it was like changing a word to do metaphor generation. But</li>
  <li>approach:
    <ul>
      <li>similar to above, to use COMET to a literal version of a similie but swapping multiple words = obtain parallel corpus = train BART</li>
    </ul>
  </li>
</ul>

<p>Visual metaphors:</p>

<ul>
  <li>given a text “he is like a lion on the battlefield”, how do you create an image to represent the man is fierce while being faithful in meaning</li>
  <li>approach: human-AI collaboration to get a dataset
    <ul>
      <li>convert the linguistic metaphor prompt to a <strong>more detailed linguistic metaphor</strong></li>
      <li>ask some <strong>human expert to make minor edits</strong> to the above</li>
      <li>prompt DALLE/Stable-Diffusion</li>
    </ul>
  </li>
  <li>evaluation:
    <ul>
      <li>human evaluation</li>
      <li>(image, claim) entailment? visual metaphors is a bit complex for since before it was trained with literal pairs/reasoning</li>
    </ul>
  </li>
</ul>

<hr />

<p><strong>WordsEye: An Automatic Text-to-Scene Conversion System</strong></p>

<h2 id="reading-notes-for-lecture-13">Reading Notes for Lecture 13</h2>

<p><strong><a href="https://aclanthology.org/2021.eacl-main.171.pdf">“Laughing at you or with you”: The Role of Sarcasm in Shaping the Disagreement Space</a></strong></p>

<ul>
  <li>
    <p>Users often use figurative language, such as sarcasm, either as persuasive devices or to attack the opponent by an ad hominem argument. This paper then demonstrate that <strong>modeling sarcasm improves the argumentative relation classification task</strong> (agree/disagree/none) in all setups</p>

    <p><img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240406165700676.png" alt="image-20240406165700676" style="zoom: 67%;" /></p>
  </li>
  <li>
    <p>so what did they do?</p>

    <ul>
      <li>feature based approach: extract <strong>Argument-relevant features</strong> (ArgF) such as N-gram, and <strong>Sarcasm-relevant features</strong> (SarcF) such as sarcasm markers (e.g., capitialization, quotation marks, etc.) and do logistics regression on each set.</li>
      <li>NN based:
        <ul>
          <li><strong>multitask of LSTM</strong> with sarcasm prediction + argument relation prediction</li>
          <li><strong>multitask of BERT</strong> doing the same as above</li>
        </ul>
      </li>
      <li>results, in all cases additionally including sarcasm features/modeling sarcasm gives performance improvement.</li>
    </ul>
  </li>
</ul>

<p><strong>“YEAH RIGHT”: SARCASM RECOGNITION FOR SPOKEN DIALOGUE SYSTEMS</strong></p>

<ul>
  <li>This paper presents some experiments toward sarcasm recognition using prosodic, spectral, and contextual cues. This paper shows that <strong>spectral and contextual features</strong> can be used to detect sarcasm as well as a human annotator would, and that <strong>prosody alone is not sufficient</strong> to discern whether a speaker is being sarcastic.</li>
  <li>task: <strong>classify if “year right” is sarcastic or not.</strong></li>
  <li>approach:
    <ul>
      <li><strong>non-prosodic features</strong> include “whether or not tehre is laughter”, “whether the ‘year right’  is an answer or a question”, etc.</li>
      <li><strong>prosodic features</strong>: average pitch, energy, intensity, etc.</li>
    </ul>
  </li>
  <li>results:
    <ul>
      <li>with human annotators trying to label them, they found it only works when context is provided:  Insofar as a sarcastic tone of voice exists, <strong>a listener also relies heavily on contextual and, when available, visual information</strong> to identify sarcasm</li>
      <li>experiments using decision tree classifier found that using prosody feature at all will hurt performance</li>
      <li><img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240406175520707.png" alt="image-20240406175520707" /></li>
    </ul>
  </li>
</ul>

<p><strong>“Sure, I Did The Right Thing”: A System for Sarcasm Detection in Speech</strong></p>

<ul>
  <li>
    <p>In this  paper, we present a system for <strong>automatic sarcasm detection in speech.</strong> The authors found that you can 1) use pitch and intensity contours, and 2) using a SimpleLogistic (LogitBoost) classifier to <strong>predict sarcasm with 81.57% accuracy</strong>. This result suggests  that certain pitch and intensity contours are predictive of  sarcastic speech.</p>

    <ul>
      <li>so this is a <mark>counter argument of the previous paper</mark>.</li>
    </ul>
  </li>
  <li>
    <p>first they found that prior sarcasm related corpus is problematic, and therefore constructed their <strong>own sarcasm corpus</strong> based on “Daria”. We collected what we  determined to be 75 sarcastic sentences and 75 sincere  sentences – these judgments took context into consideration.</p>

    <ul>
      <li>
        <p>first they went on to let human participants rate them as the definition of “sarcasm” varies. They found that instead of a bimodal distribution, there was a <strong>trimodal distribution</strong> ni annotation:</p>

        <p><img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240406172612258.png" alt="image-20240406172612258" style="zoom:50%;" /></p>

        <p>indicating that  there are also a <strong>substantial number of sentences for which participants were inconsistent.</strong></p>
      </li>
    </ul>
  </li>
  <li>
    <p>so how to do you model this?</p>

    <ul>
      <li>
        <p><strong>use sentence level acoustic features</strong> such as  mean pitch, pitch range, mean intensity, speaking rate, and etc</p>
      </li>
      <li>
        <p><strong>use word level acoustic features</strong>: prosodic contours within each word modeled by a 3  coefficient Legendre polynomial expansions, and then do some clustering + distance over all words to provide a contour over the entire sentence:</p>

        <p><img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240406173203109.png" alt="image-20240406173203109" style="zoom:50%;" /></p>
      </li>
      <li>
        <p>simply use Logistics regression based on the above features, and find that a (baseline is the sentence-level acoustic feature)</p>

        <p><img src="/lectures/images/2024-06-02-COMS6998_Spoken_Language_Processing/image-20240406173312193.png" alt="image-20240406173312193" style="zoom:50%;" /></p>
      </li>
    </ul>
  </li>
</ul>

<h1 id="speech-analysis-charismatic-speech">Speech Analysis: Charismatic speech</h1>

<p>How to make charismatic speech?</p>

<ul>
  <li>is it what you say?</li>
  <li>
    <p>or how you say it?</p>
  </li>
  <li>are there differences across culture?</li>
</ul>

<p>Some experiments done and results:</p>

<ul>
  <li>
    <p><strong>First American English Experiments</strong>: speech from democratic nomination for US president in 2004</p>

    <ul>
      <li>found that raters have good agreement on if a speaker is “accusatory, angry, passionate, intense”, but not very good agreement on “desperate, friendly, trustworthy”</li>
      <li>also tested this on <strong>arabic speakers/raters</strong>, and find strong correlation in “passionate and charismatic”</li>
    </ul>
  </li>
  <li>
    <p>is there any correlation between charismatic <em>and other characteristics?</em> Found positive correlation on:</p>

    <ul>
      <li>enthusiastic, persuasive, not boring, and more</li>
      <li>for Arabic, also found correlation on enthusiastic, persuasive, not boring</li>
    </ul>
  </li>
  <li>
    <p>does content matter? Measured how certain topics could correlate to charismatics</p>

    <ul>
      <li>english: speech about healthcare, postwar Irqa, reasons for running, greating, taxes, etc.</li>
      <li>arabic: skipped.</li>
    </ul>

    <p>so it definitely <strong>does matter!</strong> Additionally</p>

    <ul>
      <li>using “our” is better than using “you”</li>
      <li>lower complexity (grade-level content) is helpful (for winning elections)</li>
      <li><mark>positive emotions words</mark>: love, nice, etc.</li>
    </ul>
  </li>
  <li>
    <p>does <strong>speech matter</strong>? Found positive correlation on:</p>

    <ul>
      <li><strong>duration</strong>: longer better</li>
      <li><strong>speaking rate</strong>:
        <ul>
          <li>faster is better for english, but faster is worse for arabic</li>
          <li><strong>higher pause to word ratio</strong> is better</li>
          <li><strong>high F0 is better</strong> for both cultures</li>
        </ul>
      </li>
      <li>TOBI labels:
        <ul>
          <li>!H* and L+H* positively correlated with charisma rating for both languages <strong>(ends with a high/emphasis note = engaging)</strong></li>
          <li>L* has a negative correlation</li>
        </ul>
      </li>
      <li>ratio of <strong>repeated words</strong> is surprisingly helpful with charismatic</li>
    </ul>
  </li>
  <li>
    <p>interesting, when speakers rate speech which they don’t understand</p>

    <ul>
      <li><strong>charisma ratings</strong> is positively correlated across language even without understanding it</li>
    </ul>
  </li>
</ul>]]></content><author><name></name></author><category term="2024@Columbia" /><summary type="html"><![CDATA[Logistics and Introduction]]></summary></entry><entry><title type="html">CSOR4231 Analysis of Algorithms</title><link href="/lectures/2023@columbia/CSOR4231_Analysis_of_Algorithms.html/" rel="alternate" type="text/html" title="CSOR4231 Analysis of Algorithms" /><published>2024-01-20T00:00:00+00:00</published><updated>2024-01-20T00:00:00+00:00</updated><id>/lectures/2023@columbia/CSOR4231_Analysis_of_Algorithms</id><content type="html" xml:base="/lectures/2023@columbia/CSOR4231_Analysis_of_Algorithms.html/"><![CDATA[<p>*Picture credits from the Algorithms Illuminated book</p>

<h1 id="analysis-of-algorithms">Analysis of Algorithms</h1>

<p>Logistics: Mostly see Canvas, but just note that:</p>

<ul>
  <li>10 Psets, no late days, but 2 can be dropped. Each pset worth 10 points.</li>
  <li>3 non-cumulative exam,  each worth 60 points. Tentative dates Oct 3, Oct 31, Dec 7.
    <ul>
      <li>exams will have about 50% content verbatim from HW</li>
    </ul>
  </li>
  <li>textbook: the split version of Algorithms Illuminated will have the same content as the Algorithms Illuminated Omnibus version, except that problem numbering might be different</li>
  <li>skim the readings before/after class, as they are the content you are responsible for</li>
</ul>

<hr />

<p>Example demo algorithmic questions:</p>

<p><u>*For example*: Routing in Internet.</u> Let nodes/vertices be hosts, and edges be the physical/wireless connections. Let the connections be bidirectional. <strong>How do you figure out the shortest path (least number of hops) between two given hosts?</strong></p>

<ul>
  <li>
    <p>Dikstra algorithm: given a source host (e.g. node 0), we can find the shortest path to all other hosts. The key insight shortest path is composed of shortest path, <strong>assuming all edges are positive</strong>. This means that if you have a given shortest path from $v$ to $u$, and nodes $w,x,y,z$ are only connected to $u$, then any shortest path from $v$ to $w,x,y,z$ must go through $u$.</p>

    <p>The algorithm iteratively grows a “tree” of visited nodes. At each iteration, the node that has the smallest cost (e.g. node 1) will be marked as done. THen we add all the neighbors <em>of that marked node</em> (because of the insight above) to the tree of visited nodes, and update the cost of the neighbors.</p>

    <p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230905205050.png" style="zoom:100%;" /></p>

    <p>however, the issue is that it needs to remember information about the entire internet during computation (i.e. keep an adjacency matrix/is visited of all nodes), which is not scalable.</p>
  </li>
  <li>
    <h2 id="bellman-ford-algorithm-a-differential-version-that-converges-to-the-shortest-path">Bellman-Ford algorithm: a <strong>differential</strong> version that converges to the shortest path.</h2>
  </li>
</ul>

<p><u>*For example*: Sequence alignment.</u> Consider two strings composed of characters ${ A,C,G,T }$:</p>

\[AGGGCT, AGGCA\]

<p>How similar (smallest edit distance, or lowest NW score) are the two strings?</p>

<ul>
  <li>Brute force: try all possible alignments, and pick the one with the lowest score. Insanely expensive.</li>
  <li>Dynamic programming!</li>
</ul>

<hr />

<p><u>*For example:* Multiplying two numbers.</u> Given two $n$ digit number (e.g. $x=1234$, $y=5678$), find a way to find out their product.</p>

<ul>
  <li>
    <p>Grade school approach: multiply each digit by each, get partial product, and sum.</p>

    <p>Cost is $O(n^2)$ as for each digit need to do $n$ multiplication, and there are $n$ digits</p>
  </li>
  <li>
    <p>Recursive v1: We can break down multiplying numbers into <strong>multiplying parts of it</strong> and add back (<mark>divide and conquer</mark>). For instance, let $x=10^{n/2}a + b$ and $y=10^{n/2}c + d$ (e.g. $a=12, b=34$ for $x=1234$). Then realize that:</p>

\[\begin{align*}
  x\cdot y 
  &amp;= (10^{n/2}a + b) (10^{n/2}c + d) \\
  &amp;= 10^n ac + 10^{n/2} (ad + bc) + bd \\
\end{align*}\]

    <p>and then, for <strong>each of the 4 multiplication operation</strong>, we can further recurse into smaller components until we are at one digit.</p>

    <p>Is this necessarily faster than grade school? We will analyze this in the course.</p>
  </li>
  <li>
    <p>Recursive v2 (<strong>Karatsuba</strong> Algorithm): An improved version than above where we only do 3 multiplications instead of 4. Notice that we can rewrite:</p>

\[(a+b)(c+d) = ac + ad + bc + bd = ac + bd + (ad + bc)\]

    <p>therefore, to equivalently compute the 4 multiplications in v1, we can do:</p>
    <ol>
      <li>compute $ac$</li>
      <li>compute $bd$</li>
      <li>
        <h2 id="compute-abcd-and-subtract-ac-and-bd-from-it-to-get-adbc">compute $(a+b)(c+d)$ and subtract $ac$ and $bd$ from it to get $ad+bc$</h2>
      </li>
    </ol>
  </li>
</ul>

<h1 id="introduction">Introduction</h1>

<p>The basic idea is to break your problem into smaller subproblems, solve the subproblems (often recursively), and finally combine the solutions to the subproblems into one for the original problem.</p>

<h2 id="mergesort-the-algorithm">MergeSort: The Algorithm</h2>

<p><code class="language-plaintext highlighter-rouge">MergeSort</code> is a classical sorting algorithm using the divide and conquer paradigm. Recall that to sort an array, we could have done:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">SelectionSort</code>: scan the array, find the smallest element, put it in the first position, and repeat.</li>
  <li><code class="language-plaintext highlighter-rouge">InsertionSort</code>: keep two arrays, sorted and unsorted. Scan the unsorted array and place the smallest element there into the correct position of the sorted array.</li>
  <li><code class="language-plaintext highlighter-rouge">BubbleSort</code>: swap adjacent elements to make sure the smallest is in the first position, then repeat.</li>
</ul>

<p>the above three simple algorithms have a running time of $O(n^2)$, which is not great. We can do better with <code class="language-plaintext highlighter-rouge">MergeSort</code>. High level idea:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230907104943.png" style="zoom:70%;" /></p>

<p>where:</p>
<ul>
  <li>given two <strong>sorted</strong> subparts, we can combine them <strong>into a sorted array</strong> by <code class="language-plaintext highlighter-rouge">merging</code> them (use a pointer at each of the two subpart, and just move the smallest element of the two to the output array). You will see after the <a href="#the-master-method">Master Method</a> that the key to $O(n \log n)$ is that <mark>this merge only takes $O(n)$!</mark>.</li>
  <li>from the above you see the <strong>recursive</strong> nature: the base case of just one element is <strong>already sorted</strong>! So we can use this base case AND the above merging operation to sort the entire array.</li>
</ul>

<p>Specifically, the pseduocode is:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># input: array A of n distinct numbers
# output: return a sorted array from smallest to largest
</span><span class="k">def</span> <span class="nf">merge_sort</span><span class="p">(</span><span class="n">A</span><span class="p">):</span>
	<span class="c1"># base case
</span>	<span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">A</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
		<span class="k">return</span> <span class="n">A</span>
	<span class="n">c</span> <span class="o">=</span> <span class="n">merge_sort</span><span class="p">(</span><span class="n">A</span><span class="p">[:</span><span class="n">n</span><span class="o">//</span><span class="mi">2</span><span class="p">])</span>  <span class="c1"># recursively sort the first half of A
</span>	<span class="n">d</span> <span class="o">=</span> <span class="n">merge_sort</span><span class="p">(</span><span class="n">A</span><span class="p">[</span><span class="n">n</span><span class="o">//</span><span class="mi">2</span><span class="p">:])</span>  <span class="c1"># recursively sort the second half of A
</span>	<span class="k">return</span> <span class="n">merge</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span>
</code></pre></div></div>
<p>so basically all the work is to <code class="language-plaintext highlighter-rouge">merge</code> the two sorted subarrays into one sorted array. The pseudocode for <code class="language-plaintext highlighter-rouge">merge</code> is:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">merge</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">d</span><span class="p">):</span>
  <span class="n">i</span> <span class="o">=</span> <span class="mi">1</span>
  <span class="n">j</span> <span class="o">=</span> <span class="mi">1</span>
  <span class="n">e</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">d</span><span class="p">)):</span>
    <span class="c1"># there is a bit more code to deal with if one of the two arrays is exhausted
</span>    <span class="c1"># if the first unused element from c is smaller, then add it to e
</span>    <span class="k">if</span> <span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">d</span><span class="p">[</span><span class="n">j</span><span class="p">]:</span>
      <span class="n">e</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
      <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="c1"># otherwise, add the first unused element from d to e
</span>    <span class="k">else</span><span class="p">:</span>
      <span class="n">e</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>
      <span class="n">j</span> <span class="o">+=</span> <span class="mi">1</span>
  <span class="k">return</span> <span class="n">e</span>
</code></pre></div></div>

<p>So what is its runtime? How fast is this compared to $O(n^{2})$?</p>

<h2 id="mergesort-the-analysis">MergeSort: The Analysis</h2>

<p>On a high level, we can imagine the runtime as “the total number of lines of code/operation we need to execute to run the implementation”. How do we approach this? In general, we should <strong>first visualize what the algorithm does</strong>.</p>

<p>For recursive algorithms such as <code class="language-plaintext highlighter-rouge">MergeSort</code>, we can visualize it as a <strong>recursion tree</strong>:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230907220532.png" style="zoom:100%;" /></p>

<p>so basically, at each node THE REAL COST is <code class="language-plaintext highlighter-rouge">merge(C,D)</code>, assuming your code implementation can slice arrays in halves using $O(1)$ time. This means that the total runtime is:</p>

\[\sum_{n \in \text{all nodes}} \text{Cost of merge(C,D) at node $n$ }\]

<p>For a recursive algorithm, generally notice that <em>each level will receive similar input</em> (e.g. sizes). Therefore, we can instead consider:</p>

\[\sum_{j \in \text{all levels}} \text{(\# of nodes at level $j$)} \times \text{(Cost of merge(C,D) at level $j$)}\]

<p>Hence we get, for an input of length $n$ (assuming its a power of $2$)</p>
<ul>
  <li>in total there are $\log_{2} n + 1$ levels</li>
  <li>at each level, there are $2^{j}$ nodes (note that you can imagine growing a tree from top to bottom as an exponential operation, while collapsing it from bottom to top as a logarithmic operation)</li>
  <li>the input size at each node would therefore be $n/2^{j}$</li>
  <li>the cost of <code class="language-plaintext highlighter-rouge">merge</code> at a node (using the pseudocode above it is about $4m+2$, where we have $4$ operations during the loop and 2 initialization operations). For simplicity let it be $6m$.</li>
</ul>

<p>The total cost <strong>at each level</strong> is therefore:</p>

\[2^{j} \cdot 6 \left( \frac{n}{2^{j}} \right) = 6n\]

<p>and finally the <strong>total runtime cost</strong> is:</p>

\[\sum_{j \in \text{all levels}} 6n = \left( \log_{2} n + 1 \right) \cdot 6n = 6n \log_{2} n + 6n  = O(n \log n)\]

<blockquote>
  <p>Important notes:</p>
  <ul>
    <li>here we considered the <strong>worst case scenario</strong>. This would be appropriate for general purpose algorithms as we won’t know what the input is.
      <ul>
        <li>What about “average-case analysis”?	For example, in the sorting problem, we could assume that all input arrays are equally likely and then study the average running time of different sorting algorithms. A second alternative is to look only at the performance of an algorithm on a small collection of “benchmark instances” that are thought to be representative of “typical” or “real-world” inputs.</li>
      </ul>
    </li>
    <li>we are sloppy for constant factors/coefficients. This is because:
      <ul>
        <li>in real life these constants will be <em>heavily implementation dependent</em></li>
        <li>will see how the Big O notation will not care about these constants</li>
      </ul>
    </li>
    <li>related to above, we will <mark>focus on how runtime scales with input size $n$</mark>. Especially when $n$ become large.
      <ul>
        <li>yes, there are cases when a runtime of $0.5n^{2}$ is faster than $6n \log n$, for example when $n=2$. But smart algorithms doesn’t really matter if $n$ is small!</li>
        <li>the <mark>holy grail is a linear-time algorithm</mark> (seeing each input ~once). For some problems we will not find a linear time algorithm, and for some (e.g. binary search) we can by “cheating” (we are already given an sorted array)</li>
      </ul>
    </li>
  </ul>
</blockquote>

<h2 id="strassens-matrix-multiplication-algorithm">Strassen’s Matrix Multiplication Algorithm</h2>

<p>This section applies the divide-and-conquer algorithm design paradigm to the problem of multiplying matrices, culminating in Strassen’s amazing <strong>subcubic-time</strong> matrix multiplication algorithm.</p>

<p>Recall that matrix multiplication considers</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230914212838.png" style="zoom:100%;" /></p>

<p>Therefore the very basic algorithm would be:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">matrix_mut</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">):</span>
  <span class="c1"># X is n x n, Y is n x n
</span>  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
      <span class="n">Z</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
      <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">Z</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">+=</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">Y</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="n">j</span><span class="p">]</span>
  <span class="k">return</span> <span class="n">Z</span>
</code></pre></div></div>
<p>which is obviously $\Theta(n^{3})$</p>

<p>Since the input size is $O(n^{2})$, the best we can hope for would be $O(n^{2})$ runtime. So can we do better? Emboldened by the divide and conquer integer multiplication algorithm, we can try to divide the matrix into smaller submatrices and then recursively compute the product of these submatrices.</p>

<p>Consider breaking the matrix down to:
<img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230914214311.png" style="zoom:100%;" /></p>

<p>then we can write the product as:
<img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230914214322.png" style="zoom:100%;" /></p>

<p>where adding two matrices is just element-wise addition with cost $O(l^{2})$ for $l \times l$ matrices. Therefore, analogous to the integer multiplication algorithm, we can write the matrix multiplication algorithm 
<img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230914214431.png" style="zoom:80%;" /></p>

<p>which has basically eight recursive calls. The problem is that this is still $\Theta(n^{3})$!</p>

<p>The key insight from the <strong>Karatsuba algorithm</strong> was that we can <em>save one multiplication</em> by using some tricks, and <strong>that can help us get sub-cubic time!</strong></p>

<p>A high level description looks like:
<img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230914214653.png" style="zoom:80%;" /></p>

<h3 id="details-of-strassens-algorithm">Details of Strassen’s Algorithm</h3>

<p>The key detail is how to save the extra multiplication. The idea is to use the following 7 auxiliary matrices:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230914214913.png" style="zoom:80%;" /></p>

<p>which involves $O(n^{2})$ time doing additional matrix additions, but <em>just with these seven</em> we can compute the matrix product as:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230914215001.png" style="zoom:80%;" /></p>

<p>which works due to some crazy cancellation, for example in the upper left:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230914215042.png" style="zoom:80%;" /></p>

<p>the rest you can check yourself, but with it down to 7 recursive calls, we can compute the runtime (using the <a href="#The_Master_Method">The Master Method</a>): $O(n^{2.807})$!</p>

<h1 id="asymptotic-notation">Asymptotic Notation</h1>

<p>The high level idea of why to use Big O:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230907222732.png" style="zoom:80%;" /></p>

<p>where saving <em>one recursive call is a bigh win</em>, because that will get saved over and over again as the recursion goes deeper.</p>

<h2 id="big-o-notation">Big-O Notation</h2>

<p>Let $T(n)$ denote the worst-case running time of an algorithm we care about, where $n={1,2,3, …}$ being the size of the input. What does it mean to say something runs in $O(f(n))$ for some function $f(n)$?</p>

<blockquote>
  <p><strong>Big-O Notation</strong>: $T(n) = O(f(n))$ if and only if there exist positive constant $c$ and $n_0$ such that:</p>

\[T(n) \leq c \cdot f(n),\quad \text{ for all } n \geq n_0\]

  <p>i.e. eventually when input gets large enough, $T(n)$ is bounded by $c \cdot f(n)$. So all you need to show/prove is that you can <em>construct a $c$ and $n_0$</em> such that it holds.</p>
</blockquote>

<p>Pictorially, we can imagine:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230907223339.png" style="zoom:70%;" /></p>

<hr />
<p><em>For Example:</em> a degree-$k$ polynomials are $O(n^{k})$. Suppose:</p>

\[T(n) = a_{k} n^{k} + a_{k-1} n^{k-1} + ... + a_{1} n + a_{0}\]

<p>for $k \ge 0$ and $a_i$’s are real numbers. We can show that $T(n) = O(n^{k})$:</p>

\[\begin{align*}
	T(n)
	&amp;= a_{k} n^{k} + a_{k-1} n^{k-1} + ... + a_{1} n + a_{0} \\
	&amp;\le \left|a_k\right| n^{k} + \left|a_{k-1}\right| n^{k-1} + ... + \left|a_{1}\right| n + \left|a_{0}\right|\\
	&amp;\le \left|a_k\right| n^{k} + \left|a_{k-1}\right| n^{k} + ... + \left|a_{1}\right| n^k + \left|a_{0}\right| n^k\\
	&amp;= \left(\left|a_k\right| + \left|a_{k-1}\right| + ... + \left|a_{1}\right| + \left|a_{0}\right|\right) n^k\\
	&amp;\equiv c \cdot n^k

\end{align*}\]

<p>holds for all $n$, so $n_{0} = 1$ and $c = \left\vert a_k\right\vert  + \left\vert a_{k-1}\right\vert  + … + \left\vert a_{1}\right\vert  + \left\vert a_{0}\right\vert$.</p>

<hr />

<p><em>For Example:</em> a degree-$k$ polynomial is not $O(n^{k-1})$. Suppose for simplicity $T(n) = n^{k}$. Then <mark>proof by contradition</mark> that this means:</p>

\[n^{k} \le c \cdot n^{k-1}, \quad \text{ for all } n \ge n_0\]

<p>this means:</p>

\[n \le c, \quad \text{ for all } n \ge n_0\]

<p>which is a contradiction as $n$ can be arbitrarily large.</p>

<h2 id="big-omega-and-big-theta-notation">Big-Omega and Big-Theta Notation</h2>

<p>On a high level, if big-O is analogous to “less than or equal to ($\le$),” then big-omega and big-theta are analogous to “greater than or equal to ($\ge$),” and “equal to (=).”</p>

<blockquote>
  <p><strong>Big-Omega Notation</strong>: $T(n) = \Omega(f(n))$ if and only if there exist positive constant $c$ and $n_0$ such that:</p>

\[T(n) \geq c \cdot f(n),\quad \text{ for all } n \geq n_0\]

  <p>i.e. eventually when input gets large enough, $T(n)$ is <mark>bounded below</mark> by $c \cdot f(n)$.</p>
</blockquote>

<p>Pictorially, bounding from below means:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230907224630.png" style="zoom:70%;" /></p>

<p>and we would call $T(n) = \Omega(f(n))$.</p>

<blockquote>
  <p><strong>Big-Theta Notation</strong>: $T(n) = \Theta(f(n))$ if and only if there exist positive constant $c_1, c_2$ and $n_0$ such that:</p>

\[c_1 \cdot f(n) \leq T(n) \leq c_2 \cdot f(n),\quad \text{ for all } n \geq n_0\]

  <p>i.e. eventually when input gets large enough, $T(n)$ is <mark>sandwiched</mark> by $c_1 \cdot f(n)$ and $c_2 \cdot f(n)$. Notice that this is analogous to say that both $T(n) = \Theta(f(n))$ and $T(n) = O(f(n))$.</p>
</blockquote>

<p><em>For example</em>, if $T(n) = \frac{1}{2} n^{2} + 3n$, then $T(n) = \Theta(n^{2})$.</p>

<blockquote>
  <p><strong>Little-O Notation</strong>: $T(n) = o(f(n))$ if and only if <mark>for every positive constant $c&gt;0$</mark> there exists a constant $n_0$ such that:</p>

\[T(n) \le c \cdot f(n),\quad \text{ for all } n \geq n_0\]

  <p>i.e. eventually when input gets large enough, $T(n)$ is <mark>bounded above</mark> by $c \cdot f(n)$ for any $c$ you pick (note that you can pick $n_0$ based on $c$). Also note that this is much stronger than the Big O notation.</p>
</blockquote>

<p>Intuitively, this is like saying we want:</p>

\[\lim\limits_{n \to \infty} \frac{f(n)}{T(n)} = 0\]

<p>that $f(n)$ grows strictly faster than $T(n)$ (i.e. pick $c$ to be infinitesimally small in the above definition). Also note that the intutive way of converting between Big O and Little O is NOT just switching $\le$ to $&lt;$, as that would actually not change anything (see HW1 Problem 2.7)</p>

<p><em>For example</em>, $n^{k-1} = o(n^{k})$ is true for any $k \ge 1$.</p>

<h1 id="the-master-method">The Master Method</h1>

<p>This “master method” applies to analyzing most of the <em>divide-and-conquer algorithms</em> you’ll ever see, as their runtime typically follows a pattern of the form:</p>

\[T(n) = \underbrace{a \cdot T\left(\frac{n}{b}\right)}_{\text{word done by recursive calls}} + \underbrace{O(n^{d})}_{\text{clean up}}\]

<p>where $a$ would be the number of recursive calls you make, $b$ would be by how much you shrink the input size, and $O(n^{d})$ would be the time it takes to combine/clean up any of results of the recursive calls (e.g. the  cost for <code class="language-plaintext highlighter-rouge">merge</code> in <code class="language-plaintext highlighter-rouge">merge_sort</code>).</p>

<hr />

<p><em>For Example</em>, recall the multiplication problem. Grade-school algorithm would give us $O(n^{2})$. However,</p>
<ul>
  <li>
    <p>the recursive algorithm v1 (calculate $10^{n}ac + 10^{n / 2}(ad + bc) + bd$) would then give us:</p>

\[T(n) \le 4T(n / 2) + O(n)\]

    <p>where $4$ comes from doing 4 more multiplications to calculate $ac, ad, bc, bd$, and $n / 2$ because we are chopping each original interger into half $x = 10^{n / 2}a + b$ and $y = 10^{n / 2}c + d$.</p>
  </li>
  <li>
    <p>the recursive algorithm v2 (<strong>Karatsuba Algorithm</strong>) saves the computation of $ad + bc$ by computing only $(a+b)(c+d)$ and then minus $(ac + bd)$ which would be already computed. Given that addition is done in linear time:</p>

\[T(n) \le 3T(n / 2) + O(n)\]

    <p>where now you only have to do 3 more multiplications to calculate $ac, bd, (a+b)(c+d)$, with extra work in addition but that is already in $O(n)$ term.</p>
  </li>
</ul>

<p>and that for all the above cases, the base case is $T(1) = O(1)$.</p>

<hr />

<h2 id="formal-statement">Formal Statement</h2>

<p>We’ll discuss a version of the master method that handles what we’ll call <strong>“standard recurrences”</strong>, which have three free parameters and the following form:</p>

<blockquote>
  <p><strong>Standard Recurrence Format</strong>. Let $T(n) = \mathrm{constant}$ for some small enough $n$ (i.e. base case). Then for large values of $n$, we have the runtime being:</p>

\[T(n) \le a \cdot T\left(\frac{n}{b}\right) + O(n^{d})\]

  <p>where:</p>
  <ul>
    <li>$a$ is the number of recursive calls you make</li>
    <li>$b$ is by how much you shrink the input size</li>
    <li>$O(n^{d})$ is the time it takes to combine/clean up any of results of the recursive calls</li>
  </ul>
</blockquote>

<p>Then, we have the master method:</p>

<blockquote>
  <p><strong>Master Method</strong>. If $T(n)$ is defined by a standard recurrence of the form above with $a \ge 1, b &gt; 1$ and $d \ge 0$, then:</p>

\[T(n) = \begin{cases}
O(n^{d} \log n) &amp; \text{if } a = b^{d} \\
O(n^{d}) &amp; \text{if } a &lt; b^{d} \\
O(n^{\log_{b} a}) &amp; \text{if } a &gt; b^{d}
\end{cases}\]

  <p>note that</p>
  <ul>
    <li>intuitively, the second one indicates that your algorithm is “clean up step heavy”, and the third one indicates that your algorithm is “recursive call heavy”</li>
    <li>the last case <em>specifically specified a base $b$</em>, whereas the first case did not. This is because any two logarithm base differ by a constant multiple. This will be harmless in the first case because we are multiplying by a constant factor of $d$, but not in the last case because we are raising to a power of $n$.</li>
  </ul>
</blockquote>

<p>First for a sanity check, the merge sort algorithm takes the form of:</p>

\[T(n) = 2T\left(\frac{n}{2}\right) + O(n)\]

<p>hence we have $a = 2, b = 2, d = 1$, and so $a = b^{d}$, which means that the first case applies and we have $T(n) = O(n^{d} \log n) = O(n \log n)$.</p>

<p>Then we first answer the questions of runtime for KaraSuba algorithm and the recursive algo v1:</p>

<ul>
  <li>multiplication algo v1 has $a=4, b=2, d=1$ so $a &gt; b^{d}$, hence we have $T(n) = O(n^{\log_{b} a}) = O(n^{2})$, actually just as good as the grade-school algorithm.</li>
  <li>KaraSuba algo has $a=3, b=2, d=1$ so $a &gt; b^{d}$, but we have $T(n) = O(n^{\log_{b} a}) = O(n^{\log_{2} 3}) \approx O(n^{1.59})$, which is better than the grade-school algorithm.</li>
  <li>Matrix Multiplication v1 (splitting into 8 smaller matrix multiplications) have still $O(n^{3})$. To see this, there are two ways: 1) consider $T(n^{2})=8 T(n^{2} / 4) + O(n^{2})$, substitute $n^{2}=u$ we get runtime is $O(u^{\log_{a} b})$; 2) just consider the input $n^{2}$ as a function of $n$, hence runtime is $T(n) = 8T(n / 2) + O(n)$, which gives $O(n^{\log_{a} b})$.</li>
</ul>

<h2 id="proof-of-master-method">Proof of Master Method</h2>

<p>Next we prove the master’s method.</p>

<p><em>Proof</em>: Suppose that $T(1) = \text{constant}$ and we have the standard recurrence for $n &gt; 1$:</p>

\[T(n) \le a \cdot T\left(\frac{n}{b}\right) + c \cdot n^d\]

<p>where we replaced $O(n^{d})$ with $c \cdot n^{d}$ for some constant $c$.</p>

<p>We can try to write a few terms out and see if we can find a pattern, but alternatively we can also <strong>draw a recursion tree</strong> and see if we can <strong>directly find a closed-form equation</strong>:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230912225937.png" style="zoom:100%;" /></p>

<p>Our goal is to find the runtime of this entire tree. So we consider:</p>

\[T(n) = \sum_{j \in \mathrm{level}} \sum \mathrm{cost}(\text{each node})\]

<p>from which we know that:</p>
<ul>
  <li>there are <strong>$a^{j}$ subproblems/nodes</strong> at depth $j$</li>
  <li>each node at depth $j$ needs to solve problem with <strong>input size $n / b^{j}$</strong></li>
</ul>

<p>again, assuming splitting the input to $b$ subproblems takes constant time, we have the <mark>cost at each node being</mark>:</p>

\[\mathrm{cost}(\text{each node}) = c \cdot \left( \frac{n}{b^j} \right)^d\]

<p>since at each node it is just the clean up step $c \cdot n^{d}$. Then since there are $a^{j}$ nodes at level $j$, we have:</p>

\[\begin{align*}
  T(n) 
  &amp;= \sum_{j=0}^{\log_b a} a^j \cdot c \cdot \left( \frac{n}{b^j} \right)^d \\
  &amp;= c \cdot n^d \cdot \sum_{j=0}^{\log_b a} \underbrace{\left( \frac{a}{b^d} \right)^j}_{\text{this ratio!}} \\
\end{align*}\]

<p>where the ratio of $a / b^{d}$ was the ratio we had in the master method. This ratio also has a very important interpretation:</p>
<ul>
  <li>$a$ is the <mark>rate of growth/proliferation</mark></li>
  <li>$b^{d}$ is the <mark>rate of shrinkage of work</mark>. Since each of your subproblem shrink by a factor of $b$, but that goes into the term $O(n^{d})$, hence you shrink your work by a factor of $b^{d}$.</li>
</ul>

<p>Then we have the following cases:</p>
<ul>
  <li>
    <p>if $a = b^{d}$, then:</p>

\[T(n) = c \cdot n^d \cdot \sum_{j=0}^{\log_b a} \left( \frac{a}{b^d} \right)^j = c \cdot n^d \cdot \sum_{j=0}^{\log_b a} 1 = c \cdot n^d \cdot (\log_b a + 1) = O(n^d \log n)\]

    <p>note that we changed the base here.</p>
  </li>
  <li>
    <p>if $a / b^{d} = r \neq  1$, then we have a <strong>finite geometric series</strong> where:</p>

\[\sum\limits_{j=0}^{k} r^{j} = 1 + r + r^{2} + \cdots + r^{k} = \frac{r^{k+1} - 1}{r - 1}\]

    <p>which means that:</p>
    <ul>
      <li>
        <p>if $r &lt; 1$, then the first term $O(1)$ dominates. Hence we get</p>

\[T(n) = c \cdot n^d \cdot O(1) = O(n^d)\]

        <p>which is basically the <mark>work done by the root node</mark>!</p>
      </li>
      <li>
        <p>if $r &gt; 1$, then the last term $O(r^{k})$ dominates. Hence we get</p>

\[T(n) = c \cdot n^d \cdot O\left[ \left( \frac{a}{b^{d}} \right)^{\log_{b} n} \right]\]

        <p>note that since $b^{-d \log_{b} n} = (b^{\log_b n})^{-d} = n^{-d}$, we get:</p>

\[T(n) = O(a^{\log_{b} n}) = O(n^{\log_{b} a})\]

        <p>where $a^{\log_{b} n}$ is basically <mark>the number of leaves</mark>! However we still use the $n^{\log_{b} a}$ because it’s easier to apply.</p>
      </li>
    </ul>
  </li>
</ul>

<hr />

<h1 id="linear-time-selection">Linear-Time Selection</h1>

<p>This section discusses another divide-and-conquer algorithm, but won’t take the standard form of the master method (probably the only case in this course).</p>

<blockquote>
  <p><strong>Selection Problem</strong>. Given an array $A$ of $n$ distinct numbers and an index $i$, find the $i$th smallest element of $A$.</p>
</blockquote>

<p>The naive solution would be a sort + indexing, which takes $O(n \log n)$ time. However, we can do better by using the divide-and-conquer strategy. The intuition is that we can select a pivot and partition the array in such a way that we will only need to <em>recurse on one of the two partitions</em> = <strong>reduced input size</strong>!</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230914220414.png" style="zoom:100%;" /></p>

<p>one very important finding is that the <strong>pivot is at the “rightful” position</strong> which can tell us two things:</p>
<ol>
  <li><em>that pivot element</em> is in the right position as if it’s sorted, <mark>such that</mark>:</li>
  <li>if we are looking for, say, the $5$-th smallest element, the entire left partition (red) is <strong>irrelevant</strong></li>
</ol>

<p>Thus a high level sketch of the algorithm is as follows:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">select</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">i</span><span class="p">):</span>  <span class="c1"># n is the length, i is the i-th smallest
</span>  <span class="k">if</span> <span class="n">n</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">A</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="c1"># select a pivot and sort
</span>    <span class="n">p</span> <span class="o">=</span> <span class="n">pivot</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>

    <span class="c1"># recursively select
</span>    <span class="n">partition</span><span class="p">(</span><span class="n">A</span> <span class="n">around</span> <span class="n">p</span><span class="p">)</span>  <span class="c1"># O(n) to put smaller element on left, larger on right
</span>    <span class="n">j</span> <span class="o">=</span> <span class="s">"p's position "</span>  <span class="c1"># 1-indexed
</span>    <span class="k">if</span> <span class="n">j</span> <span class="o">==</span> <span class="n">i</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">p</span>
    <span class="k">elif</span> <span class="n">j</span> <span class="o">&gt;</span> <span class="n">i</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">select</span><span class="p">(</span><span class="n">A</span><span class="p">[:</span><span class="n">j</span><span class="p">],</span> <span class="n">j</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="c1"># note the new length of RHS search is n - j 
</span>      <span class="c1"># since RHS is all larger, the new i is i - j
</span>      <span class="k">return</span> <span class="n">select</span><span class="p">(</span><span class="n">A</span><span class="p">[</span><span class="n">j</span><span class="p">:],</span> <span class="n">n</span> <span class="o">-</span> <span class="n">j</span><span class="p">,</span> <span class="n">i</span> <span class="o">-</span> <span class="n">j</span><span class="p">)</span>
</code></pre></div></div>

<p>But what’s the running time? We have not yet discussed how to find a “good” pivot, but we know that:</p>
<ul>
  <li><strong>worst pivot</strong>: we always pick the minimum/maximum element, so that <strong>each recursive call can only throw away one element</strong>. This is bad, as it results in $\Theta(n^2)$.</li>
  <li><strong>best pivot</strong>: if we managed to pick the median (the $i= (n-1) / 2$-th smallest element, which we don’t know), then we can throw away half of the array each time. This is good, as it will result in $O(n)$ (try with the master method), but we don’t know how to find the median.</li>
</ul>

<p>(we will discuss how to find a “good enough” pivot, such that we can still get $O(n)$)</p>

<h2 id="median-of-medians">Median of Medians</h2>

<p>The trick to linear-time selection is to <strong>use the “median-of-medians” as a proxy</strong> for the true median. First we show the full <code class="language-plaintext highlighter-rouge">select</code> algorithm, and then we will discuss the intuition and runtime behind it.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">select</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">i</span><span class="p">):</span>  <span class="c1"># n is the length, i is the i-th smallest
</span>  <span class="k">if</span> <span class="n">n</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">A</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="c1">### select a pivot and sort
</span>    <span class="n">C</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="mi">5</span><span class="p">):</span>
      <span class="c1"># sort each 5-element subarray
</span>      <span class="n">B</span> <span class="o">=</span> <span class="n">sort</span><span class="p">(</span><span class="n">A</span><span class="p">[</span><span class="n">h</span><span class="p">:</span><span class="n">h</span><span class="o">+</span><span class="mi">5</span><span class="p">])</span>
      <span class="c1"># find/keep the median of each 5-element subarray
</span>      <span class="n">C</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">B</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>  <span class="c1">### first round winners
</span>    <span class="n">p</span> <span class="o">=</span> <span class="n">select</span><span class="p">(</span><span class="n">C</span><span class="p">,</span> <span class="n">n</span> <span class="o">/</span> <span class="mi">5</span><span class="p">,</span> <span class="n">n</span> <span class="o">/</span> <span class="mi">10</span><span class="p">)</span>  <span class="c1">### median of medians, recursively select 1
</span>
    <span class="n">partition</span><span class="p">(</span><span class="n">A</span> <span class="n">around</span> <span class="n">p</span><span class="p">)</span>  <span class="c1"># O(n) to put smaller element on left, larger on right
</span>    <span class="n">j</span> <span class="o">=</span> <span class="s">"p's position in the sorted array"</span>  <span class="c1"># 1-indexed
</span>    <span class="k">if</span> <span class="n">j</span> <span class="o">==</span> <span class="n">i</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">p</span>
    <span class="k">elif</span> <span class="n">j</span> <span class="o">&gt;</span> <span class="n">i</span><span class="p">:</span>  <span class="c1">### recursively select 2
</span>      <span class="k">return</span> <span class="n">select</span><span class="p">(</span><span class="n">A</span><span class="p">[:</span><span class="n">j</span><span class="p">],</span> <span class="n">j</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="c1"># note the new length of RHS search is n - j 
</span>      <span class="c1"># since RHS is all larger, the new i is i - j
</span>      <span class="k">return</span> <span class="n">select</span><span class="p">(</span><span class="n">A</span><span class="p">[</span><span class="n">j</span><span class="p">:],</span> <span class="n">n</span> <span class="o">-</span> <span class="n">j</span><span class="p">,</span> <span class="n">i</span> <span class="o">-</span> <span class="n">j</span><span class="p">)</span>
</code></pre></div></div>
<p>This warrants several “issues”:</p>

<ul>
  <li>Since there is a <code class="language-plaintext highlighter-rouge">sort</code>, how is this not $O(n \log n)$ runtime? This is because in this case we are sorting a <em>constant</em> number of elements , hence it becomes $O(5 \log 5) = O(1)$. But, since there will be $n / 5$ groups of 5 elements, the total runtime is $O(n)$!</li>
  <li>why 5 elements in particular? A short answer is that this is the <em>smallest odd number</em> that can give this algorithm a linear time. For exercise, try using $3$ and compute the runtime.</li>
  <li>how much smaller is the reduced input size <em>after this median of median pivot</em>? The answer is that this <strong>guarantees throwing at least 30% of the array away</strong>.</li>
</ul>

<blockquote>
  <p><strong>Lemma</strong>. The median of median pivot $p$ is at least the $30$th percentile of the array $A$. To see this, consider $k = n / 5$ is the number of groups you have spliited up, and $x_i$ is the $i$th smallest element <em>amongst the $k$ middle elements</em>. Then we can arrange the full array $A$ into the following way: 
<img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230914223004.png" style="zoom:20%;" />
where basically numbers are <strong>guaranteed to be bigger</strong> going from bottom to top, though not necessarily left to right. However, this still indicates that:</p>
  <ul>
    <li>the red highlighted bottom left corner is <strong>smaller than $x_{k / 2}$</strong></li>
    <li>the red highlighted top right corner is <strong>larger than $x_{k / 2}$</strong>
therefore, this means that the median of median, $x_{k / 2}$ is bigger than 3/5 of the rows and &gt;50% of the columns, hence it is at least the 30th percentile.</li>
  </ul>
</blockquote>

<h2 id="runtime-of-select-algorithm">Runtime of Select Algorithm</h2>

<p>Now given that the median is guaranteed to throw away at least 30% of the array, we can write the recurrence relation as follows:</p>

\[T(n) = \underbrace{T\left( \frac{n}{5} \right)}_{\text{recursive call by pivot()}} + \underbrace{T \left( \frac{7}{10}n \right)}_{\text{after pivot, search the other 70\%}} + \underbrace{O(n)}_{\text{sort the 5-element subarrays + partition}}\]

<p>note that we <em>cannot</em> use master’s method here, as now we have <em>two recursive calls</em>. In this case, we will need to show that with “guess the solution and check”: that <strong>this is $O(n)$ time</strong>.</p>

<hr />

<p><em>Proof</em>: We want to show tat $T(n) = c \cdot n$ for all $n \ge n_{0} = 1$ in this case. (Hindsight) let $c = 10a$, where $a$ is the constant in the $O(n)$ runtime of the <code class="language-plaintext highlighter-rouge">sort</code> function:</p>

\[T(n) \le T\left( \frac{n}{5} \right) + T \left( \frac{7}{10}n \right) + an\]

<p>is already given. We can prove $T(n) \le c \cdot n$ by induction on $n$:</p>

<ol>
  <li>base case: when $n=1$ this trivially holds as $T(1) = 1 \le c = 10a$ and $a&gt;1$.</li>
  <li>induction hypothesis: assume $T(k) \le c \cdot k$ for all $k &lt; n$ (e.g. holds for $k= n-1$)</li>
  <li>
    <p>induction step: we show that it holds for $n$:</p>

\[\begin{align*}
 T(n) 
 &amp;\le T\left( \frac{n}{5} \right) + T \left( \frac{7}{10}n \right) + an\\
 &amp;\le c \cdot \frac{n}{5} + c \cdot \frac{7}{10}n + an\\
 &amp;= \frac{9}{10}cn + an\\
 &amp;= n \cdot \left( \frac{9}{10}c + a \right)\\
 &amp;= n \cdot 10 a = c \cdot n
\end{align*}\]

    <p>where the second inequality comes from the induction step that we assumed $T(k)\le c \cdot k$ holds.</p>
  </li>
</ol>

<hr />

<h1 id="quicksort">QuickSort</h1>

<p>This is perhaps the most famous sorting algorithm, and it is also based on the idea of <strong>divide-and-conquer</strong>. Although it also operates with $O(n \log n)$, in practice there are differences compared to <code class="language-plaintext highlighter-rouge">merge_sort</code>:</p>
<ul>
  <li>The big win for QuickSort over MergeSort is that it CAN run in place. For this reason it needs to allocate only a minuscule amount of additional memory for intermediate computations. However <code class="language-plaintext highlighter-rouge">merge_sort</code> needs to allocate a whole new array for each merge step.</li>
  <li>On the aesthetic side, QuickSort is just a remarkably beautiful algorithm.</li>
</ul>

<p>The implementation follows directly from the <code class="language-plaintext highlighter-rouge">DSelect</code> and <code class="language-plaintext highlighter-rouge">partition</code> algorithm:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230919223127.png" style="zoom:80%;" /></p>

<p>how does this help <em>sort</em> the array?</p>

<ol>
  <li>the <strong>pivot element already winds up in its rightful position</strong>,</li>
  <li>partitioning has <strong>reduced the size of this problem</strong>: sorting the elements less than the pivot (which conveniently occupy their own subarray) and the elements greater than the pivot (also in their own subarray).</li>
</ol>

<p>After recursively sorting the elements in each of these two subarrays, the algorithm is done</p>

<p>Therefore the algorithm is simply:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">quick_sort</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">n</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">A</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">pivot</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
    <span class="n">A_1</span><span class="p">,</span> <span class="n">A_2</span> <span class="o">=</span> <span class="n">partition</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>
    <span class="n">A_1_sorted</span> <span class="o">=</span> <span class="n">quick_sort</span><span class="p">(</span><span class="n">A_1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">A_1</span><span class="p">))</span> 
    <span class="n">A_2_sorted</span> <span class="o">=</span> <span class="n">quick_sort</span><span class="p">(</span><span class="n">A_2</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">A_2</span><span class="p">))</span>
    <span class="c1"># if you can sort in place, you don't need this
</span>  <span class="k">return</span> <span class="n">A_1_sorted</span> <span class="o">+</span> <span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="o">+</span> <span class="n">A_2_sorted</span>
</code></pre></div></div>

<p>Even though the quick runtime analysis above gives the same result as <code class="language-plaintext highlighter-rouge">merge_sort</code>, the <code class="language-plaintext highlighter-rouge">quick_sort</code> algorithm feels a bit different. This is because the order of operations is different. In <code class="language-plaintext highlighter-rouge">merge_sort</code>, the recursive calls are performed first, followed by the combine step, <code class="language-plaintext highlighter-rouge">merge</code>. In <code class="language-plaintext highlighter-rouge">quick_sort</code>, the <strong>recursive calls occur after partitioning</strong>, and their results don’t need to be <code class="language-plaintext highlighter-rouge">merge</code>d at all!</p>

<p>But first of all, is this even correct? Here we prove it formally using induction, which is very suitable for recursive algorithms.</p>

<hr />

<p><em>Proof of Correctness</em>: We will prove by induction. Let $P(n)$ denote the statement “for any array $A$ of length $n$, <code class="language-plaintext highlighter-rouge">quick_sort(A, n)</code> returns a correctly sorted array”.</p>

<ol>
  <li>Base case: $P(1)$ is trivially true, as the array is already sorted.</li>
  <li>Inductive hypothesis: assume $P(k)$ is true for all $k &lt; n$, for any $n &gt; 1$.</li>
  <li>Induction step. Now we need to imagine an input of $P(n)$. First, we note that the pivot element $p$ is already in the right sorted position. Then, we note that since <code class="language-plaintext highlighter-rouge">A_1</code> and <code class="language-plaintext highlighter-rouge">A_2</code> are subarrays with size at most $n-1$, this means that <code class="language-plaintext highlighter-rouge">A_1_sorted</code> and <code class="language-plaintext highlighter-rouge">A_2_sorted</code> are correctly sorted by the induction hypothesis. Therefore, the concatenation of <code class="language-plaintext highlighter-rouge">A_1_sorted</code>, <code class="language-plaintext highlighter-rouge">p</code>, and <code class="language-plaintext highlighter-rouge">A_2_sorted</code> is also correctly sorted.</li>
</ol>

<h2 id="in-place-partition">In-Place Partition</h2>

<p>To sort the array in place using <code class="language-plaintext highlighter-rouge">quick_sort</code>, we just need a routine that can partition the array in place. This is a bit tricky, but it is possible to do this in <strong>a single scan</strong> over the array, <strong>while doing it in-place</strong>.</p>

<blockquote>
  <p><em>Key Idea</em>: while scanning through the array, we can urge to keep the following <strong>invariant</strong>:</p>

  <p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230919225947.png" style="zoom:100%;" /></p>

  <p>where to put the pivot element to the first position is just a swap in $O(1)$ during preprocessing. If we can check each new element in the unpartitioned part and <strong>swap it to the correct partition</strong>, then we can <mark>maintain this invariant = correctness</mark>!</p>
</blockquote>

<p>This is easiest to first go through an example. Consider an input:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230919230212.png" style="zoom:100%;" /></p>

<p>where we consider the invariant formally to be:</p>

<blockquote>
  <p><strong>Invariant</strong>: all elements between the pivot and $i$ are <em>less than</em> the pivot (the $&lt; p$ partition), and all elements between $i$ and $j$ are <em>greater than</em> the pivot (the $&gt; p$ partition). This means that:</p>
  <ul>
    <li>$i$ represent the boundary between the $&lt; p$ and $&gt; p$ partitions, and</li>
    <li>$j$ represent the boundary for yet unseen elements.</li>
  </ul>
</blockquote>

<ol>
  <li>We initialize $i,j$ to be right next to the pivot (first) element. As there is no element between $i$ and $j$ or between the pivot and $i$, the invariant is trivially satisfied.</li>
  <li>At each iteraction, we look at a new element and consider what to do to maintain the invariant:
<img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230919230632.png" style="zoom:100%;" />
in this case $8$ is larger than the pivot and invariant is maintained.</li>
  <li>If the new element is smaller than the pivot. To maintain invraiant, we can <em>swap it with the first element after $i$ and then increment $i$</em>:
<img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230919230757.png" style="zoom:90%;" /></li>
  <li>We continue increment $j$ to see the new element. If it is bigger than the pivot, we can just continue as the invariant is maintained.
<img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230919230942.png" style="zoom:100%;" /></li>
  <li>One last, example, now we see another element smaller than the pivot, so we need to swap and increment $i$:
<img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230919231113.png" style="zoom:100%;" /></li>
</ol>

<p>Hence the pseudocode is:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">partition_inplace</span><span class="p">(</span><span class="n">A</span><span class="p">):</span>
  <span class="n">p</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># assuming pivot is the first element
</span>  <span class="n">i</span> <span class="o">=</span> <span class="mi">1</span>
  <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">A</span><span class="p">)):</span>
    <span class="k">if</span> <span class="n">A</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">p</span><span class="p">:</span>
      <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">A</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
      <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
  <span class="n">A</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">A</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># swap pivot to the correct position
</span>  <span class="k">return</span> <span class="n">A</span>
</code></pre></div></div>

<h2 id="randomized-quicksort">Randomized QuickSort</h2>

<p>Now, what about runtime? Again, the key step is how we choose the pivot element. Similar to <code class="language-plaintext highlighter-rouge">DSelect</code>, this will have a huge impact:</p>
<ul>
  <li>if we choose min/max of the array, we get $\Omega(n^{2})$ runtime (technically also $O(n^{2})$, but just to emphasize the slowness).</li>
  <li>if we choose the median of the array, we get $T(n) = 2 T( n / 2) + O(n) = O(n \log n)$ where the $O(n)$ cost would be calling <code class="language-plaintext highlighter-rouge">DSelct</code> to find the median.</li>
</ul>

<p>While the median is the best choice, it is also the most expensive to compute. Therefore, we will use a <strong>randomized</strong> version of <code class="language-plaintext highlighter-rouge">quick_sort</code> that chooses a random pivot element. This is a very simple modification to the algorithm, and we will show that it has <strong>average case $O(n \log n)$!</strong></p>

<blockquote>
  <p>Why on earth would you want to inject randomness into your algorithm? Aren’t algorithms just about the most deterministic thing you can think of? As it turns out, there are hundreds of computational problems for which randomized algorithms are faster, more eﬀective, or easier to code than their deterministic counterparts.</p>
</blockquote>

<p>To prove the average case runtime, let’s define some notations:</p>

<ul>
  <li>sample space $\Omega$: the set of all possible outcomes of some random experiment</li>
  <li>random variable $X$: a (numerical) measurement of the outcome if a random process, so $X: \Omega \to \R$</li>
  <li>$P(\omega)$ is the probability of getting a particular outcome $\omega \in \Omega$.</li>
</ul>

<p>In the case of <code class="language-plaintext highlighter-rouge">quick_sort</code>, we have:</p>

<ul>
  <li>$\Omega$ being the set of all possible outcomes caused by some random (sequence of) choice of pivot element. (note that it is <em>not</em> defined on the length of the array)</li>
  <li>$X=RT$ that we care about is the runtime of this randomized <code class="language-plaintext highlighter-rouge">quick_sort</code> <em>given</em> a sequence of pivot choices. I.e. given $w \in \Omega$, we get a deterministic runtime $RT(\omega)$.</li>
</ul>

<p>So our goal is to find:</p>

\[\mathbb{E}[RT] = \sum_{\omega \in \Omega} P(\omega) RT(\omega)\]

<p>But this $RT(\omega)$ is hard to compute. Taking a look at the algorithm, we notice that we can simplify this random variable to:</p>

<blockquote>
  <p><strong>Lemma</strong>: For every input array $A$ of length $n \ge 2$ and every pivot sequence $\omega$:</p>

\[RT(\omega) \le a \cdot C(\omega)\]

  <p>for some constant $a &gt; 0$, and $C$ denote the random variable equal to the <strong>total number of comparisons made between pairs of input elements performed by <code class="language-plaintext highlighter-rouge">quick_sort</code></strong> with a given sequence of pivot choices.</p>
</blockquote>

<p>See the book chapter 5.5 for more details, but on a high level: the main operation in <code class="language-plaintext highlighter-rouge">quick_sort</code> is the <code class="language-plaintext highlighter-rouge">partition</code> call, and that is where the comparisons are made.</p>

<p>But $C$ is still a difficult random variable. The trick is that we can <mark>decompose it further</mark>. Let $X_{ij}$ denote the total number of times the elements $z_i$  and $z_j$ get compared in <code class="language-plaintext highlighter-rouge">quick_sort</code>:</p>

\[C(\omega) = \sum\limits_{i=1}^{n-1} \sum\limits_{j=i+1}^{n} X_{ij}(\omega)\]

<p>which literally represents the sum of all comparisons between pairs of elements in the array. Without loss of generality, let $z_i$, $z_j$ also be the $i$-th and $j$-th <em>smallest</em> elements in the array. Then, the question is how many times do we compare $z_i$ and $z_j$?</p>

\[X_{ij}(\omega) = \{0,1\}\]

<p>because comparisons only happen during <code class="language-plaintext highlighter-rouge">partition</code>:</p>
<ul>
  <li>if one of the elements is the pivot, then they can be compared at most once (and then they will be separated by the pivot and sent to different partitions)</li>
  <li>after they are separated, they will never be compared again.</li>
</ul>

<p>Now the real trick is to use the <strong>linearity of expectation</strong>:</p>

<blockquote>
  <p><strong>Linearity of Expectation</strong>: For any random variables $X_1, X_2, \dots, X_n$ and any constants $a_1, a_2, \dots, a_n$:</p>

\[\mathbb{E}[a_1 X_1 + a_2 X_2 + \dots + a_n X_n] = a_1 \mathbb{E}[X_1] + a_2 \mathbb{E}[X_2] + \dots + a_n \mathbb{E}[X_n]\]

  <p>In other words, the expectation of a sum of random variables is the sum of their expectations. Note that this is true even if the random variables are not independent.</p>
</blockquote>

<p>Then we compute the expectation of $C$:</p>

\[\begin{aligned}
\mathbb{E}[C] &amp;= \mathbb{E} \left[ \sum\limits_{i=1}^{n-1} \sum\limits_{j=i+1}^{n} X_{ij} \right] \\
&amp;= \sum\limits_{i=1}^{n-1} \sum\limits_{j=i+1}^{n} \mathbb{E}[X_{ij}] \\
&amp;= \sum\limits_{i=1}^{n-1} \sum\limits_{j=i+1}^{n} P(X_{ij} = 1) \\
&amp;= \sum\limits_{i=1}^{n-1} \sum\limits_{j=i+1}^{n} P(\text{did compare $z_i$ and $z_j$ in QuickSort})
\end{aligned}\]

<blockquote>
  <p><strong>Lemma</strong> If $z_i$ and $z_j$ denote the $i$-th and $j$-th smallest elements in the array, with $i &lt; j$, then the probability that they are compared in <code class="language-plaintext highlighter-rouge">quick_sort</code> is:</p>

\[P(\text{did compare $z_i$ and $z_j$ in QuickSort}) = \frac{2}{j-i+1}\]

</blockquote>

<p>Proof Sketch: Consider fixing $z_i$, $z_j$ with $i &lt; j$, and let some pivot element $z_k$ be chosen during the <em>first recursive call to <code class="language-plaintext highlighter-rouge">quick_sort</code></em>. What happens next?</p>
<ol>
  <li>if $z_k$ is smaller than $z_i$ or bigger than $z_j$, then $z_i, z_{i+1}, …, z_{j}$ will be in the same partition, and will be sent to the next recursive call. They <em>might</em> be compared against in the future, we don’t know yet.</li>
  <li>if $z_k$ happens to be between $z_i$ and $z_j$, then $z_i$ and $z_j$ will be separated by the pivot, and <strong>are not and will never</strong> be compared again.
<img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230919235354.png" style="zoom:100%;" /></li>
  <li>if $z_k$ happens to be $z_i$ or $z_j$, then they will be <strong>compared once</strong>, and then separated by the pivot, and <strong>are not and will never</strong> be compared again.</li>
</ol>

<p>Therefore, the first condition is just a “placeholder” that will eventually lead to the second or third conditions. So the probability of $z_i$ and $z_j$ being compared is equivalent to:</p>

\[P(\text{$z_i$ or $z_j$ is chosen as the pivot before any other element in $z_{i+1}, ..., z_{j-1}$}) = \frac{2}{j-i+1}\]

<p>Finally we can compute the expectation of $C$ (hence the average runtime):</p>

\[\begin{aligned}
\mathbb{E}[\cdot C]
&amp;= \sum\limits_{i=1}^{n-1} \sum\limits_{j=i+1}^{n} P(\text{did compare $z_i$ and $z_j$ in QuickSort}) \\
&amp;= \sum\limits_{i=1}^{n-1} \sum\limits_{j=i+1}^{n} \frac{2}{j-i+1} \\
&amp;\le \sum\limits_{i=1}^{n-1} \left( 2 \sum\limits_{k=2}^{n} \frac{1}{k} \right) \\
&amp;= 2n \sum\limits_{k=2}^{n} \frac{1}{k} \\
&amp;\le 2n \log n = O(n \log n) 
\end{aligned}\]

<p>where</p>
<ul>
  <li>
    <p>the third inequality comes from the fact that the largest sum we can get is when $i=1$:</p>

\[\sum\limits_{j=i+1}^{n} \frac{1}{j-i+1} = \frac{1}{2} + \frac{1}{3} + ... + \left( \frac{1}{n} \right)\]
  </li>
  <li>
    <p>the last inequality can be proven graphically:</p>

    <p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230920000352.png" style="zoom:80%;" /></p>

    <p>where the sum covers the green highlighted rectangles, and the intergral covers the entire area under the blue curve.</p>
  </li>
</ul>

<h1 id="graphs-the-basics">Graphs: The Basics</h1>

<p>Here we just go over some basics and notations, so that we are consistent for the rest of the course.</p>

<blockquote>
  <p><strong>Representing Graphs</strong>: Let $G=(V,E)$ consist of vertices and edges. Let $n$ be the number of <em>verticies</em> and $m$ be the number of <em>edges</em>.</p>
  <ul>
    <li>note that if $G$ is undirected, then you will have $m \le { n \choose 2 }$</li>
    <li>note that if $G$ is directed, then you will have $m \le 2 { n \choose 2 } = n(n-1)$</li>
  </ul>
</blockquote>

<p>Note that in either case, we have $m \le n^{2}$. Therefore in some proofs you will see, we might just swap $\log m$ with $\log n$ since:</p>

\[\log m \le \log n^{2} = 2 \log n \implies O(\log m) \le O(\log n)\]

<blockquote>
  <p><strong>Tree</strong> a connected graph that has no cycles = have $n$ vertices and $n-1$ edges. For example:
<img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230921225225.png" style="zoom:75%;" /></p>
</blockquote>

<blockquote>
  <p><strong>Ingredients for Adjacency List</strong>: the adjacency list <em>representation of graphs</em> is the dominant one we will use in this course. The main ingredients for representing such a list include:</p>
  <ul>
    <li>an array containing all the vertices</li>
    <li>an array containing all the edges</li>
    <li>for each edge, a pointer to each of its two endpoints</li>
    <li>for each vertex, a pointer to each of its incident edges
so visually, something like this:
<img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230921230015.png" style="zoom:100%;" />
where essentially we have $V_0$ having neighbor [2,3,4], and $V_2$ having neighbor [1,8], etc. Or alternatively, you can think of it as:
<img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230922215707.png" style="zoom:30%;" /></li>
  </ul>
</blockquote>

<p>But how much <em>memory</em> do we need to represent a adjaceny list? Well, we need:</p>
<ul>
  <li>$O(n)$ space for the array of vertices</li>
  <li>$O(m)$ space for the array of edges</li>
  <li>$2m = O(m)$ space for the pointers to the edges’ endpoints. This is because each edge has two endpoints, hence $2m$.</li>
  <li>$2m = O(m)$ space for the pointers to the vertices’ incident edges. If you think about this, this is the same as the previous point, as the pointers to the edges’ endpoints are the same as (reversing) the pointers to the vertices’ incident edges.</li>
</ul>

<p>Therefore we need <strong>in total $O(n+m)$ space to represent a graph using adjaceny list</strong>. Note that this is more efficient than adjaceny matrix, which need $O(n^2)$ space:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230921225855.png" style="zoom:70%;" /></p>

<h2 id="breadth-first-search-and-depth-first-search">Breadth-First Search and Depth-First Search</h2>

<p>Both BFS and DFS would work whether if the graph is directed or undirected. On a high level, recall that</p>

<blockquote>
  <p>BFS Idea: start a vertex $s$ (layer 0), we want to explore all neighbors (layer 1), and repeat this process (reaching layer 2, layer 3, etc.) until we have explored all vertices.</p>
</blockquote>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230921230806.png" style="zoom:70%;" /></p>

<p>So how do we implement it? The trick is to use a queue (FIFO) to keep track of the vertices still need to visit in the order of their discovery. The pseudocode is as follows:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">bfs</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">s</span><span class="p">):</span>
  <span class="c1"># let G be the adjaceny list representation of the graph
</span>  <span class="c1"># let s be the starting vertex
</span>  <span class="n">explored</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">=</span> <span class="bp">True</span>
  <span class="n">Q</span> <span class="o">=</span> <span class="n">Queue</span><span class="p">()</span>
  <span class="n">Q</span><span class="p">.</span><span class="n">enqueue</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>  <span class="c1"># initialize the queue with the starting vertex
</span>  <span class="k">while</span> <span class="n">Q</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">empty</span><span class="p">:</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">Q</span><span class="p">.</span><span class="n">dequeue</span><span class="p">()</span>  <span class="c1"># dequeue the first vertex in the queue
</span>    <span class="k">for</span> <span class="n">each</span> <span class="n">edge</span> <span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span> <span class="ow">in</span> <span class="n">G</span><span class="p">.</span><span class="n">adjacentEdges</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>  <span class="c1"># explore all neighbors of v
</span>      <span class="k">if</span> <span class="ow">not</span> <span class="n">explored</span><span class="p">[</span><span class="n">w</span><span class="p">]:</span>
        <span class="n">explored</span><span class="p">[</span><span class="n">w</span><span class="p">]</span> <span class="o">=</span> <span class="bp">True</span>
        <span class="n">Q</span><span class="p">.</span><span class="n">enqueue</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>  <span class="c1"># enqueue the neighbor at the end
</span></code></pre></div></div>

<blockquote>
  <p>DFS Idea: when you reach a vertex, immediately start exploring its (not yet visited) neighbors and backtracking only when necessary (i.e. when you have no more neighbors to explore).</p>
</blockquote>

<p>The most intuitive explanation is to talk about an example. Suppose we are given a graph, and the adjaceny list happened to give $s \to a$ before $s \to b$, then starting from $s$ we would go:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230921231717.png" style="zoom:80%;" /></p>

<p>where the “frontier” marks the “borderline” between the explored and unexplored vertices. To make things interesting, let’s say the adjacency list had $c \to d$ before $c\to e$. This would then give us:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230921231916.png" style="zoom:80%;" /></p>

<p>Now there is a problem: at vertex $e$ we have <strong>no unvisited neighbors</strong>. So DFS is forced to retreat to its previous vertex $d$: and now, it discovered one unexplored vertex $b$.</p>

<p>After this, DFS collapse quickly as each vertex has no unvisited neighbors, and DFS will eventually retreat all the way to $s$. <mark>If all neighbors of $s$ are visited</mark>, then DFS is done.</p>

<p>Therefore the pseudocode is as follows:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">dfs</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">s</span><span class="p">):</span>
  <span class="c1"># let G be the adjaceny list representation of the graph
</span>  <span class="c1"># let s be the starting vertex
</span>  <span class="n">explored</span> <span class="o">=</span> <span class="p">{}</span>  <span class="c1"># mark all vertices as unexplored
</span>  <span class="n">S</span> <span class="o">=</span> <span class="n">Stack</span><span class="p">()</span>
  <span class="n">S</span><span class="p">.</span><span class="n">push</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>  <span class="c1"># initialize the stack with the starting vertex
</span>  <span class="k">while</span> <span class="n">S</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">empty</span><span class="p">:</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">S</span><span class="p">.</span><span class="n">pop</span><span class="p">()</span>  <span class="c1"># pop the first vertex in the stack
</span>    <span class="k">if</span> <span class="ow">not</span> <span class="n">explored</span><span class="p">[</span><span class="n">v</span><span class="p">]:</span>
      <span class="n">explored</span><span class="p">[</span><span class="n">v</span><span class="p">]</span> <span class="o">=</span> <span class="bp">True</span>
      <span class="k">for</span> <span class="n">each</span> <span class="n">edge</span> <span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span> <span class="ow">in</span> <span class="n">G</span><span class="p">.</span><span class="n">adjacentEdges</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>  <span class="c1"># explore all neighbors of v
</span>        <span class="n">S</span><span class="p">.</span><span class="n">push</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>  <span class="c1"># push the neighbor at the top
</span></code></pre></div></div>

<p>Why stack? If you think about the more “natural” recursive implementation, you will realize that essentially you are using a call <em>stack</em>. So the iterative implementation is just a “translation” of the recursive implementation.</p>

<blockquote>
  <p><strong>Runtime of BFS/DFS</strong>: The running time for both algorithms is $O(n + m)$ being <mark>linear in the size of the graph</mark>. This is because both BFS/DFS will:</p>
  <ul>
    <li>examine each vertex at most once</li>
    <li>examine each edge at most twice (once for each endpoint)
therefore the total number of operations is $O(n + 2m) = O(n + m)$.</li>
  </ul>
</blockquote>

<h2 id="generic-search">Generic Search</h2>

<p>Is BFS and DFS correct? How do we prove that its runtime is $O(n+m)$? The answer is to realize that they both fall into the pattern of a generic search algorithm:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">generic_search</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">s</span><span class="p">):</span>
  <span class="c1"># let G=(V, E) be the adjaceny list representation of the graph
</span>  <span class="c1"># let s be the starting vertex
</span>  <span class="n">explored</span> <span class="o">=</span> <span class="p">{</span><span class="n">s</span><span class="p">}</span> <span class="c1"># mark s as explored, others as unexplored
</span>  <span class="k">while</span> <span class="n">there</span> <span class="ow">is</span> <span class="n">an</span> <span class="n">edge</span> <span class="p">(</span><span class="n">v</span><span class="p">,</span><span class="n">w</span><span class="p">)</span> <span class="ow">in</span> <span class="n">E</span> <span class="k">with</span> <span class="n">v</span> <span class="n">explored</span> <span class="ow">and</span> <span class="n">w</span> <span class="n">unexplored</span><span class="p">:</span>
    <span class="n">choose</span> <span class="n">some</span> <span class="n">such</span> <span class="n">edge</span> <span class="p">(</span><span class="n">v</span><span class="p">,</span><span class="n">w</span><span class="p">)</span>
    <span class="n">explored</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
</code></pre></div></div>

<p>To see why this could contain both BFS and DFS, consider the following example graph:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230923155032.png" style="zoom:100%;" /></p>

<ol>
  <li>initially only our home base $s$ is marked as explored.</li>
  <li>In the fist iteration of the while loop, two edges meet the loop condition: $( s, u )$ and $( s, v )$. The GenericSearch algorithm chooses one of these edges — $(s, u)$, say — and marks $u$ as explored.</li>
  <li>In the second iteration of the loop, there are again two choices: $( s, v )$ and $( u, w )$. The algorithm might choose $( u, w )$ being DFS-like or $( s, v )$ being BFS-like.</li>
</ol>

<blockquote>
  <p><strong>Correctness of Generic Graph Search</strong>: At the conclusion of the <code class="language-plaintext highlighter-rouge">generic_search</code>, a vertex is $v \in V$ is explored if and only if there is a path from $s$ to $v$ in $G$.</p>
  <ul>
    <li>this also means that every vertex $v$ is explored</li>
    <li>for BFS/DFS, it is then easy to see that each vertex is also explored <em>only once</em> (if reachable)</li>
  </ul>
</blockquote>

<p><em>Proof</em>: This is IFF proof, so we need to argue from both directions.</p>

\[\text{$v$ is explored in generic\_search} \implies \text{there is a path from $s$ to $v$ in $G$}\]

<p>this is trivially true, as the only way we can discover $v$ is by following paths from $s$.</p>

\[\text{there is a path from $s$ to $v$ in $G$} \implies \text{$v$ is explored in generic\_search}\]

<p>This basically says that the <code class="language-plaintext highlighter-rouge">generic_search</code> algorithm didn’t miss any vertex. We can prove this by contradiction: let there be a path from $s\leadsto v$, but <mark>`generic_search` halted and missed it</mark>. The intuition is that this cannot be, because we checked every edge given a vertex. More formally, let $S \subseteq V$ be the set of vertices just now marked as explored by the algorithm. Then vertex $s \in S$ and, by assumption, $v$ does not. But since there is a path from $s \leadsto v$, then there must exist a path from a vertex in $S$ going to one outside $S$ (reaching $v$). Then, our algorithm would have picked this during the <code class="language-plaintext highlighter-rouge">while</code> loop, and the algorithm would have at least explored one more vertex instead of halting, and would have eventually reached $v$. This is a contradiction, as we assumed that the algorithm halted and missed $v$.</p>

<h2 id="computing-connected-components">Computing connected Components</h2>

<p>This is one typical application of BFS/DFS. Let’s use BFS here.</p>

<p>Recall that</p>

<blockquote>
  <p><strong>Connected Component</strong> is a maximal set of vertices $S \subseteq V$ such that for every pair of vertices $u,v \in S$, there is a path from $u$ to $v$ in $G$. Visually:
<img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230921233123.png" style="zoom:70%;" /></p>
</blockquote>

<p>Consider $G=(V,E)$ being an undirected graph, and consider the task being to identify all connected components of $G$ (e.g. assign each vertex <code class="language-plaintext highlighter-rouge">v</code> a label <code class="language-plaintext highlighter-rouge">cc(v)</code> indicating which connected component it belongs to).</p>

<p>The idea is simple: we can use an outer loop to make a single pass over the vertices, and invoke BFS as a subroutine whenever we encounter an unexplored vertex. The pseudocode is as follows:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">ucc</span><span class="p">(</span><span class="n">G</span><span class="p">):</span>
  <span class="c1"># let G be the adjaceny list representation of the graph
</span>  <span class="n">cc</span> <span class="o">=</span> <span class="p">{}</span>  <span class="c1"># mark all vertices as unexplored
</span>  <span class="n">num_cc</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># number of connected components
</span>  <span class="k">for</span> <span class="n">each</span> <span class="n">vertex</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">G</span><span class="p">.</span><span class="n">vertices</span><span class="p">:</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">explored</span><span class="p">[</span><span class="n">v</span><span class="p">]:</span>
      <span class="n">cc</span><span class="p">[</span><span class="n">v</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>  <span class="c1"># label the connected component
</span>      <span class="n">num_cc</span> <span class="o">+=</span> <span class="mi">1</span>  <span class="c1"># increment the number of connected components
</span>
      <span class="c1">### BFS subroutine
</span>      <span class="n">Q</span> <span class="o">=</span> <span class="n">Queue</span><span class="p">()</span>
      <span class="n">Q</span><span class="p">.</span><span class="n">enqueue</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>  <span class="c1"># initialize the queue with the starting vertex
</span>      <span class="k">while</span> <span class="n">Q</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">empty</span><span class="p">:</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">Q</span><span class="p">.</span><span class="n">dequeue</span><span class="p">()</span>  <span class="c1"># dequeue the first vertex in the queue
</span>        <span class="k">for</span> <span class="n">each</span> <span class="n">edge</span> <span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> <span class="ow">in</span> <span class="n">G</span><span class="p">.</span><span class="n">adjacentEdges</span><span class="p">(</span><span class="n">w</span><span class="p">):</span>  <span class="c1"># explore all neighbors of w
</span>          <span class="k">if</span> <span class="ow">not</span> <span class="n">explored</span><span class="p">[</span><span class="n">x</span><span class="p">]:</span>
            <span class="n">explored</span><span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="o">=</span> <span class="bp">True</span>
            <span class="n">cc</span><span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>  <span class="c1"># assign the same connected component to x
</span>            <span class="n">Q</span><span class="p">.</span><span class="n">enqueue</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># enqueue the neighbor at the end
</span>  <span class="k">return</span> <span class="n">cc</span>
</code></pre></div></div>

<p>What’s the runtime? Although this <em>looks like</em> looping over $O(m+n)$ which is the cost of BFS, in fact we note that <mark>BFS/DFS$(G,s)$ is technically linear in the size of the connected component of $s$</mark>. Therefore the runtime is:</p>

\[\underbrace{O(n)}_{\text{looping over every vertex}} + O\left( \sum \text{connected component's size} \right) = O(n) + O(n + m) = O(n + m)\]

<h2 id="topological-sort">Topological Sort</h2>

<p>Here is another classic <em>application</em> of DFS. Imagine that you have a bunch of tasks to complete, and there are <strong>precedence constraints</strong>, meaning that you cannot start some of the tasks until you have completed others. ne application of topological orderings is to sequencing tasks so that all precedence constraints are respected. More formally</p>

<blockquote>
  <p><strong>Topological Orderings</strong>: let $G=(V,E)$ be a <mark>directed</mark> graph. A topological ordering of $G$ is an assignment $f(v)$  of every vertex $v \in V$ to a different number such that:</p>

\[\text{for every }v\to w \text{ edge}, f(v) &lt; f(w)\]

  <p>i.e. all of $G$’s directed edges should travel forward, with the arrow heading pointing to a vertex with a higher number.</p>
</blockquote>

<p>Visually, consider the following example:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230926223914.png" style="zoom:100%;" /></p>

<p>and there are two ways to topologically sort this graph:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230926223904.png" style="zoom:100%;" /></p>

<p>You can visualize a topological ordering by <strong>plotting</strong> the vertices in order of their f-values. In a topological ordering, <strong>all edges of the graph are directed from left to right</strong>.</p>

<blockquote>
  <p><strong>Note</strong> that this means, it is impossible to topologically order the vertices of a graph that contains a <mark>directed cycle</mark>. Therefore, in general a topological order exists only for a directed graph without any directed cycles - <mark>a directed acyclic graph</mark> (DAG).</p>
</blockquote>

<p>In fact</p>

<blockquote>
  <p><strong>Theorem 8.6</strong>: Every DAG has a topological ordering.</p>
</blockquote>

<p>To show this, first realize that</p>

<blockquote>
  <p><strong>Theorem 8.7</strong>: Every DAG has a source.</p>
  <ul>
    <li>proof: if you keep following incoming edges backward out of an arbitrary vertex of a directed acyclic graph, you’re bound to eventually reach a source vertex. Otherwise, there would be a directed cycle.</li>
    <li>i.e.: if you DFS and is stuck in a DFS, then there is a cycle in your graph.``</li>
  </ul>
</blockquote>

<p>where:</p>
<ul>
  <li>A <strong>source vertex</strong> of a directed graph is a vertex with no incoming edges.</li>
  <li>Analogously, a <strong>sink vertex</strong> is one with no outgoing edges.</li>
</ul>

<p>Then, we can prove Theorem 8.6 very easily. Let $G$ be a directed acyclic graph with $n$ vertices. The task is to assign $f$-values to vertices in an increasing order:</p>
<ol>
  <li>the source vertex will be assigned 1</li>
  <li>obtain $G’$ by removing the source vertex and all its outgoing edges. Note that this cannot produce a directed cycle, as deleting stuff can’t create new cycles</li>
  <li>repeat from step 1 on $G’$</li>
</ol>

<p>So how to do compute a topological sorting, i.e. output a <strong>topological ordering</strong> of the vertices of a DAG $G$?</p>

<ul>
  <li>the proof above naturally leads to an algorithm: a loop ($O(n)$) over each vertex where we find the source ($O(n)$), and then deleting it to repeat. This gives us $O(n^2)$.</li>
  <li>next up: a slicker solution via DFS resulting in $O(n+m)$.</li>
</ul>

<p>First we show the algorithm, the high level idea is simple: we use DFS to dive to the sink and assign the lowest ordering to it, but also <strong>assign things during backtracking!</strong>. We then mark it as explored (i.e. as if we removed the vertex from G) and repeat.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">curLabel</span> <span class="o">=</span> <span class="o">|</span><span class="n">V</span><span class="o">|</span>  <span class="c1"># tracks the ordering
</span><span class="n">f</span> <span class="o">=</span> <span class="p">{}</span>  <span class="c1"># topological ordering
</span>
<span class="k">def</span> <span class="nf">topo_sort</span><span class="p">(</span><span class="n">G</span><span class="p">):</span>
  <span class="c1"># let G = (V, E) be the adjaceny list representation of the graph
</span>  <span class="c1"># let s be the starting vertex
</span>  <span class="n">explored</span> <span class="o">=</span> <span class="p">{}</span>  <span class="c1"># mark all vertices as unexplored
</span>  <span class="k">for</span> <span class="n">each</span> <span class="n">vertex</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">G</span><span class="p">.</span><span class="n">vertices</span><span class="p">:</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">explored</span><span class="p">[</span><span class="n">v</span><span class="p">]:</span>
      <span class="n">dfs_topo</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">explored</span><span class="p">)</span>
  <span class="k">return</span>

<span class="k">def</span> <span class="nf">dfs_topo</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">explored</span><span class="p">):</span>
  <span class="k">global</span> <span class="n">curLabel</span><span class="p">,</span> <span class="n">f</span>

  <span class="n">explored</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">=</span> <span class="bp">True</span>
  <span class="k">for</span> <span class="n">each</span> <span class="n">edge</span> <span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span> <span class="ow">in</span> <span class="n">s</span> <span class="n">outgoing</span> <span class="n">adjaceny</span> <span class="nb">list</span><span class="p">:</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">explored</span><span class="p">[</span><span class="n">w</span><span class="p">]:</span>
      <span class="n">dfs_topo</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">explored</span><span class="p">)</span>
  <span class="n">f</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">=</span> <span class="n">curLabel</span>  <span class="c1"># assign the ordering
</span>  <span class="n">curLabel</span> <span class="o">-=</span> <span class="mi">1</span>  <span class="c1"># decrement the ordering
</span>  <span class="k">return</span>
</code></pre></div></div>
<p>note that <code class="language-plaintext highlighter-rouge">topo_sort</code> doesn’t need to us to start at a particular vertex. We can start at any vertex, and the algorithm will still work. (Basically the algorithm dives as deep as possible, and <strong>assign that deepest vertex</strong> (regardless which starting vertex you choose) <strong>with $f(\cdot) = \vert V\vert$</strong>.)</p>

<p>Correctness: first of all, it is obvious to see that:</p>
<ul>
  <li>every vertex $v$ is assigned a unique number $f(v)$, as each is called by <code class="language-plaintext highlighter-rouge">dfs_topo</code> only once.</li>
  <li>to argue why the returned <code class="language-plaintext highlighter-rouge">f</code> must be a topological order, we need to show <strong>for any arbitrary edge $(v,w)$ such that $v\to w$, we have $f(v) &lt; f(w)$</strong>.</li>
</ul>

<hr />

<p><em>Proof</em> if there is an edge $(v,w)$, then there are two cases in running <code class="language-plaintext highlighter-rouge">topo_sort</code>:</p>
<ol>
  <li>if $v$ is explored before $w$, i.e. we <code class="language-plaintext highlighter-rouge">dfs_topo</code> is invoked with vertex $v$ before $w$ is explored. Then as $v \to w$ is reachable, we will get a call stack of [<code class="language-plaintext highlighter-rouge">dfs_topo(v)</code> -&gt; <code class="language-plaintext highlighter-rouge">dfs_topo(w)</code>]. Since the nature of recursive call will mean <code class="language-plaintext highlighter-rouge">dfs_topo(w)</code> will terminate first, it will be assigned a higher ordering than <code class="language-plaintext highlighter-rouge">dfs_topo(v)</code>. Therefore $f(v) &lt; f(w)$.</li>
  <li>if $w$ is explored before $v$, then it means there <strong>cannot</strong> be a path from $w$ <strong>back</strong> to $v$ (because we already have $v \to w$ and we know the graph is a DAG). Therefore, the call <code class="language-plaintext highlighter-rouge">dfs_topo(w)</code> will terminate without calling <code class="language-plaintext highlighter-rouge">dfs_topo(v)</code>. Then, as <code class="language-plaintext highlighter-rouge">topo_sort</code> will eventually call <code class="language-plaintext highlighter-rouge">dfs_topo(v)</code> <strong>later</strong>, it means $v$ will get a lower ordering. Hence $f(v) &lt; f(w)$.</li>
</ol>

<hr />

<p>Runtime: runs in linear time $O(n+m)$, as it is just DFS with a little extra bookkeeping:</p>
<ul>
  <li>it explores each edge only once (from its tail), only performs a constant amount of work per edge/vertex</li>
  <li>therefore, the runtime is $O(n+m)$</li>
</ul>

<h2 id="computing-strongly-connected-components">Computing Strongly Connected Components</h2>

<p>In short, while it didn’t matter much for undirected graph, for directed graph having a <strong>connected component</strong> makes things more complicated. First, recall that a connected component for <em>undirected</em> graph is defined as maximal regions within which you can get from anywhere to anywhere else in the region. For directed graph, consider</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230926232541.png" style="zoom:80%;" /></p>

<p>Following the logic, the answer should be zero.</p>

<blockquote>
  <p><strong>Strongly Connected Component (SCC)</strong> a maximal set of vertices $S \subseteq V$ such that there is a directed path from any vertex in $S$ to any other vertex in $S$.</p>
</blockquote>

<p>For example</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230926232718.png" style="zoom:60%;" /></p>

<p>First of all, why would <code class="language-plaintext highlighter-rouge">ucc</code> not work? Consider evoking BFS on the following vertices</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230926233006.png" style="zoom:60%;" /></p>

<p>first, notice all the edges are organized to go mainly from left to right. In the case on the left, we would get a <em>wrong result</em>: BFS will discover every vertex and mark them as the same connected component. In the case on the right, we would get a <em>correct result</em>. This indicates that graph search can uncover strongly connected components, <mark>provided you start from the right place</mark>. But how? The key observation is that we want to first start from a <mark>sink SCC</mark>, i.e. the SCC with no outgoing edges to other SCCs. Then, we can go in a reverse topological order, plucking off sink SCCs one by one.</p>

<blockquote>
  <p><strong>Key Lemma</strong>: the SCC Meta-Graph is directed acyclic. Visually this is simple to see:
<img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230926235651.png" style="zoom:15%;" />
and the argument is also simple. If two meta SCC are not acyclic, then you would have collapsed them into one, i.e., the two meta SCC were not maximal at the first place.</p>
  <ul>
    <li>this lemma is actually very important. This means that all we need to do is to find <mark>one vertex</mark> in a <mark>sink SCC</mark>, run BFS/DFS to label all vertices it can reach (and mark them as explored), and repeat</li>
    <li>the above works because for a directed acyclic graph + using a sink SCC, you cannot get out of that sink SCC.</li>
  </ul>
</blockquote>

<p>On a high level, the arguments above in the lemma is pretty much what we will do, except you might be a bit confused by the graph reversing step</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># sktech of Kosaraju’s algorithm
</span><span class="k">def</span> <span class="nf">kosaraju_idea</span><span class="p">(</span><span class="n">G</span><span class="p">):</span>
  <span class="n">G_rev</span> <span class="o">=</span> <span class="n">reverse</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>  <span class="c1"># reverse the graph, i.e. reverse all edges
</span>  <span class="n">dfs_loop</span><span class="p">(</span><span class="n">G_rev</span><span class="p">),</span> <span class="n">let</span> <span class="n">f</span><span class="p">[</span><span class="n">v</span><span class="p">]</span> <span class="o">=</span> <span class="s">"finishing time"</span> <span class="n">of</span> <span class="n">DFS</span> <span class="n">on</span> <span class="n">a</span> <span class="n">vertex</span> <span class="n">v</span>
  <span class="n">dfs_loop</span><span class="p">(</span><span class="n">G</span><span class="p">),</span> <span class="n">using</span> <span class="n">f</span> <span class="n">to</span> <span class="n">process</span> <span class="n">vertices</span> <span class="ow">in</span> <span class="n">decreasing</span> <span class="n">order</span>  <span class="c1"># i.e. start from the sink vertex
</span>  <span class="k">return</span> <span class="n">vertices</span> <span class="k">with</span> <span class="n">their</span> <span class="n">labels</span>
</code></pre></div></div>

<p>while yes, the second relates to some kind of topological order, and third step relates to us wanting to get a reverse topological order before diving DFS to label the vertices. But there are a few caveat:</p>
<ul>
  <li>second step did something on a <strong>reversed</strong> graph. Why?</li>
  <li><strong>we thought about the <code class="language-plaintext highlighter-rouge">topo_sort</code> algorithm only in DAGs</strong>, and here we have a <strong>general directed graph</strong>.</li>
  <li>the second and third is <em>not equivalent</em> to <code class="language-plaintext highlighter-rouge">topo_sort</code> of a normal <code class="language-plaintext highlighter-rouge">G</code> and then start from the sink vertex.</li>
</ul>

<p>So what’s going on? First we show the full algorithm, and then we will illustrate how it works, and why it is correct.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">global</span> <span class="n">numSCC</span><span class="p">:</span> <span class="nb">int</span>

<span class="k">def</span> <span class="nf">Kosaraju</span><span class="p">(</span><span class="n">G</span><span class="p">):</span>
  <span class="c1"># let G = (V, E) be the adjaceny list representation of the graph
</span>  <span class="n">G_rev</span> <span class="o">=</span> <span class="n">reverse</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>  <span class="c1"># reverse the graph, i.e. reverse all edges
</span>  <span class="n">mark</span> <span class="nb">all</span> <span class="n">vertices</span> <span class="ow">in</span> <span class="n">G_rev</span> <span class="k">as</span> <span class="n">unexplored</span>

  <span class="c1"># first pass of DFS
</span>  <span class="c1"># computes f(v), the magical ordering
</span>  <span class="n">TopoSort</span><span class="p">(</span><span class="n">G_rev</span><span class="p">)</span>

  <span class="c1"># second pass of DFS
</span>  <span class="c1"># finds SCCs in reverse topological order
</span>  <span class="n">mark</span> <span class="nb">all</span> <span class="n">vertices</span> <span class="ow">in</span> <span class="n">G</span> <span class="k">as</span> <span class="n">unexplored</span>
  <span class="k">global</span> <span class="n">numSCC</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># number of SCCs, global variable
</span>  <span class="k">for</span> <span class="n">each</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">V</span><span class="p">,</span> <span class="ow">in</span> <span class="n">increasing</span> <span class="n">order</span> <span class="n">of</span> <span class="n">f</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">explored</span><span class="p">[</span><span class="n">v</span><span class="p">]:</span>
      <span class="n">numSCC</span> <span class="o">+=</span> <span class="mi">1</span>
      <span class="c1"># assign scc-values for all vertices in the SCC
</span>      <span class="n">dfs_scc</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">dfs_scc</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">s</span><span class="p">):</span>
  <span class="k">global</span> <span class="n">numSCC</span>
  <span class="n">explored</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">=</span> <span class="bp">True</span>
  <span class="n">scc</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">=</span> <span class="n">numSCC</span>
  <span class="k">for</span> <span class="n">each</span> <span class="n">edge</span> <span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span> <span class="ow">in</span> <span class="n">s</span> <span class="n">outgoing</span> <span class="n">adjaceny</span> <span class="nb">list</span><span class="p">:</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">explored</span><span class="p">[</span><span class="n">w</span><span class="p">]:</span>
      <span class="n">dfs_scc</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>
  <span class="k">return</span>
</code></pre></div></div>

<p>So, it turns out all the concern above will be addressed after thinking about this.</p>

<blockquote>
  <p><strong>Why reverse graph + topological sort?</strong></p>
</blockquote>

<p>What we want, in the end, is to <strong>find a vertex in a <em>sink SCC</em> of $G$</strong>. The hope with <code class="language-plaintext highlighter-rouge">topo_sort</code> is that, we recall, the vertex in the last position ($f(v)=\vert V\vert$) must be a sink vertex (hence inside sink SCC) of $G$. However, it was for DAGs. So are we lucky enough that this would hold for a general graph? The answer is sadly no. If we consider the following example where we started at vertex <code class="language-plaintext highlighter-rouge">1</code> (recall that <code class="language-plaintext highlighter-rouge">topo_sort</code> starts at random vertex):</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">correct source but wrong sink</th>
      <th style="text-align: center">correct source and correct sink</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230927012532.png" style="zoom:50%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230927012538.png" style="zoom:60%;" /></td>
    </tr>
  </tbody>
</table>

<p>where basically the left is made by trying to start at vertex 1 and wind up ending at vertex 4 during the first iteration, while the right is made by starting at vertex 1 and ends at vertex 8 during the first iteration of <code class="language-plaintext highlighter-rouge">topo_sort</code>. Although we couldn’t consistently find a vertex in a sink, it turns out we <strong>can consistently find a vertex in the source SCC</strong>. But in fact, the statement is even stronger: tThe topological order of the SCCs will <em>also be a topological ordering of the meta-graph</em>, if we label each SCC with the smallest $f$ of one of its vertices, i.e. formally</p>

<blockquote>
  <p><strong>Theorem 8.10</strong>: Topological Ordering of the SCCs. Let $G$ be a directed graph, with vertices ordered arbitrarily, and for each vertex $v \in V$ let $f(v)$ be the position of $v$ computed by <code class="language-plaintext highlighter-rouge">topo_sort</code>. Let $S_1, S_2$ denote two SCCs of $G$, and suppose $G$ has an edge $(v,w)$ with $v \in S_1$ and $w \in S_2$, then:</p>

\[\min_{x \in S_1} f(x) &lt; \min_{y \in S_2} f(y)\]

  <p>i.e. even if <code class="language-plaintext highlighter-rouge">topo_sort</code> is incorrect in this case globally for every vertex, it is still correct locally for the SCCs!.</p>
</blockquote>

<p>the proof is similar to the correctness of <code class="language-plaintext highlighter-rouge">topo_sort</code>. If we consider the following illustration:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230927014115.png" style="zoom:70%;" /></p>

<p>then there are two cases that can happen during <code class="language-plaintext highlighter-rouge">topo_sort</code> labeling all the vertices:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">topo_sort</code> explored and initialized a DFS from a vertex $s \in S_1$ before any vertex in $S_2$. But because we know vertices in a SCC can reach each other, then $s \leadsto v$, and since $v \to w$, then we can reach from $s$ to any vertex in $S_2$. Therefore, because <code class="language-plaintext highlighter-rouge">topo_sort</code> is a DFS/recursive call, the call <code class="language-plaintext highlighter-rouge">dfs_topo(s)</code> will not terminate until all the vertices in $S_2$ terminates. Therefore, $f(v)$ must also be smaller than $f(w)$.</li>
  <li><code class="language-plaintext highlighter-rouge">topo_sort</code> explored and initialized a DFS from a vertex $s \in S_2$ before any vertex in $S_1$. Then, <strong>because the meta-graph is directed acyclic</strong>, we are stuck in $S_2$, and $S_1$ will be unscathed. Since the counter for $f$ is a global variable, this means we will get a smaller $f$ for $S_1$ than $S_2$.</li>
</ul>

<p>The end result? We are sure that the <mark>first vertex resides in a source SCC</mark> if we do <code class="language-plaintext highlighter-rouge">topo_sort</code>. So to find a vertex in a sink SCC, all we need is to <mark>reverse the graph first</mark>.</p>

<hr />

<p>Finally, an example before going to the correctness and runtime discussion. We want to check that the magical reverse graph + <code class="language-plaintext highlighter-rouge">topo_sort</code> will indeed help us get vertices in a sink SCC, and so that the second pass of depth-first search discovers the SCCs in reverse topological order.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">$G_{rev}$ and compute $f(v)$</th>
      <th style="text-align: center">$G$ with computed $f(v)$</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230927015408.png" style="zoom:100%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230927015414.png" style="zoom:100%;" /></td>
    </tr>
  </tbody>
</table>

<p>Then, given the progress above (by reversing the graph and calling <code class="language-plaintext highlighter-rouge">topo_sort</code>), we continue to the second pass to DFS, which checks through vertices in increasing order:</p>

<ol>
  <li>first call to DFS-SCC is initiated at the vertex 1 with smallest $f$. (the vertex in a sink SCC!)</li>
  <li>then it will label all vertices $1,3,5$, and mark as done.</li>
  <li>the second smallest and third is with vertex 3, which is visited already.</li>
  <li>the third smallest is vertex 11, which is also (a vertex in) the second sink SCC.</li>
  <li>continues</li>
</ol>

<h3 id="correctness-and-runtime-of-kosarajus-algorithm">Correctness and Runtime of Kosaraju’s Algorithm</h3>

<p>The argument will be short as the proofs are mostly covered in the previous section.</p>

<p><strong>Correctness</strong>: each time we initiates a new call to <code class="language-plaintext highlighter-rouge">dsf_scc</code>, the algorithm discovers <em>exactly one new SCC</em> - the <em>sink SCC</em> relative to the not-yet-explored part of the graph.</p>

<p><strong>Runtime</strong>: each of the two passes of DFS does a constant number of operations per vertex or edge. Therefore, the runtime is $O(n+m)$.</p>

<h1 id="dijkstras-shortest-path-algorithm">Dijkstra’s Shortest Path Algorithm</h1>

<p>We’ve arrived at another one of computer science’s greatest hits: Dijkstra’s shortest-path algorithm.</p>

<blockquote>
  <p><strong>Assumptions with Dijkstra’s Algorithm</strong>: this algorithm works in any <em>directed graph with nonnegative edge length</em>.</p>
  <ul>
    <li>can we extend it to undirected graph? (Yes, by changing the ‘frontier’ condition)</li>
    <li>can we extend it to negative edge length? (No, but Bellman-Ford can)</li>
  </ul>
</blockquote>

<p><strong>Problem definition</strong>: consider a directed graph $G=(V,E)$, a starting vertex $s \in V$, and a nonnegative length $l_e$ for each edge $e \in E$. The goal is to compute the <strong>length of a shortest path $D(v)$ from $s$ to every other vertex $v$ in $G$</strong>.</p>

<blockquote>
  <p>Why can’t we use BFS? Remember that breadth-first search computes the minimum number of edges in a path from the starting vertex to every other vertex (i.e. we continue layer by layer). This is the special case of the single-source shortest path problem <strong>in which every edge has length 1</strong>.</p>
  <ul>
    <li>but then can’t we just think of an edge with a longer length $l&gt;1$ as a <em>path of edges</em> that each have length 1?
<img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230922003244.png" style="zoom:80%;" /></li>
    <li>Yes, in principle, you can solve the single-source shortest path problem by expanding + using BFS</li>
    <li>However, the problem with this is that it blows up the size of the graph</li>
  </ul>
</blockquote>

<h2 id="dijkstras-algorithm">Dijkstra’s Algorithm</h2>

<p>The idea of Dijkstra’s algorithm is to use a <strong>greedy</strong> approach: at each step, we will <strong>grow the frontier by one vertex</strong>. Overall it looks similar to BFS/DFS by iterating over the new vertices, but the clever part is <strong>how we choose which vertex to process next/is done</strong>.</p>

<p>Consider some example graph, where each edge $e$  has a length of $l_e$:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230922003934.png" style="zoom:80%;" /></p>

<p>Consider the pseudo-code</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">dijkstra</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">s</span><span class="p">):</span>
  <span class="c1"># let G = (V, E) be the adjaceny list representation of the graph
</span>  <span class="c1"># let s be the starting vertex
</span>  <span class="n">X</span> <span class="o">=</span> <span class="p">{</span><span class="n">s</span><span class="p">}</span>  <span class="c1"># list of vertices processed so far
</span>  <span class="n">dist</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span> <span class="c1"># tracks the cost of shortest path distance
</span>  <span class="n">path</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># tracks the shortest path, empty for s
</span>  
  <span class="k">while</span> <span class="n">there</span> <span class="ow">is</span> <span class="n">an</span> <span class="n">edge</span> <span class="p">(</span><span class="n">v</span><span class="p">,</span><span class="n">w</span><span class="p">)</span> <span class="k">with</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">X</span> <span class="ow">and</span> <span class="n">w</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">X</span><span class="p">:</span>  <span class="c1"># check edges that crossed the "frontier"
</span>    <span class="p">(</span><span class="n">v</span><span class="o">*</span><span class="p">,</span> <span class="n">w</span><span class="o">*</span><span class="p">)</span> <span class="o">=</span> <span class="n">edge</span> <span class="n">minimizing</span> <span class="n">dist</span><span class="p">[</span><span class="n">v</span><span class="p">]</span> <span class="o">+</span> <span class="n">l_vw</span>
    <span class="n">X</span><span class="p">[</span><span class="n">w</span><span class="o">*</span><span class="p">]</span> <span class="o">=</span> <span class="bp">True</span>  <span class="c1"># grow exactly one vertex
</span>    <span class="n">dist</span><span class="p">[</span><span class="n">w</span><span class="o">*</span><span class="p">]</span> <span class="o">=</span> <span class="n">dist</span><span class="p">[</span><span class="n">v</span><span class="o">*</span><span class="p">]</span> <span class="o">+</span> <span class="n">l_vw</span>
    <span class="n">path</span><span class="p">[</span><span class="n">w</span><span class="o">*</span><span class="p">]</span> <span class="o">=</span> <span class="n">path</span><span class="p">[</span><span class="n">v</span><span class="o">*</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">w</span><span class="o">*</span><span class="p">]</span>
  
  <span class="k">return</span> <span class="n">dist</span><span class="p">,</span> <span class="n">path</span>
</code></pre></div></div>

<p>Visually, this works like:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230922113037.png" style="zoom:100%;" /></p>

<p>Is this algorithm correct? If you think about it, this is what Dijkstra’s algorithm is trying to say. Consider an edge $(v,w)$ with $v \in X$ and $w \notin X$. Then <mark>the shortes path from $s$ to $w$ consists of the shortest path from $s$ to $v$ (or $s \leadsto v$) with edge $(v,w)$ tacked at the end</mark>. So is this correct?</p>

<h2 id="correctness-of-dijkstras-algorithm">Correctness of Dijkstra’s Algorithm</h2>

<p>Essentially Dijkstra’s algorithm iterates over the entire $V$ space, so we can consider induction on the number of vertices $n$.</p>

<p><em>Proof</em>: Let $P(n)$ denote that “the Dijkstra algorithm correctly computes the shortest-path distance of the $n$th vertex added to the processed set $X$”. We will prove this by induction on $n$:</p>
<ol>
  <li>Base case: $P(1)$ is trivially true, as the starting vertex $s$ is the first vertex in $X$ and the shortest path distance from $s$ to $s$ is indeed $0$.</li>
  <li>Inductive hypothesis: Let $P(k)$ be true for all $k=1,2,3…, n-1$. This means that we have $d(v)=\mathrm{shortest}(s,v)$ correctly computed for the first $n-1$ vertices added by Dijkstra to $X$.</li>
  <li>
    <p>Inductive step: now we need to show $P(n)$. Let $w^{<em>}$ be the $n$th vertex being added, and <strong>let Dijkstra to have selected the $(v^*, w^*)$ edge for that to happen</strong> (i.e. $v^{</em>}\to w^{*}$ is the shortest edge at the frontier). We need to show that:</p>

\[d(v^*) + l_{v^{*}w^{*}} = \mathrm{shortest}(s, w^*)\]

    <p>We can show this by:</p>
    <ul>
      <li>showing $d(v^<em>) + l_{v^{</em>}w^{<em>}} \ge \mathrm{shortest}(s, w^</em>)$, that the shortest path can only be less than or equal to the path from $s$ to $v^<em>$ plus the edge $(v^</em>, w^*)$. This is trivially true by definition of the shortest path.</li>
      <li>
        <p>showing $d(v^<em>) + l_{v^{</em>}w^{<em>}} \le \mathrm{shortest}(s, w^</em>)$, namely every competitor path $s \leadsto w^{<em>}$ must be at least  $d(v^</em>) + l_{v^{<em>}w^{</em>}}$. To show this, consider a “crazily short” path:</p>

        <p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230922011917.png" style="zoom:60%;" /></p>

        <p>where because we know that path has to start at $s$ and ends at $w^{*}$ which is <mark>outside $X$</mark>, then it must have crossed the frontier at some point. Let’s denote the <strong>first edge from that path crossing the frontier be $(y,z)$</strong>, such that $y\in X, z \notin X$. So in essence we can considering any competitor path $P’$ taking the form:</p>

\[P' = \underbrace{s \leadsto y}_{\text{inside X}} \to z \leadsto w^{*}\]

        <p>we note that this path must has at least:</p>

\[len(P') \ge \text{shortest}(s,y) + l_{yz} + 0 = d(y) + l_{yz}\]

        <p>where we used $+0$ <mark>because we assumed no edges can be negative</mark>, and that $d(y) = \text{shortest}(s,y)$ from the inductive hypothesis. But we notice that this $d(y) + l_{yz}$ exactly represents <mark>an edge that just crossed the frontier</mark>. This means that according to Dijkstra’s algorithm that since we picked $(v^{<em>}, w^{</em>})$ edge:</p>

\[d(y) + l_{yz} \ge d(v^{*}) + l_{v^{*}w^{*}}\]

        <p>Therefore every competitor path $P’$ must be at least $d(v^<em>) + l_{v^{</em>}w^{*}}$, and we are done. (Intuitively, this is saying that <mark>*any path $P'$* going outside of $X$ will need to use the shortest path inside $X$ + something outside $X$</mark>, and while Dijkstra is minimizing exactly this, it works.)</p>
      </li>
    </ul>
  </li>
</ol>

<p><strong>Q: What if we are dealing with a directed graph that has negative edges, but let’s say, <em>no negative cycles</em>?</strong></p>

<blockquote>
  <p>The main insight here is that the algorithm only looks at all directly connected edges and it takes the smallest of these edge. The algorithm <mark>does not look ahead</mark>.</p>
</blockquote>

<p>Therefore, you can consider the following example (from <a href="https://stackoverflow.com/questions/13159337/why-doesnt-dijkstras-algorithm-work-for-negative-weight-edges#:~:text=You%20can%20use%20dijkstra%27s%20algorithm,lose%20it%27s%20fast%20time%20complexity.">stackoverflow</a>)</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230923160616.png" style="zoom:100%;" /></p>

<p>where Dijkstra would return the shortest path from $A\leadsto D$ being at a cost of 2, but in reality it is $-4900$.</p>

<p><strong>Q: is there a case where Dijkstra algorithm is <em>still correct despite there are negative edges</em>?</strong></p>

<p>Yes. Consider a directed graph $G$ and a starting vertex $s$ with the following properties: <strong>no edges enter the starting vertex $s$; edges that leaves have arbitrary (possibly negative) lengths</strong>; and all other edge lengths are nonnegative. Dijkstra’s algorithm correctly solve the single-source shortest path problem. You can see this in two ways:</p>
<ul>
  <li>notice that adding the same positive constant $M$ to each of s’s outgoing edges preserves all shortest paths, as the lengths of all the $s \leadsto v$ path goes up by precisely $M$</li>
  <li>go back to the formal correctness proof of Dijkstra, and realize that the induction step would still work.</li>
</ul>

<h1 id="hash-tables-and-bloom-filters">Hash Tables and Bloom Filters</h1>

<p>The goal of a hash table is to facilitate <strong>super-fast searches</strong>, which are also called lookups in this context. Compared to other data structures we will discuss later (e.g. heaps and search trees), hash tables do not maintain any ordering information.</p>

<blockquote>
  <p>A hash table keep track of an evolving set of objects with keys while supporting fast lookups (by <strong>key</strong>).</p>
</blockquote>

<p>e.g. if you company manages an e-commerce site, you might use one hash table to keep track of employees (perhaps using names as keys).</p>

<blockquote>
  <p><strong>Hash Table Operations</strong>: a hash table needs to support the following operations:</p>
  <ul>
    <li>insert: given a new <strong>object</strong> $x$, add it to the hash table</li>
    <li>lookup: given a <strong>key</strong> $k$, return a pointer to an object in the hash table with key $k$ (or null if no such object exists)</li>
    <li>delete: given a key $k$, remove the object with key $k$ from the hash table, if it exists</li>
  </ul>

  <p>(for programming purposes you can just imagine the key a numerical representation of the object (e.g. memory address of the object), and a hash function $h$ operates on the key $h(k)$)</p>
</blockquote>

<p>and to really be a hash table:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Operation</th>
      <th style="text-align: center">Typical/Average Runtime</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">Lookup</td>
      <td style="text-align: center">O(1)*</td>
    </tr>
    <tr>
      <td style="text-align: center">Insert</td>
      <td style="text-align: center">O(1)</td>
    </tr>
    <tr>
      <td style="text-align: center">Delete</td>
      <td style="text-align: center">O(1)*</td>
    </tr>
  </tbody>
</table>

<p>where:</p>
<ul>
  <li>the asterisk (*) indicates that the running time bound <strong>holds if and only if</strong> the hash table is implemented properly (with a good hash function and an appropriate table size) and the data is non-pathological (see later).</li>
  <li>insert is technically always $O(1)$, not average runtime.</li>
</ul>

<p>Since this is really for fast lookups, example applications of hash tables include:</p>
<ul>
  <li>2-SUM problem: given a target $t$ and a list of integers $A$, find two distinct integers $x,y \in A$ such that $x+y=t$.
    <ul>
      <li>realize that given a $x$, there is only one possible $y$ that can achieve this = just look up $t-y$!</li>
    </ul>
  </li>
  <li>deduplication: given a list of $n$ items, remove all duplicates in $O(n)$ time
    <ul>
      <li>first check if the hash table already has the key, if not, insert the k and store the object</li>
    </ul>
  </li>
</ul>

<h2 id="implementation-separate-chaining">Implementation: Separate Chaining</h2>

<p>So how do we get a (near) constant lookup time? Here we discuss a very common implementation of hash tables, which is called <strong>separate chaining</strong> (and the other popular one is called <strong>open addressing</strong>). We will first discuss separate chaining.</p>

<p>Visually, this is very easy to understand:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230928225818.png" style="zoom:60%;" /></p>

<p>so that:&gt;</p>

<blockquote>
  <p><strong>Separate Chaining</strong>: Let there be an array $A$ of $n$ <strong>buckets</strong>, and for each bucket you have a linked list so that given a key $k$, <mark>lookup/insert/delete essentially all operate on the linked list $A[h(k)]$</mark>.</p>
  <ul>
    <li>note that this means your hash function needs to do $h: U \to {0,1,2,…,n-1}$ where $U$ is all possible objects/keys, which can be achieved by simply doing modulo n.</li>
  </ul>
</blockquote>

<p>But now we get some problems:</p>
<ul>
  <li>insert is surely constant time</li>
  <li>
    <p>but lookup and delete technically need:</p>

\[\text{Runtime(lookup/delete)} = O(\text{length of linked list})\]
  </li>
</ul>

<p>So our goal is to keep small linked list for each bucket. First of all, in what cases can we get bad performance?</p>
<ol>
  <li>Size of $n$ is too small, so that we have too many collisions.
    <ul>
      <li>This is easy to fix: just increase the size of $n$. But then you also need to rehash everything.</li>
    </ul>
  </li>
  <li>Using a bad hash function (e.g. $h(k) = 0$ a constant function).
    <ul>
      <li>So then what is a good hash function? One that <strong>Mimics a random function</strong> by spreading non-pathological datasets (see below) roughly evenly across the positions of the hash table</li>
    </ul>
  </li>
  <li>The data is pathological, i.e. it is <em>always</em> possible to adversarially come up with some kind of data such that they all hash to the same bucket. i.e. for every hash function $h: U \to {0,1,2,…,n-1}$, there exists a set $S$ of keys such that $h(k_1) = h(k_2)$ for every $k_{1}, k_{2} \in S$.
    <ul>
      <li>this is unfixable. The best we can do is to assume that the data is not pathological.</li>
    </ul>
  </li>
</ol>

<blockquote>
  <p><strong>Takeaway</strong>: while 1 and 2 are somewhat avoidable, condition 3 means that hash tables <mark>cannot guarantee $O(1)$ for lookup or delete</mark>.</p>
</blockquote>

<p>However, we <em>can</em> guarantee $O(1)$ is <em>average runtime</em> under some conditions (actually all the three will need to be addressed)</p>

<blockquote>
  <p><strong>Claim</strong>: let there be a dataset $S$. If our hash table has a reasonably big size $\vert S\vert =O(n)$ (condition 1), and $h(x)$ is like a random function (condition 2), and $S$ is not pathological (condition 3), then the average runtime of lookup and delete is $O(1)$.</p>
</blockquote>

<p><em>Proof</em>: since we are discussing average time, the procedure will be similar to quick sort analysis. We begin by figuring out the random variable we want to analyze, then decompose it to simpler random variables, and finally use linear expectation to get the result.</p>

<p>Suppose you have inserted all $s \in S$ into the hash table. 
Consider a lookup for a new random object $x$ with key $k$, which might or might not be in $S$. Then the runtime is:</p>

\[\mathrm{Runtime} = O(\text{list length of }A[h(k)]) = O(l)\]

<p>where $l$ is the random variable as it could be long or short. But notice that</p>

\[O(l) = O(\# \text{of collisions $x$ is making})\]

<p>This means that:</p>

\[\begin{align*}
  l \le 1 + \sum\limits_{y \in S, y \neq x} z_{y}  
\end{align*}\]

<p>where $z_y$ is (again) an indicator random variable indicating if there is a collision, and the one is there if there is a $y=x$ (i.e. essentially $x$ was an object $S$).</p>

\[z_{y} = 
\begin{cases}
1, &amp; \text{if $h(x)=h(y)$ } \\
0, &amp; \text{otherwise}
\end{cases}, \quad \forall y \in S\]

<p>Now decomposition is complete, we realize that:</p>

\[\begin{align*}
  \mathbb{E}[l]
  &amp;\le \mathbb{E}\left[1 + \sum\limits_{y \in S, y \neq x} z_{y}\right] \\
  &amp;= 1 + \sum\limits_{y \in S, y \neq x} \mathbb{E}[z_{y}] \\
  &amp;= 1 + \sum\limits_{y \in S, y \neq x} \Pr[h(x)=h(y)]
\end{align*}\]

<p>But we realize that if $h$ is a perfectly random hash function, then $\Pr[h(x)=h(y)]$ given an $x$ is like throwing the $y$ dart randomly at the $n$ buckets, and hoping that it lands on the same bucket as $x$. Therefore, the probability is $1/n$. Hence we get:</p>

\[\begin{align*}
  \mathbb{E}[l]
  &amp;\le 1 + \sum\limits_{y \in S, y \neq x} \Pr[h(x)=h(y)] \\
  &amp;= 1 + \sum\limits_{y \in S, y \neq x} \frac{1}{n} \\
  &amp;= 1 + \frac{|S|-1}{n} \\
  &amp;= O(1)
\end{align*}\]

<p>where the last equality is because we had said $\vert S\vert =O(n)$, i.e. our hash table is reasonably big.</p>

<h2 id="implementation-open-addressing">Implementation: Open Addressing</h2>

<p>Why did we have a linked list version before (i.e. separate chaining)? <mark>In the end it was to resolve collision</mark>, but letting them live in the same bucket. Note that such collision is inevitable, as we have fixed size of data structure but your dataset $S$ is huge.</p>

<p>The idea of open addressing is, instead of letting the collision live in the same bucket, we will <mark>try to find another bucket</mark> for the colliding object, assuming $n \ge \vert S\vert$. In this implementation, each bucket stores only 0 or 1 object.</p>

<blockquote>
  <p><strong>Open Addressing</strong>: given an object $x$ with key $k$ and its position to insert $h(k)$. We will use some <strong>probe sequence</strong> (i.e. a sequence of buckets to check) if $h(k)$ is occupied.</p>
  <ul>
    <li>so for insert, we continue this sequence until the first empty bucket, and insert the object there</li>
    <li>for lookup, we continue this sequence until we find the bucket storing $x$, or an empty bucket (return not found)</li>
    <li>we will <em>not</em> support delete.</li>
  </ul>
</blockquote>

<p>So the trick is this “probe sequence”. One simple sequence would be a <strong>linear probing</strong>: $h(k), h(k)+1, …, \text{wrap around}, h(k)-1$.</p>

<p>We skip other details here, but discuss its performance compared to separate chaining.</p>

<ul>
  <li>with chaining, the lookup time is affected by linked list length; with open addressing, its the <strong>number of probes required</strong> to either hit an empty slot or find the object.</li>
  <li>in both implementations, when the hash table gets increasingly full, performance degrades.</li>
  <li>however, with an appropriate hash table size and hash function, <strong>open addressing achieves the same running time bound</strong> as chaining.</li>
</ul>

<h2 id="bloom-filters">Bloom Filters</h2>

<p>Bloom filters have became a very popular data structure since its usage in internet routers. It has a very similar idea to hash tables, but:</p>

<ul>
  <li>it is more space efficient</li>
  <li>it can only return <code class="language-plaintext highlighter-rouge">true/false</code> for lookup (i.e. if the object is in the set or not)</li>
  <li>it <em>can</em> return false negatives (i.e. even if the object is not in the set, it might return <code class="language-plaintext highlighter-rouge">true</code>)</li>
  <li>it <em>guarantees</em> constant-time operations for every dataset.</li>
</ul>

<blockquote>
  <p><strong>Blook Filter Supported Operations</strong>: a bloom filter supports the following operations:</p>
  <ul>
    <li>lookup: given a key $k$, return <code class="language-plaintext highlighter-rouge">true</code> if $k$ is in the bloom filter, and <code class="language-plaintext highlighter-rouge">false</code> if $k$ is not in the bloom filter</li>
    <li>insert: add a new key $k$ to the bloom filter (since we are only returning <code class="language-plaintext highlighter-rouge">true/false</code> for lookup, we don’t need to store the key/object itself)</li>
  </ul>
</blockquote>

<p>The idea of Bloom filter is simple. Consider an array of $n$ bits all initially zero. Then the data structure uses $m$ hash functions $h_1, h_{2}, …, h_m$ each mapping $h_{i} : U \to { 0,1,2, … , n-1 }$.</p>
<ul>
  <li>you can create $m$ hash functions <em>*using one real hash function $h_{</em>}$<em>*, by doing $h_{1}(k) = m \cdot h_</em>(k), h_{2} = m \cdot h_*(k) + 1$, etc.</li>
  <li>typically $m$ is quite small, like $m=5$.</li>
</ul>

<p>Then the operations is simply:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">insertion</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
  <span class="c1"># flip all A[h_i(k)] = 1
</span>  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
    <span class="n">A</span><span class="p">[</span><span class="n">h_i</span><span class="p">(</span><span class="n">k</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">1</span>

<span class="k">def</span> <span class="nf">lookup</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
  <span class="c1"># check if all A[h_i(k)] == 1
</span>  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">A</span><span class="p">[</span><span class="n">h_i</span><span class="p">(</span><span class="n">k</span><span class="p">)]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
      <span class="k">return</span> <span class="bp">False</span>
  <span class="k">return</span> <span class="bp">True</span>
</code></pre></div></div>

<p>Visually:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20230928235431.png" style="zoom:80%;" /></p>

<p>hence it is obvious that:</p>
<ul>
  <li>you cannot get false negative: if an object is in the set, then its bits must <em>have been flipped to 1</em> (as we are not supporting deletion).</li>
  <li>you can get false positive: if an object is not in the set, then its bits <em>might have been flipped to 1</em> by other objects.</li>
</ul>

<p>Now, error analysis: is this really worth it? How much error will this give? The goal is to get <strong>a $n$ not too large but still have a small false positive rate</strong>.</p>

<p>Suppose that we have inserted all elements $x \in S$ into the bloom filter. Consider a lookup for a new random object $x$ with key $k$, which is a false positive. For this to happen, we need:</p>

\[\Pr[\text{false positive}] = \Pr[\text{all $m$ bits are flipped for $x$}] = \Pr[ \text{one bit is flipped} ]^{m}\]

<p>What’s the probability that one bit is flipped?</p>

\[\Pr[ \text{one bit is flipped} ] = 1 - \Pr[ \text{all data missed that bit} ] = 1 - {\underbrace{\left( 1 - \frac{1}{n}\right)}_{\text{one hash function missed}}}^{m |S|}\]

<p>where its raised to the power of $m \vert S\vert$ since there are $\vert S\vert$ objects we inserted, and for each object we had $m$ “dart shots” (recall that we assume $h$ is a perfectly random function). This form approximates that of an exponential function:</p>

\[\Pr[ \text{one bit is flipped} ] =  1 - {\left( 1 - \frac{1}{n}\right)}^{m |S|} \approx 1 - e^{- m|S| / {n}}\]

<p>finally:</p>

\[\Pr[\text{false positive}] \approx \left( 1 - e^{- m|S| / {n}} \right)^{m}\]

<p>Notice that this is a function of $n,m, \vert S\vert$. Therefore, depending on the application, we can <mark>optimize for the error rate</mark> (using calculus), if we fix $n / \vert S\vert$ representing the number of bits per object:</p>

\[m^{*} = \frac{n}{|S|} \ln 2\]

<p>this means that if we are having an array for about <strong>8 bits per object</strong>, then we should use <strong>$m=5 \sim 6$ hash functions</strong> which gives an <strong>error rate of about 2%</strong>.</p>

<h1 id="introduction-to-greedy-algorithms">Introduction to Greedy Algorithms</h1>

<p>This is another <em>class</em> of algorithm, where compared to the divide and conquer algorithm:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Divide and Conquer</th>
      <th style="text-align: center">Greedy Algorithms</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231005214058.png" style="zoom:100%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231005214110.png" style="zoom:100%;" /></td>
    </tr>
    <tr>
      <td style="text-align: center">relatively easy to prove correct (e.g. induction)</td>
      <td style="text-align: center">usually hard correctness proof</td>
    </tr>
    <tr>
      <td style="text-align: center">harder to analyze runtime</td>
      <td style="text-align: center">usually straightforward sorting + single pass</td>
    </tr>
  </tbody>
</table>

<p>While it is myoptic and simple to implement, it is <strong>often hard to come up with a correct greedy algorithm</strong> (e.g. Dijkstra was one), and for many problems <strong>there might not exist a correct greedy algorithm</strong>. More specifically, you shall see that correctness proofs for greedy algorithms are more art than science, though there will be a useful trick, called the <strong>exchange argument</strong>, which we will show next.</p>

<h2 id="scheduling-problem">Scheduling Problem</h2>

<p>Consider the scheduling task in OS, where given some set of jobs $J$ with each job $j$ having known length $l_j$ (i.e. how long it takes to complete), and a weight $w_j$ (e.g. priority). We want to have a scheduling algorithm that can find the “best” sequence of jobs to complete $\sigma$. What is a “best” schedule?</p>

<ul>
  <li>
    <p>first of all, how many posisble schedules are there? $n!$.</p>
  </li>
  <li><strong>completion time</strong> $C_j(\sigma)$ of a job $j$ is the sum of lengths of the jobs preceding $j$ in $\sigma$, plus the length of $j$ itself. i.e. time elapsed when $j$ is completed.
    <ul>
      <li>e.g. consider three jobs with length $l_1=1, l_{2}=2, l_3=3$, weight $w_1=3, w_2=2, w_{3} = 1$. Suppose we scheduled them to be in the order of $j_1, j_2, j_3$. Then this means the completion time is $C_{1} = 1, C_{2} = 3, C_{3} = 6$. Visually</li>
    </ul>

    <p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231005220948.png" style="zoom:60%;" /></p>
  </li>
  <li>
    <p><strong>sum of weighted completion times</strong>. This is <mark>our objective function</mark>:</p>

\[\min_\sigma \sum\limits_{j =1}^{n} w_j C_j(\sigma)\]

    <p>i.e. we want shorter/more important jobs to be completed earlier.</p>
  </li>
</ul>

<blockquote>
  <p><strong>Scheduling Task</strong>: given a set of $n$ jobs with positive lengths $l_j$ and positive weights $w_j$, find a schedule $\sigma$ that minimizes the sum of weighted completion times.</p>
</blockquote>

<p>To solve this problem, let us <em>first posit that there actually is a correct greedy algorithm</em> for the problem. Then, we need to consider some <mark>intuitions by thinking about some "special cases"</mark>.</p>

<blockquote>
  <p><strong>Intuition</strong>:</p>
  <ul>
    <li>if all job lengths are equal, then we should schedule jobs with a <strong>higher weight</strong> first.</li>
    <li>if all job weights are equal, then we should schedule <strong>shorter jobs</strong> first. (Why? Realize that in general, the job scheduled first <em>contributes to the completion times of all the jobs</em>, as all jobs must wait for the first one to finish.)</li>
  </ul>
</blockquote>

<p>These two rules of thumbs make sense, but in reality we can have a job with high weight but long length, and vice versa. So how do we combine these two rules of thumbs? Consider a simple greedy idea where we 1) use a formula to compile each job’s length and weight into a single number, and 2) schedule the jobs greedily using that score. So what is the formula?</p>

<p>From our intuition above, we know that the formula <strong>must have two properties</strong>:</p>
<ol>
  <li>holding length constant, the score should increase with weight (assuming we want to schedule higher score first)</li>
  <li>holding weight constant, the score should decrease with length (longer length smaller score)</li>
</ol>

<p>So we can <em>guess</em> two candidates:</p>

<ul>
  <li>score 1: $w_{j} - l_{j}$. The <strong>GreedyDiff</strong> algorithm.</li>
  <li>score 2: $w_{j} / l_{j}$. The <strong>GreedyRatio</strong> algorithm.</li>
</ul>

<p>Obviously if they propose different schedules, then one of them must be wrong (or in general, both are wrong). In this case, we can rule out the first by considering the following example:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231005222454.png" style="zoom:80%;" /></p>

<p>where the first job would have a larger ratio, so GreedyRatio would schedule it first, but GreedyDiff would schedule the second job first. But we realize that the weighted completion time:</p>

<ul>
  <li>for GreedyRatio is $3 \cdot 5 + 1 \cdot 7 = 22$</li>
  <li>for GreedyDiff is $1 \cdot 2 + 3 \cdot 7 = 23$ is worse!</li>
</ul>

<p>So we can rule out GreedyDiff, and we are left with GreedyRatio. But is GreedyRatio correct? Luckily in this case it is!</p>

<blockquote>
  <p><strong>Theorem: Correctness of GreedyRatio</strong>. For every set of positive job weights $w_1, w_2, …, w_n$ and positive job length $l_1, l_2, … , l_n$, the GreedyRatio algorithm outputs a schedule with the minimum possible sum of weighted completion times.</p>
</blockquote>

<p><em>Proof</em>: we will use <mark>exchange arguments</mark>. The key idea is prove that every feasible/alternative solution can be improved by modifying it to look more like the output of the greedy algorithm $\implies$ the greedy algorithm is optimal.</p>

<p>Without loss of generality, let us compute the ratio for every job $j$ and renumber the jobs such that:</p>

\[\frac{w_1}{l_1} \ge \frac{w_2}{l_2} \ge ... \ge \frac{w_n}{l_n}\]

<p>so that $\sigma$ is the sequence $[1,2, … , n]$. Suppose by contradiction that we have some competitor $\sigma^{<em>}$ that is better, and $\sigma^{</em>} \neq \sigma$. For the greedy output we get essentially:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231005224435.png" style="zoom:80%;" /></p>

<p>but note that for any other schedule, we will have a <strong>consecutive inversion</strong>: a pair of job $i &gt; j$ (so $j$ has a higher score) such that job $i$ is processed immediately before job $j$. For instance $\sigma^{‘}$ has a consecutive inversion:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">$\sigma^{*}$</th>
      <th style="text-align: center">$\sigma^{‘}$</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231005225000.png" style="zoom:70%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231005225006.png" style="zoom:70%;" /></td>
    </tr>
  </tbody>
</table>

<blockquote>
  <p><strong>Lemma: Non-Greedy Schedules Have Inversions</strong>. Every schedule $\hat{\sigma}$ different from the greedy schedule $\sigma$ has at least one consecutive inversion.</p>
  <ul>
    <li>proof: if $\hat{\sigma}$ has no consecutive inversion, then the index of each job is at least 1 larger than the job that came before. Since there are only $n$ jobs and the maximum index is $n$, the jump between two consecutive job must be 1. Then $\hat{\sigma}$ must be the same as $\sigma$.</li>
  </ul>
</blockquote>

<p>Now, the key idea is to perform an exchange from $\sigma^{*}$ (to reach $\sigma^{‘}$) and realize it can only perform at least as good. After the swap above of job $i,j$, we realize that:</p>
<ul>
  <li>the objective does not change for the jobs before $i$ and after $j$</li>
  <li>for job $i$ in $\sigma^{*}$, it went up in $\sigma^{‘}$ so the cost increased by $l_{j} \cdot w_i$</li>
  <li>for job $j$ in $\sigma^{*}$, it went down in $\sigma^{‘}$ so the cost decreased by $l_{i} \cdot w_j$</li>
</ul>

<p>But since $i &gt; j$ by construction ($j$ had a higher score), it means:</p>

\[\frac{w_i}{l_i} \le \frac{w_j}{l_j} \implies l_{j} \cdot w_i \le l_{i} \cdot w_j\]

<p>So $\sigma^{‘}$ is at least as good as $\sigma^{<em>}$, with $\sigma^{‘}$ being more ordered = more similar to $\sigma$! More precisely, we can show that $\sigma^{‘}$ has <mark>exactly one less inversion</mark> than $\sigma^{</em>}$. To see this, define an inversion to be a pair $k,m$ of job such that $k &lt; m$ (so $k$ has a higher score) but $m$ is schedules before $k$, AND that they need not be consecutive. Then, realize that swapping one consecutive inversion does not change the relative order of $k,m$ relative to each other or $k,m$ relative to $i,j$:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231005231255.png" style="zoom:70%;" /></p>

<p>In other words, restoring consecutive inversion doesn’t affect any other inversions (if any). Therefore, this means:</p>

<ul>
  <li>having <strong>one less consecutive inversion produces a schedule at least as good</strong>!</li>
  <li>having <strong>one less consecutive inversion also decreases the total number of inversion by one</strong></li>
</ul>

<p>Therefore, we can repeatedly swap jobs to remove consecutive inversions until we get $\sigma$, which has no inversions. During the process, the objective function can not increase ($\le$). Hence $\sigma$ is at least as good as any $\sigma^{*}$ along the way. This means that $\sigma$ is optimal, and we are done.</p>

<h1 id="huffman-codes">Huffman Codes</h1>

<p>Huffman coding is a widely-used method for lossless compression. For example, every time you import or export an MP3 audio file, your computer uses Huffman codes. This section will cover the optimality of Huffman codes, and a fast algorithm for computing them.</p>

<blockquote>
  <p><strong>Compression Task</strong>: consider an input “string” that consists of symbols from an alphabet $\Sigma$ (e.g. a set of 64 symbols including all 26 letters plus punctuations and some special characters). Your goal is to represent this string to a <em>binary code</em>, i.e. a sequence of 0s and 1s, so that the code is as short as possible while still being able to recover the original string.</p>
</blockquote>

<p>Note that there are two different tasks here:</p>
<ol>
  <li><strong>encoding</strong>: find a mapping that maps each symbol to a binary code</li>
  <li><strong>decoding</strong>: given a binary code, can recover the original string without ambiguity</li>
</ol>

<p>For instance, consider the following alphabet to encode:</p>

\[\Sigma = \{ A,B,C,D \}\]

<p>and consider the following two encoding schemes:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">fixed-length code</th>
      <th style="text-align: center">variable-length code</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231010233843.png" style="zoom:80%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-                    .png" style="zoom:80%;" /></td>
    </tr>
  </tbody>
</table>

<p>While variable code in general can be shorter if designed correctly (so we will focus on this), but in this case what would the string “001” decode to? Note that this issue does not arise with fixed-length codes since we know where to start and end for each symbol. With variable-length codes, we must <strong>impose a constraint to prevent ambiguity</strong>.</p>

<h2 id="prefix-free-codes">Prefix-Free Codes</h2>

<p>We can eliminate all ambiguity by insisting that a code is <strong>prefix-free</strong>. This means that given any two pair of distinct symbols $a,b \in \Sigma$, the encoding of $a$ is not a prefix of that of $b$, and vice versa.</p>

<blockquote>
  <p>With a prefix-free code, encodings are unambiguous</p>
</blockquote>

<p>Why? If, say, the first 5 bits of a sequence match the encoding of a symbol $a$, then $a$ was definitely the first symbol encoded. Because the code is prefix-free, there’s no way these 5 bits could correspond to (a prefix of) the encoding of any other symbol.</p>

<p>An example of prefix-free code would be fixed length code, or the following variable-length code:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231011002350.png" style="zoom:100%;" /></p>

<p>But how do we find a variable-length code that is also prefix-free? Crucial to reasoning about the problem is a method of <strong>associating codes with labeled binary trees</strong>. This is most easy to see with examples:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Encoding</th>
      <th style="text-align: center">Tree</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-        .png" style="zoom:80%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-   .png" style="zoom:80%;" /></td>
    </tr>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231011002732.png" style="zoom:80%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-      .png" style="zoom:80%;" /></td>
    </tr>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231011002944.png" style="zoom:80%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231011002953.png" style="zoom:80%;" /></td>
    </tr>
  </tbody>
</table>

<p>where essentially edges are the encoding, and vertices are potential symbols. Notice that</p>
<ul>
  <li><strong>every binary code can be represented as a binary tree</strong> with left and right child edges labeled with “0” and “1,” respectively, and with each symbol of the alphabet used as the label for exactly one node</li>
  <li>the number of edges in a path/depth equals the number of bits used to encode the corresponding symbol</li>
</ul>

<p>But more importantly:</p>
<ul>
  <li>In general, the encoding of a symbol $a$ is a prefix of that of another symbol $b$ <strong>if and only if the node labeled $a$ is an ancestor of the node labeled $b$</strong>.</li>
  <li>therefore, because no leaf can be the ancestor of another, <mark>a tree with labels only at the leaves defines a prefix-free code</mark> (i.e., no label will be parent)</li>
</ul>

<p>Finally, we can visualize decoding as traversing the tree until we hit a leaf, and restarting from the root. For example, given the input string “010111” and the tree below, we would decode it as “ABD”:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231011003933.png" style="zoom:80%;" /></p>

<h2 id="huffmans-greedy-algorithm">Huffman’s Greedy Algorithm</h2>

<p>Now that we have a way to represent a prefix-free code as a binary tree, we can formulate the problem as follows:</p>

<blockquote>
  <p><strong>Task: Optimal prefix-free code</strong>. Given a string to encode, with each symbol $a \in \Sigma$ having a frequency $p_a$, our objective is to minimize:</p>

\[\min_T \sum\limits_{a \in \Sigma} p_a \cdot \text{depth}(a)\]

  <p>where $T$ is a binary tree with labels only at the leaves, which would define any prefix-free code.</p>
</blockquote>

<p>Now since we can have symbols of different frequency, it becomes apparent that variable length prefix-code is what we are looking for: associate the most frequent symbols with the shortest codes/number of bits.</p>

<p>The overall idea is to consider a bottom-up algorithm. We start with every symbol $a \in \Sigma$ as a leaf, and then we will repeatedly merge some symbols until we get a tree. But what do we choose which ones to merge in order to minimize the objective?</p>

<blockquote>
  <p><em>Intuition</em>: labels with high frequency are costly so they should be at the top of the tree. Hence, we should keep small frequency labels at the deeper levels.</p>

  <p>So, the idea for greediness is to consider merging ‘‘symbols’’ with the <strong>smallest frequencies</strong> first (bottom-up). i.e. every iteration of Huffman’s greedy algorithm myopically performs the merge that least increases this objective function.</p>
</blockquote>

<p>Why could it possibly be a good idea? Realize that each merge <strong>increments the depths of all the leaves in the two participating trees</strong> and, hence, the encoding lengths of the corresponding symbols:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Before Merge</th>
      <th style="text-align: center">After Merge</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-              .png" style="zoom:70%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-             .png" style="zoom:70%;" /></td>
    </tr>
  </tbody>
</table>

<p>where technically you are merging two trees (or two root nodes) each time, and specifically for every leaf/symbol in the two trees after merging, the depth increases by 1. This causes the <strong>objective function to increase by</strong>:</p>

\[\sum\limits_{a \in T_1} p_{a} +  \sum\limits_{a \in T_2} p_{a}\]

<p>because for symbol has increased one more bit, but as it appears $p_a$ times,the total cost increases $p_a$ for each leaf. <strong>Huffman’s greedy criterion thus dictates that we merge the pair of trees for which the sum above is as small as possible</strong>.</p>

<p>The pseudo code thus look like:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">huffman</span><span class="p">(</span><span class="n">S</span><span class="p">):</span>
  <span class="c1"># S is a set of symbols with frequencies p_a
</span>  <span class="c1"># initialize a forest of trees, one for each symbol
</span>  <span class="n">F</span> <span class="o">=</span> <span class="p">{</span> <span class="n">Tree</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">p_a</span><span class="p">)</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">S</span> <span class="p">}</span>

  <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">F</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">T_1</span><span class="p">,</span> <span class="n">T_2</span> <span class="o">=</span> <span class="n">two_trees_with_smallest_freq</span><span class="p">(</span><span class="n">F</span><span class="p">)</span>
    <span class="c1"># merge them into a new tree
</span>    <span class="n">T_3</span> <span class="o">=</span> <span class="n">merge</span><span class="p">(</span><span class="n">T_1</span><span class="p">,</span> <span class="n">T_2</span><span class="p">)</span>  <span class="c1"># root of T1, T2 become the children of a new internal node
</span>    <span class="n">T_3</span><span class="p">.</span><span class="n">p_a</span> <span class="o">=</span> <span class="n">T_1</span><span class="p">.</span><span class="n">p_a</span> <span class="o">+</span> <span class="n">T_2</span><span class="p">.</span><span class="n">p_a</span>  <span class="c1"># invariant: for every internal node, its p_a is the sum of its children
</span>
    <span class="n">F</span><span class="p">.</span><span class="n">remove</span><span class="p">(</span><span class="n">T_1</span><span class="p">)</span>
    <span class="n">F</span><span class="p">.</span><span class="n">remove</span><span class="p">(</span><span class="n">T_2</span><span class="p">)</span>
    <span class="n">F</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">T_3</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">the</span> <span class="n">only</span> <span class="n">tree</span> <span class="ow">in</span> <span class="n">F</span>
</code></pre></div></div>

<p>Before proof of correctness, consider a quick example. Given input of</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231011010013.png" style="zoom:100%;" /></p>

<p>and each iteration of the algorithm looks like:</p>

<ol>
  <li>initialize with 4 trees, each with a single symbol
<img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231011010135.png" style="zoom:100%;" /></li>
  <li>smallest is node C and D:
<img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231011010204.png" style="zoom:100%;" />
merge and obtain a new subtree with root CD at cost of $0.10+0.05=0.15$</li>
  <li>smallest two are $0.15$ and $0.25$, so merge the subtree CD with B:
   <img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231011010318.png" style="zoom:100%;" />
   and obtain a new subtree with cost $0.4$</li>
  <li>Finally<br />
<img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231011010443.png" style="zoom:100%;" />
where if we take the left edge to represent 0 and the right 1, this returns a variable length prefix-free code of A=0, B=10, C=110, D=111.</li>
</ol>

<h2 id="correctness-of-huffmans-algorithm">Correctness of Huffman’s Algorithm</h2>

<p>Now we want to show that the encoding returned by the above greedy algorithm is correct. In general greedy algorithm is not easy to prove, and here we will use induction + exchange argument to prove it.</p>

<p>Before the proof, we first notice that the algorithm is <strong>iteratively committing two smallest $p_a$ symbols $a,b$ to be siblings in the final tree</strong>. Therefore the plan is to show that:</p>

<ol>
  <li>Huffman’s tree is the best (minimizes the average leaf depth) amongst all possible trees in which $a$ and $b$ are siblings</li>
  <li>there is an optimal tree in which $a$ and $b$ are siblings</li>
</ol>

<p>Visually, each iteration of the algorithm is like:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231011094550.png" style="zoom:10%;" /></p>

<p>and to prove that the output tree is optimal (combining claim 1 and 2) we need to show that:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231011094612.png" style="zoom:10%;" /></p>

<p>If we can prove both of the above, then we are basically done (by induction).</p>

<hr />
<p><em>Proof</em> by induction. Let us denote $P(k)$ be the statement that Huffman’s tree output the best with an alphabet size at most $k$.</p>
<ol>
  <li>base case: when $k=2$, there is only a tree with one root and two leaves. So Huffman’s tree is optimal.</li>
  <li>inductive hypothesis: assume $P(k’)$ is true for $k’ &lt; k$.</li>
  <li>
    <h2 id="inductive-step-we-need-to-show-that-pk-is-true-since-each-step-of-the-algorithm-we-are-merging-two-least-frequent-symbols-the-root-of-the-subtree-we-want-to-show-claim-1-and-claim-2-to-hold-in-order-to-prove-that-the-output-tree-at-this-stage-is-optimal">inductive step: we need to show that $P(k)$ is true. Since each step of the algorithm we are merging two least frequent “symbols” (the root of the subtree), we want to show claim 1 and claim 2 to hold in order to prove that the <strong>output tree at this stage is optimal</strong>.</h2>
  </li>
</ol>

<p><em>Proof for claim 2</em>: we begin by first showing that there is an optimal tree in which $a$ and $b$ are siblings. To prove this, we will use the <em>exchange argument</em> again. Consider some arbitrary tree $T$, and without loss of generality, denote a sibling at the lowest level of the tree as $x,y$. Let $a,b$ the nodes with the smallest frequency $p_a$. We want to show that the objective function/cost is at least as good as the one with $a,b$ as siblings.</p>

<p>Consider changing the $a,b$ and $x,y$  pair:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231011095113.png" style="zoom:100%;" /></p>

<p>Then notice that the new tree $T’$ changed cost function by:</p>

\[\begin{align*}
  \Delta L
  &amp;= \underbrace{p_{a} (\mathrm{depth}(x) - \mathrm{depth}(a)) + p_{b} (\mathrm{depth}(y) - \mathrm{depth}(b))}_{\text{cost}} \\
  &amp;+ \underbrace{p_{x} (\mathrm{depth}(a) - \mathrm{depth}(x)) + p_{y} (\mathrm{depth}(b) - \mathrm{depth}(y))}_{\text{benefit}} \\
\end{align*}\]

<p>which we can simplify to</p>

\[\Delta L = (p_{a} - p_{x}) \cdot (\Delta(x,a)) + (p_{b} - p_{y}) \cdot (\Delta(y,b))\]

<p>where by definition of $x,y$ being the deepest we know that $\Delta(x,a) \ge 0$ and $\Delta(y,b) \ge 0$. Additionally, since by construction $p_a, p_{b} \le p_x, p_y$, we know that $\Delta L \le 0$ after the exchange, so the cost is at least as good $\implies$ there exists an optimal tree with $a,b$ being siblings.</p>

<hr />

<p><em>Proof of Claim 1</em>: We will use induction to show that Huffman’s tree is the best amongst the sibling trees $T_{ab}$ where $a,b$ being the least frequent symbol are siblings. The trick is that we can do induction proof on $\Sigma’$-tree, where each step of the algorithm we “rename” the symbols instead of denoting them as subtree (e.g. merging $a,b$ gives the new symbol $ab$). Then note that the tree constructed in this notation is essentially the same as tree constructed in the original notation with $\Sigma$:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231011102337.png" style="zoom:80%;" /></p>

<p>with the only difference being $p_{ab} = p_a + p_b$, and the average leaf depth is the same up to a constant that is independent of the choice of the tree:</p>

\[L(T) = L(T') + p_a + p_b\]

<p>because the expanded tree has node $a,b$ being one level deeper. Now, we can very easily show that running Huffman on $\Sigma’$ (replacing $a,b$ with $ab$ and $p_{ab} = p_{a} + p_{b}$) using the <strong>induction hypothesis</strong> we left off earlier. Since now $\vert \Sigma’\vert  &lt; \vert  \Sigma\vert  = k$, <strong>Huffman algorithm returns the optimal tree $T’_{ab}$ for $\Sigma’$-tree</strong>.</p>

<p>Then, because each $\Sigma’$-tree correspond to $\Sigma$-tree (with $a,b$ being siblings) and the average leaf depth is preserved (up to a constant), then knowing an optimal tree in $\Sigma’$-tree, is knowing an optimal in $\Sigma$-tree with $a,b$ being siblings.</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231011102843.png" style="zoom:80%;" /></p>

<p>where RHS is what we just proved, and LHS is claim 1.</p>

<hr />

<p>Combining claim 1 and claim 2, the induction step is complete because by claim 1, Huffman outputs the best-possible tree from the restricted $T_{ab}$ set and by claim 2, such a tree $T_{ab}$ must be optimal.</p>

<h2 id="running-time-of-huffman-algorithm">Running Time of Huffman Algorithm</h2>

<p>The simple implementation would run in $O(n^{2})$, because we will merge in total $n-1$ times for $n = \left\vert \Sigma\right\vert$ , and each iteration needs to identify the two smallest trees in the forest, which takes $O(2n)$ time by simple scan. There, however, is a small change we can make it run a bit faster:</p>

<blockquote>
  <p><strong>Heap</strong>: a special Tree-based data structure in which the tree is a <strong>complete binary tree</strong>.</p>
  <ul>
    <li>Min-Heap: the key present at the <strong>root node must be minimum</strong> among the keys present at all of it’s children. The same property must be recursively true for all sub-trees in that Binary Tree.</li>
    <li>Max-Heap: the key present at the <strong>root node must be maximum</strong> among the keys present at all of it’s children. The same property must be recursively true for all sub-trees in that Binary Tree.
<img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231011111524.png" style="zoom:30%;" /></li>
  </ul>

  <p>and the key usage is that deleting the top element of the heap or the highest priority element, and then <strong>re-balancing the tree only takes $O(\log N)$</strong>. (Actually it is $O(H)$ for $H$ being the height of the tree, which is $\log N$ if it is a complete binary tree). Therefore each find min/find max operation takes $O(\log N)$ time.</p>
</blockquote>

<p>Therefore, since we are repeatedly finding the minimum, we can use a min-heap to store the nodes/symbols, and then each iteration we can delete the top two elements and insert the new node, which takes $O(\log n)$ time. Therefore, the overall running time is $O(n \log n)$.</p>

<h1 id="minimum-spanning-trees">Minimum Spanning Trees</h1>

<p>The MST problem is a uniquely great playground for the study of greedy algorithms, in which <em>almost</em> any greedy algorithm that you can think of turns out to be correct. The goal is to find, in a given graph $G= (V,E)$ with weight $w$ on edges, what is the best subset of edges $T \subseteq E$ such that the resulting graph with $T$ will:</p>
<ol>
  <li>spanning: <strong>connect every vertex in $V$ (i.e. one connected component)</strong></li>
  <li>tree: it is a spanning <em>tree</em>: there are <strong>no cycles</strong>.</li>
  <li>minium: it has the <strong>minimum total weight</strong></li>
</ol>

<blockquote>
  <p><strong>Minimum Spanning Tree Problem</strong>. Input undirected graph $G=(V,E)$ in which each edge $e$ has a real-valued cost $c_e$, and the goal is to output a minimum spanning tree $T \subseteq E$  of $G$.</p>
  <ul>
    <li>note that it would only make sense if $G$ is a connected graph, otherwise there is no spanning tree.</li>
  </ul>
</blockquote>

<p>For example, the red highlighted is a MST with cost $7$:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231013004832.png" style="zoom:80%;" /></p>

<h2 id="prims-algorithm">Prim’s Algorithm</h2>

<p>The algorithm closely resembles Dijkstra’s shortest-path algorithm, except that we have no ‘‘source vertex’’ and we are trying to find a spanning tree rather than a shortest-path. The idea is to greedily pick the cheapest edge that cross the frontier until done (starting from any random vertex).</p>

<p>So an example before we going to the pseudo code:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">iteration 1</th>
      <th>iteration 2</th>
      <th>iteration 3</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-          .png" style="zoom:100%;" /></td>
      <td><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231013005456.png" style="zoom:100%;" /></td>
      <td><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231013005519.png" style="zoom:100%;" /></td>
    </tr>
  </tbody>
</table>

<p>where we started from vertex $b$, and at each iteration we checked the all edge that cross the  “frontier” and picked the cheapest one. The pseudo code is:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">prim</span><span class="p">(</span><span class="n">G</span><span class="p">):</span>
  <span class="c1"># G is a connected graph with edge weights w
</span>  <span class="c1"># initialization
</span>  <span class="n">X</span> <span class="o">=</span> <span class="p">{</span><span class="n">s</span><span class="p">}</span>  <span class="c1"># s is an arbitrary vertex
</span>  <span class="n">T</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># output and also an INVARIANT: edges that span X
</span>
  <span class="k">while</span> <span class="n">X</span> <span class="o">!=</span> <span class="n">V</span><span class="p">:</span>
    <span class="c1"># find the cheapest edge (u,v) with u in X, v not in X
</span>    <span class="n">e</span> <span class="o">=</span> <span class="p">(</span><span class="n">u</span><span class="p">,</span><span class="n">v</span><span class="p">)</span> <span class="o">=</span> <span class="n">cheapest</span> <span class="n">edge</span> <span class="k">with</span> <span class="n">u</span> <span class="ow">in</span> <span class="n">X</span><span class="p">,</span> <span class="n">v</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">X</span>
    <span class="n">T</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
    <span class="n">X</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">T</span>
</code></pre></div></div>

<p>where :</p>
<ul>
  <li>one obvious implementation could give $O (mn)$ since you are looping over all vertices once (n times) and finding the cheapest edge (m times) for loop.</li>
  <li>we will first show that this indeed outputs a MST</li>
  <li>and then we will also see that the algorithm is correct no matter which vertex it chooses to start from</li>
</ul>

<h3 id="correctness-of-prims-algorithm">Correctness of Prim’s Algorithm</h3>

<p>Proving the correctness of Prim’s algorithm is a bit easier when all the edge costs are distinct (this is to just make the proof easier, the algorithm is still correct without it), and let us take that as an <mark>assumption</mark> for now.</p>

<p>To prove this, we consider showing two things:</p>
<ol>
  <li>Prim outputs a <em>tree</em> (with no cycles)</li>
  <li>The tree is <em>spanning and minimal</em>.
    <ul>
      <li>first show that every edge picked by Prim satisfies the “minimum bottleneck property”</li>
      <li>then we show that a spanning tree with only MBP edges is a MST</li>
    </ul>
  </li>
</ol>

<hr />

<p>Proof for claim 1: consider a generic graph $G$ that can have multiple connected components. Then consider adding one edge $(u,v)$:</p>
<ul>
  <li>Type 1: if $u,v$ already in the same CC:
    <ul>
      <li>this <strong>will create a cycle</strong> (because there was already path from $u$ to $v$)</li>
      <li><strong>number of CC remains the same</strong></li>
    </ul>
  </li>
  <li>Type 2: if $u,v$ in different CC:
    <ul>
      <li>this <strong>will not create a cycle</strong></li>
      <li><strong>number of CC decreases by 1</strong></li>
    </ul>
  </li>
</ul>

<p>to visualize this:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231013234626.png" style="zoom:60%;" /></p>

<p>where having the red edge will create a cycle, and the blue will not. Now, notice that in Prim’s algorithm, we will 1) start with $n$ distinct CCs, 2) add $n-1$ edges to the graph, and 3) finish with one CC. Therefore, every edge added must be type 2, and hence the output is a tree (graph with no cycle).</p>

<blockquote>
  <p>Note that the above also proved the statement: <strong>if $T \subseteq E$ has only $n-1$ edges AND the resulting graph is connected, then $T$ must be a tree</strong>.</p>
</blockquote>

<hr />

<p>Proof for claim 2: we need to first define the MBP property, prove that Prim’s algorithm only picks MBP, and finally prove that a tree with only MBP edges is a MST.</p>

<blockquote>
  <p><strong>Minimum Bottleneck Property</strong>: an edge $(u,v) \in E$ with cost $c_{uv}$ satisfies the MBP if and only if there is no $u \overset{p}{\leadsto} v$ path that consists solely of edges with cost less than $c_{uv}$.</p>
  <ul>
    <li>i.e. for any other path you can think of, there is <em>at least one edge</em> that is more expensive than $(u,v)$</li>
  </ul>
</blockquote>

<p>For example, in the following graph, edge $(a,d)$ does not satisfy MBP, but edge $(a,c)$ does:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231013235651.png" style="zoom:80%;" /></p>

<p>Now, we prove that <strong>Prim’s algorithm only picks MBP edges</strong>. The trick is to realize that <strong>any path (see below) $v^{<em>} \leadsto w^{</em>}$ will have at least one edge that crosses the frontier</strong>. Since Prim picks the cheapest such edge, all other path must have at least one edge that is more expensive than the one picked by Prim.</p>

<p>To see this more concretely, consider the same argument as from Dijkstra’s proof. Consider an edge $(v^{<em>}, w^{</em>})$ chosen in an iteration of Prim’s algorithm, with $v^{<em>} \in X$ and $w \notin X$. Now, consider any arbitrary path $v^{</em>} \overset{p}{\leadsto} w^{*}$:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231013235845.png" style="zoom:70%;" /></p>

<p>Note that since $w^{*} \notin X$, at some point the path will go inside the frontier to the outside. Let that happen with edge $(x,y)$ crossing the frontier in that path. However, since Prim guaranteed:</p>

\[c_{v^{*}w^{*}} \le c_{xy}\]

<p>for every edge $(x,y)$ that crosses the frontier. Now, since this means there is at least one edge on any other path that will exceeded $c_{v^{<em>}w^{</em>}}$, we know that $(v^{<em>}, w^{</em>})$ satisfies the MBP.</p>

<p>Finally, we need to show that <strong>a tree with only MBP edges is a MST</strong>. To show this, we consider by contradiction that there is a MST $T^{*}$ that does not have the MBP property all the way but still has the minimum cost.(shown in solid lines):</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231014000728.png" style="zoom:70%;" /></p>

<p>Let Prim’s tree be $T$. Since $T \neq T^{<em>}$, there is at least one MBP edge, e.g. $e_1=(u,v)$, that is not in $T^{</em>}$. Since $T^{<em>}$ is a tree, there exists a path $u \overset{p}{\leadsto} v$. But since $e_1$ is an MBP edge, this means there exists an edge $e_2$ on $u \overset{p}{\leadsto} v$ that has cost *higher</em> than $e_1$. Now, consider an <mark>exchange argument</mark> that:</p>
<ol>
  <li>we add $e_1$ to $T^{*}$. This is a type 1 edge and will create a cycle and does not increase the number of CC (still one)</li>
  <li>Remove $e_2$ from $T^{*}$. Since you are removing an edge from the cycle, this is undoing type 1 edge and also does not increase the number of CC (still one)</li>
</ol>

<p>Now, we obtain $T’$:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231014001152.png" style="zoom:70%;" /></p>

<p>where by the above argument, $T’$ has also just $n-1$ edges and is connected $\implies$ $T’$ is a valid spanning tree. However, since $\mathrm{cost}(e_1) \le  \mathrm{cost}(e_2)$ by MBP, then cost of $T’$ is less than $T^{<em>}$, which is a contradiction. Therefore, every edge in $T^{</em>}$ must satisfy MBP to be MST, and hence Prim’s $T$ is a MST.</p>

<blockquote>
  <p><strong>Note</strong>: from HW 5, you can also show that the converse is true: every edge on a MST must satisfy MBP.</p>
  <ul>
    <li>this does <mark>not imply your MST will include every $(u,v)$ edge that is MBP</mark>, because having $u,v$ being connected in your MST may not even require having a $u\to v$ edge).</li>
  </ul>
</blockquote>

<h3 id="running-time-of-prims-algorithm">Running Time of Prim’s Algorithm</h3>

<p>The obvious runtime we discussed is $O(nm)$, but notice that it was <strong>repeatedly doing extract min</strong>. This hints at using a heap data structure.</p>

<blockquote>
  <p><strong>Recall: (min-)Heap</strong>: a special Tree-based data structure in which the tree is a <strong>complete binary tree</strong>, such that you can <code class="language-plaintext highlighter-rouge">insert</code> a new node with (key, value) pair into the tree, <code class="language-plaintext highlighter-rouge">extract_min</code> to get the node with the smallest key and rebalance the tree, and <code class="language-plaintext highlighter-rouge">delete</code> to remove a node from the tree and rebalance the tree. The tree <code class="language-plaintext highlighter-rouge">orders</code> nodes by the keys, and <strong>all of these operations take $O(\log n)$ time</strong>.</p>
  <ul>
    <li>how? a short peek into the implementation is that you either percolate up or percolate down the tree to rebalance it</li>
    <li>e.g. fo insert, you add the new node at the bottom, and then percolate up (swap with parent if this is smaller until done). Since the height of the tree is $O(\log n)$, this takes $O(\log n)$ time.</li>
  </ul>
</blockquote>

<p>To use <code class="language-plaintext highlighter-rouge">heap</code> for Prim, since we are repeatedly picking the minimum cost edge that <em>crossed the frontier</em>, we want the heap to:</p>
<ul>
  <li>Invariant 1: only store edges that cross the frontier</li>
  <li>Invariant 2: for each $v \notin X$, we will always keep $\mathrm{key}(v)=$ cheapest edge $(u,v)$ that crosses the frontier with $u \in X$. If no such edge exist for a node, store $\infty$.</li>
</ul>

<p>For example, invariant 2 would look like:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231014003326.png" style="zoom:70%;" /></p>

<p><em>If the above two invariant hold</em> for every iteration of our implementation, then it is obvious that taking the minimum from such heap $\implies$ cheapest edge amongst the cheapest for each nod $\notin X$  $\implies$ the cheapest edge that crosses the frontier.</p>

<p>How to we keep the two invariants? Invariant 1 hold easily because after we <code class="language-plaintext highlighter-rouge">extract_min</code> we removed the $(u,v)$ from the heap $\iff$ that $v$ was outside $X$ is now inside the frontier. So it is automatically satisfied. But after <code class="language-plaintext highlighter-rouge">extract_min</code>, e.g. we took vertex $x$ from the above image to $X$, some of the $\mathrm{key}(v)$ might need to be updated (e.g. that of vertex $z$). But note that since <strong>our frontier only changed by that newly added vertex</strong>, we only need to <strong>update keys related to that vertex!</strong> Specifically, we need to:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># w* is just extracted
</span>
<span class="c1"># for every edge from w* that crossed the frontier
</span><span class="k">for</span> <span class="n">every</span> <span class="n">edge</span> <span class="p">(</span><span class="n">w</span><span class="o">*</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="k">with</span> <span class="n">y</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">X</span><span class="p">:</span>
    <span class="c1"># update the new min cost for y = key(y)
</span>    <span class="k">if</span> <span class="n">c_w</span><span class="o">*</span><span class="n">y</span> <span class="o">&lt;</span> <span class="n">key</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
      <span class="n">delete</span> <span class="n">y</span> <span class="k">from</span> <span class="n">heap</span>
      <span class="n">key</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="n">c_w</span><span class="o">*</span><span class="n">y</span>
      <span class="n">best_edge</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="p">(</span><span class="n">w</span><span class="o">*</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
      <span class="n">insert</span> <span class="n">y</span> <span class="n">into</span> <span class="n">heap</span>
</code></pre></div></div>

<p>Now, the full algorithm looks like:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="k">def</span> <span class="nf">prim_w_heap</span><span class="p">(</span><span class="n">G</span><span class="p">):</span>
  <span class="n">X</span> <span class="o">=</span> <span class="p">{</span><span class="n">s</span><span class="p">}</span>  <span class="c1"># s is an arbitrary vertex
</span>  <span class="n">T</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># output and also an INVARIANT: edges that span X
</span>  <span class="n">H</span> <span class="o">=</span> <span class="n">heap</span><span class="p">()</span>  <span class="c1"># heap of edges that cross the frontier
</span>
  <span class="c1"># initialization
</span>  <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">V</span> <span class="ow">and</span> <span class="n">v</span> <span class="o">!=</span> <span class="n">s</span><span class="p">:</span>
    <span class="c1"># for every edge that crosses the frontier s
</span>    <span class="k">if</span> <span class="p">(</span><span class="n">s</span><span class="p">,</span><span class="n">v</span><span class="p">)</span> <span class="ow">in</span> <span class="n">E</span><span class="p">:</span>
      <span class="n">key</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="o">=</span> <span class="n">c_s</span><span class="o">*</span><span class="n">v</span>
      <span class="n">best_edge</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="o">=</span> <span class="p">(</span><span class="n">s</span><span class="p">,</span><span class="n">v</span><span class="p">)</span>
      <span class="n">insert</span> <span class="n">v</span> <span class="n">into</span> <span class="n">H</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">key</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="o">=</span> <span class="n">inf</span>
      <span class="n">best_edge</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="o">=</span> <span class="bp">None</span>
  
  <span class="c1"># main loop
</span>  <span class="c1"># if H is empty, then there is no vertex NOT in X = we are done!
</span>  <span class="k">while</span> <span class="n">H</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">empty</span><span class="p">:</span>
    <span class="c1"># extract the cheapest edge that crosses the frontier
</span>    <span class="n">w</span><span class="o">*</span> <span class="o">=</span> <span class="n">extract_min</span><span class="p">(</span><span class="n">H</span><span class="p">)</span>
    <span class="n">T</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">best_edge</span><span class="p">(</span><span class="n">w</span><span class="o">*</span><span class="p">))</span>  <span class="c1">##### greedy choice
</span>    <span class="n">X</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">w</span><span class="o">*</span><span class="p">)</span>

    <span class="c1"># update the keys for every edge from w* that crossed the frontier
</span>    <span class="k">for</span> <span class="n">every</span> <span class="n">edge</span> <span class="p">(</span><span class="n">w</span><span class="o">*</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="k">with</span> <span class="n">y</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">X</span><span class="p">:</span>
      <span class="c1"># update the new min cost for y = key(y)
</span>      <span class="k">if</span> <span class="n">c_w</span><span class="o">*</span><span class="n">y</span> <span class="o">&lt;</span> <span class="n">key</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
        <span class="n">delete</span> <span class="n">y</span> <span class="k">from</span> <span class="n">heap</span>
        <span class="n">key</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="n">c_w</span><span class="o">*</span><span class="n">y</span>
        <span class="n">best_edge</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="p">(</span><span class="n">w</span><span class="o">*</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">insert</span> <span class="n">y</span> <span class="n">into</span> <span class="n">heap</span>
  <span class="k">return</span> <span class="n">T</span>
</code></pre></div></div>

<p>So what is the runtime of this?</p>

<ul>
  <li>initialization phase performs does $n-1$ heap insert (i.e. once for every vertex not $s$), and $O(m)$ additional work as it checks the edges. So this takes $O(n \log n + m)$ time.</li>
  <li>the main while loop goes for $n-1$ iterations, and inside it at least does extract mins. This is already $O(n \log n)$. But additionally, notice there is also a for loop. However, realize that each edge of $G$ will enter this for loop exactly once, at the time when first of its endpoints get sucked into $X$. Therefore, since there are $m$ edges, this will give in total for the entire algrithm $O(m \log n)$.</li>
</ul>

<p>Hence adding up we get:</p>

\[O((n+m) \log n) = O(m \log n)\]

<p>since for a connected graph $G$, the least number of edges is $m \ge n-1$. Therefore, you can simplify the above to $O(m \log n)$.</p>

<h2 id="kruskals-algorithm">Kruskal’s Algorithm</h2>

<p>Why this in addition to Prim?</p>
<ul>
  <li>provides an opportunity to study a new and useful data structure, the disjoint-set or <strong>union-find</strong> data structure.</li>
  <li>there are some very cool connections between Kruskal’s algorithm and widely-used <strong>clustering</strong> algorithms</li>
</ul>

<p>Similar to Prim, this algorithm is greedy. Different from Prim’s algorithm which grows a single tree from a starting vertex, <strong>Kruskal can grow multiple trees in parallel</strong>, and coalesce into a single tree only at the end of the algorithm.</p>

<blockquote>
  <p><strong>Idea</strong>: repeatedly (greedily) pick the cheapest edge that does not create a cycle, until done.</p>
</blockquote>

<p>For example:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">iteration 1</th>
      <th style="text-align: center">iteration 2</th>
      <th style="text-align: center">iteration 3</th>
      <th style="text-align: center">iteration 4</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231018005153.png" style="zoom:100%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231018005200.png" style="zoom:100%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231018005216.png" style="zoom:100%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231018005224.png" style="zoom:100%;" /></td>
    </tr>
  </tbody>
</table>

<p>where we started with $T$ being empty, and at each iteration we picked the cheapest edge that does not create a cycle. The pseudo code is:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">kruskal</span><span class="p">(</span><span class="n">G</span><span class="p">):</span>
  <span class="c1"># G=(V,E) with costs c_e for each e in E
</span>  <span class="n">T</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># output
</span>  <span class="n">sorted_edges</span> <span class="o">=</span> <span class="n">sort</span><span class="p">(</span><span class="n">E</span><span class="p">)</span>  <span class="c1"># sort edges by increasing cost
</span>  <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">sorted_edges</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">adding</span> <span class="n">e</span> <span class="n">to</span> <span class="n">T</span> <span class="n">does</span> <span class="ow">not</span> <span class="n">create</span> <span class="n">a</span> <span class="n">cycle</span><span class="p">:</span>
      <span class="n">T</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">T</span>
</code></pre></div></div>

<p>note that similar to Prim, it requires a connected undirected graph $G=(V,E)$ with edge weights $c_e$ for each $e \in E$.</p>

<p>A straight-forward runtime for this algorithm is:</p>

\[O(m \log m) + O(m n) = \log(m \log n) + O(mn) = O(mn)\]

<p>where:</p>
<ul>
  <li>$O(m \log m) = O(m \log n)$ because we know $m \le n^{2}$, hence $O(\log m) = O(2 \log n)$. This equality will be used later as well</li>
  <li>$O(mn)$ because you can search for cycles in $O(m)$ time using DFS/BFS (this is equivalent to <mark>checking if the new edge $e=(u,v)$ are already reachable</mark>).</li>
</ul>

<p>Before we discuss how to make this faster using union-find, we need to first prove that this algorithm is correct. Without prior context, it is hard to see why this produces a tree that <em>spans all vertices</em>.</p>

<h3 id="correctness-of-kruskals-algorithm">Correctness of Kruskal’s Algorithm</h3>

<p>This section proves Kruskal’s algorithm is correct, under the simlar assumption that all edge costs are distinct (this is to just make the proof easier, and does not affect the algorithm’s correctness).</p>

<p>It is obvious that Kruskal produces <em>no cycles</em>, but we need to show that:</p>
<ol>
  <li>the output is <em>connected</em></li>
  <li>the output is a <em>spanning tree</em></li>
  <li>the output is <em>minimal</em> (by achieving MBP)</li>
</ol>

<hr />

<p><em>Proof for Claim 1</em>: Consider $T$ be the set of edges chosen by Kruskal so far, and that in this iteration Kruskal just finished examining an edge $e = (v,w)$. Then in the algorithm:</p>

<ul>
  <li>if $v,w$ are already in the same CC, then adding $e$ will create a cycle, so this is skipped</li>
  <li>otherwise, $(v,w)$ is added to $T$, fusing their CCs into one</li>
</ul>

<p>Therefore, just after this $(v,w)$ will be <strong>in the same CC</strong>. Since this is true for every iteration, we know that at the end of the algorithm, all vertices (since it will check all edges and the input graph is connected) will be in the same CC, and hence the output is connected.</p>

<hr />

<p><em>Proof for Claim 2</em>: since the algorithm explicitly ensures that the output is acyclic, and we just showed that all its vertices belong to the same CC, then it is a tree.</p>

<hr />

<p><em>Proof for Claim 3</em>: We prove by contrapositive, that Kruskal never includes an edge that is NOT MBP. To show this, consier an edge not being a MBP, and we want to show that Kruskal’s algorithm will never include it.</p>

<p>Let $e=(v,w)$ be not a MBP. Then there exists a path $v \overset{p}{\leadsto} w$ that consists <strong>solely of edges with cost less than $c_{vw}$</strong>. Because Kruskal scans through (greedily) the edges in non-decreasing cost, all edge of $P$ will be checked before $e$. From claim 1, we know that once an edge $e’=(x,y)$ is checked, both $x,y$ are in the same CC. Therefore, when we reached $e=(v,w)$, we know that $v,w$ are already in the same CC, and hence adding $e$ will create a cycle. Therefore, Kruskal will never include $e$.</p>

<p>Visually, by the time we are checking the black $e$ edge, we would have checked all the blue edges:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231018012523.png" style="zoom:50%;" /></p>

<hr />

<h3 id="speeding-up-kruskal-with-union-find">Speeding up Kruskal with Union-Find</h3>

<p>Prim’s algorithm is sped up using a genric data structure called heap, and Kruskal can also be sped up using a data structure called <strong>union-find</strong>.</p>

<blockquote>
  <p><strong>Union-Find Data Structure</strong>: the goal is to maintain a partition of a static set of objects. This is often used to efficiently track and manipulate connected components or disjoint sets. It supports the following operations:</p>
  <ul>
    <li><code class="language-plaintext highlighter-rouge">Initialization</code>: create a new union-find data structure with $n$ objects ($O(n)$)</li>
    <li><code class="language-plaintext highlighter-rouge">Union</code>: given two objects form a (different) union, merge the two sets into a single set</li>
    <li><code class="language-plaintext highlighter-rouge">Find</code>: determine which set a given object belongs to</li>
  </ul>
</blockquote>

<p>note that (though not used by Kruskal), with a good implementation the <code class="language-plaintext highlighter-rouge">Union</code> and <code class="language-plaintext highlighter-rouge">Find</code> operations both take time logarithmic in the number of objects. Since Kruskal itreatively <strong>checks connected components (if there is a cycle) and grow them</strong>, we can visualize the process as:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231018013613.png" style="zoom:100%;" /></p>

<p>such that finding if two vertices are in the same CC is just checking if they have the same root in a <code class="language-plaintext highlighter-rouge">union</code>. So instead of a DFS/BFS, we could just have done it in $O(1)$ by comparing if the two vertices have the same root! But how does union-find work?</p>

<hr />

<p><em>Quick-and-Dirty Implementation of Union-Find</em>.</p>

<p>The datastructure can be implemented by an array, where each index position represent a vertex $v \in V$, and stores the <strong>parent</strong> vertex (e.g., a root vertex representing the CC).</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Implementation</th>
      <th style="text-align: center">Visualization</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231018105402.png" style="zoom:100%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231018105314.png" style="zoom:15%;" /></td>
    </tr>
  </tbody>
</table>

<p>where in the drawing, the green vertices and edges are the original graph. The black circle highlights the ‘‘leader’’ representing this CC, and the red edges represent which vertex is the parent of which. This red graph is sometimes also called <mark>the parent graph</mark>.</p>

<p>With the notion that it stores the parent graph, the rest is easy:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">initialize</code>: for each $i=1,2,3, … , n$, initialize $parent[i] = i$ (i.e. each vertex is its own parent)
    <ul>
      <li>therefore, this takes $O(n)$ cost</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">find</code>: given a vertex $v$, repeatedly check $parent[v]$, until $parent[v] = v$ (i.e. $v$ is its own parent).
    <ul>
      <li>therefore, this takes $O(\mathrm{depth})$ of the parent tree</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">union</code> pick the union $x$ that has a larger size (with the parent keep a field <code class="language-plaintext highlighter-rouge">size</code>), and let the other union be $y$. Find the root of both unions, let them be $i,j$. Then set $parent[j] = i$ and update the <code class="language-plaintext highlighter-rouge">size</code>.
    <ul>
      <li>if we don’t merge the smaller one with the larger one so that our size <em>at least doubles</em>, we cannot get the logarithmic runtime</li>
      <li>if we don’t merge with the root node, then the depth of vertices in $y$ will increase by <em>more than one</em>, impacting runtime. Visually for <code class="language-plaintext highlighter-rouge">union</code> if done o non-root node:
<img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231018110926.png" style="zoom:80%;" /></li>
    </ul>
  </li>
</ul>

<hr />

<p>Now, we can implement Kruskal’s algorithm in $O((m+n) \log n)$ time. The idea is to:</p>

<ul>
  <li><strong>the parent pointer <em>all</em> point to the root of a CC</strong>, so that finding the root is $O(1)$. This means checking if two vertices are in the same CC is $O(1)$.</li>
  <li>to maintain the above invariant, when an edge $e=(u,v)$ is picked, <strong>merge all members of the smaller union into the larger union</strong>. Note that this is <em>not $O(n)$</em> for each merge:
    <ul>
      <li>each vertex can only be called to be merged/updated $\log_{2}$ times since each merge at least double the size.</li>
      <li>since there are in total $n$ vertices, the total cost in the entire algorithm is $n \log n$.</li>
    </ul>
  </li>
</ul>

<p>So finally we get preprocessing $O(m \log n)$, cycle check $O(m)$, and union update $O(n \log n)$, which gives $O((m+n) \log n)$.</p>

<h2 id="clustering">Clustering</h2>

<p>We will show that one <strong>application</strong> of Kruskal’s algorithm is to solve a problem called <strong>clustering</strong>. The goal is to partition a set of objects into a collection of clusters, such that given $n$ data points, they are classified into a coherent group:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231018111845.png" style="zoom:100%;" /></p>

<p>to do this, we assume that we are given:</p>

<ol>
  <li>a distance measure $d(p,q)$ between each pair of data points</li>
  <li>a distance measure being symmetric</li>
  <li>we’ve decided to get to $k$ clusters</li>
</ol>

<p>There are many ways to do this (e.g. bottom-up, top-down, k-means). Here we discuss <strong>bottom-up</strong> or <strong>agglomerative</strong> clustering is to begin with every data point in its own cluster, and then successively merge pairs of clusters until exactly $k$ remain.</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231018112326.png" style="zoom:100%;" /></p>

<blockquote>
  <p><strong>so the key part</strong> is how to decide which two clusters to merge at each step.</p>
</blockquote>

<p>Here we discuss one way to do it: <strong>single-link clusering</strong>, where we are optimistic such that we consider two clusters to be similar if their <strong>closest points are close</strong>. Formally, let the similarity measure between <em>two clusters</em> being $F$, then:</p>

\[F(S_1, S_2) = \min_{p \in S_1, q \in S_2} d(p,q)\]

<p>Therefore our single-link bottom up clustering algorithm is:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">bottom_up</span><span class="p">():</span>
  <span class="k">while</span> <span class="n">C</span> <span class="n">contains</span> <span class="n">more</span> <span class="n">than</span> <span class="n">k</span> <span class="n">clusters</span><span class="p">:</span>
    <span class="n">C1</span><span class="p">,</span> <span class="n">C2</span> <span class="o">=</span> <span class="n">closest</span> <span class="n">pair</span> <span class="n">of</span> <span class="n">clusters</span> <span class="ow">in</span> <span class="n">C</span>
    <span class="n">remove</span> <span class="n">C1</span> <span class="ow">and</span> <span class="n">C2</span> <span class="k">from</span> <span class="n">C</span>
    <span class="n">add</span> <span class="n">C1</span> <span class="n">union</span> <span class="n">C2</span> <span class="n">to</span> <span class="n">C</span>
  <span class="k">return</span> <span class="n">C</span>
</code></pre></div></div>

<p>note that one advantage of bottom-up algorithm is that during the process of running this, you <mark>also get the result for all $k' &lt; k$</mark>!</p>

<blockquote>
  <p><strong>Connection to Kruskal’s Algorithm</strong>: recall that in kruskal we “merge” two vertices if they are the <em>smallest edge</em> and <em>are in different CC</em>. This has great similarilty to merging two clusters if the simialrlity function checks the best pair of points from each cluster. In fact, the two are exactly the same except that in Kruskal does not stop at $k$</p>
  <ul>
    <li>define a complete undirected graph $G=(X,E)$ from the dataset $X$, such that $E$ represent every pair of points in $X$, and the edge costs are $d(p,q)$</li>
    <li>run kruskal on $G$ until $k$ connected components, return the tree $(X,T)$</li>
    <li>compute the connected components of $(X,T)$, which is the clustering result</li>
  </ul>
</blockquote>

<h1 id="introduction-to-dynamic-programming">Introduction to Dynamic Programming</h1>

<p>Most people initially find dynamic programming difficult and counterintuitive. However, this is relatively formulaic hence can be learned with practice. In this section, we are getting warmed up with some simple examples.</p>

<h2 id="weighted-independent-set">Weighted Independent Set</h2>

<p>First, some terminologies</p>

<blockquote>
  <p><strong>Independent Set</strong>: a subset of vertices $S \subseteq V$ such that no two vertices in $S$ are adjacent. More formally, every $v,w \in S$ has $(v,w)\notin E$.</p>
</blockquote>

<p>For example, in the two graphs below</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Graph 1</th>
      <th style="text-align: center">Graph 2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231019225023.png" style="zoom:80%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231019225032.png" style="zoom:80%;" /></td>
    </tr>
  </tbody>
</table>

<ul>
  <li>the first graph has six independent sets: $\emptyset$ and five singletons</li>
  <li>the second has the same six independent sets that the complete graph does, plus some (five) independent sets of size two. In total eleven.</li>
</ul>

<blockquote>
  <p><strong>Weighted Independent Set Problem</strong>: given an undirected grpah $G=(V,E)$ and a non-negative weight $w_v$ for each <em>vertex</em> $v \in V$, find an independent set $S \subseteq V$ of maximum total weight (of the vertices).</p>
  <ul>
    <li>the solution is also called a <strong>maximum-weight independent set (MWIS)</strong></li>
    <li>e.g., if vertices represent courses, vertex weights represent units, and edges represent conflicts between courses, the MWIS corresponds to the feasible course schedule with the heaviest load (in units)</li>
  </ul>
</blockquote>

<p>This is quite a difficult problem <mark>even if we just consider path graphs to be $G$</mark></p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231019225607.png" style="zoom:100%;" /></p>

<p>where by looking at it we can see the solution is $8$.</p>
<ul>
  <li>if we do <strong>exhaustive</strong> search, notice that there are <strong>8 independent sets</strong>. This will grow exponentially (consider adding one more vertex to the path graph, and think about how many more independent sets you will have).</li>
  <li>if we do <strong>greedy</strong>, maybe consider simply start picking from the largest vertex (i.e., with weight 5). Immediately you got the wrong answer.</li>
  <li>if we do <strong>divide-and-conquer</strong> is natural if we can break this into smaller subproblems. So we can consider maybe recursively computing MIS of the left half, the right half, and merge? But the problem is how do we merge to keep the independence?</li>
</ul>

<h2 id="linear-time-algorithm-for-wis-in-path-graph">Linear-Time Algorithm for WIS in Path Graph</h2>

<blockquote>
  <p>Insight: the trick for DP is to consider how an optimal solution must be <strong>constructed in a prescribed way from optimal solutions to smaller subproblems</strong>, and vice versa</p>
</blockquote>

<p>This feels very similar to divide-and-conquer, so here I hightlight the difference (from stackoverflow):</p>
<ul>
  <li>DnC:
    <ul>
      <li>dividing the problem into sub-problems, <strong>conquer each sub-problem independently</strong> and combine these solutions.</li>
      <li>Most of the canonical applications of the divide-and-conquer paradigm replace a straightforward polynomial-time algorithm</li>
    </ul>
  </li>
  <li>DP:
    <ul>
      <li>solving problems with <strong><mark>overlapping</mark> subproblems</strong>. Each sub-problem is solved only once and the result of each sub-problem is usually stored in a table (generally implemented as an array or a hash table) for future references.</li>
      <li>The killer applications of dynamic programming are polynomial-time algorithms for optimization problems for which straightforward solutions (like exhaustive search) require an exponential amount of time.</li>
    </ul>
  </li>
</ul>

<blockquote>
  <p><strong>WIS in Path Graph Problem</strong>. Consider $G=(V,E)$ being a $n$-vertex path graph with edges $(v_1, v_2), (v_2, v_3), …, (v_{n-1}, v_n)$ and a non-negative weight $w_i$ for each vertex $v_{i} \in V$.  Find an independent set $S \subseteq V$ of maximum total weight (of the vertices).</p>
</blockquote>

<p>Suppose we are given an optimal solution MWIS $S \subseteq V$ with total weight $W$. <mark>What can we say about $S$? What can we say about the solution to a smaller subproblem given $S$?</mark></p>

<p>The trick to this problem is that $S$ either contains the last vertex $v_n$ or doesn’t. We have two cases:</p>

<ol>
  <li>$v_n \notin S$. Then let $G’ = G$ without $v_n$. This would mean that:
    <ul>
      <li>the set $S$ is also an independent set in $G’$, and since $S$ is the MWIS in $G$, then <em>$S$ is also the MWIS in $G’$</em>.</li>
      <li>we can show the above (MWIS for $G’$) by contradiction: if there is $S^{<em>}$ that is MWIS for $G’$ with weight larger than $S$, then this means $S^{</em>}$ would also be an independent set with larger weight than $S$ in $G$, which is a contradiction.</li>
    </ul>

    <p>in other words, <em>if you know MWIS for $G’$</em> and <em>you know $v_n \notin S$</em>, then you can just use the MWIS for $G’$ as the MWIS for $G$.</p>
  </li>
  <li>$v_{n} \in S$. Then since $S$ is an indepednt set, we know that the penultimate vertex is not there.
<img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231019232103.png" style="zoom:70%;" />
Therefore, we can consider $G’’$ to be $G$ without $v_n$ and $v_{n-1}$. Then we can show that:
    <ul>
      <li>$S - {v_n}$ is an independent set for $G’’$, and since $S$ is the MWIS in $G$, then <em>$S - {v_n}$ is also the MWIS in $G’’$</em>.</li>
      <li>again can be proven by contradiction using a simlar logic as above.</li>
    </ul>
  </li>
</ol>

<p>in other words, <em>if you know MWIS for $G’’$</em> and <em>you know $v_n \in S$</em>, then you can just use the MWIS for $G’’$ as the MWIS for $G$.</p>

<blockquote>
  <p>The upshot of the above analysis is that <mark>now you have a recipe for building UP a solution</mark> from subproblems:
Let $S$ be an MWIS for $G$ with at least two vertices, and the nwe can find $S$ must be either</p>
  <ol>
    <li>an MWIS for $G’=G_{n-1}$ (i.e. without $v_n$)</li>
    <li>an MWIS for $G’‘=G_{n-2}$ plus $v_n$</li>
  </ol>

  <p>where $G_i$ denote the subgraph comprising its first $i$ vertices.</p>
</blockquote>

<p>So all we need to do is to solve small problem, and then build up. Now how do we implement this?</p>

<hr />

<p><em>Naive Recursive Approach</em> from divide-and-conquer. Since the best solution is either of the two, we can just try both and return the max!</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">recursive_mwis</span><span class="p">(</span><span class="n">G</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">G</span> <span class="n">has</span> <span class="n">no</span> <span class="n">vertices</span><span class="p">:</span>
    <span class="k">return</span> <span class="mi">0</span>
  <span class="k">elif</span> <span class="n">G</span> <span class="n">has</span> <span class="n">one</span> <span class="n">vertex</span><span class="p">:</span>
    <span class="k">return</span> <span class="p">{</span><span class="n">v1</span><span class="p">}</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="c1"># case 1: MWIS for G' without v_n
</span>    <span class="n">mwis1</span> <span class="o">=</span> <span class="n">recursive_mwis</span><span class="p">(</span><span class="n">G</span> <span class="n">without</span> <span class="n">v_n</span><span class="p">)</span>
    <span class="c1"># case 2: MWIS for G'' without v_n and v_{n-1}
</span>    <span class="n">mwis2</span> <span class="o">=</span> <span class="n">recursive_mwis</span><span class="p">(</span><span class="n">G</span> <span class="n">without</span> <span class="n">v_n</span> <span class="ow">and</span> <span class="n">v_</span><span class="p">{</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">})</span> <span class="o">+</span> <span class="n">v_n</span>
    <span class="k">return</span> <span class="n">max_weight</span><span class="p">(</span><span class="n">mwis1</span><span class="p">,</span> <span class="n">mwis2</span><span class="p">)</span>
</code></pre></div></div>

<p>This is guaranteed to be correct using proof by induction and the property of $S$ we just proved. But what is the runtime? <strong>Exponential!</strong></p>

<ul>
  <li>each recursive call only throws away one or two vertices, so there are $O(n)$ height in the recursion tree (compared to the ‘correct’ DnC ones, there were only logarithmic height)</li>
  <li>since the branching factor is 2, this gives $O(2^{n})$ number of leaves!</li>
</ul>

<p>The key difference now, between DP and DnC is that DP could <em>avoid a lot of computation</em> by <strong>memoizing</strong> the results of subproblems. Why is this related in this context? Consider <mark>how many distinct subproblem did the recursive algorithm solve</mark>?</p>
<ul>
  <li>since each subproblem is defined by the input graph, this is equivalent to how many distinct graphs we are solving</li>
  <li>the answer is $n+1$ since each time we are removing graphs from the tail! (empty graph, $G_1$, …, $G_n$).</li>
</ul>

<p>Therefore, we could cache the results of each subproblem, and then we can just look it up when we need it. This is called <strong>memoization</strong>. Implementation-wise, we can just use an array, where $A[i]$ represent the MWIS of $G_i$. However to <em>really see the runtime speed up</em>, the more direct way is to <mark>build from bottom up</mark>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">wis</span><span class="p">(</span><span class="n">G</span><span class="p">):</span>
  <span class="n">A</span> <span class="o">=</span> <span class="p">[]</span> <span class="o">*</span> <span class="p">(</span><span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># solutions for n+1 subproblems
</span>  <span class="n">A</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">A</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">w1</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="n">wi</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">A</span><span class="p">[</span><span class="n">n</span><span class="p">]</span>
</code></pre></div></div>

<p>note that now:</p>
<ul>
  <li>this is DP</li>
  <li>this is clearly linear time</li>
  <li>but it only returns the maximum weight, not the vertices themselves. Therefore a <mark>common step after DP is a postprocessing *reconstruction algorithm*</mark>
    <ul>
      <li>though you can hack this <code class="language-plaintext highlighter-rouge">wis</code> to also let $A$ store the vertices of an MWIS of $G_i$, the reconstruction algorithm is more genreally memory and time efficient</li>
    </ul>
  </li>
</ul>

<h2 id="reconstruction-algorithm-mis">Reconstruction Algorithm (MIS)</h2>

<p>Typically when you have a DP, you would have a reconstruction algorithm easily defined based on the same principle as the algorithm you came up with.</p>

<p>Consider back to the question: is $v_{n}$ included in the solution? Since we know $A$, we can actually answer this question immediately by looking at $A[n-1]$ and $A[n-2]$:</p>

<ul>
  <li>if $A[n-1] \ge A[n-2] + w_n$, then $v_n$ is not in the solution. Continue the process with thinking about $v_{n-1}$</li>
  <li>otherwise, $v_n$ is in the solution. Continue the process with thinking about $v_{n-2}$</li>
</ul>

<p>therefore the reconstruction algorithm is:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">wis_reconstruction</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">A</span><span class="p">):</span>
  <span class="c1"># A is the array we computed from `wis`
</span>  <span class="n">S</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># the solution
</span>  <span class="n">i</span> <span class="o">=</span> <span class="n">n</span>
  <span class="k">while</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="mi">2</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="n">wi</span><span class="p">:</span>
      <span class="n">i</span> <span class="o">-=</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">S</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">v_i</span><span class="p">)</span>
      <span class="n">i</span> <span class="o">-=</span> <span class="mi">2</span>
  <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">S</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">v_1</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">S</span>
</code></pre></div></div>

<p>wich is like doing a <mark>single backward pass</mark>, which runs in $O(n)$ to get us the real solution.</p>

<blockquote>
  <p>Note: <strong>the full MWIS problem on arbitrary graph is NP-complete</strong>. Even though we know that from HW 6, the following relation hold for arbirary graph:</p>

\[W_{G} = \max\{W_H, W_K + w_v\}\]

  <p>where $G$ is the <code class="language-plaintext highlighter-rouge">'original</code> graph, $H$ is the graph without $v$, $K$ is the graph without $v$ and $v$’s neighbor, and $w_v$ is the weight of $v$. So why does not NOT lead to linear time algorithm? The number of times you will need to lookup a subproblem’s solution is NOT constant!</p>
</blockquote>

<h2 id="principles-of-dynamic-programming">Principles of Dynamic Programming</h2>

<p>The above example showcase a paradigm in DP:</p>

<blockquote>
  <p><strong>DP Paradigm</strong>: we begin by thinking about the <em>optimal solution if we are given the optimal solution of smaller problems (and vice versa)</em>. Then:</p>
  <ol>
    <li>identify a relatively small number of subproblems (otherwise the runtime will be exponential)</li>
    <li>show how to quickly and correctly solve a larger problem using the solutions to a small number of subproblems</li>
    <li>quickly and correctly infer the final solution from the computed subproblem solutions (e.g. reconstruction algorithm)</li>
  </ol>
</blockquote>

<p>More specifcally, DP under this paradigm would be <em>fast</em> if we consider the runtimes:</p>

\[\underbrace{f(n)}_{\text{\# subproblems}} \times \underbrace{g(n)}_{\text{time/subproblem}} + \underbrace{h(n)}_{\text{postprocessing}}\]

<p>where $f(n),g(n), h(n)$ would come from point 1,2,3 mentioned above, respectively. In the case of WIS, we have:</p>
<ul>
  <li>$f(n) = n$ since there are $n+1$ subproblems</li>
  <li>$g(n) = O(1)$ since each subproblem is just a constant time comparison</li>
  <li>$h(n)=O(n)$ is the backward reconstruction cost</li>
</ul>

<p>so the total runtime is $O(n)$ for our WIS example.</p>

<h2 id="the-knapsack-problem">The Knapsack Problem</h2>

<p>The next example is the Knapsack problem, which follows closely to the paradigm we just discussed.</p>

<blockquote>
  <p><strong>Knapsack Problem</strong>: consider $n$ items with value $v_1, …, v_n$ and sizes $s_1, …, s_n$, all being positive integers. Consider you have a knapsack with capacity $C$, and you want to maximize the total value of items you can put in the knapsack.</p>
</blockquote>

<p>For example, given the following configuration, the maximum value you can stuff in is 8 for a capacity of 6:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231020004340.png" style="zoom:80%;" /></p>

<p>Now we can kind of just copy over the idea for WIS we had. Again, suppose someone gave you the optimal solution $S \subset {1,2,3 ,…,n }$ telling you the best items to put in the knapsack. <strong>We can we say about $S$ and problems of smaller size?</strong> Either $S$ includes the last item $n$ or it doesn’t.</p>

<ol>
  <li>$n \notin S$. Since the the optimal solution $S$ excluded it, the solution $S$ must also be feasible and optimal for the knapsack of size $C$ and items $1,2,3,…,n-1$.</li>
  <li>$n \in S$. First of all, this only happens if $s_{n} \le C$. Then what happens if we remove $n$? The solution $S - { n}$ is an optimal solution for the knapsack of size $C - s_n$ and items $1,2,3,…,n-1$. Notice the difference with <code class="language-plaintext highlighter-rouge">wis</code>:
    <ul>
      <li>both case in <code class="language-plaintext highlighter-rouge">wis</code> consider both subproblems by knocking out vertices.</li>
      <li>here, we need to change <em>both size and items</em></li>
    </ul>
  </li>
</ol>

<p>But regardless, this gives us a recipe of how to build up a solution from subproblems. Again writing down the recurrence: let $V_{i,x}$ denote the maximum total value for a subset of the first $i$ items with total size at most $c$.  Then:</p>

\[V_{i,c} = \max \begin{cases}
  V_{i-1, c} \\
  V_{i-1, c-s_i} + v_i, &amp; \text{only if } c \ge s_i. \text{ otherwise it will be $V_{i-1, c}$}
\end{cases}\]

<p>So what are the subproblems we need to solve in this case? $V_{i,c}$ for all $i \in {0,1,2, …, n}$ and $c \in { 0,1,2, …, C }$. Another way to see this is that now we have <strong>two parameters to specify input for each subproblem</strong>. Therefore it is natural that now we are filling up a 2D array</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">knapsack</span><span class="p">(</span><span class="n">V</span><span class="p">,</span><span class="n">S</span><span class="p">,</span><span class="n">C</span><span class="p">):</span>
  <span class="n">A</span> <span class="o">=</span> <span class="p">(</span><span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">C</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="n">array</span>  <span class="c1"># 2D array for solutions to subproblems
</span>  <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">C</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">A</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># base case
</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">C</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
      <span class="k">if</span> <span class="n">c</span> <span class="o">&gt;=</span> <span class="n">s_i</span><span class="p">:</span>
        <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">c</span><span class="p">],</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">c</span><span class="o">-</span><span class="n">s_i</span><span class="p">]</span> <span class="o">+</span> <span class="n">v_i</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">c</span><span class="p">]</span>

  <span class="k">return</span> <span class="n">A</span><span class="p">[</span><span class="n">n</span><span class="p">,</span><span class="n">C</span><span class="p">]</span>
</code></pre></div></div>

<p>Runtime? Obviously $O(nC)$ since we are filling up a 2D array.</p>

<p>Reconstruction? Again, a backward pass to figure out from $A[n][C]$ which case (whether $n$-th item is included) it is:</p>
<ul>
  <li>if $A[n-1][C] = A[n][C]$, then obviously $n$ is not included and we continue to $A[n-1][C]$</li>
  <li>otherwise, then $n$ is included and we continue to $A[n-1][C-s_n]$</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">knapsack_reconstruct</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">C</span><span class="p">):</span>
  <span class="n">S</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># the solution
</span>  <span class="n">c</span> <span class="o">=</span> <span class="n">C</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="n">c</span><span class="p">]</span> <span class="o">!=</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">c</span><span class="p">]:</span>
      <span class="n">S</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
      <span class="n">c</span> <span class="o">-=</span> <span class="n">s_i</span>
    <span class="c1"># else we are skipping i, capactiy is the same
</span>  <span class="k">return</span> <span class="n">S</span>
</code></pre></div></div>

<p>which runs in $O(n)$. Visually it is doing this:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231020011132.png" style="zoom:100%;" /></p>

<p>Finally, correctness. In general this will be proven by <strong>induction + the property we used to come up with the DP algorithm/recurrence itself</strong>. Hence, we omit the proof here.</p>

<h1 id="advanced-dynamic-programming">Advanced Dynamic Programming</h1>

<p>In this section we will discuss some more advanced DP problems, where the structure of optimal solution is more complex than that of the last section.</p>

<h2 id="sequence-alignment">Sequence Alignment</h2>

<p>This problem is both used in computational genomics and in NLP (e.g. to compute the edit distance). Consider the input consist of strings (e.g. representing portions of genomes) over some alphabet:</p>

\[\text{Input: AGGGCT},\qquad \text{Output: AGGCA}\]

<p>and the goal is to say “how similar the two strings are”. How do we measure similarity?</p>

<blockquote>
  <p><strong>Alignment</strong>: a way of inserting gaps such that the two strings have the same length. For example:
<img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231025012521.png" style="zoom:80%;" /></p>
</blockquote>

<p>so that then we can define the similarity of the two strings as the quality of the best alignment, for example</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231025012620.png" style="zoom:80%;" /></p>

<blockquote>
  <p><strong>Finding Optimal Sequence Alignment</strong> then is used to answer the question “how similar the two strings are”. Formally, consider two strings $X,Y$ over the alphabet $\Sigma$. And let there be a penalty $\alpha_{xy}$ for swapping $x$ with $y$, and $\alpha_{\mathrm{gap}}$ be the cost of inserting a gap. The goal is to find an optimal alignment of $X,Y$ that <strong>minimizes the total penalty</strong>.</p>
  <ul>
    <li>intuitively, is saying “how similar are the two strings” = “most plausible explanation” of how one of the strings might have evolved into the other.</li>
    <li>the minimum penalty of an aligmment is famous enough as a concept that it has a name: <strong>Needleman-Wunsch or NW score</strong>.</li>
  </ul>
</blockquote>

<p>So how do we solve it? Consider some alternative, e.g. greedy algorithm. If you give enough thought, you will realize that it is impossible because you <em>really need to think ahead to avoid bad choices</em> early on, which is the opposite of greedy.</p>

<p>The savior is again dynamic programming. Similar to prior approaches, we begin by reasoning about how <strong>optimal solution relates to optimal solutions of subproblems, and vice versa</strong>. Consider we are already given the optimal solution, and similar to previous problems, consider the <mark>subproblem is having one less character to align</mark>:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231025013516.png" style="zoom:90%;" /></p>

<p>This naturally becomes similar to WIS and Knapsack, but here we could have more cases. Let the optimal alignment for $X= x_1, x_2, …, x_m$ and $Y= y_1, y_2, …, y_n$ be given above. Denote $X’ = x_1, x_2, …, x_{m-1}$ and $Y’ = y_1, y_2, …, y_{n-1}$ both with last one removed:</p>

<ol>
  <li>
    <p>Case 1: $x_m$ is aligned with $y_n$, two actual characters (may or may not be the same). Then you can peel them off and the rest of the alignment should also be optimal:
<img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231025103754.png" style="zoom:80%;" />
note that this alignment between $X’$ and $Y’$ will also be the <em>optimal aligmnent</em>. (Proof by contradiction: suppose that the penalty for this induced alignment of $X’, Y’$ is $P$, but there is another better competitor $P’ &lt; P$. Then appending $x_m, y_n$ to the competitor alignment gives back $X,Y$, with new cost:</p>

\[P' + \alpha_{x_m y_n} &lt; P + \alpha_{x_m y_n}\]

    <p>which is a contradiction that $P + \alpha_{x_m y_n}$ was the optimal alignment.) Note that $\alpha_{x_m y_n}$ could be zero.</p>
  </li>
  <li>Case 2: $x_m$ is aligned with a gap. Then the induced alignment of $X’,Y$ is optimal.
<img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231025104438.png" style="zoom:80%;" /></li>
  <li>Case 3: $y_n$ is aligned with a gap. Then the induced alignment of $X,Y’$ is optimal.</li>
  <li>Case 4: a gap with a gap. Note that this is <strong>not a scenario</strong>, as we could have removed both gaps. Therefore, in general, <em>any column/pairing in an alignment will be either of the three cases above</em>.</li>
</ol>

<p>Now we can build a recurrence relation: since the optimal solution must be either one of the three cases, and each case either removes a character from $X$ or $Y$, we can write the recurrence as:</p>

\[P_{m,n} = \min \begin{cases}
  P_{m-1, n-1} + \alpha_{x_m y_n} \\
  P_{m-1, n} + \alpha_{\mathrm{gap}} \\
  P_{m, n-1} + \alpha_{\mathrm{gap}}
\end{cases}\]

<p>since this must be true for every $n=1,2, …$ and $m=1,2, …$  we get more generally from bottom-up:</p>

\[P_{i,j} = \min \begin{cases}
  P_{i-1, j-1} + \alpha_{x_i y_j} \\
  P_{i-1, j} + \alpha_{\mathrm{gap}} \\
  P_{i, j-1} + \alpha_{\mathrm{gap}}
\end{cases}\]

<p>for every $i=1,2, …$ and $j=1,2, …$ representing the <strong>subproblem of aligning first $i$ symbols in $X$ with first $i$ symbols in $Y$</strong>. Finally, what if one of $i,j$ is zero? This is the <strong>base case</strong>: imagine $X$ of the $X,Y$ is empty, then the alignment cost will be $\alpha_{\mathrm{gap}} \vert  X \vert$. So we obtained:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231025105309.png" style="zoom:70%;" /></p>

<p>which means our algorithm would be progresively filling in a 2D array:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231025105502.png" style="zoom:75%;" /></p>

<p>which obviously has a runtime of $O(nm)$.</p>

<p><strong>Proof of correctness?</strong> Induction on $i+j$ (the subproblem size), with the recurrence relationship justifying the inductive step.</p>

<p><strong>How do we reconstruct it?</strong> Start from the top $A[m][n]$ and figure out which of the three cases it went into. This can be done by checking A[i-1][j-1], A[i-1][j], A[i][j-1] and see which one it is. Then we can continue to that case and repeat. Details omitted here but this will be $O(n+m)$ since each time you are decreasing at least one of the two numbers $i,j$ by one.</p>

<h2 id="optimal-binary-search-trees">Optimal Binary Search Trees</h2>

<p>Goal: compute the best-on-average search tree given stastistics about the frequencies of different searches. Recall that the defining property of search tree is</p>

<blockquote>
  <p><strong>Search Tree Property</strong>: for every object $x$</p>
  <ol>
    <li>object in $x$’s left subtree must have keys smaller than $x$</li>
    <li>object in $x$’s right subtree must have keys larger than $x$
(assuming no duplicate keys for simplicity)</li>
  </ol>
</blockquote>

<p>This means that visually we are dealing with a fast search datastructure that looks like:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231025110413.png" style="zoom:70%;" /></p>

<p><strong>for every subtree</strong> in the search tree. An example would be:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231025110504.png" style="zoom:80%;" /></p>

<h3 id="average-search-time">Average Search Time</h3>

<p>Normally, when we consider a binary search tree, we measure the <strong>search time</strong> for a key $k$ to be the nunmber o nodes it need to visit while searching for $k$ (including $k$ itself). For exmaple in the following tree:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231025110917.png" style="zoom:80%;" /></p>

<p>key “1” wold have a search time 5. Therefore, without weights, the ideal search tree would be a balanced one</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231025111023.png" style="zoom:100%;" /></p>

<p>because this would minimize the length of the longest root-leaf path, or equivalently, the maximum search time. Minimzing the maximum search time <strong>makes sense since you don’t have knowledge about which searches are more likely than others</strong>.</p>

<p>However, here we consider the problem</p>

<blockquote>
  <p><strong>Optimal Binary Search Trees</strong>: A sorted list of keys $k_{1} &lt; k_{2} &lt; … &lt; k_n$ and nonnegative frequency $p_i$ for each key $k_i$. We want to minimize the <strong>weighted search time</strong>:</p>

\[\sum_{i=1}^n p_i \times \text{search time for } k_i = \sum_{i=1}^n p_i \times (1 + \mathrm{depth}_T(k_i) )\]

  <p>where $\mathrm{depth}_T(k_i)$ represent the depth of $k_i$ in the tree $T$. (The root will be considered as depth zero.)</p>
</blockquote>

<p>This looks <strong>very similar to the optimal prefix-tree code problem</strong>, where the goal is to also related to find a tree to minimize the average (weighted) depth. However, the challenge here is that, in the prefix-free code problem, the only restriction is that symbols appear at leaves, but here we have the <strong>search tree property</strong>. This makes greedy algorithm not work in this problem. Similarly divide-and-conquer algorithm would also struggle (imagining recursively choosing a root node to be the median, and continue). Fundamentally this is because <strong>the choice of root has unpredictable repercussions further down the tree</strong> if you chose too early.</p>

<p>So how do we do it? Different from other previous problems, there is no <em>clear notion of the rightmost/last object to pluck off and obtain optimal thing for subproblem</em>. But the intuition is that we can imagine building the tree from bottom up, and imagine the <strong>last decision we have to make = determing the root node!</strong>. Consider, if we know the optimal solution is the following</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231025130312.png" style="zoom:80%;" /></p>

<p>Then we (intuitively) also</p>
<ul>
  <li><mark>know the optimal solution for keys $1, ..., r-1$ and $r+1,. .., n$ will be $T_1, T_2$</mark>. (see proof below)</li>
  <li>the key is IF we know <mark>"what $r$ is"</mark>
    <ul>
      <li>recall that in WIS, we know the rest of the solution if we know “whether the last vertex is included or not”</li>
      <li>recall that in Knapsack, we know the rest of the solution if we know “whether last item is included or not”</li>
    </ul>
  </li>
  <li>therefore, the smaller subproblem is the trees $T_1, T_2$, and the case analysis will be <em>all the possible roots</em>.</li>
</ul>

<hr />

<p><em>Proof</em>: Let the root of $T$ have key $r$ (same as figure above). We want to show that the residents of $T_1$ with $p_1, …, p_{r-1}$ is optimal, and similarly for $T_2$ with $p_{r+1}, …, p_n$.</p>

<p>Suppose by contradiction that one of the subtrees, e.g. $T_1$ is NOT an optimal solution, so that we have a search tree $T_1^*$ that achieves a better search time with the same keys:</p>

\[\sum\limits_{k=1}^{r-1} p_{k} \cdot  (k\text{'s search time in $T_1^{*}$}) &lt; \sum\limits_{k=1}^{r-1} p_{k} \cdot (k\text{'s search time in $T_1$})\]

<p>Then intuitively, we want to show that we can cut and paste this tree into $T$ and the obtain a cost better than $T$:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231025162139.png" style="zoom:80%;" /></p>

<p>where RHS is the one we cut and pasted. The weighted search time of the original tree $T$ is:</p>

\[\begin{align*}
  &amp; p_{r} + \sum\limits_{i=1}^{r-1} (1 + 1 + \mathrm{depth}_{T_1}(k_i) ) + \sum\limits_{j=r+1}^{n} (1 + 1 + \mathrm{depth}_{T_2}(k_j) ) \\
  &amp;=  \sum\limits_{i=1}^{n} p_i + \sum\limits_{i=1}^{r-1} (1 + \mathrm{depth}_{T_1}(k_i) ) + \sum\limits_{j=r+1}^{n} (1 + \mathrm{depth}_{T_2}(k_j) ) \\
  &amp;= \sum\limits_{i=1}^{n} p_i + \text{weighted search time of $T_1$} + \text{weighted search time of $T_2$}
\end{align*}\]

<p>since the first and third term is the same for the weight time in $T^{<em>}$, and we know that $T_1^{</em>}$  is better than $T_1$, this is a contradiction to the statement that $T$ was optimal.</p>

<hr />

<p>From the above observation, we obtain the recurrence relationship that, llet $W_{i,j}$ denote the weighted search time for keys ${i, i+1, …, j}$, then:</p>

\[W_{1,n} = \sum\limits_{k=1}^{n} p_{k} + \min\limits_{r \in \{1,2, ..., n\}} \left( W_{1,r-1} + W_{r+1,n} \right)\]

<p>where $W_{1,n}$ is the full problem, and  $W_{1,r-1}, W_{r+1,n}$ are the subproblems. Notice that this also implies solving the subproblems (recursively) <strong>must be a dealing with a contiguous chunk of keys</strong> = a subtree. Since for the search tree property to hold, the above <strong>must be true for every subtree</strong>:</p>

\[W_{i,j} = \sum\limits_{k=i}^{j} p_{k} + \min\limits_{r \in \{i,i+1, ..., j\}} \left( W_{i,r-1} + W_{r+1,j} \right)\]

<p>where intutively, $W_{i, i}$ would representing you building a search tree with just the root node $r=i$. Then, the algorithm would just iteratively grow this tree like this:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231025125708.png" style="zoom:80%;" /></p>

<p>Alternatively you can also just start with the purple diagonal as base case in your algorithm, and go to the top left. And you will fill each new diagional from bottmo left to top right (think about why by looking at the recurrence relation).</p>

<p>and the detailed algorithm would be:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231025164341.png" style="zoom:70%;" /></p>

<p>where the runtime would be:</p>

<ul>
  <li>there are $O(n^2)$ subproblems</li>
  <li>each subproblem does a min over $O(n)$ choices</li>
</ul>

<p>so the total runtime is $O(n^3)$ (though with some optimization, you can get to $O(n^{2})$)</p>

<h1 id="shortest-path-revisited">Shortest Path Revisited</h1>

<p>This chapter considers a DP approach for computing the shortest path in a graph. Both are slower than Dijkstra or Prim’s algorithm, but:</p>

<ul>
  <li>Bellman-Ford can deal with negative edge weights and can be done in a <em>distributed</em> manner</li>
  <li>Floyd-Warshall can also deal with negative edge weights and can compute shortest-path distance between <em>any pair</em> of vertices</li>
</ul>

<h2 id="shortest-path-with-negative-edge-length">Shortest Path with Negative Edge Length</h2>

<p>As mentioned before, Dijkstra algorithm ca nfail with graphs that has negative edges (but not negative cycles). The reason is the greedy decision it makes now doesn’t work. Consider:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231026233920.png" style="zoom:70%;" /></p>

<p>where the shortest path from $s \leadsto t$  will be $s \to t$ in the first iteration of Dijkstra, which is wrong.</p>

<p>In general (for any graph that may have negative edges or cycles):</p>
<ul>
  <li>if you have a negative cycle, then any shortest distance doesn’t make sense as its $- \infty$</li>
  <li>What if in the presence of a negative cycle you forbidden that option for your optimal path? This version where <em>no repeat vertices is allowed</em> of the single-source shortest path problem is actually a NP-hard problem.</li>
</ul>

<p>Therefore, in this section we will consider the revised problem</p>

<blockquote>
  <p><strong>Shortest Path Revised</strong>: given a directed graph $G=(V,E)$ with edge lengths $l_e$ for each edge $e \in E$, and a source vertex $s \in V$, either:</p>
  <ul>
    <li>If there is a negative cycle, then the algorithm should report it and done.</li>
    <li>Otherwise, compute the shortest path distance $d_v$ from $s$ to every other vertex $v \in V$.</li>
  </ul>
</blockquote>

<p>However, if there is no negative cycle, then there are a few properties we can exploit to help us reach a solution quickly:</p>

<blockquote>
  <p>If a graph has no negative cycle, the optimal path $s \leadsto v$  must <mark>contain at most $n-1$ edges/cannot contain repeated vertices</mark>.</p>
</blockquote>

<p>Proof: consider an optimal path $P’$ that has at least $n$ edges. This means it visits at least $n+1$ vertices, meaning some vertex $w$ is visited twice. This means we can splice the repeated part out from $P’$ while keeping thee same endpoints <strong>but with fewer edges now</strong>:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231026235102.png" style="zoom:75%;" /></p>

<p>But because there is no negative cycle, this spliced out (path) cycle must have nonnegative length. Therefore, the new path $P’’$ is shorter than $P’$, which is a contradiction.</p>

<h2 id="bellman-ford-algorithm">Bellman-Ford Algorithm</h2>

<p>Again, the most important step is to reason about the optimal solution: <strong>what are the different ways that an optimal solution might be built up from optimal solutions to smaller subproblems</strong>?</p>

<p>Naively, you may think of subproblems being something based on a subset of the $G$ we need to solve (e.g., similar to how we solve WIS, where input graph is a path graph and we just pluck the last vertex out). However, the problem now is that <em>where is the “last vertex” in a generic graph</em>? Bellman-Ford thus considers a different approach. Although there is no sequentiality in input graph, <em>there is sequentialality in output graph, i.e., the optimal path</em>:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231027112721.png" style="zoom:80%;" /></p>

<p>which we will show that $P’$ must also be shortest (even if $w \to v$ can ve negative). This is great, but <mark>what is the subproblem</mark>?</p>

<blockquote>
  <p><strong>Bellman-Ford Subproblem</strong>: we only consider (optimal) paths that use <em>less than $i$ edges</em> each time. More formally, let the input graph be $G=(V,E)$ with a given source vertex $s \in V$. Consider finding the optimal $P$ bewteen $(s,v)$ that includes <em>at most $i$ edges</em>.</p>
  <ul>
    <li>note that different from previous DP, each subproblem here <em>still work on the full input</em></li>
  </ul>
</blockquote>

<p>How does this help construct an optimal solution to a larger problem? Consider the following:</p>

<ol>
  <li>that optimal $P$ for $s \leadsto v$ has <strong>at most $i-1$ edges</strong> (already a pretty good path using a budget $i-1$). Then $P$ must also be the <strong>optimal solution with edge budget $i-1$ for $s \leadsto v$</strong>. (Proof by contradiction: if not, then that shorter path would also be shorter for the original subproblem of at most $i$ edges.)</li>
  <li>that optimal $P$ uses <strong>exactly $i$ edges</strong>. Consider visually that optimal path and $P’$ being the last edge plucked (say $(w,v)$):
<img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231027113744.png" style="zoom:80%;" />
then that $P’$ is <strong>an $s \leadsto w$ optimal path with at most $i-1$ edges</strong> (<mark>a smaller subproblem BUT with different destination</mark>). This can be easily shown by contradiction as well, because if there exists a better path with at most $i-1$ edges from $s \leadsto w$, then we can swap that out and obtain a better $P$ to the original problem.</li>
</ol>

<p>Therefore:</p>
<ul>
  <li>we can construct an optimal $P$ for the budget of $i$ using the “two” cases above</li>
  <li>but how many subsoluions will the original subproblem need to look at? Consider computing the optimal path $s \leadsto v$ with cost $i$. Then “case 1” is one candidate, and “case 2” would have $\text{in-degree}(v)$ candidates. So in total it will scan through $1+\text{in-degree}(v)$ candidates.</li>
</ul>

<p>Anyway, this gives use the recurrence relationship. Let $L_{i,v}$ denote the minimum length of an $s\leadsto v$ path with at most $i$ edges, <em>cycles allowed</em> (since we have an edge budget, even negative cycles could be fine in this definition for now). Then for every $i \ge 1, v \in V$:</p>

\[L_{i,v} = \min \begin{cases}
  L_{i-1, v} \\
  \min\limits_{(w,v) \in E} \left( L_{i-1, w} + l_{wv} \right)
\end{cases}\]

<p>if no such path exist, then $L_{i,v} = \infty$. But when should we stop $i$?</p>

<blockquote>
  <p><strong>Bellman-Ford Convergence</strong>: interestingly, we can show that $L_{i,v}$ will converge if for some $k \ge 0$:</p>

\[L_{k+1,v} = L_{k,v}  \qquad \forall v \in V\]

  <p>then this would mean:</p>
  <ol>
    <li>$L_{k’,v} = L_{k,v}$ for every $k’ \ge k$ and any destination $v$</li>
    <li>for every destination $v$, then $L_{k,v}$ must be the $\mathrm{shortest}(s,v)$ in $G$</li>
  </ol>
</blockquote>

<p><em>Proof for statement 1:</em> Because $L_{k+1,v} = L_{k,v}$, then this means the subproblem of $L_{k+2}$ is doing</p>

\[L_{k+2,v} = \min \begin{cases}
  L_{k+1, v} \\
  \min\limits_{(w,v) \in E} \left( L_{k+1, w} + l_{wv} \right)
\end{cases} = \min \begin{cases}
  L_{k, v} \\
  \min\limits_{(w,v) \in E} \left( L_{k, w} + l_{wv} \right)
\end{cases}
= L_{k+1,v}\]

<p>Thus, any future subproblem will be the same as $L_{k+1,v}$, which is the same as $L_{k,v}$ by assumption.</p>

<p><em>Proof for statement 2:</em> if $L_{k,v}$ is NOT the shortest path for subproblem with at most $k$ edges. Then the shortest path must be beyond $k$ edges. This is a contradiction since we know that $L_{k’,v} = L_{k,v}$ for any $k’ \ge k$ if the assumption holds.</p>

<blockquote>
  <p><strong>Bellman-Ford Stops with No Negative Cycles</strong>: if there ARE negatiev cycles in the graph, then the condition $L_{k+1,v} = L_{k,v}, \forall v \in V$ in general will not even happen. But if there are <strong>no negative cycles</strong>, then it will converge exactly when reached $n-1$ edge budget (i.e., every vertex used in the path):</p>

\[L_{n,v} = L_{n-1,v}  \qquad \forall v \in V\]

  <p>the contrapositive statement of this is also powerful:</p>

\[\text{no neg cycle means convergence} \implies \text{not converging means has neg cycle}\]

  <p>so this algorithm can also detect negative cycles.</p>
</blockquote>

<p>Why? Remeber we showed that in Section <a href="#Shortest_Path_with_Negative_Edge_Length">Shortest Path with Negative Edge Length</a>, the optimal $s \leadsto v$ path in a graph with no negative cycle must at most visited every vertex once (otherwise we could remove the cycle and get a shorter path). Therefore, this is <mark>the only place where we need the no-negative cycle condition</mark>, such that Bellman-Ford’s algorithm will stop/converge at $n-1$ iterations. <strong>If not, then there is a negative cycle</strong>:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231027121122.png" style="zoom:80%;" /></p>

<p>where again, we needed to fill up a 2D array because we have two parameters, $i,v$ for the subproblem.</p>

<p><strong>Proof of Correctness</strong>: induction on $i$, with our recurrence relationship justifying the inductive step.</p>

<p><strong>Runtime</strong>: Superficially it looks like $O(n^{2})$ loops with $O(n)$ to compute the recurrence relation in the inner most loop. However, realize that during the “for $v\in V$” loop we actually just did:</p>

\[\sum_{v \in V} \text{in-degree}(v) = m\]

<p>abd in the outer for loop over $n$ iterations, we thus only need $O(nm)$ time! (if the graph is <em>dense</em>, then $m=O(n^{2})$ so we get the same solution as our naive analysis).</p>

<h2 id="floyd-warshall-algorithm">Floyd-Warshall Algorithm</h2>

<p>Now we can deal with all-pairs shortest path:</p>

<blockquote>
  <p><strong>All-Pairs Shortest Path Problem</strong>: consider a directed graph $G=(V,E)$ with a real-valued length $l_e$ for each edge. The goal is to:</p>
  <ul>
    <li>find the shortest path distance $\mathrm{shortest}(u,v)$ from <em>every</em> vertex $u$ to every other vertex $v$.</li>
    <li>if there is a negative cycle, then the algorithm should report it and done.</li>
  </ul>
</blockquote>

<p>Technically, we could solve this using Bellman-Ford by treating every vertex as source vertex. This will give us $O(n^{2}m)$ runtime, with potentially $m=O(n^{2})$. We show that we can do better than this by finishing in $O(n^{3})$.</p>

<p>The trick here is to still look at the output paths, and also puts some contraint on length. However, we further restrict the <em>identity of the vertices that can go into the solution</em>.</p>

<blockquote>
  <p><strong>Floyd-Warshall Subproblem</strong>: First we label each vertex $v\in V$ with names ${1,2,3, …, n}$. Then, consider the shortest path from $v$ to $w$ that only uses vertices in ${1,2, …, k}$ as intermediate vertices. i.e. this minimum path</p>
  <ul>
    <li>begins at $v$ and ends at $w$</li>
    <li>the path (excluding $v,w$) only includes vertices in ${1,2, …, k}$</li>
    <li>does not contain a directed cycle (by <mark>assuming there is no negative cycle</mark> so that we can splice out any cycle out of a path and end up with a lower cost.)
      <ul>
        <li>We shall also see how negative cycles can be detected later</li>
      </ul>
    </li>
  </ul>

  <p>Let $L_{k, u, v}$ denote the length of this path. If no such path exists, then $L_{k, u, v} = \infty$. Note that you can therefore <strong>imaging subproblem size defined by $k$</strong>: for a fixed origin-destination pair $v,w$, the set of allowable path will grow by $k$ and the minimum cost will only decrease.</p>
</blockquote>

<p>For example:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231027123349.png" style="zoom:80%;" /></p>

<p>In this graph, if we had source and vertex being $1,5$, then if $k=0,1,2$ there is no feasible path so $L_{k,1,5}=\infty$. However, when $k=3$, then the path $1 \to 2 \to 3 \to 5$ is eligible (and being the only one) with cost $L_{3,1,5} = 3$.</p>

<p>This we will soon see will make the optimal solution naturally break down into only two smaller subproblems. Suppose $P$ is a $v \leadsto w$ with no cycles and only uses vertices in ${1,2, …, k}$ as intermediate vertices. Then realize that that $P$ can  <em>either use the lastly added vertex $k$ or not</em>:</p>

<ol>
  <li>Case 1: <strong>optimal $P$ for $v \leadsto w$ did NOT use $k$</strong> as an intermediate vertex. Then $P$ must be an optimal path with at most $k-1$ intermediate vertices as well. (Proof by contradiction)</li>
  <li>
    <p>Case 2: <strong>optimal $P$ for $v \leadsto w$ did use $k$</strong>. Then we can split the path into two by <em>removing $k$ to be uneligible</em>:
<img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231027124934.png" style="zoom:80%;" /></p>

    <p>because $k$ could have only appeared in $P$ once (by assumption of cycle-free optimal path), then $P_1$ is optimal with origin $v$ and destination $k$, and $P_2$ is optimal with origin $k$ and destination $w$, <strong>both with a smaller subproblem using only ${1,2, …, k-1}$ vertices</strong>.</p>
    <ul>
      <li>to prove that $P_1, P_2$ is also optimal is slightly tricky here. Suppose there is a better $P_1^{<em>}$ for $v \leadsto k$. To concatenate $P_1</em>$ with $P_2$ we want to have a lower cost than $P$ to get a contradiiction.
        <ul>
          <li>If $P_1^{*}$ with $P_2$ will have no cycle, proof done.</li>
          <li>If $P_1^{<em>}$ with $P_2$, denote $P^{</em>}$, now has a cycle, we need to invoke the assumption that there is no negative cycle in $G$. Therefore we can splice up the cycle in $P^{<em>}$ such that we still hhave the same origin $u$ and destination $v$ in now a cycle free path $\hat{P}$, which can only be shorter than $P^{</em>}$.</li>
        </ul>
      </li>
    </ul>
  </li>
</ol>

<blockquote>
  <p>In sum, we broke the large problem into “two” subproblems: <strong>case 1 is reducing the problem size by one</strong>, and case 2 is <strong>reducing the problem size by one AND changing the source/destination pairs</strong>.</p>
</blockquote>

<p>Therefore, <mark>suppose (for now) $G$ has no negative cycles</mark>. Then the <strong>recurrence relation</strong> is deinfed by letting $L_{k,v,w}$ be the minimum length of a cycle-free path from $v$ to $w$ that only uses vertices in ${1,2, …, k}$ as intermediate vertices. Then:</p>

\[L_{k,v,w} = \min \begin{cases}
  L_{k-1, v, w} \\
  L_{k-1, v, k} + L_{k-1, k, w}
\end{cases}\]

<p>which has to be true for every $k \in {1,2, …, n}$ and every $v,w \in V$.</p>

<p>Finally this gives the algorithm:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231027130119.png" style="zoom:75%;" /></p>

<p>where note that:</p>
<ul>
  <li>since we are viewing subproblems defined by size $k$, the base cases are $L_{0,v,w}$. This can result in three cases:
    <ul>
      <li>if $v=w$, then $L_{0,v,w}=0$</li>
      <li>if $(v,w) \in E$, then $L_{0,v,w}=l_{vw}$</li>
      <li>otherwise $L_{0,v,w}=\infty$</li>
    </ul>
  </li>
  <li>since the subproblems grows by $k$, the outermost loop will start with $k$</li>
  <li>this algorithm <mark>can detect negatiev cycles as well</mark> (see below why)</li>
</ul>

<p><strong>Proof of Correctness</strong>: induction on $k$, with our recurrence relationship justifying the inductive step.</p>

<p><strong>Runtime</strong>: $O(n^{3})$ since we are filling in a 3D array, and each subproblem takes $O(1)$ time to compute.</p>

<h3 id="detecting-negative-cycles">Detecting Negative Cycles</h3>

<p>What if the input graph has a negative cycle?</p>

<blockquote>
  <p><strong>Lemma 18.8</strong>: the graph $G$ has a negative cycle if and only if, at the conclusion of the algorithm, there is a vertex $v$ such that $L_{n,v,v} &lt; 0$.</p>
</blockquote>

<p><em>Proof</em>: if there is no negative cycle, then obviously $L_{n,v,v} = 0$ for every $v$ since every shortest path will also be cycle free. But if there is a negative cycle, then this means $G$ has a negative cycle with no repeated vertices other than its start and end (e.g. $v$). The trick is to think about two paths to form such a cycle, and argue how a repeated vertex can be spliced out.</p>

<p>Let $C$ denote such a cycle, and let $k$ be the largest labeled vertex of $C$ with $k \neq v$:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231027132431.png" style="zoom:80%;" /></p>

<p>then we know:</p>
<ul>
  <li>$P_1, P_2$ are cycle-free $v \leadsto k$ and $k \leadsto v$ paths respectively (since this cycle has no repeated vertex other than source) with vertices restricted to ${1,2, …, k-1}$</li>
  <li>then Floyd-Warshall would found $L_{k-1, v, k}$ and $L_{k-1, k, v}$ to be at least smaller or equal to the actual length of $P_1, P_2$ (being cycle-free)</li>
  <li>therefore, $L_{k,v,v}$, which is at most the length $L_{k-1, v, k} + L_{k-1, k, v}$, <strong>will also be smaller or equal $C$</strong>, which is negative.</li>
</ul>

<p>Therefore, if there is a negative cycle, $L_{k,v,v}$ will at least once become negative. This means $L_{n,v,v}$ will be negative since for each iteration $k’ &gt; k$ the minimum length only decreases.</p>

<h1 id="max-flows-and-min-cuts">Max Flows and Min Cuts</h1>

<p>Before we dive into the algorithms, its sometimes enlightening to see how those seemingly “unrelated/unpractical” algorithms can be very useful in practice. Here we will see two examples.</p>

<h2 id="minimum-cut-problem">Minimum Cut Problem</h2>

<blockquote>
  <p><em>Minimum Cut Problem</em>: consider a flow nertwork consisting of a directed graph $G=(V,E)$ with <strong>a source vertex $s$ and a sink vertex $t$</strong>. Each edge $e \in E$ has a capacity $c_e$. The goal is to find a $(s,t)$ cut into two sets $A,B$ such that it minimizes the total capacity of edges sticking out from set $A$ into $B$.</p>

\[\min \sum_{e =(u,v); u \in A, v \in B} c_e\]

  <ul>
    <li>basically think of those source and sink as water flows, and the capacity is the pipe</li>
    <li>the cut is basically coming up with two groups of vertices but one needs to include $s$ and the other needs to include $t$.</li>
  </ul>
</blockquote>

<p>Visually, a cut below would be optimal with a total capcity of 3:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231102231406.png" style="zoom:30%;" /></p>

<p>where:</p>
<ul>
  <li>the purple edge would not count as it is <em>not flowing from $A$ to $B$</em></li>
  <li>the green edge will count</li>
  <li>the blue edge would not count as it is <em>flowing from $B$ to $A$</em></li>
</ul>

<p>Notice that since this is just choosing which vertex goes where, there are $2^{n-2}$ possible cuts (excluding source and sink). We will not see an algorithm here, but we will see how this can be solved in linear time in the next section.</p>

<h2 id="minimum-cut-application-image-segmentation">Minimum Cut Application: Image Segmentation</h2>

<p>We will see how this minimum cut problem relates to how we can do image segmentation. First we formalize the “version” of image segmentation we are considering:</p>

<blockquote>
  <p><em>Image Segmentation with Fore/background</em>: Consider the task of classifying pixels of an image to be either foreground or background. Let us be given some prior (e.g. heuristics, non-negative) that each pixel could be in foreground with $a_v$ and background with $b_v$. Additionally, we are given non-negative $p_e$ for each undirected edge between each pixel, which represents the fact that we want neighboring pixels to be close together, i.e. smooth.</p>

  <p>Then, we can define the segmentation as an <em>undirected graph</em> with all those costs/rewards assigned to the vertices and edges:
<img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231102232526.png" style="zoom:30%;" /></p>

  <p>where the first value of the nertex denotes $a_v$ and second denotes $b_v$ in this example. We <strong>want to maximize the objective</strong>:</p>

\[\max_{(X,Y)}\quad \sum_{v \in X} a_v + \sum_{v \in Y} b_v - \sum_{e \in \delta(X)} p_e\]

  <p>which represents an “MLE” objective of wanting all the foreground-likely pixels in $A$, and all the background-likely pixels in $B$, while also wanting to minimize the cost of the “incongruity” between $A$ and $B$. $\delta(X)$ denotes the cut edges between $A$ and $B$.</p>
</blockquote>

<p>The claim is that this problem reduces to the minimum cut problem. First we note a few similarlities and differences to motivate the reduction:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Similarities</th>
      <th style="text-align: center">Differences</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">both problem needs a partition</td>
      <td style="text-align: center">here we consider <em>undirected edges</em></td>
    </tr>
    <tr>
      <td style="text-align: center">both want to minimize the cut across partitions</td>
      <td style="text-align: center">missing a <em>source and sink vertex</em></td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: center">additional $a_v, b_v,p_e$ costs</td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: center">maximization instead of minimization</td>
    </tr>
  </tbody>
</table>

<blockquote>
  <p>Our overall reduction approach will be intuitive for this class:</p>
  <ol>
    <li>transform the problem into the problem that can be solved by (e.g. min cut algorithm)</li>
    <li>transform the solution of that problem back to the original problem</li>
    <li>finally show that the transformed solution is optimal to the original problem</li>
  </ol>
</blockquote>

<p>So how do we convert from the two different graph problems? A few are easy fixes. Let the original segmentation graph be $G$, we consider building a new graph $G’$:</p>

<ul>
  <li>
    <p><strong>max problem to a min problem?</strong> Multiply by negative one:</p>

\[\max_{(X,Y)} \sum_{v \in X} a_v + \sum_{v \in Y} b_v - \sum_{e \in \delta(X)} p_e \implies \min_{(X,Y)} -\sum_{v \in X} a_v - \sum_{v \in Y} b_v + \sum_{e \in \delta(X)} p_e\]

    <p>and we can “remove the negative sign” by adding the constant $\sum\limits_{v \in V}a_{v} + \sum\limits_{v \in V}b_{v}$ to <em>every</em> edge, which gives:</p>

\[\implies \min_{(X,Y)} +\sum_{v \in X} b_v +\sum_{v \in Y} a_v + \sum_{e \in \delta(X)} p_e\]

    <p>which (unlike the case of shortest path problem) does <em>not</em> change the optimal solution.</p>
  </li>
  <li>
    <p><strong>undirected edges to directed?</strong> add both and give both a penalty of $p_e$ to mimic $c_e$:</p>

    <p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231102234327.png" style="zoom:35%;" /></p>
  </li>
  <li>
    <p><strong>missing source and sink?</strong> Add them to the new graph $G’$ so that $V’ = V \cup {s,t}$</p>

    <p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231102234446.png" style="zoom:30%;" /></p>

    <p>where we can make $s$ the source by adding a directed edge from $s$ to <em>every edge in $V$ but not $t$</em>, and similarlity make $t$ the sink by adding a directed edge from <em>every edge in $V$ but not $s$</em> to $t$:</p>
  </li>
  <li>
    <p><strong>additional $a_v, b_v$ costs?</strong> Since now we have an edge from $s$ to every vertex $v \in V$, we can just assign $a_v$ to the capacity of that edge, and similarly for $b_v$.</p>

    <p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231102234841.png" style="zoom:25%;" /></p>
  </li>
</ul>

<p>Now, compare the two graphs we get $G$ and $G’$:</p>

<ul>
  <li>
    <p>there is a bijection where every parition $X,Y$ of $V$ will correspond to a cut $A,B$ in $G’$. This is basically because we can just have $A \iff X \cup {s}$ and $B \iff Y \cup {t}$.</p>

    <p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231102235254.png" style="zoom:15%;" /></p>
  </li>
  <li>
    <p>then we argue that <strong>computing the capacity $\sum_{e =(u,v); u \in A, v \in B} c_e$ of such cut in $G’$</strong> is the same as <strong>computing the objective function of $\sum_{v \in X} b_v +\sum_{v \in Y} a_v + \sum_{e \in \delta(X)} p_e$</strong>. How?</p>

    <p>Consider computing the capacity of the cut $A,B$ in $G’$. You see that the edges that going across $A,B$ would be:</p>
    <ul>
      <li>for every $v \in Y$, we pay $a_v$ for edges $(s,v)$ which crosses the boundary (left to right)</li>
      <li>for every $v \in X$, we pay $b_v$ for edges $(v,t)$ which crosses the boundary (left to right)</li>
      <li>finally we pay $p_e$ for all the edge that starst in $A$ and ends in $B$ (which is exactly $\sum_{e \in \delta(X)} p_e$)</li>
    </ul>

    <p>adding all the above up we get exactly $\sum_{v \in X} b_v +\sum_{v \in Y} a_v + \sum_{e \in \delta(X)} p_e$ for $G$.</p>
  </li>
  <li>
    <p>since we can minimize the capacity in $G’$, we can minimze $\sum_{v \in X} b_v +\sum_{v \in Y} a_v + \sum_{e \in \delta(X)} p_e$, which maximizes the original objective function.</p>
  </li>
  <li>
    <p>finally to reconstruct the partition $X,Y$ from the cut $A,B$, we just remove $s$ from $A$ and $t$ from $B$.</p>
  </li>
</ul>

<h2 id="maximum-flow-algorithm">Maximum Flow Algorithm</h2>

<p>Similar to minimum flow, we start with a flow graph $G=(V,E)$  wth <strong>directed edges</strong>, a source vertex $s$ and a sink $t$. Each edge $e \in E$ has a capacity $c_e$. The goal is to find a “flow” $f$ that maximizes the total flow from $s$ to $t$.</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231109222028.png" style="zoom:80%;" /></p>

<p>where in the right flow, we made “three streams of water flow”:</p>
<ul>
  <li>path $s \to v \to t$ with flow 2, because the $v\to t$ bottlenecks at 2</li>
  <li>path $s \to w \to t$ with flow 2, because the $s\to w$ bottlenecks at 2</li>
  <li>path $s \to v \to w \to t$ with flow 1, because the $s \to v$ only has 1 capacity left</li>
</ul>

<p>But how do we formalize this into a problem (and find an algorithm to solve it)? First, we need to redefine what it means to be a valid flow:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">View 1</th>
      <th style="text-align: center">View 2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231109222428.png" style="zoom:70%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231109222415.png" style="zoom:70%;" /></td>
    </tr>
  </tbody>
</table>

<p>and notice that <mark>these two are equivalent</mark>: specifying a configuation of <mark>valid flow is the same as obeying the conservation principle</mark>. If each edge is spending $\le$ its full capacity and for each vertex (except for $s,t$) the <mark>total outflow equals total inflow</mark>, then it is a valid flow. (Note that this understanding is critical to figure out why the algorithm works.)</p>

<p>Therefore, this gives us the formal definition:</p>

<blockquote>
  <p><strong>Maximum Flow Problem</strong>: given a flow graph, assign a flow amount $f_e \ge 0$ to every edge such that:</p>
  <ul>
    <li>for every edge $e \in E$, $f_e \le c_e$ (i.e. you cannot exceed the capacity)</li>
    <li>for every vertex $v \in V \setminus {s,t}$, the total inflow equals total outflow</li>
  </ul>

  <p>the goal is to <strong>maximize</strong> the total flow from $s$ to $t$ = total flow out of $s$ = total flow into $t$.</p>
</blockquote>

<p>The intuition of solving this is to first try a intuitive greedy approach, figure out what went wrong, and attempt to fix that (magically reach the correct algorithm in this case).</p>

<h3 id="naive-greedy-maximum-flow-algorithm">Naive Greedy Maximum Flow Algorithm</h3>

<p>Idea:  start with the all-zero flow (i.e. all edges assigned $f_e = 0$) and greedily produce ﬂows with ever-higher value:</p>

<ol>
  <li>find a viable path $s \overset{P}{\leadsto} t$ in the graph (i.e. can send flow through) using BFS/DFS while checking $f_{e} \le u_e$ does not exceed capacity</li>
  <li>if none exist, then we are done</li>
  <li>if found, find how much we can send through on that path $\Delta = \min_{e \in P} (u_e - f_e)$ where $f_e$ represents the current flow we assigned on that edge</li>
</ol>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231109223809.png" style="zoom:70%;" /></p>

<p>Technically this is already greedy, to make it “greedier” consider step 1 to always pick the path that has highest $\Delta$. Either way, we show that this algorithm is incorrect:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Greedy Output</th>
      <th style="text-align: center">Optimal Output</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231109224100.png" style="zoom:70%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231109224111.png" style="zoom:70%;" /></td>
    </tr>
  </tbody>
</table>

<p>where the greedy algorithm can be “unlucky” in that if it picked the zig-zag path in the first iteration, then it has to terminate with flow 3. But the optimal solution is flow 5.</p>

<h3 id="residual-graph-and-the-ford-fulkerson-algorithm">Residual Graph and the Ford-Fulkerson Algorithm</h3>

<p>The key idea is to imagine to be able to send flow <strong>backward</strong> along the edge. How does this work? Essentially it relies on the equivalent view that <mark>all we need is conservation of flow at each vertex</mark>. For example considering the blue path:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Sending Flow Backward</th>
      <th style="text-align: center">Optimal Solution</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231109224747.png" style="zoom:70%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231109224800.png" style="zoom:70%;" /></td>
    </tr>
  </tbody>
</table>

<p>Now notice that <strong>these are the same</strong>! Because we are sending flow in the opposite direction, we can just subtract that from the existing flow we assigned (alike thinking about Kirchoff’s law in circuits). This is the idea of the <strong>residual graph</strong>:</p>

<blockquote>
  <p><em>Residual Graph</em>: given a flow graph $G=(V,E)$ with a flow $f$ assigned to each edge, the residual graph $G_f$ is defined as:</p>
  <ul>
    <li>the same set of vertics</li>
    <li>but with two directed edges for each edge in $G$
an edge $e = (v,w)$ that carries flow $f_e$ spawns into a forward edge of $G_f$ with capacity $u_e - f_e$, and a backward edge with capacity $f_e$.</li>
  </ul>

  <p>Visually:</p>

  <p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231109225642.png" style="zoom:70%;" /></p>

  <p>and as a result, <strong>any feasible flow in $G$ must still be feasible in $G_f$</strong>, because the remaining flow is kept by the forward edge. But since we now also have backward edges, the “search space” for possible flows is now larger. Though how is this useful?</p>
</blockquote>

<p>First a concrete example of what a redidual graph looks like:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Given a flow $f$ graph</th>
      <th style="text-align: center">Resdiual $G_f$ verbose</th>
      <th style="text-align: center">Residual $G_f$ simplified</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231109224100.png" style="zoom:70%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231109225311.png" style="zoom:70%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231109225318.png" style="zoom:70%;" /></td>
    </tr>
  </tbody>
</table>

<p>where essentially now:</p>
<ul>
  <li>the forward edge in residual graph means how much flow can you <em>still send out</em></li>
  <li>the backward edge is how much you can undo, i.e. from the flow you <em>already sent out</em></li>
</ul>

<p>We now show that the Ford-Fulkerson algorithm <strong>just needs to use that residual graph to be correct</strong>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">ford_fulkerson</span><span class="p">():</span>
  <span class="n">initialize</span> <span class="p">{</span><span class="n">f_e</span><span class="p">}</span> <span class="n">to</span> <span class="n">be</span> <span class="nb">all</span> <span class="n">zero</span>
  <span class="n">G_f</span> <span class="o">=</span> <span class="n">residual_graph</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="p">{</span><span class="n">f_e</span><span class="p">})</span>  <span class="c1"># a residual graph is defined with a flow
</span>  <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
    <span class="c1"># simple modified DFS/BFS can do this in O(m)
</span>    <span class="n">P</span> <span class="o">=</span> <span class="n">find_path</span><span class="p">(</span><span class="n">G_f</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>  <span class="c1"># find a path in RESIDUAL graph s.t. every edge has positive capacity
</span>    <span class="k">if</span> <span class="n">P</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
      <span class="k">return</span> <span class="p">{</span><span class="n">f_e</span><span class="p">}</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">Delta</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">capacity</span> <span class="n">of</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">G_f</span> <span class="ow">in</span> <span class="n">that</span> <span class="n">path</span> <span class="n">P</span><span class="p">)</span>  <span class="c1"># find the bottleneck capacity
</span>
      <span class="c1"># increase the flow from what we found
</span>      <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">P</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">e</span> <span class="ow">is</span> <span class="n">forward</span> <span class="n">edge</span> <span class="ow">in</span> <span class="n">G</span><span class="p">:</span>  <span class="c1"># flow in the real graph
</span>          <span class="n">f_e</span> <span class="o">+=</span> <span class="n">Delta</span>
        <span class="k">else</span><span class="p">:</span>
          <span class="n">f_e</span> <span class="o">-=</span> <span class="n">Delta</span>
    <span class="n">G_f</span> <span class="o">=</span> <span class="n">residual_graph</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="p">{</span><span class="n">f_e</span><span class="p">})</span>  <span class="c1"># update the residual graph
</span></code></pre></div></div>

<p>where the only difference is that now we are <strong>searching for path in the residua graph</strong> (which has more options). But why it this correct?</p>

<h3 id="correctness-of-ford-fulkerson-algorithm">Correctness of Ford-Fulkerson Algorithm</h3>

<p>The plan is similar to proving <a href="#prims-algorithm">Prim’s Algorithm</a> where we show correctness by:</p>
<ol>
  <li>FF algorithm outputs a viable flow</li>
  <li>There is some property that gives rises to the maximum flow</li>
  <li>FF output satisfies that property</li>
</ol>

<hr />

<p><em>Proof of Claim 1</em>: The intuition is that every iteration of the algorithm we are maintainining the invariance that ${f_e}_{e \in E}$ is a flow. This is essentially because</p>
<ul>
  <li>we chose $\Delta$ such that no $f_e$ in the real graph $G$ to become negative or exceeds $u_e$</li>
  <li>every edge still preserves “flow in equals flow out”. Why? Consider a vertex $v \in P$ for a $P$ in $G_f$ we picked at the current iteration of the algorithm. Then there is an edge $(x,v)$ and $(v,w)$ with some flow we assigned. Since this flow assigned is in the residual graph:
    <ul>
      <li>if $(x,v)$ corresponded to the forward edge in $G$, vertex $v$ <em>increased incoming flow by $\Delta$</em>. If $(v,w)$ corresponds also to forward edge, then it <em>increased outgoing flow by $\Delta$</em>. Therefore, the net flow in/out $v$ stayed the same.</li>
      <li>if $(x,v)$ corresponded to the forward edge in $G$, vertex $v$ <em>increased incoming flow by $\Delta$</em>. If $(v,w)$ corresponds also to backward edge, then it <em>decreased incoming flow by $\Delta$</em>. Therefore, the net flow in/out $v$ stayed the same.</li>
      <li>… in total four cases, and all of them preserve the flow in/out $v$.</li>
    </ul>
  </li>
</ul>

<p>Therefore, if the algorithm halted, the flow ${f_e}_{e \in E}$ <strong>is a viable flow</strong>. Finally, since every iteration of the algorithm increases the value of the current flow by $\Delta &gt; 0$, and since there is only a finite amount of flow that can come out of $s$ source, the algorithm <strong>will terminate</strong> eventually.</p>

<hr />

<p><em>Proof of Claim 2</em>: Recall that in a directed graph $G$ with a source $s$ and sink $t$, an $s-t$ cut is a partition of $V$ into $A,B$ such that $s \in A$ and $t \in B$. The capacity of the cut is the sum of the capacities of edges <strong>crossing from $A$ to $B$</strong>. We claim that</p>

<blockquote>
  <p><strong>Optimality Condition for Max Flow</strong>: let $f$ be a valid flow in graph $G$, then:</p>
  <ul>
    <li>$f$ is a maixmum flow</li>
    <li>$\iff$ there is an $s-t$ cut with capacity equal to the value of $f$</li>
    <li>$\iff$ there is no $s \leadsto t$ path with positive capacity in the residual graph $G_f$</li>
  </ul>

  <p>where condition 3 is basically when FF algorithm terminates, so if we can prove this then we are done.</p>
</blockquote>

<p>(note that condition 3 is quite “strong”, it means <strong>all you need to do is to somehow come up with a flow $f$ such that the residual network has no more viable $s \leadsto t$ path</strong>.)</p>

<blockquote>
  <p>First we show that condition (2) implies condition (1)</p>
</blockquote>

<p>The intuition is that for ean $s-t$ cut we do, that cost will include all the edge costs that flows out of $A$. Therefore, for any flow configuration $f$, it will consist of path that goes out from $A$ to $B$. Since the maximum/best case scenraio is the flow configuration exhausts all out-flowing capacity, therefore:</p>

\[\text{value of any }f \le \text{capacity of any }s-t \text{ cut}\]

<p>To prove this inequality a bit more formally, the value $f$ of any flow can be considered as</p>

\[\text{value of }f = \sum\limits_{e \in \delta^{+}(s)} f_{e} = \sum\limits_{e \in \delta^{+}(s)} f_{e} - \underbrace{\sum\limits_{e \in \delta^{-}(s)} f_{e}}_{\mathrm{zero}}\]

<p>since $\delta^{-}(s) = \empty$ as source has no incoming edges. Then, consider any $A,B$ cut in residual graph $G_f$. Since the conservation property hold, all other vertices will have the two terms zero:</p>

\[\text{value of }f = \sum\limits_{v \in A} \left( \sum\limits_{e \in \delta^{+}(v)} f_{e} - \sum\limits_{e \in \delta^{-}(v)} f_{e} \right)\]

<p>which is essentially to count every edge’s contribution in $A$. But then that is <strong>essentially treating $A$ as a giant “source” vertex</strong>, so that:</p>

\[\text{value of }f = \sum\limits_{e \in \delta^{+}(A)} f_{e} - \sum\limits_{e \in \delta^{-}(A)} f_{e}\]

<p>Then the rest is obvious: all the flow coming out of $A$ cannot be larger than the capacity $u_e$, and all $f_e$ back into $A$ are non-negative, so:</p>

\[\begin{align*}
  \text{value of }f 
  &amp;= \sum\limits_{e \in \delta^{+}(A)} f_{e} - \sum\limits_{e \in \delta^{-}(A)} f_{e} \\
  &amp;\le \sum\limits_{e \in \delta^{+}(A)} u_e - \sum\limits_{e \in \delta^{-}(A)} 0 \\
  &amp;= \sum\limits_{e \in \delta^{+}(A)} u_e \\
\end{align*}\]

<p>therefore, visually this inequality means:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231109234433.png" style="zoom:80%;" /></p>

<p>so if value of <strong>one of $s-t$ cut overlapped with the cross in the figuer above</strong> (condition 2), then that cross has to be the maximum $f$ you can have due to the inequality above $\implies$ condition (1).</p>

<blockquote>
  <p>Next we show that (1) implies (3)</p>
</blockquote>

<p>This is obvious. If by contrapositive that we still find a s-t path in $G_f$, then we can just increase the flow by $\Delta$ and still have a viable flow. But this contradicts the fact that (1) is a maximum flow.</p>

<blockquote>
  <p>Finally we show (3) implies (2).</p>
</blockquote>

<p>If (3) is true (no $s \leadsto t$ path possible in $G_f$), then we can obtain a partition $A$ by just doing a BFS/DFS from $s$ until we get stuck:</p>

\[A = \{ v \in V: \text{ther is an $s \leadsto v$ path in $G_f$} \}\]

<p>then the other partition $V-A$ will contain $t$. Additionally, such a cut must look like this:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231110000720.png" style="zoom:80%;" /></p>

<p>where no (positive) edges would be sticking out of $A$, as otherwise we would have expanded $A$. But what does this cut mean <strong>for the original graph $G$</strong>?</p>

<ul>
  <li>
    <p>Every edge sticking <em>out</em> of $A$ in $G$ must had assigned $f_e = u_e$ saturated the capacity. If not, then the residual graph $G_f$ would have a positive capacity edge forward edge (representing how much capacity you can still send) sticking out of $A$.</p>
  </li>
  <li>
    <p>Every edge going <em>into</em> $A$ in $G$ must have an assigned $f_{e} = 0$. This corresponds to the residual graph $G_f$ having an edge of $0$ sticking <em>out of</em> $A$ to $B$ (recall that the corresponding backward edge in $G_f$ represents the flow you have already sent out).</p>
  </li>
</ul>

<p>Now recall that we had the inequality before, it now becomes equality</p>

\[\begin{align*}
  \text{value of }f 
  &amp;= \sum\limits_{e \in \delta^{+}(A)} f_{e} - \sum\limits_{e \in \delta^{-}(A)} f_{e} \\
  &amp;= \sum\limits_{e \in \delta^{+}(A)} u_e - \sum\limits_{e \in \delta^{-}(A)} 0 \\
  &amp;= \sum\limits_{e \in \delta^{+}(A)} u_e \\
  &amp;= \text{capcity of }(A, V-A)
\end{align*}\]

<p>this completes the proof.</p>

<h3 id="reduction-to-min-cut">Reduction to Min Cut</h3>

<p>This now becomes trivial, as you recall this figure</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231109234433.png" style="zoom:80%;" /></p>

<p>The recall that in the third part of <a href="#correctness-of-ford-fulkerson-algorithm">Correctness of Ford-Fulkerson Algorithm</a> proof we said</p>

\[\text{value of }f = \text{capcity of }(A, V-A), \quad \text{for $f$ is a max flow}\]

<p>therefore the correspdong $(A, V-A)$ parition must be a minimum cut (based on Figure 7 above, corresponding to an overlap of cross and circle).</p>

<h3 id="runtime-of-ford-fulkerson-algorithm">Runtime of Ford-Fulkerson Algorithm</h3>

<p>So what about the runtime? The worst case is $f$ many iterations, where $f$ is the value of the maximum flow in the graph (because we are increasing the flow by $\Delta$ each time). But note that:</p>

<blockquote>
  <p>Ford-Fulkerson Algorithm always terminates for networks whose edge capacities are integral (or, equivalently, rational). On the other hand, it might <em>fail to terminate if networks have an edge with an irrational capacity</em>.</p>
</blockquote>

<p>However, we can make it polynomial time by using BFS to find an augmentation path, which is called Edmonds-Karp algorithm, which we will not cover here.</p>

<h3 id="reduction-to-bipartite-matching">Reduction to Bipartite Matching</h3>

<blockquote>
  <p><em>Bipartite Matching Problem</em>: consdier an undirected bipartite graph $G=(V \cup W \cup E)$ (see image below), with every edge of $E$ having one endpoint in each of $V$ and $W$. That is, no edges internal to $V$ or $W$ are allowed. The feasible solutions are the matchings of the graph, meaning we can only <strong>pick $S \subset E$ of edges that share no endpoints</strong>. <strong>The goal is to pair up as many vertices as possible (using edges of $S$)</strong></p>
</blockquote>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231103000933.png" style="zoom:30%;" /></p>

<p>For example, in the following graph, the maximum matching is 1 (pair of vertex):</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231103001131.png" style="zoom:40%;" /></p>

<blockquote>
  <p><em>Claim</em>: maximum-cardinality matching reduces in linear time to <strong>maximum flow</strong>.</p>
</blockquote>

<p>The trick is to consider transformation of the bipartite graph $G$ to the following:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231110012430.png" style="zoom:80%;" /></p>

<p>where given a bipartite graph $G=(V \cup W \cup E)$, we construct a flow graph $G’$ with:</p>

<ul>
  <li>add $s$ source with edges to all vertices in $V$ with <strong>outgoing capacity exactly 1</strong></li>
  <li>add $t$ sink with edges from all vertices in $W$ with <strong>incoming capacity exactly 1</strong></li>
  <li>all other edges from a vertex in $V$ to $W$ can have <strong>any capacity greater than 1</strong>. Here we use infinity to illustrate this.</li>
</ul>

<p>Notice that this construction gives <em>any flow in $G’$</em> to</p>

<ul>
  <li>use each vertex in $x \in V$ at most once, since there is only one edge that can flow to $x$ and has the bottleneck capacity of 1</li>
  <li>use each vertex in $y \in W$ at most once, since there is only one edge that can flow from $y$ and has the bottleneck capacity of 1</li>
</ul>

<p>Therefore:</p>

<ul>
  <li>$\implies$ a bijection between a bipartite matching in $G$ with an integer-valued flow in $G’$</li>
  <li>$\implies$ the bijection also gives the same cost: the size of flow you assigned is th same as the cardinality of the matching</li>
  <li>$\implies$ the maximum flow in $G’$ is the same as the maximum cardinality matching in $G$</li>
</ul>

<h2 id="additional-proporties-of-flow-in-graphs">Additional Proporties of Flow in Graphs</h2>

<p>This section all considers a flow graph $G$ being a directed graph with a source $s$ and sink $t$, and each edge $e \in E$ has a positive, interger capacity $c_e$.</p>

<blockquote>
  <p><strong>Acyclic Flow</strong>: a flow is acyclic if, for <strong>every</strong> cycle in the flow graph $C \subset G$:</p>

\[C = \{ x_1 \to x_2, x_2 \to x_3, ... , x_n \to x_1 \}\]

  <p>have at least one edge $e = (x_i, x_{i+1}) \in C$ having a flow of zero $f(e) = 0$. (otherwise we have a cycle flow)</p>
</blockquote>

<blockquote>
  <p><strong>Partitionable Flow</strong>: a flow is partitionable if there is a collection of $s,t$ paths flows $P_1, P_2, …, P_{\vert f\vert }$ with paths can be duplicates, $\vert f\vert$ is the value of the flow (i.e. total out of source $s$), and every path just consumes flow of $1$, so that:</p>

\[f(e) = \mathrm{size}( \{ i | e \in P_i \} ), \quad \forall e \in E\]

  <p>i.e. the flow on an edge $e$ is the number of paths that use that edge.</p>
</blockquote>

<p>Then some properties of flow include:</p>

<ol>
  <li>For every flow, there exists an acyclic flow with the same value.</li>
  <li>every acyclic flow is partitionable</li>
</ol>

<hr />

<p>Proof sketch for 1: realize that edges from a source vertex or the sink cannot be involved in any cycle. Therefore, for every cycle in the graph, we can decrement the flow on every edge until one of the edges hit zero. This will result in:</p>

<ul>
  <li>no change in flow value (since source/sink aren’t affected)</li>
  <li>still a valid flow since for every vertex, the total inflow equals total outflow (since we decremented the same amount into each vertex and out of each vertex)</li>
</ul>

<hr />

<p>Proof sketch for 2: We can decompose the flow in the network as follows:</p>

<ol>
  <li>Identify a path from the source to the sink that carries a positive flow. This can be done by starting at the source and following edges with positive flow until the sink is reached.</li>
  <li>The minimum flow in an edge along this path is the bottleneck of the path. We can consider this as a single unit of flow and subtract this flow value from every edge along this path.
    <ul>
      <li>This process <strong>does not violate</strong> the flow conservation principle at any node since that path will also be acyclic = i.e. every vertex on the graph is <strong>entered and exited exactly once.</strong></li>
      <li>if the original path is cyclic, then this does not work: we may find a cyclic path where a vertex is exited, entered (a cycle), and exited again = net flow in/out is not conserved on that path.</li>
      <li>this will decrease the original flow value of the network by the bottleneck value of the path</li>
    </ul>
  </li>
  <li>Because the conservation principle holds, the remaining flow is still valid. This means that by definition, if the remaining flow $&gt; 0$, then there must still exists flow paths from the source to the sink with positive flow (i.e. the water is still running).</li>
</ol>

<p>Repeat the above step until <strong>no more paths with positive flow from the source to the sink can be found in the residual network</strong>. Each time a path is found, it is distinct and non-overlapping with previously found paths because:</p>

<ol>
  <li>The flow in an edge cannot be counted more than once since each path uses the minimum flow on its route (the bottleneck), which is then subtracted from the network.</li>
  <li>Once the flow on an edge is reduced to zero, <strong>that edge cannot be used</strong> in subsequent paths.</li>
</ol>

<h1 id="linear-programming">Linear Programming</h1>

<p>Linear programming is a method to solve optimization problems where the objective function and constraints are linear. It is special in that:</p>

<ul>
  <li>Linear programming is a remarkable sweet spot between <em>generality and
computational efficiency</em> (too general a problem becomes NP-Hard)</li>
  <li>exists many commercial solvers (i.e. algorithm implementations) that can solve those problems within <em>polynomial time</em></li>
  <li>many problems we have seen in the later part of this course <em>can be formulated as linear programming problems</em></li>
</ul>

<p>We will mostly focus on how to reduce problems into a linear programming problem, and not so much on the algorithmic details of solving it.</p>

<h2 id="ingredients-of-a-linear-program">Ingredients of a Linear Program</h2>

<p>So <strong>what kind of problems can linear programming solve</strong>? The answer is to formulate questions in the following form:</p>

<blockquote>
  <p><strong>Ingredients of a Linear Program</strong>: basically you can specify what variables to solve/be returned, what constraints you have, and what is the objective.</p>
  <ol>
    <li><em>Decision Variables</em>: the variables you want to solve for, denoted as $x_1, x_2, …, x_{n} \in \R$.</li>
    <li>
      <p><em>Linear Constraints</em>: you can have as many as you want, but each needs to be in the form of:</p>

\[\sum_{j=1}^n a_j x_j \{* \} b_i\]

      <p>where $*$ can be $\le, \ge, =$. (Really all you need is $\le$, because to get $\ge$ you can multiply by $-1$ and to get $=$ you can do both $\le$ and $\ge$.)</p>
    </li>
    <li>
      <p><em>Linear Objective Function</em>: one objective function to maximize or minimize, in the form of:</p>

\[\max \sum_{j=1}^n c_j x_j\]

      <p>or the minimum (again, you can just multiply by $-1$ to get the other one).</p>
    </li>
  </ol>

  <p>note that <strong>you can specify the $a_j,b_i,c_j$</strong>, and the algorithm will solve for the $x_j$.</p>
</blockquote>

<p>A starter example is to consider finding the solution to:</p>

\[\max x_1 + x_2\]

<p>subject to the following (four) linear constraints:</p>

\[\begin{align*}
  x_1 \ge 0 \\
  x_{2} \ge 0 \\
  2x_1 + x_2 \le 4 \\
  x_1 + 2 x_2 \le 1
\end{align*}\]

<p>then obviously this fits directly with the linear programming formulation, where $x_1, x_2$ are the decision variables. Visually, this linear problem does:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231115010146.png" style="zoom:80%;" /></p>

<p>where the</p>
<ul>
  <li><strong>dimension of space</strong> we are working with is specified by the number of decision variables</li>
  <li><strong>constraints</strong> specify the feasible region (the shaded area)</li>
  <li><strong>objective</strong> specifies the direction of optimization (the green arrow)</li>
</ul>

<p>To be more general:</p>

<blockquote>
  <p><strong>Geometric Interpretation of Linear Programs</strong>:</p>
  <ol>
    <li>A linear <strong>constraint</strong> in $n$ dimensions corresponds to a halfspace in $\R^{n}$. Thus a feasible region is an intersection of halfspaces (i.e. many constraints), the higher-dimensional analog of a polygon.</li>
    <li>The <strong>objective function</strong> specifies parallel $(n-1)$ dimensional hyperplans, with a direction vector specified by the vector $\vec{c} = [c_1, …, c_n]$. (in the previous example, $\vec{c} = [1,1]$)</li>
    <li>The <strong>optimal solution</strong> is the point in the feasible region that is furthest in the direction of $\vec{c}$.</li>
    <li>When there is a <em>unique</em> optimal solution, it is vertex (i.e. a corner) of the feasible region.</li>
  </ol>
</blockquote>

<p>besides the above, also note that for any given linear programming problem:</p>
<ul>
  <li>There might be <em>no feasible solutions</em> at all</li>
  <li>optimal objective function value might be <em>unbounded</em>, which the linear programming algorithms should detect if this is the case</li>
  <li>there might be <em>multiple optimal solutions</em>. Whenever the feasible region is bounded, however, there always exists an optimal solution</li>
</ul>

<h2 id="example-applications-of-linear-programming">Example Applications of Linear Programming</h2>

<p>Zillions of problems reduce to linear programming. Here we cover a few interesting ones.</p>

<h3 id="linear-programming-for-maximum-flow">Linear Programming for Maximum Flow</h3>

<p>The problem of maximum literally translates directly to a linear program (though Ford-Fulkerson algorithm is more efficient).</p>

<p>Proof: in maximum flow we wanted to find a flow for each edge $f_e$, such that the sum of flow is maximum, subjective to conservation constraints. This sounds exactly like linear programming:</p>

<ol>
  <li><em>Decision Variables</em>: the flows for each edge ${ f_e }_{e \in E}$</li>
  <li>
    <p><em>Constraints</em>: We needed the conservation contraints, and the capacity constraints</p>

\[\sum\limits_{e  \in \delta^{+}(v)} f_e - \sum\limits_{e \in \delta^{-}(v)} f_e = 0, \quad \forall v \in V \setminus \{s,t\}\]

    <p>which gives $n-2$ constraint equations, where $e  \in \delta^{+}(v)$ means edges going out of $v$ and $e \in \delta^{-}(v)$ means edges going into $v$. Then we additionally have for each edge:</p>

\[f_{e} \le u_e\]

    <p>and finally</p>

\[f_e \ge 0\]

    <p>So in total this is $n-2+2m$ contraints. <mark>Note that these are all linear (each decision variable $f_e$ only appears by itself with some constant)!</mark></p>
  </li>
  <li><em>Objective Function</em>: simply:</li>
</ol>

\[\max \sum\limits_{e \in \delta^{+}(s)} f_e\]

<p>which you can do by specifing a weight $c_j$ to be one only for edges from the source and zero otherwise.</p>

<h3 id="linear-programming-for-minimum-cost-flow">Linear Programming for Minimum-Cost Flow</h3>

<blockquote>
  <p>Problem: in addition to maximum flow, consider two changes:</p>
  <ul>
    <li>there is a cost $c_e$ associated with each unit of flow spent</li>
    <li>
      <p>the flow is required to be exactly $d$</p>

\[\sum_{e \in \delta^{+}(s)} f_e = d\]
    </li>
  </ul>

  <p>so the objective function is to minimize routing over “expensive pipes”:</p>

\[\min \sum_{e \in E} c_e f_e\]

</blockquote>

<p>Notice that this can be reduced to the <em>same linear program</em> in the previous section, but with:</p>

<ul>
  <li>an additional constraint: $\sum_{e \in \delta^{+}(s)} f_e = d$</li>
  <li>objective function changed to $\min \sum_{e \in E} c_e f_e$ (which is linear since $c_e$ are constants)</li>
</ul>

<h3 id="linear-programming-for-regression">Linear Programming for Regression</h3>

<p>We now consider two less obvious applications of linear programming, to basic problems in
machine learning.</p>

<blockquote>
  <p><strong>Regression</strong>: consider inputs of labeled data ${ \vec{p}^{1}, \vec{p}^{2}, …, \vec{p}^{m} }$ consisting of $m$ data points in $\R^{d}$, and their corresponding labels ${ y^{1}, y^{2}, …, y^{m} }$, where $y^{i} \in \R$.</p>
  <ul>
    <li>for example, a dataset of features of $m$ undergraduate students, and $y^{i}$ are their GPAs.</li>
  </ul>

  <p>The goal is to find a linear function $h(\vec{z}) = \vec{w} \cdot \vec{z} + b= \sum_{i=1}^{d} w_i z_i + b$ that fits this data as well as possible.</p>
</blockquote>

<p>We now show that computing the best line under the definition of <strong>minimizing absolute error</strong> can be formulated as a linear program (for the more common one, mean squared error, check the ML notes).</p>

<p>First recall that for a $d$-dimensional space, a linear function $h  : \R^{d} \to \R$ has the form:</p>

\[h(\vec{z}) = \vec{w} \cdot \vec{z} + b = \sum_{i=1}^{d} w_i z_i + b\]

<p>where the <strong>coefficients $w_i$’s and $b$ are unknown</strong>. The absolute error for one data point is defined as:</p>

\[E_i ( \vec{w} ,b) = \left| \underbrace{\left( \sum\limits_{j=1}^{d} w_j p_j^{i} +b\right)}_{\text{prediction}} - y^{i} \right|\]

<p>and so the total loss over the entire dataset is:</p>

\[\min_{\vec{w} ,b} \sum\limits_{i=1}^{m} E_i(\vec{w} ,b)\]

<p>note that up to this point, this problem had:</p>

<ul>
  <li>$d+1$ decision variables: $\vec{w} ,b$</li>
  <li>no constraints for the weights and bias</li>
  <li>a nonlinear objective function (because it used absolute value)</li>
</ul>

<p>So how is this linear programmable? The trick is we can <strong>convert the absolute value in objective function to become constraints</strong>. Consider introducing $m$ new decision variables $e_1, e_2, … , e_m$ which would represent  $E_i ( \vec{w} ,b)$. We make it look like it can choose $e_i$, but in fact not because we know:</p>

\[| x| = \max \{ x, -x \}\]

<p>so we can get inequalities to represent absolute values:</p>

\[e_{i} \ge \left( \sum\limits_{j=1}^{d} w_j p_j^{i} +b \right) - y^{i} \\
e_{i} \ge - \left( \sum\limits_{j=1}^{d} w_j p_j^{i} +b \right) + y^{i}\]

<p>and the objective function is:</p>

\[\min \sum\limits_{i=1}^{m} e_i\]

<p>so that now we consider</p>

<ul>
  <li>$d+1+m$ decision variables: $\vec{w} ,b, e_1, e_2, … , e_m$</li>
  <li>$2m$ constraints for the weights and bias</li>
  <li>a linear objective function where obtaining the best $e_i$’s becomes obtaining the best absolute error (think about obtaining a better $e_i$ subject to this contraint is the same as obtaining $\vec{w},b$ with a lower loss )</li>
</ul>

<p>note that the $e_i$ under the hood <mark>aren't ''free'' variables</mark>:</p>
<ul>
  <li>After the program found out about $w_j$ and $b$, the $e_i$’s are determined by picking to be <strong>as close as possible to the inequality (i.e. represents the absolute error)</strong> because of the objective function being a minimizer</li>
  <li>then, the objective function also correctly represents the total absolute error</li>
</ul>

<h3 id="linear-programming-for-linear-classifier">Linear Programming for Linear Classifier</h3>

<blockquote>
  <p><strong>Linear Classifier</strong>: consider inputs of binary classification, where you get $m$ positive data points $\vec{p}^{1}, …, \vec{p}^{m} \in \R^{d}$ and $m’$ negative data points $\vec{q}^{1}, …, \vec{q}^{m’} \in \R^{d}$.</p>

  <p>The goal is to compute a linear function $h(\vec{z}) = \vec{w} \cdot \vec{z} + b= \sum_{i=1}^{d} w_i z_i + b$ that separates the positive and negative data points as well as possible. In other words:</p>

\[h(\vec{p}^{i}) &gt; 0, \quad \forall i \in [m] \\\]

  <p>and for negative points:</p>

\[h(\vec{p}^{i}) &lt; 0, \quad \forall i \in [m'] \\\]

</blockquote>

<p>Visually, it looks likes:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms/image-20231115015439.png" style="zoom:80%;" /></p>

<p>Assuming there exists such a classifier, the problem almost looks exactly like a linear program, except that we have strict inequalities here. Again, the simple trick of adding an extra decision variable solves the problem.</p>

<p>To encode this strict inequality, we introduce a new decision variable $\delta$ representing the <mark>margin</mark> by which the nearest data point is on the correct side of the decision boundary. Then we have a new constraint with <strong>inequality</strong>:</p>

\[\sum\limits_{j=1}^{d} w_j p_j^{i} +b \ge \delta, \quad \forall i \in [m] \\
\sum\limits_{j=1}^{d} w_j q_j^{i} +b \le -\delta, \quad \forall i \in [m']\]

<p>with the objective of maximzing the margin $\delta$:</p>

\[\max \delta\]

<p>so that we have a linear program with:</p>
<ul>
  <li>$d+2$ decision variables: $\vec{w} ,b, \delta$</li>
  <li>$m + m’$ constraints for the weights and bias</li>
  <li>a linear objective function</li>
</ul>

<p>(note that this looks awfully like SVM)</p>

<hr />

<p><strong>However, what if the points <em>aren’t</em> perfectly separable?</strong> In SVM we had slack varittlables, but here we can consider another extension: allow for errors, but penalize them.</p>

<p>More specifically, let’s say that in a perfect world, we would like a linear function $h$ such that:</p>

\[h(\vec{p}^{i}) &gt; 1, \quad \forall i \in [m] \\\]

<p>and</p>

\[h(\vec{q}^{i}) &lt; -1, \quad \forall i \in [m'] \\\]

<p>where the constant $1$ is a bit arbitrary here. Though the goal is to consider a <strong>hinge loss</strong> such that it penalizes on incorrect classifications, but gives zero loss as long as you have a correct classification with a margin of at least $1$:</p>

\[\mathrm{loss} = \begin{cases}
  \max \{1 - h(\vec{p}^{i}), 0 \}, \quad \text{for positive points}\\
  \max \{1 + h(\vec{q}^{i}), 0 \}, \quad \text{for negative points}
\end{cases}\]

<p>so then our task is to find a linear function that <strong>minimizes total hinge loss</strong>. While hinge loss looks non-linear, it really is just the maximum of two linear functions. We claim that this can be formulated as a linear program with constraints:</p>

\[\begin{align*}
  e_i &amp;\ge 1 - \left( \sum\limits_{j=1}^{d} w_{j} p_j^{i} +b \right), \quad \text{for every positive point $\vec{p}^i$ }\\
  e_i &amp;\ge 1 + \left( \sum\limits_{j=1}^{d} w_{j} q_j^{i} +b \right), \quad \text{for every negative point $\vec{q}^i$ }\\
  e_i &amp;\ge 0, \quad \text{for every point}
\end{align*}\]

<p>which is basically the hinge-loss, and then the objective is:</p>

\[\min \sum\limits_{i=1}^{m} e_i\]

<p>so again, we introduced $m$ new decision variables $e_i$ <mark>which aren't real ''free'' variables</mark>:</p>
<ul>
  <li>After the program found out about $w_j$ and $b$, the $e_i$’s under the hood are determined by picking to be as close as possible to the inequality (i.e. represents the hinge loss) because of the objective function being a minimizer</li>
  <li>then, the objective function also correctly represents the total hinge lossa</li>
</ul>]]></content><author><name></name></author><category term="2023@Columbia" /><summary type="html"><![CDATA[*Picture credits from the Algorithms Illuminated book]]></summary></entry><entry><title type="html">CSOR4231 Analysis of Algorithms part2</title><link href="/lectures/2023@columbia/CSOR4231_Analysis_of_Algorithms_part2.html/" rel="alternate" type="text/html" title="CSOR4231 Analysis of Algorithms part2" /><published>2024-01-20T00:00:00+00:00</published><updated>2024-01-20T00:00:00+00:00</updated><id>/lectures/2023@columbia/CSOR4231_Analysis_of_Algorithms_part2</id><content type="html" xml:base="/lectures/2023@columbia/CSOR4231_Analysis_of_Algorithms_part2.html/"><![CDATA[<h1 id="np-hard-problems">NP-Hard Problems</h1>

<p>Beyond the collection of efficient algorithms we have talked about? In the first part of the notes, we have seen problems such as sorting, graph search, shortest path, MST, etc being solved in almost linear time. Here, we essentially discuss the class of problems for which <strong>NO fast algorithms are KNOWN</strong> (notice the distinction between “no fast algorithms exist” and “no fast algorithms are known”).</p>

<h2 id="the-traveling-salesman-problem">The Traveling Salesman Problem</h2>

<p>By definition, this looks <em>very</em> alike MST:</p>

<blockquote>
  <p><strong>Traveling Salesman Problem Definition</strong>: given a <em>complete</em> undirected graph $G=(V,E)$ and a real-valued cost $c_e$ for each edge $e\in E$, find a minimum-cost tour that visits each vertex exactly once.</p>
  <ul>
    <li>difference from MST: MST is a <em>spanning tree</em> while TSP is a <em>tour</em>.</li>
    <li>technically MST had only needed “connected” graph, which is actually <em>more general</em> (as you can mimic non-complete graphs by having some edges cost $\infty$)</li>
  </ul>
</blockquote>

<p>How many distinct tours are there? Since each tour is a cycle, we have $n! / (2n)$ because for each vertex, it is repeated twice (once as start, once as end).</p>

<p>Despite significant effort, until today (2023) there is no known fast algorithm for the TSP.</p>

<blockquote>
  <p>Conjecture: maybe no fast algorithm exists for TSP.</p>
</blockquote>

<p>But how do we even attempt to “prove” this? (Spoiler: we kind of don’t. We just try to show TSP is NP-hard $\implies$ solving it efficiently would prove $\mathcal{P} = \mathcal{NP}$, and until today no-one has done it.)</p>

<h2 id="introduction-to-p-and-np">Introduction to P and NP</h2>

<h3 id="polynomial-time-algorithms">Polynomial-Time Algorithms</h3>

<p>So what does it mean to be $\mathcal{P}$?</p>

<blockquote>
  <p><strong>Polynomial-Time Solvable Problems</strong> A problem is in $\mathcal{P}$ if there is a polynomial-time algorithm to solve it.</p>
  <ul>
    <li>polynomial-time algorithm: one that correctly solves the problem with worst-case running time $O(n^k)$ for some constant $k$.</li>
    <li>here $n$ denotes the input size, which you can image as “the number of bits needed to represent the entire input” for a generic problem.</li>
  </ul>
</blockquote>

<h3 id="np-hard-problems-1">NP-hard Problems</h3>

<p>Going back to our original problem: the goal is to gather evidences to show that “there exists no polynomial-time algorithm for TSP”. Just to be clear, no one has proven this yet, but we have some evidence to support this conjecture: to show that TSP is <em>relatively speaking, hard</em>.</p>

<blockquote>
  <p><strong>Strong Evidence of A Problem being Hard</strong>: A polynomial-time algorithm for the TSP would solve thousands of problems (i.e. by reduction), that have resisted the efforts of tens (if not hundreds) of thousands of brilliant minds over many decades.</p>
  <ul>
    <li>basically TSP must be “at least as hard as” any of those other problems.</li>
  </ul>
</blockquote>

<p>More formally, here comes the notion of NP-hardness.</p>

<blockquote>
  <p>Complexity Class $\mathcal{NP}$: a problem is in $\mathcal{NP}$ if</p>
  <ol>
    <li>for every instance of the problem, every candidate <strong>solution can be described</strong> (e.g. in bits) by using, bounded above, <strong>a polynomial function of the input size</strong>.</li>
    <li>for any of the candidate solutions, we can <strong>verify in polynomial time</strong> whether it is indeed a valid solution.</li>
  </ol>
</blockquote>

<p>Notice that by this definition, almost all the search problems that you’ve seen qualify for $\mathcal{\mathcal{NP}}$. But additionally, let every candidate solution be described in $O(n^{d})$ bits, for an instance of the problem having input size $n$. Then, an exhaustive search algorithm over all solutions is:</p>

\[O(2^{O(n^{d})}) \times O(n^{k}) = O(2^{O(n^{d})})\]

<p>where:</p>
<ul>
  <li>since every solution can be described/encoded in $O(n^{d})$ <strong>bits</strong>, there are $2^{O(n^{d})}$ possible solutions.</li>
  <li>the exhaustive search would basically loop over all possible solutions, and for each solution, it would take $O(n^{k})$ time to verify whether it is indeed a valid solution.</li>
  <li>this therefore is <strong>exponential runtime</strong> (but of course, many problems have smart algorithms to solve them)</li>
</ul>

<blockquote>
  <p><strong>NP-hard Problems</strong>: a problem is $\mathcal{NP}\text{-}\mathcal{hard}$ if <strong>every problem</strong> in $\mathcal{NP}$ can be <strong>reduced to it</strong> in polynomial time.</p>
  <ul>
    <li>recall if A reduces to B, then it means we can use B as a black-box to solve A.</li>
    <li>so the consequence is that if you can solve one $\mathcal{NP}\text{-}\mathcal{hard}$ problem in polynomial time, you can solve all $\mathcal{NP}$ problems in polynomial time.</li>
    <li>then $\mathcal{P} = \mathcal{NP}$</li>
  </ul>

  <p>notice that a problem can be $\mathcal{NP}\text{-}\mathcal{hard}$ without being in $\mathcal{NP}$ (see figure at the end of this section)</p>
</blockquote>

<p>We will see a bit later that TSP is $\mathcal{NP}\text{-}\mathcal{hard}$ being a strong evidence that we <em>think there exists no polynomial-time algorithm for TSP</em> (basically by reducing the 3-SAT problem to it, and somebody has already done the hardest work showing that 3-SAT is $\mathcal{NP}\text{-}\mathcal{hard}$)!</p>

<p>But visually this means that there is a bunch of $\mathcal{NP}$ problems $A_i$’s such that:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms_part2/image-20231117004546.png" style="zoom:20%;" /></p>

<p>In addition, since no-one so far has solved in polynomial time any $\mathcal{NP}\text{-}\mathcal{hard}$ problem, we have:</p>

<blockquote>
  <p><strong>Conjecture</strong>: $\mathcal{P} \neq  \mathcal{NP}$. Motivation why it may be true?</p>
  <ul>
    <li>empirical: all you need is one polynomial time algorithm for one $\mathcal{NP}\text{-}\mathcal{hard}$ problem to prove $\mathcal{P} = \mathcal{NP}$, but no one has found it yet.</li>
    <li>philosophical: if $\mathcal{P} \neq  \mathcal{NP}$, then it means “solving a problem is as hard as checking a solution of a problem”. Then life is too easy.</li>
    <li>mathematical: as of today, absent of evidence.</li>
  </ul>
</blockquote>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms_part2/image-20231117010439.png" style="zoom:70%;" /></p>

<p>A “surprising” example of $\mathcal{NP}$ problem: Knapsack:</p>
<ul>
  <li>recall that there is an $O(nC)$-time dynamic programming algorithm for the problem</li>
  <li>but this is NOT polynomial in the size of input. this is a polynomial-time algorithm <em>in the special case in which $C$ is bounded by a polynomial function of $n$.</em></li>
  <li>think of the number of keystrokes to type $C=10$, which is $2$, to $C=100$, which is $3$. The input size increased by $1.5$, but runtime increased by a factor of $10$.</li>
</ul>

<p>Finally, a more complete picture of P, NP, and NP-hard:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms_part2/image-20231118213057.png" style="zoom:35%;" /></p>

<h2 id="simple-reductions-for-np-hardness">Simple Reductions for NP-Hardness</h2>

<p>Recall that we have used reductions before. For instance, to compute the Image Segmentation problem we used a minimum s-t cut algorithm as a black-box (i.e. Image segmentation reduces to minimum s-t cut):</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms_part2/image-20231117011431.png" style="zoom:75%;" /></p>

<p>where we:</p>
<ul>
  <li>assumed that minimum s-t cut is polynomial-time solvable (it is)</li>
  <li>created the image segmentation problem by preprocessing the input (convert to flow graph) and postprocessing the output (convert back)</li>
</ul>

<p>Reductions <strong>will also be used here</strong>, but for the purpose of spreading <strong>intractibiliy or tractibiliy</strong> (i.e. polynomial-time solvability) of a problem.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Tractibility</th>
      <th style="text-align: center">Intractibility</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms_part2/image-20231117014759.png" style="zoom:100%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms_part2/image-20231117014805.png" style="zoom:100%;" /></td>
    </tr>
  </tbody>
</table>

<p>so that more formally:</p>

<blockquote>
  <p><strong>Reductions Spread Tractability</strong>: if $A$ reduces to $B$ and $B$ is solvable in polynomial time, then $A$ is solvable in polynomial time.</p>

  <p><strong>Reductions Spread Intractability</strong>: if $A$ reduces to $B$ and $A$ is not solvable in polynomial time, then $B$ is not solvable in polynomial time.</p>
  <ul>
    <li>think of it as a contrapositive of the previous statement</li>
  </ul>
</blockquote>

<p>We have seen many nice examples of the first part: “spreading tractability”, in addition to the image segmentation problem:</p>
<ul>
  <li>Finding the median of an array of integers reduces to the problem of sorting the array</li>
  <li>The all-pairs shortest path problem reduces to the single-source shortest path problem (iterating over all vertices is still polynomial time)</li>
</ul>

<p>But the latter part: “spreading intractability” is like the <strong>dark-side of the force</strong>, where we use in this case to show many problems are $\mathcal{NP}\text{-}\mathcal{hard}$.</p>
<ul>
  <li>if we know a problem $A$ is $\mathcal{NP}\text{-}\mathcal{hard}$, and we can reduce $A$ to $B$, then $B$ is also $\mathcal{NP}\text{-}\mathcal{hard}$. Why?</li>
  <li>because if $B$ is solvable in polynomial time (the green box in the image segmentation example), then $A$ is also solvable in polynomial time.</li>
  <li>This would imply all other $\mathcal{NP}$ problems are solvable in polynomial time (since $A$ is $\mathcal{NP}\text{-}\mathcal{hard}$). Then $\mathcal{P}=\mathcal{NP}$!</li>
</ul>

<p>Some examples of $\mathcal{NP}\text{-}\mathcal{hard}$ problems?</p>

<p>This also highlights a template for proving if a problem is $\mathcal{NP}\text{-}\mathcal{hard}$:</p>

<blockquote>
  <p><strong>Proving $\mathcal{NP}\text{-}\mathcal{hard}$</strong>: to prove a problem $B$ is $\mathcal{NP}\text{-}\mathcal{hard}$, we can:</p>
  <ol>
    <li>find/choose an existing $\mathcal{NP}\text{-}\mathcal{hard}$ problem $A$.</li>
    <li>Prove that $A$ reduce to $B$ in polynomial time. (i.e. can use $B$ to solve $A$)</li>
  </ol>
</blockquote>

<h3 id="np-hardness-of-cycle-free-shortest-paths">NP-Hardness of Cycle-Free Shortest Paths</h3>

<p>Here we discuss an example of known $\mathcal{NP}\text{-}\mathcal{hard}$ problems, and how we can use reduction to show that another problem we discussed in the first part of the notes is also $\mathcal{NP}\text{-}\mathcal{hard}$.</p>

<p>Recall that we had this problem:</p>

<blockquote>
  <p><strong>Cycle-Free Shortest Path (CFSP)</strong>: given a directed graph $G=(V,E)$ with real-valued edge costs $c_{e} \in \R$ and a source vertex $s$, find a <strong>shortest cycle-free path</strong> from $s$ to every other vertex in $G$. If there is no $s-v$ path for some $v$, report $+\infty$ for them.</p>
  <ul>
    <li>why did we want cycle free? The problem is that if we had <em>negative cycles</em>, then the shortest path would be $-\infty$</li>
    <li>in the first part of the notes, we have seen Bellman-Ford algorithm which find shortest path and “detect negative cycles” in $O(mn)$ time, i.e. <code class="language-plaintext highlighter-rouge">break</code> when there is a negative cycle.</li>
  </ul>
</blockquote>

<p>We want to prove that this version of the problem is $\mathcal{NP}\text{-}\mathcal{hard}$</p>

<blockquote>
  <p><strong>Directed Hamiltonian Path (DHP)</strong>: given a directed graph $G=(V,E)$, output “yes” if there exists a directed path that visits each vertex exactly once, and “no” otherwise.</p>

  <p>This is a famous $\mathcal{NP}\text{-}\mathcal{hard}$ problem in computer science.</p>
</blockquote>

<p>Now we want to show that DHP reduces to CFSP. Therefore since DHP is $\mathcal{NP}\text{-}\mathcal{hard}$, CFSP is also $\mathcal{NP}\text{-}\mathcal{hard}$.</p>

<hr />

<p><em>Proof</em>: The key question to think is: how do we use a subroutine for the cycle-free shortest path problem to solve the directed Hamiltonian path problem? In the former it will find shortest cycle-free path, whereas the latter needs a path that visits each vertex exactly once. Some key insights would be:</p>

<ul>
  <li>trick the CFSP into thinking that <strong>long paths (like an s-t Hamiltonian path) are actually short</strong></li>
  <li>to achieve this, we can assign $c_{e} = -1$ for every edge $e$ in the graph</li>
</ul>

<p>Therefore, consider the following reduction for DHP:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms_part2/image-20231117162336.png" style="zoom:70%;" /></p>

<p>Why can this algorithm (embedded with CFSP subroutine) solve DHP, i.e. is <strong>correct</strong>? To show this, we need to prove that this algorithm will output “yes” if and only if there is a Hamiltonian path in the graph. Notice that:</p>

<ul>
  <li>in the constructed cycle-free shortest paths instance, the <strong>minimum length of a cycle-free s-t path equals $-1$ times the maximum number of hops</strong></li>
  <li>given a $s,t$, how do we get maximum hops in this case? Visit as many vertices as possible.</li>
  <li>therefore, a cycle-free shortest path uses $\vert V\vert  - 1$ hops at most, in which case it is a Hamiltonian path.</li>
</ul>

<p>Hence, we just need to check if the shortest path from $s$ to $t$ is of length $-(\vert V\vert  - 1)$. This would correctly solve DHP problem.</p>

<h2 id="rookie-mistakes-and-acceptable-inaccuracies">Rookie Mistakes and Acceptable Inaccuracies</h2>

<p>Here are a few common misunderstandings about the notion of $\mathcal{NP}\text{-}\mathcal{hard}$.</p>

<p><strong>Rookie Mistakes:</strong> (plain wrong)</p>

<ol>
  <li>thinking $\mathcal{NP}$ stands for “not polynomial time solvable”</li>
  <li>using $\mathcal{NP}$ and $\mathcal{NP}\text{-}\mathcal{hard}$ interchangeably.
    <ul>
      <li>this is because in $\mathcal{NP}$ is actually a “good thing”. as it tells us a problem can be verified in polynomial time (but says nothing about how quickly we can solve it)</li>
    </ul>
  </li>
</ol>

<p><strong>Acceptable Inaccuracies:</strong></p>

<ol>
  <li>Assuming $\mathcal{P} \neq \mathcal{NP}$ is true</li>
  <li>Using the terms $\mathcal{NP}\text{-}\mathcal{hard}$ and $\mathcal{NP}\text{-}\mathcal{complete}$ interchangeably.
    <ul>
      <li>$\mathcal{NP}\text{-}\mathcal{complete}$ is a subset of $\mathcal{NP}\text{-}\mathcal{hard}$, and the practical implications is the same as $\mathcal{NP}\text{-}\mathcal{hard}$.</li>
      <li>assuming $\mathcal{P} \neq \mathcal{NP}$ is true, then both $\mathcal{NP}\text{-}\mathcal{hard}$ and $\mathcal{NP}\text{-}\mathcal{complete}$ are not solvable in polynomial time.</li>
    </ul>
  </li>
  <li>Conflating $\mathcal{NP}\text{-}\mathcal{hard}$ with requiring exponential time in the worst case</li>
</ol>

<h1 id="compromising-on-correctness-efficient-inexact-algorithms">Compromising on Correctness: Efficient Inexact Algorithms</h1>

<p>At the end of the day, you still have to come up with <em>some algorithms</em> to solve NP-hard problems. Because it’s NP-hard, you (probably) are confident that your algorithm can only <strong>achieve two out of the three</strong> properties:</p>
<ol>
  <li>fully general</li>
  <li>always correct</li>
  <li>fast</li>
</ol>

<p>In fact, we have <strong>already seen algorithms that compromises on generality</strong> over this course. For instance:</p>
<ul>
  <li>Dijkstra’s algorithm assumes non-negative edge costs</li>
  <li>Bellman-Ford algorithm assumes graphs without negative cycles</li>
  <li>Maximum Weighted Independent Set assumes path graphs</li>
  <li>a polytime Knapsack algorithm assumes $C$ is bounded by a polynomial function of $O(n^{k})$</li>
</ul>

<p>Therefore, instead of compromising on generality, in this section we will discuss algorithms that <mark>compromise on correctness</mark>, i.e. they are <em>NOT always correct</em>, but often we can <em>quantify an upper-bound of how much error they can make</em>.</p>

<blockquote>
  <p>Note: this makes <em>greedy algorithms</em> particularly suitable for this purpose, as they are often fast and general, but not always correct.</p>
</blockquote>

<h2 id="makespan-minimization">Makespan Minimization</h2>

<p>This is another scheduling problem like the one we have seen in the first part of the notes, but we have a few changes:</p>

<blockquote>
  <p><strong>Makespan Minimization</strong>: given $n$ jobs with processing times $l_{i}$, and $m$ machines, find an assignment of jobs to machines that minimizes the <strong>makespan</strong>, i.e. the maximum completion time of all jobs.</p>
  <ul>
    <li>basically a “multi-processing” version of the scheduling problem we have seen before</li>
    <li>goal is to minimize the “latest” finishing job</li>
  </ul>
</blockquote>

<p>For example, consider four jobs with processing time $l_1=2, l_2=2, l_3=1, l_4=3$, and two schedules:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms_part2/image-20231122003057.png" style="zoom:80%;" /></p>

<p>the first one will have makespan $4$, and the second one will have makespan $5$ due to the jobs on the first machine. So intuitively, we an ideal schedule would have a <mark>perfectly balanced-load on every machine</mark>. But unfortunately:</p>

<blockquote>
  <p><strong>Makespan Minimization is NP-Hard</strong>: there is (currently) no polynomial-time algorithm for makespan minimization</p>
</blockquote>

<p>So what kind of algorithm can solve this in a general case, is fast, but may not always give us the best answer?</p>

<h3 id="grahams-algorithm">Graham’s Algorithm</h3>

<p>The intuition is that our goal is create a balanced load on every machine, so that the makespan is minimized. Therefore, we can just have a greedy algorithm that iteratively assigns the next job to the machine with the smallest load.</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms_part2/image-20231122003624.png" style="zoom:70%;" /></p>

<p>where for a fast <code class="language-plaintext highlighter-rouge">argmin</code> implementation, we can use a min-heap to keep track of the smallest load machine. But why this algorithm specifically? It turns out that this is not only fast (with min-heap) giving $O(n \log m)$, but also guarantees a rather good error bound.</p>

<h3 id="grahams-algorithm-error-bound">Graham’s Algorithm Error Bound</h3>

<p>First, let’s demonstrate one example where Graham’s algorithm is not optimal. Consider having 20 jobs with processing time $l_i = 1$ for all $i$, and one last job with processing time $l_{21} = 5$. Suppose we have $m=5$ machines. Then:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Graham’s Algorithm</th>
      <th style="text-align: center">Optimal Solution</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms_part2/image-20231122004228.png" style="zoom:70%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms_part2/image-20231122004240.png" style="zoom:70%;" /></td>
    </tr>
  </tbody>
</table>

<p>where Graham would output a makespan of $9$, whereas the optimal solution would be $5$. This is quite bad, but can it be worse? The answer is actually no, that this is as bad as it can get.</p>

<blockquote>
  <p><strong>Graham’s Algorithm Error Bound</strong>: Graham’s algorithm is guaranteed to produce a schedule with makespan $\le 2$ times the optimal makespan.</p>
  <ul>
    <li>with some algorithmic modifications, we can actually get the error bound to $4/3$ times the optimal makespan.</li>
    <li>technically, it is $2 - 1/m$, where $m$ is the number of machines</li>
    <li>technically, it is $\le 2$ <em>any possible optimal makespan</em></li>
    <li>in practice, Graham’s (often) does much better than this error bound.</li>
  </ul>
</blockquote>

<p>But how can we even go about proving it if we don’t even know what the optimal solution is (as it is NP-hard)? The key idea is to compare with the <em>lower bound</em> of what any optimal solution can achieve, i.e., a perfect load balance.</p>

<p><em>Proof</em>: First, we need to consider the lower bound of this problem. Let the minimum possible makespan schedule be $M^{*}$. Then:</p>

<ol>
  <li>
    <p><strong>Lower Bound #1:</strong> every job needs to be processed, so the best completion time must be at least as big than any of the processing time:</p>

\[M \ge l_{j}\quad \forall j \in \{1, \ldots, n\}\]

    <p>or alternatively $M^{*} \ge \max l_j$.</p>
  </li>
  <li>
    <p><strong>Lower Bound #2:</strong> as the best case scenario is to have a perfectly balanced load (why? If not, one machine will have a larger load and another smaller. But since the objective is the <em>maximum makespan</em>, it is strictly worse):</p>

\[M^{*} \ge \frac{1}{m} \sum_{j=1}^{n} l_{j}\]
  </li>
</ol>

<p>Now we consider the lower bound of Graham’s algorithm. Let $M$ be the makespan of the schedule produced by Graham’s algorithm. Consider the “worst” machine that contributed to this load $M$, i.e. the machine with <strong>largest load $L_i$ such that $L_{i} = M$</strong>. Rewind the algorithm to the point where that machine was assigned its last job $j$, and let $\hat{L}_i$ denote that machine’s load at that point. So that obviously:</p>

\[M = L_{i} = \hat{L}_{i} + l_{j}\]

<p>But how big was $\hat{L}_{i}$? By the greedy criterion of the algorithm, it must have looked like this (if that machine is #1):</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms_part2/image-20231122013331.png" style="zoom:90%;" /></p>

<p>i.e. it must be <strong>the lightest loaded before $j$ is assigned</strong>. How light can that be?:</p>

\[\hat{L}_{i} \le \frac{1}{m} \sum_{k=1}^{j-1} l_{k}\]

<p>since the lightest load you can get at that point in time is a perfectly balanced load. Now since the comparison we need to make is:</p>

\[M = \hat{L}_i + l_{j} \le l_{j} + \frac{1}{m} \sum_{k=1}^{j-1} l_{k} \le \text{something }M^{*}\]

<p>we consider the following “tricks”:</p>

<ul>
  <li>
    <p>transform the above expression:</p>

\[M \le l_{j} + \frac{1}{m} \sum_{k=1}^{j-1} l_{k} \le l_{j} + \frac{1}{m} \sum_{k \neq j} l_{k}\]

    <p>where we basically added a bunch of terms ($l_{j+1} / m, l_{j+2} / m, …$ ) so that RHS is of course larger or equal to LHS</p>
  </li>
  <li>
    <p>the second term above is almost comparable with $M^{*}$, so we do some minor arithmetic operations:</p>

\[l_{j} + \frac{1}{m} \sum_{k \neq j} l_{k} = l_{j} - \frac{l_j}{m} + \frac{1}{m} \sum\limits_{k=1}^{n}l_{k} = \left( 1- \frac{1}{m} \right) l_{j}  + \frac{1}{m} \sum\limits_{k=1}^{n}l_{k}\]
  </li>
</ul>

<p>Now we can use the lower bound we found above</p>

\[M \le \left( 1- \frac{1}{m} \right) l_{j}  + \frac{1}{m} \sum\limits_{k=1}^{n}l_{k} \le \left( 2 - \frac{1}{m} \right) M^{*}\]

<p>because using lower bound #1 we know $\left( 1- \frac{1}{m} \right) l_{j} \le \left( 1- \frac{1}{m} \right) M^{<em>}$ and lower bound #2 tells us $\frac{1}{m} \sum\limits_{k=1}^{n}l_{k} \le M^{</em>}$. This completes the proof.</p>

<h3 id="longest-processing-time-first">Longest Processing Time First</h3>

<p>Here we discuss a modification of Graham’s algorithm that can achieve a better error bound of $4/3$ times the optimal makespan. The observation is that:</p>
<ul>
  <li>in the contrieved example where we showed Graham’s algorithm is not optimal (given 20 jobs with processing time $l_i = 1$ for all $i$ …), if only the <em>algorithm considered the longest processing time job first</em>, then it would have been optimal.</li>
  <li>in the error bound proof, we see that it advocates for <strong>making the last job assigned to the least loaded machine as small as possible</strong>.</li>
</ul>

<p>This gives the longest processing time first algorithm, which <strong>saves those small jobs for the end</strong>:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms_part2/image-20231122015101.png" style="zoom:70%;" /></p>

<p>again, this algorithm is not always correct, but it is guaranteed to produce a schedule with makespan $\le 3/2$ times the optimal makespan. How?</p>

<hr />

<p>Proof: similar to the original Graham algorithm, we start with some lower bounds. Consider we have sorted the jobs from <mark>longest to shortest</mark>, so that the $j$-th job is <em>longer</em> than the $j+1$-th job.</p>

<ul>
  <li>
    <p><strong>Modified Lower bound #1</strong>: if $M^{<em>}$ denotes the minimum possible makespan, and say we have scheduled the first $m$ jobs (i.e. one for each machine). Let $j$ be *any</em> job after the first $m$ jobs. Then:</p>

\[M^{*} \ge 2l_j\]

    <p>which is evident by the pigeon-hole principle: the new job $j$ means we have now ay least $m+1$ jobs to schedule $\implies$ at least one machine had two jobs on it $\implies$ that machine has at least twice the time of $l_j$ since $l_j$ is the shortest amongst those $m+1$ jobs, by construction.</p>
  </li>
</ul>

<p>Now, the trick to prove this $3 / 2$ bound is to realize that we can improve the final inequality in the previous proof by having $\left( 1- \frac{1}{m} \right) l_{j} \le \left( 1- \frac{1}{m} \right) (M^{*} / 2)$! Why?</p>

<ul>
  <li><strong>in the same analysis as before, we consider $M$ with the “worst machine” that just got assigned the final job $j$</strong>.</li>
  <li>there needs to be at least one job assigned to that machine <em>prior to $j$</em> (otherwise it means there are in total $\le m$ jobs to assign $\implies$ Graham will return the optimal schedule with one job per machine)</li>
  <li>this means that job $j$ is after the sorted first $m$ jobs, hence the inequality in modified lower bound applies.</li>
</ul>

<p>Plugging this in our previous last step:</p>

\[M \le \left( 1- \frac{1}{m} \right) l_{j}  + \frac{1}{m} \sum\limits_{k=1}^{n}l_{k} \le \left( 1 - \frac{1}{m} \right) \frac{M^{*}}{2} + M^{*} = \left( \frac{3}{2} - \frac{1}{2m} \right) M^{*}\]

<p>which has a better error bound as the original Graham.</p>

<h2 id="maximum-coverage-problem">Maximum Coverage Problem</h2>

<blockquote>
  <p><strong>Maximum Coverage Problem</strong>: given a collection of <em>subsets</em> $A_1, …, A_{m} \subseteq U$ and a universal ground set $U$, and a number $k$, pick $k$ subsets that reaches <strong>the most coverage</strong>, i.e. the most number of elements in $U$.</p>
  <ul>
    <li>e.g. $A_i$ could represent the programming languages candidate $i$ is familiar with, and $U$ is the set of all programming languages in the world</li>
    <li>e.g. the goal is to assemble $k$ candidates such that they cover the most number of programming languages in the world</li>
  </ul>

  <p>a bit more formally, pick a choice $K$:</p>

\[K \subseteq \{1, ..., m\}, \quad |K| = k\]

  <p>such that $f_{\mathrm{cov}}(K)$ is maximized:</p>

\[f_{\mathrm{cov}}(K) = \left|\bigcup_{i \in K} A_{i}\right|\]

</blockquote>

<p>Again, this problem is NP-hard, so we want to come up with an algorithm that is almost always correct. Consider the case when $k=1$: just pick $A_i$ with the largest size. But what about $k=2$? So the intuition is to maybe pick the second subset that <strong>increases coverage the most</strong>:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms_part2/image-20231122015923.png" style="zoom:80%;" /></p>

<p>This looks good, but when does it break? What is its error bound?</p>

<p>Consider the following example of three subsets with a budget $k=2$:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Input</th>
      <th style="text-align: center">Greedy Output</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms_part2/image-20231122020358.png" style="zoom:65%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms_part2/image-20231122020558.png" style="zoom:65%;" /></td>
    </tr>
  </tbody>
</table>

<p>where you can achieve all elements by picking $A_1, A_2$. But if $A_3$ is a bit larger than $1 / 2$, then the algorithm would pick $A_3$ and you are immediately screwed: you would only cover about 75% of the elements. Similarly, consider this with budget $k=3$:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Input</th>
      <th style="text-align: center">Greedy Output</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms_part2/image-20231122020303.png" style="zoom:60%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms_part2/image-20231122020858.png" style="zoom:60%;" /></td>
    </tr>
  </tbody>
</table>

<p>where again, we can trick the greedy algorithm to pick $A_5$ first. Then, this would decrease the contribution of picking $A_1, A_2, A_3$ as they would only roughly contribute $(1 / 3)(2 / 3) = 2 / 9$ portions. Therefore, we can then trick the algorithm to pick $A_4$. Finally, choosing either one of $A_1, A_2, A_3$ would only result in $1 - 2 \times (1 / 3) (4 / 9) = 19 /27 \approx 70\%$ of the total size. But obviously the optimal solution would be to pick $A_1, A_2, A_3$.</p>

<p>Interestingly, before we go into the error bound, we already observe that (if you extend this example to arbitrary $k$):</p>

<blockquote>
  <p><strong>Bad Examples of GreedyCoverage</strong>: for every positive interger $k$, we can come up with an instance such that:</p>
  <ul>
    <li>there exists $k$ subsets that reaches $100\%$ coverage</li>
    <li>the greedy algorithm picks $k$ subsets <em>might only cover $1 - (1 - 1/k)^{k}$ fraction of the elements</em>.</li>
  </ul>

  <p>But since by definition:</p>

\[e = \lim _{n \rightarrow \infty}\left(1+\frac{1}{n}\right)^{n}\]

  <p>this is approximately, as $k \to \infty$:</p>

\[\lim _{k \rightarrow \infty} 1 - \left(1 - \frac{1}{k}\right)^{k} \approx 1 - \frac{1}{e} \approx 63\%\]

</blockquote>

<p>So in those particular constructions, GreedyCoverage may cover only upto $63\%$ of the elements. But what about the general case? Is this generic enough?</p>

<h3 id="greedycoverage-error-bound">GreedyCoverage Error Bound</h3>

<p>It turns out this expression is general for GreedyCoverage, and in fact, it was proven (in other ways) that the number $1 - \frac{1}{e}$ is intrinsic to the maximum coverage problem.</p>

<blockquote>
  <p><strong>GreedyCoverage Error Bound</strong>: the coverage of the greedy algorithm is guaranteed to cover at least $1 - (1 - \frac{1}{k})^{k}$ fraction of the maximum-possible coverage (i.e.. worst-case scenario) for any instance of the problem.</p>
  <ul>
    <li>note that guaranteeing to cover $100\%$ would, of course, become an algorithm that is always correct.</li>
  </ul>
</blockquote>

<p>To prove this, we need to consider some key lemmas:</p>

<blockquote>
  <p><strong>Lemma 20.8</strong>: consider pausing the algorithm when it has picked $j$ subsets, and let $C_j$ denote the coverage achieved at that point. For each such $j = {1,2, …, k}$, the $j$-th subset we just picked must cover <em>at least</em> $\frac{1}{k}(C^{*} - C_{j-1})$ new elements so that:</p>

\[C_j - C_{j-1} \ge \frac{1}{k}(C^{*} - C_{j-1})\]

  <p>where $C^{*}$ is the maximum possible coverage with $k$ subsets.</p>
</blockquote>

<p><em>Proof</em>: let $K_{j-1}$ denote the indices of the $j-1$ subsets picked so far, and $C_{j-1}$ its coverage. Any potential $\hat{K}$ (may or may not be optimal) that contains $k$ indices, and $W$ be the set of elements covered by $\hat{K}$ <em>but not by $K_{j-1}$</em>:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms_part2/image-20231122023659.png" style="zoom:80%;" /></p>

<p>where in the above example, basically $K_{j-1} = {4,5}$ and the alterative $\hat{K}=K^{*}$. Then this means:</p>

\[\sum\limits_{i \in \hat{K}} \left[ \underbrace{f_{\mathrm{cov}}(K_{j-1} \cup \{i\} - C_{j-1})}_{\text{coverage increase by adding $A_i$ into our collection }} \right] \ge W \ge \hat{C} - C_{j-1}\]

<p>where:</p>
<ul>
  <li>the inequality on the RHS is obvious, as $W$ is the gap</li>
  <li>the inequality on the LHS holds because each element in $W$ must came from one of the subsets in $\hat{K} \implies$ adding every subset in $\hat{K}$ to $K_{j-1}$ must have covered at least all $W$ elements.</li>
</ul>

<p>Next, since the sum on the LHS has $k$ terms, this means:</p>

\[\max_{i \in \hat{K}} \left[ f_{\mathrm{cov}}(K_{j-1} \cup \{i\} - C_{j-1}) \right] \ge \frac{1}{k} \sum\limits_{i \in \hat{K}} \left[ f_{\mathrm{cov}}(K_{j-1} \cup \{i\} - C_{j-1}) \right] \ge \frac{1}{k} (\hat{C} - C_{j-1})\]

<p>Finally we consider $K^{*}$ instead of $\hat{K}$, where the inequality still holds as our argument was for any candidate $\hat{K}$:</p>

\[\underbrace{\max_{i \in K^{*}} \left[ f_{\mathrm{cov}}(K_{j-1} \cup \{i\} - C_{j-1}) \right]}_{\text{i.e. GreedyCoverage can at LEAST pick this subset in the next iteration}} \ge \frac{1}{k} (C^{*} - C_{j-1})\]

<p>Therefore:</p>

\[C_j - C_{j-1} \ge \frac{1}{k}(C^{*} - C_{j-1})\]

<hr />

<p>Finally, we can prove the bound by iterating over all $j$ using the above lemma, staring with $k$:</p>

\[C_{k} \ge C_{k-1} + \frac{1}{k}(C^{*} - C_{k-1}) = \frac{C^{*}}{k}  + \left( 1 - \frac{1}{k} \right) C_{k-1}\]

<p>applying again for $C_{k-2}$:</p>

\[\begin{align*}
   C_{k} 
   &amp;\ge \frac{C^{*}}{k}+ \left( 1 - \frac{1}{k} \right)\left( \frac{C^{*}}{k}+ \left( 1 - \frac{1}{k} \right) C_{k-2} \right) \\
   &amp;= \frac{C^{*}}{k}+ \left( 1 - \frac{1}{k} \right) \frac{C^{*}}{k}+ \left( 1 - \frac{1}{k} \right)^{2} C_{k-2}\\
   &amp;= \frac{C^{*}}{k}+ \left( 1 - \frac{1}{k} \right) \frac{C^{*}}{k}+ \left( 1 - \frac{1}{k} \right)^{2} \frac{C^{*}}{k} + ... \left( 1 - \frac{1}{k} \right)^{k-1} \frac{C^{*}}{k}\\
\end{align*}\]

<p>where for the last inequality we assumed $C_0=0$. This is basically a geometric series with:</p>

\[\begin{align*}
   C_{k} 
   &amp;\ge \frac{C^{*}}{k} \left( 1 + \left( 1-\frac{1}{k} \right) + \left( 1-\frac{1}{k} \right) ^{2} + ... + \left( 1-\frac{1}{k} \right)^{k-1}\right)\\
   &amp;= \frac{C^{*}}{k} \left( \frac{1 - \left( 1-\frac{1}{k} \right)^{k}}{1 - \left( 1-\frac{1}{k} \right)} \right)\\
   &amp;= C^{*}\left( 1 - \left( 1 - \frac{1}{k} \right)^{k} \right)
\end{align*}\]

<p>i.e. GreedyCoverage will cover at least $1 - (1 - \frac{1}{k})^{k}$ fraction of the maximum-possible coverage.</p>

<h1 id="compromising-on-speed-exact-inefficient-algorithms">Compromising on Speed: Exact Inefficient Algorithms</h1>

<p>The goal here is to design a general-purpose and correct algorithm that is <strong>as fast as possible</strong>, and certainly <strong>faster than exhaustive search</strong>, on as many inputs as possible. Yes, it is <em>still exponential-time,</em> but the in practice the runtime will be much better than exhaustive search.</p>

<p>Just as greedy algorithm played a key role in the previous section, <strong>dynamic programming</strong> will play a key role here. Recall that to dynamic programming many involves:</p>
<ul>
  <li>reasoning about the <strong>structure of an optimal solution</strong> which contains optimal solution to <strong>smaller subproblems</strong> (e.g. see WIS, Knapsack, etc.)</li>
  <li>iteratively construct solutions from small subproblems</li>
  <li>is much faster than exhaustive search, <em>if the set of subproblems are small</em></li>
</ul>

<h2 id="the-bellman-held-karp-algorithm-for-the-tsp">The Bellman-Held-Karp Algorithm for the TSP</h2>

<p>Before discussing how to solve this using a DP algorithm, let’s first consider the exhaustive search runtime. Recall that TSP operates on a complete graph, and your goal is to find a <strong>minimum-cost tour (cycle)</strong> that visits every vertex exactly once.</p>

<p>Some facts about TSP:</p>
<ul>
  <li>there are $n!/(2n) = \frac{1}{2}(n-1)!$ possible tours, so this is $O(n!)$</li>
  <li>factorial grows <strong>faster than exponential</strong>. e.g. $n! = n \cdot (n-1) \cdot … 2 \cdot 1$ which has $n$ terms mostly larger than $2$, while $2^{n}$ has $n$ terms of $2$’s.</li>
</ul>

<p>In this section we will often compare exponentials with factorials, so it is useful to know that:</p>

<blockquote>
  <p><strong>Sterling’s Approximation</strong>: in general pretty accurate:</p>

\[n! \approx \sqrt{2 \pi n}\left(\frac{n}{e}\right)^{n}\]

  <p>i.e. is roughly $(n/e)$ to the $n$ power. For large $n$ then $n / e » 2$!</p>
</blockquote>

<p>Now, we present an approach that can solve TSP in $O(n^{2} 2^{n})$ as opposed to $O(n!)$ using DP.</p>

<hr />

<ul>
  <li>
    <p><strong>optimal solution’s structure</strong>: suppose you already have a minimum cost tour $T$ using vertices $V={1,2, …, n}$ labeled without loss of generality. WLOG, let the path “start and end at vertex $1$”. Then, <mark>suppose this optimal path's last hop was $j-1$</mark> for some $j \in V \setminus {1}$ :</p>

    <p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms_part2/image-20231129003245.png" style="zoom:90%;" /></p>

    <p>then this $1-j$ path must be a <mark>minimum cost, cycle-free path using vertices $V$</mark>. This means that:</p>

\[\text{optimal tour cost} = \min_{j \in \{2, ..., n\}} \left( \text{min cost of cycle free 1-j path that visits $V$} + c_{j1} \right)\]

    <p>but how do we reason about the “min cost of cycle free 1-j path that visits $V$”? Realize that by a similar logic:</p>

    <p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms_part2/image-20231129004029.png" style="zoom:80%;" /></p>

    <p>i.e. plucking off the penultimate hop $k-j$ for some $k \in V \setminus {1, j}$, we have a <mark>minimum, cycle-free path using vertices $V - \{j\}$ </mark>. (this is the tricky part, instead of being the minimum cycle-free path using vertices $V$, because enabling $j$ could give us shortcuts). Therefore, this means:</p>

\[\text{min cost of 1-j path for $V$} = \min_{k \in \{2, ..., n\} \setminus \{j\}} \left( \text{min cost of 1-k path for $V \setminus \{j\}$} + c_{kj} \right)\]

    <p>and the above indeed can recurse into a DP algorithm.</p>
  </li>
  <li>
    <p><strong>subproblems and recursions</strong>: this leads to TSP recurrence. Let $C_{S,j}$ denote the minimum cost of a cycle-free <strong>path</strong> that visits all vertices in $S$, <strong>begins with $1$ and ends at $j$</strong> (note beginning with a vertex $1$ is fine as the final solution is a tour). Then, for every subset $S \subset V$ that contains vertex $1$:</p>

\[C_{S,j} = \min_{k \in S, k \neq 1,j} \left( C_{S \setminus \{j\}, k} + c_{kj} \right)\]

    <p>i.e. there are $\vert S\vert -2$ candidate solutions for an optimal path that visits all vertices in $S$ and ends at $j$, each designating a different penultimate vertex $k$ (see the figure above). Obviously, given this the final solution is:</p>

\[\text{optimal total cost} = \min_{j \in \{2, ..., n\}} \left( C_{V, j} + c_{j1} \right)\]

    <p>until $S$ grows in size and reached $V$.</p>
  </li>
</ul>

<p>Finally, we can use this recurrence to construct a DP algorithm:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms_part2/image-20231129005839.png" style="zoom:80%;" /></p>

<p>where we had</p>
<ul>
  <li>$\vert S\vert  \ge 2$ because every subset $S$ must contain vertex $1$ and at least one other vertex $j$ for the “figure above to work”</li>
  <li>base case: if there are just two vertices in $S$, and we need to find a path that starts with vertex $1$, then there is only one choice for each $C_{S,j}$.</li>
  <li>there are in total $2^{n-1}-1$ subproblems of set $\vert S\vert  \ge 2$.</li>
</ul>

<hr />

<p><strong>Correctness</strong> of this algorithm can be proven using induction on subproblem size $\vert S\vert$.</p>

<p><strong>Runtime</strong>: as for a typical DP algorith, we consider:</p>
<ul>
  <li>number of subproblems: the size of $A$, which is $(2^{n-1}-1)(n-1) = O(n 2^{n})$</li>
  <li>time per subproblem: we still needed to do a $A[S][j] = \min (…)$, so $O(n)$</li>
  <li>post-processing (not reconstruction): another $\min$ before we return, so $O(n)$</li>
</ul>

<p>hence in total we get:</p>

\[O(n 2^{n}) \times O(n) + O(n) = O(n^{2} 2^{n})\]

<p>Note that this is still exponential, but much better than $O(n!)$.</p>

<p>How do we reconstruct the tour? See problem set 10.</p>

<h2 id="finding-long-paths-by-color-coding">Finding Long Paths by Color Coding</h2>

<blockquote>
  <p><strong>Minimum-Cost $k$-Path</strong>: given an undirected graph $G=(V,E)$ with edge costs $c_{e} \in \R$, and a positive integer $k$, find a <strong>path of length $k-1$ with minimum total cost</strong>.</p>
  <ul>
    <li>if $G$ has no $k$-path, then output $+\infty$.</li>
    <li>yes, a $k$-path can start/end at any vertex in $G$, as long as it is cycle-free and has $k-1$ edges</li>
  </ul>
</blockquote>

<p>For example, in the following graph the optimal 4-path has cost 8, which is $(c \to a \to b \to e)$.</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms_part2/image-20231129011207.png" style="zoom:100%;" /></p>

<p>As you may have guesses, this is also NP-hard and shares many similarities with TSP. But before we go to a DP approach, what is the runtime for exhaustive search? Given a $k$:</p>

<ul>
  <li>we can iterate over all possible $k$-sized tuples of vertices</li>
  <li>therefore, there is $n \cdot (n-1) \cdot … \cdot (n-k+1) = O(n^{k})$ tuples to check</li>
  <li>to compute the cost of each tuple, it takes $O(k)$. <strong>So in total $O(k n^{k})$</strong>.</li>
  <li>this is again worse than things like $O(2^{k})$, as $n$ can be very large in practice.</li>
</ul>

<p>So how do we solve this using DP?</p>

<hr />

<p>Attempt 1: use the same trick from <a href="#the-bellman-held-karp-algorithm-for-the-tsp">The Bellman-Held-Karp Algorithm for the TSP</a>, where we define $C_{S,v}$ as the minimum cost cycle-free path that ends at vertex $v$ and visits exactly once each vertex in $S$, for $\vert S\vert  \le k$.</p>
<ul>
  <li>note that this differs from TSP where we do not require “start at vertex $1$ AND end at vertex $v$”, as we can start at any vertex</li>
</ul>

<p>We then just need to build up the solution from $\vert S\vert =1$ to $\vert S\vert =k$, and the optimal solution will be the minimum of $\min_{S_k, v} C_{S_k, v}$ for $S_{k}$ has size $k$ and $v \in S_k$.</p>

<p>While this would work, but how many subproblems are there?</p>

<ul>
  <li>to choose $\vert S\vert  \le k$, we have  $\sum\limits_{i=1}^{k} {n \choose i} = O(n^{k})$</li>
  <li>to scan over every $v \in S$, we have $O(k)$</li>
</ul>

<p>so this would give $O(k n^{k})$, which is the same as exhaustive search.</p>

<hr />

<h3 id="color-coding">Color Coding</h3>

<p>The trick is to use <strong>color coding</strong> to track less information about a path than the full set of vertices it visits. The idea is to assign a color to each vertex, and then <strong>track the colors</strong> of the vertices visited by a path.</p>

<p>Given a graph $G=(V,E)$ with length bound $k$:</p>

<blockquote>
  <p><strong>Color Coding</strong>: suppose you are given a partition of $k$ groups $V_{1} \cup V_{2} \cup … \cup V_{k} = V$ so that the minimum cost $k$-path is <strong>panchromatic</strong>, i.e. every one of the $k$ vertices reside in a different partition</p>

  <p>Why is this useful? The plan is this:</p>
  <ul>
    <li>we can later show that with some randomized calls, we WILL eventually get a “lucky enough” partition where the optimal $k$-path is panchromatic</li>
    <li>given the path is panchromatic, we find it much quicker than exhaustive search</li>
  </ul>
</blockquote>

<p>For example, consider the following graph with $k=4$, where we can imagine each partition having a different color:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms_part2/image-20231129014034.png" style="zoom:80%;" /></p>

<h3 id="computing-a-minimum-cost-panchromatic-path">Computing a Minimum-Cost Panchromatic Path</h3>

<p>Now you will see why this is faster, as instead of iterating over all possible $k$-sized tuples of vertices (which has $O(n^{k})$ subproblems), we can instead iterate over all possible $k$-sized tuples of colors:</p>

\[\sum\limits_{i=1}^{k} {n \choose i} = O(n^{k}) \quad \to \quad \sum\limits_{i=1}^{k} {k \choose i} = O(2^{k})\]

<p>since each subproblem now only needs to consider a path that visits $\le k$ vertices of <strong>different colors</strong> (assuming that the optimal path is panchromatic). Now, all we need to do is to redefine the subproblems and recursion using colors.</p>

<hr />

<p>Let $C_{S,v}$ denote the minimum cost of an $S$-path that ends at some vertex $v$, and visits exactly once each color in $S$, for $S \subseteq {1,2, … ,k}$. Let $\sigma(v)$ denote the color of vertex $v$.</p>

<ul>
  <li>
    <p><strong>optimal solution’s structure</strong>: essentially the same as TSP where we can pluck the last vertex out, along with its color:</p>

    <p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms_part2/image-20231129015016.png" style="zoom:100%;" /></p>

    <p>note that we do not have a start vertex here, and the smaller subproblem represents having one less color to visit (which skips a LOT of subproblems)!</p>
  </li>
  <li>
    <p><strong>subproblems and recurrence</strong>: again building from bottom up, for every subset $S \subseteq {1,2, … ,k}$ and every vertex $v \in V$:</p>

\[C_{S,v} = \min_{(w,v) \in E} \left( C_{S \setminus \{\sigma(v)\}, w} + c_{wv} \right)\]

    <p>where there are a couple differences from TSP:</p>
    <ul>
      <li>we still need to check every vertex $v \in V$ to build up the solution, but <mark>after checking one $v$ we can throw out all vertices of the same color $\sigma(v)$</mark></li>
      <li>since this is looking for a path, we just need to check $(w,v) \in E$.</li>
    </ul>

    <p>The final optimal solution is then:</p>

\[\min_{v \in V} C_{\{1,2, ... ,k\}, v}\]

    <p>where $S={1,2, … ,k}$ is the full set of colors.</p>
  </li>
</ul>

<p>Hence our DP algorithm is:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms_part2/image-20231129020101.png" style="zoom:80%;" /></p>

<p>again, this assumes that the optimal path is panchromatic.</p>

<hr />

<p><strong>Correctness</strong>: induction by problem size on $\vert S\vert$</p>

<p><strong>Runtime</strong>: here the main cost is in the triple for loop:</p>

<ul>
  <li>to compute $A[s][v] = \min(…)$ it takes $O(\mathrm{degree}(v))$ time</li>
  <li>to compute <code class="language-plaintext highlighter-rouge">for v in V</code> then takes $O(\sum\limits_{n\in V} \mathrm{degree}(v)) = O(2m)=O(m)$ time</li>
  <li>since then it just iterates over all possible $S \subseteq {1,2, …, k}$, we get $O(2^{k} m)$ time</li>
</ul>

<p>This is great as it is much better than $O(n^{k})$, but what do we do about the “lucky case” of the optimal path being panchromatic?</p>

<h3 id="randomized-color-coding">Randomized Color Coding</h3>

<p>The idea is that <strong>perhaps with a uniformly randomly colored graph</strong>, we can eventually get lucky enough to find a panchromatic path.</p>

<p>Suppose we uniformly assign a color ${1, …, k}$ for each vertex at random. What is the probability that a given $k$-path is panchromatic?</p>

<ul>
  <li>there are in total $k^{k}$ possible colorings for that $k$-path</li>
  <li>being panchromatic means that each color is used exactly once, so there are $k!$ ways to do that</li>
  <li>therefore, the <strong>probability of being panchromatic is $k! / k^{k}$</strong></li>
</ul>

<p>How big is it? Now we can use steriling’s approximation to better see:</p>

\[p = \frac{k!}{k^{k}} \approx \frac{\sqrt{2 \pi k}\left(\frac{k}{e}\right)^{k}}{k^{k}} = \frac{\sqrt{2\pi k}}{e^{k}}\]

<p>with $k=7$ this number is already less than 1% due to the exponential term. But we <mark>don't need to get this done in one-shot. All we need is to be lucky for once in a reasonable number of trials.</mark> So what is the probability of getting at least once panchromatic path in $T$ trials?</p>

<ul>
  <li>this is equivalent to $1 - (1-p)^{T}$, where $p$ is computed above as the probaility of success in one trial, hence $(1-p)^{T}$ is the chance that <strong>all $T$ trials were unlucky</strong></li>
  <li>
    <p>to compute this, consider bounding $1-p$ from above by $e^{-p}$, which works because:</p>

    <p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms_part2/image-20231129021512.png" style="zoom:40%;" /></p>

    <p>therefore we get:</p>

\[(1-p)^{T} \le (e^{-p})^{T} = e^{-pT}\]
  </li>
</ul>

<p>And therefore for a failure rate <strong>smaller than $\delta=0.01$</strong>, i.e. failure rate of 1%, we can set:</p>

\[e^{-pT} \le \delta \implies T \ge \frac{1}{p} \ln \frac{1}{\delta} \approx \frac{e^{k}}{\sqrt{2\pi k}} \ln \frac{1}{\delta}\]

<p>This gives our final algorithm of color coding with randomized trials:</p>

<p><img src="/lectures/images/2024-01-20-CSOR4231_Analysis_of_Algorithms_part2/image-20231129021934.png" style="zoom:80%;" /></p>

<p>where basically in the yellow part you just recolor everything for $T$ trials. This gives the total runtime of:</p>

\[O\left( e^{k} \ln \frac{1}{\delta} \right) \times O(2^{k} m) = O\left( (2e)^{k} m \ln \frac{1}{\delta} \right)\]

<p>which gives probability of success (i.e. reaching the lucky case of optimal path being panchromatic) at least $1-\delta$.</p>]]></content><author><name></name></author><category term="2023@Columbia" /><summary type="html"><![CDATA[NP-Hard Problems]]></summary></entry><entry><title type="html">COMS3203 Discrete Math</title><link href="/lectures/2022@columbia/COMS3203_Discrete_Math.html/" rel="alternate" type="text/html" title="COMS3203 Discrete Math" /><published>2023-05-11T00:00:00+00:00</published><updated>2023-05-11T00:00:00+00:00</updated><id>/lectures/2022@columbia/COMS3203_Discrete_Math</id><content type="html" xml:base="/lectures/2022@columbia/COMS3203_Discrete_Math.html/"><![CDATA[<h1 id="discrete-math-logistics">Discrete Math Logistics</h1>

<ul>
  <li>Content on Courseworks, homework on Gradescope</li>
  <li><strong>Notes</strong> on Coursework provided by the Professor. Additional examples (not on the book) will be gone over during classes.</li>
  <li><strong>Recitations</strong> will be recorded, and content in the recitation needs to be studied</li>
  <li><strong>Homework</strong>: weekly, needs to be typed</li>
</ul>

<h1 id="logic">Logic</h1>

<p>Propositional logic, truth tables, Boolean algebra, inference.</p>

<h2 id="axioms-of-numbers">Axioms of Numbers</h2>

<blockquote>
  <p><strong>Natural Numbers</strong> contain all positive whole numbers (excluding zero)</p>

\[\mathbb{N} = \{ 1,2,3,... \}\]

</blockquote>

<blockquote>
  <p><strong>Even Numbers</strong> an integer $a$ if even IFF $a$ is divisible by 2; or exists an integer $b$ such that $a = 2b$</p>
</blockquote>

<blockquote>
  <p><strong>Odd Numbers</strong> an integer $a$ if is odd provided there exists a number $q \in \mathbb{Z}$ s.t. $a = 2q+1$</p>
</blockquote>

<blockquote>
  <p><strong>Prime Numbers</strong> let $p \in \mathbb{Z}, p&gt;1$. We call a number prime provided it is only divisible by $1$ and itself.</p>

  <ul>
    <li>e.g. 2, 3, 5…. By definition $1$ is therefore not prime.</li>
  </ul>
</blockquote>

<p>etc. Just to recall:</p>

<ul>
  <li>$\mathbb{Z}$ represents integer, $\mathbb{Q}$ represents rational numbers (fractions with integer num/denom), $\mathbb{R}$ represents real numbers</li>
  <li>$\mathbb{N}\subseteq Z \subseteq Q \subseteq R$</li>
</ul>

<h2 id="introduction-to-logic">Introduction to Logic</h2>

<blockquote>
  <p><strong>Proposition</strong>: a proposition is an objective, declarative statement that’s either true or false.</p>
</blockquote>

<p>for example, proposition includes:</p>

<ul>
  <li>$2+2=4$ (is true)</li>
  <li>$2 &gt; 5$ (is false)</li>
  <li>$x+2=5$ (used in first order logic as it depends on $x$=a predicate, but it is a proposition)</li>
</ul>

<p>not propositions:</p>

<ul>
  <li>Newborns are cute (subjective)</li>
  <li>Hello.</li>
</ul>

<blockquote>
  <p><strong>Atomic Proposition</strong>: simplest (elementary) form of a proposition. Some common notations used to denote atomic proposition include $p,q,r,t,s,z$ etc.</p>
</blockquote>

<blockquote>
  <p><strong>Compound Proposition</strong>: a proposition constructed from two or more atomic propositions using <em>connectives</em>, or adding a connective to an atomic proposition.</p>
</blockquote>

<blockquote>
  <p><strong>Major Connectives in Propositional Logic</strong>: if we have a proposition $p$</p>

  <ul>
    <li>
      <p><strong>negation</strong> (not): $\neg p$. For example, $p=$ it is snowing, $\neg p$ = it is not snowing. All possible negation actions include:</p>

      <p><img src="/lectures/images/2023-05-11-COMS3203_Discrete_Math/image-20230119110421501.png" alt="image-20230119110421501" style="zoom: 50%;" /></p>

      <p>note that the <strong>Truth Table</strong> above basically lays out all the possible “scenarios”</p>
    </li>
    <li>
      <p><strong>conjunction</strong> (and): $p \land q$.</p>

      <p><img src="/lectures/images/2023-05-11-COMS3203_Discrete_Math/image-20230119110900415.png" alt="image-20230119110900415" style="zoom:50%;" /></p>

      <p>now that there are 2 “variables”, we have $2^2$ possibilities</p>
    </li>
    <li>
      <p><strong>dis-junction</strong> (or): $p \lor q$.</p>

      <p><img src="/lectures/images/2023-05-11-COMS3203_Discrete_Math/image-20230119111803562.png" alt="image-20230119111803562" style="zoom:50%;" /></p>
    </li>
    <li>
      <p><strong>exclusive or</strong> (xor). $p \oplus q$. You expect only one of the options. interestingly this is more related to using “or” in natural language: e.g. “you can either have $p$ as side dish or $q$”</p>

      <p><img src="/lectures/images/2023-05-11-COMS3203_Discrete_Math/image-20230119112042366.png" alt="image-20230119112042366" style="zoom:50%;" /></p>
    </li>
    <li>
      <p><strong>implication</strong> (if, or implies): $p \to q$. For example, “if heavy snow ($p$), then Columbia is closed ($q$)”. So whenever $p$ is fulfilled, we expect $q$ to happen.</p>

      <p><img src="/lectures/images/2023-05-11-COMS3203_Discrete_Math/image-20230119112342403.png" alt="image-20230119112342403" style="zoom:50%;" /></p>

      <p>the first two rows are straight-forward. Consider “If I get an A in this course ($p$), then I will give you a dollar ($q$)”.</p>

      <ul>
        <li>If $p,q$ both happened, then I kept my promise. If $p$ happened but I didn’t give you a dollar ($\neg q$), then I broke the promise.</li>
        <li>If $p$ didn’t happen in the first place, then technically I <em>haven’t yet</em> break the promise. In this case we <strong>assume it is still true</strong>, i.e. the <mark>benefit of doubt</mark></li>
      </ul>
    </li>
    <li>
      <p><strong>if and only if</strong> (iff) $p \iff q$. Basically this means a conjunction to two implications $(p \to q)\land (q \to p)$</p>

      <p><img src="/lectures/images/2023-05-11-COMS3203_Discrete_Math/image-20230124102509957.png" alt="image-20230124102509957" style="zoom: 43%;" /></p>

      <p>where the last one has $(p \to q)=T$ and $(q \to p)=T$ due to benefit of doubt. Hence $(p \iff q) = (T \land T) = T$. Notice that basically $p \iff q$ is true when $p,q$ are equivalently true or equivalently false.</p>
    </li>
  </ul>
</blockquote>

<p>note that</p>

<ul>
  <li>every connective mentioned above except for negation are <em>binary connectives</em>.</li>
  <li>the order of evaluation would go from
    <ol>
      <li>$()$ processed from inside to outside</li>
      <li>$\neg$ negation</li>
      <li>$\land$ and</li>
      <li>$\lor,\oplus$</li>
      <li>$\to$ implies</li>
      <li>$\iff$</li>
      <li>left to right</li>
    </ol>
  </li>
</ul>

<p>and in English</p>

<p><img src="/lectures/images/2023-05-11-COMS3203_Discrete_Math/image-20230126104413095.png" alt="image-20230126104413095" style="zoom:50%;" /></p>

<p>where the more tricky ones are highlighted.</p>

<ul>
  <li>“$p$ only if $q$” means only if the consequence $q$ happens</li>
  <li>“$q$ is a necessary condition for $p$” means “$q$ is a necessary <em>conclusion</em> for $p$”</li>
  <li>a trick can be to consider which one maps correctly to “if $p$ then $q$”.</li>
</ul>

<hr />

<p><em>For Example</em>, consider $p \lor q \implies \neg r$.</p>

<p>First of all, how many rows will there be? Since there are three variables, $2^3=8$ rows.</p>

<p><img src="/lectures/images/2023-05-11-COMS3203_Discrete_Math/image-20230124103755936.png" alt="image-20230124103755936" style="zoom:50%;" /></p>

<hr />

<p>Implication can be very tricky when combined with negation:</p>

<ul>
  <li>
    <p><strong>negation of implication</strong>: $\neg (p \to q)$ is $p \land \neg q$.</p>

    <ul>
      <li>for instance $\neg$(hit$\to$hurt) is (hit$\to\neg$hurt)</li>
      <li>is proven below (of course, they don’t come out of nowhere. See the example in the proof)</li>
    </ul>
  </li>
  <li>
    <p>if $p\to q$ is implication, then</p>

    <ul>
      <li><strong>converse</strong> $q \to p$</li>
      <li><strong>contrapositive</strong> $\neg q \to \neg p$</li>
      <li><strong>inverse</strong> $\neg p \to \neg q$</li>
    </ul>

    <p>why they are named like this can be seen more clearly from the truth table:</p>

    <table>
      <thead>
        <tr>
          <th style="text-align: left">p</th>
          <th style="text-align: left">q</th>
          <th style="text-align: center">$p \to q$</th>
          <th style="text-align: center">$q\to p$</th>
          <th style="text-align: center">$\neg q \to \neg p$</th>
          <th style="text-align: center">$\neg p \to \neg q$</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td style="text-align: left">T</td>
          <td style="text-align: left">T</td>
          <td style="text-align: center">T</td>
          <td style="text-align: center">T</td>
          <td style="text-align: center">T</td>
          <td style="text-align: center">T</td>
        </tr>
        <tr>
          <td style="text-align: left">T</td>
          <td style="text-align: left">F</td>
          <td style="text-align: center">F</td>
          <td style="text-align: center">T</td>
          <td style="text-align: center">F</td>
          <td style="text-align: center">T</td>
        </tr>
        <tr>
          <td style="text-align: left">F</td>
          <td style="text-align: left">T</td>
          <td style="text-align: center">T</td>
          <td style="text-align: center">F</td>
          <td style="text-align: center">T</td>
          <td style="text-align: center">F</td>
        </tr>
        <tr>
          <td style="text-align: left">F</td>
          <td style="text-align: left">F</td>
          <td style="text-align: center">T</td>
          <td style="text-align: center">T</td>
          <td style="text-align: center">T</td>
          <td style="text-align: center">T</td>
        </tr>
      </tbody>
    </table>

    <p>notice that $p \to q$ <mark>is the same as</mark> $\neg q \to \neg p$, and $q\to p$ <mark>is the same as</mark> $\neg p \to \neg q$.</p>
  </li>
</ul>

<blockquote>
  <p><strong>Logical Equivalence</strong>: two propositions $p,q$ are called <em>logical equivalent</em> provided they have the <mark>same truth table</mark></p>

\[p \equiv q,\quad \mathrm{or}\quad p=q\]

  <p>we will mostly use $\equiv$. Note that this is <em>not a connective</em>, but rather a <em>relation</em>.</p>
</blockquote>

<p>Now you can show that $\neg (p \to q) \equiv p \land \neg q$</p>

<table>
  <thead>
    <tr>
      <th style="text-align: left">p</th>
      <th style="text-align: left">q</th>
      <th style="text-align: center">$p \to q$</th>
      <th style="text-align: center">$\neg (p \to q)$</th>
      <th style="text-align: center">$p\land \neg q$</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">T</td>
      <td style="text-align: left">T</td>
      <td style="text-align: center">T</td>
      <td style="text-align: center">F</td>
      <td style="text-align: center">F</td>
    </tr>
    <tr>
      <td style="text-align: left">T</td>
      <td style="text-align: left">F</td>
      <td style="text-align: center">F</td>
      <td style="text-align: center">T</td>
      <td style="text-align: center">T</td>
    </tr>
    <tr>
      <td style="text-align: left">F</td>
      <td style="text-align: left">T</td>
      <td style="text-align: center">T</td>
      <td style="text-align: center">F</td>
      <td style="text-align: center">F</td>
    </tr>
    <tr>
      <td style="text-align: left">F</td>
      <td style="text-align: left">F</td>
      <td style="text-align: center">T</td>
      <td style="text-align: center">F</td>
      <td style="text-align: center">F</td>
    </tr>
  </tbody>
</table>

<p>And similarly, you can show that:</p>

\[p \to q \equiv \neg p \lor q \equiv \neg q \to \neg p\]

<p>So implication is just a <mark>disjunction</mark>! This is very important to know!</p>

<ul>
  <li>e.g. if I hit my thumb, it will hurt $\equiv$ I don’t hit my thumb, or else it will hurt</li>
</ul>

<blockquote>
  <p><strong>Tautology</strong>: a proposition is always true is called a <em>tautology</em>. For example, $p \lor \neg p$ is a tautology as no matter what value $p$ takes, <em>every</em> row in the truth table is <em>true</em>.</p>
</blockquote>

<p>A more interesting example would be</p>

<ul>
  <li>you may feel this is similar to $\iff$. But $\equiv$ is a relation <em>between</em> propositions, whereas $\iff$ is a <em>connective</em>.</li>
  <li>e.g. we know $p\to q \equiv \neg p \lor q$ as they have the same truth table. Then this also mean $(p\to q) \equiv (\neg p \lor q)$ is a <strong>tautology</strong></li>
</ul>

<blockquote>
  <p><strong>Fallacy/Contradiction</strong>: a proposition that is always false. For example, $p \land \neg p$.</p>
</blockquote>

<blockquote>
  <p><strong>Contingency</strong>:  a proposition that is not a tautology or fallacy, i.e. is a valid proposition. Usually we can just call this a (valid) “proposition”.</p>
</blockquote>

<hr />

<p><em>For Example:</em> Wason Puzzle</p>

<p>Consider a set of four cards. Each card has a letter on one side and one number on the other side.</p>

<p><img src="/lectures/images/2023-05-11-COMS3203_Discrete_Math/image-20230124111846624.png" alt="image-20230124111846624" style="zoom:50%;" /></p>

<p>Consider the proposition: “If there is a vowel on one side, then there is an even number on the other side.”</p>

<p><strong>Question</strong>: What are the only cards that you <em>need to turn</em> to check if the proposition is True or False?</p>

<p><strong>Answer</strong>: you only need to turn $A$ and $3$. Let $p$=is vowel and $q$=other side is even. To falsify it, we need to basically get <strong>(vowel and not even)</strong> because this is the only case the <strong>implication $(p\to q)=F$</strong>. Therefore, the two relevant checks will be $p=T$ and $q=F$, corresponding to the card $A$ and card $3$.</p>

<p>More interestingly, notice that checking $3$ is the same as the $\neg q \to \neg p$ which is the <strong>contrapositive</strong>!</p>

<h2 id="laws-of-propositional-logic">Laws of Propositional Logic</h2>

<p>These basic laws (equivalences) are important as:</p>

<ul>
  <li>can be used to show that a proposition is equivalent than other ones, a tautology, of fallacy</li>
  <li>simplify a proposition</li>
</ul>

<p><img src="/lectures/images/2023-05-11-COMS3203_Discrete_Math/image-20230126105134138.png" alt="image-20230126105134138" style="zoom:50%;" /></p>

<p>where the most important ones are highlighted. Most of them has something to do with simplifying $\land$ and $\lor$</p>

<ul>
  <li><strong>associativity</strong>: has to be used on the <em>same</em> connective (e.g. $(p\lor q)\land r$ has to be done in a distributive case)</li>
  <li><strong>distributivity</strong>: you can also show that $(q \lor r) \land p \equiv (q \land p) \lor (r \land p)$ by using the <em>commutativity law</em> and the first row in Distributive law</li>
  <li><strong>absorption</strong>: note that this is different from “Idempotence law”</li>
  <li><strong>DeMorgan’s</strong>: how to distribute <strong>negation</strong></li>
</ul>

<p><strong><em>Proof</em></strong> of $p \lor (p \land q) \equiv p$.</p>

<p>To get only $p$ on the RHS, we can consider $p \land T = p$ or $p \lor p = p$ as the last step. Here we use the first one:</p>

\[p \lor (p \land q) = (p \land T) \lor (p \land q) = p \land (T \lor q) = p \land T = p\]

<p><strong><em>Proof</em></strong> of $p \land (p \lor q) \equiv p$</p>

\[p \land (p \lor q) = (p \lor F) \land (p \lor q) = p \lor (F \land q) =  p \lor F = p\]

<p>which we already know is $p$ from the previous proof.</p>

<hr />

<p><em>For Example</em>: show that</p>

\[(p \lor q) \land (p \lor \neg q) \quad \text{is a tautology}\]

<p><strong><em>Proof</em></strong>: (first you start intuitively), realize that you are “or”ing $q$ and $\neg q$, hence:</p>

\[(p \lor q) \land (p \lor \neg q) = p \lor ( q \land \neg q) = p \lor (T) = T\]

<h2 id="logical-inference">Logical Inference</h2>

<p>Or logical deduction.</p>

<blockquote>
  <p><strong>Logical inference/argument</strong>: a sequence of propositions such that:</p>

  <ul>
    <li>all but the last propositions are called premises (i.e. precedes conclusion)</li>
    <li>the last proposition ($q$) is called conclusion</li>
  </ul>

\[\frac{p_1p_2,\dots p_n}{q}\]

  <p>an argument is called <mark>valid if the premises imply the conclusion</mark>. This means that:</p>

\[(p_1 \land p_2 \land \dots \land p_n) \to q \equiv T \quad \text{(is a tautology)}\]

</blockquote>

<p>But notice that implication has the benefit of doubt, so it <mark>only makes sure that if all $p_i$ is satisfied, $q$ will happen</mark>. If one of the $q_i$ is false, it does not affect anything.</p>

<hr />

<p><em>For Example</em>:</p>

\[\frac{p_1p_2}{p_1 \land p_2} \quad \text{is valid}\]

<p>because it is basically $p \to p$. In fact, if you have <strong>equivalence</strong>, such as</p>

\[\text{both}\quad \frac{\neg \neg p}{p},\frac{p}{\neg \neg p}\quad \text{are valid}\]

<p>you can also see that via a Truth Table</p>

<p><img src="/lectures/images/2023-05-11-COMS3203_Discrete_Math/image-20230131105859364.png" alt="image-20230131105859364" style="zoom:50%;" /></p>

<hr />

<p><strong>Rules of Inference</strong></p>

<ul>
  <li>
    <p><strong>addition</strong>:</p>

\[\frac{p}{p \lor q}\]

    <p>you can prove this by showing that $p \to (p\lor q) \equiv T$</p>

\[\neg p \lor (p \lor q) = T \lor q = T\]

    <p>e.g. “it is raining” concludes “it is raining or xxxx” is obviously true.</p>
  </li>
  <li>
    <p><strong>conjunction</strong>:</p>

\[\frac{p \quad q}{p \land q}\]

    <p>basically means $(p \land q) \to (p \land q)$</p>
  </li>
  <li>
    <p><strong>simplification</strong>:</p>

\[\frac{p \land q}{p}\text{    and    } \frac{p \land q}{q}\]

    <p>because $p \land q \to p \equiv T$</p>
  </li>
  <li>
    <p><strong>disjunctive syllogism</strong>:</p>

\[\frac{p \lor q \quad \neg p}{q}\]

    <p>proof is left to you as an exercise, but intuitively if the premises is true, then it means $p$ is false hence $F \lor q$ is true concludes $q$ is true.</p>
  </li>
  <li>
    <p><strong>hypothetical syllogism</strong>:</p>

\[\frac{p \to q \quad q \to r}{p \to r}\]

    <p>which implies that implication is transitive.</p>
  </li>
  <li>
    <p><strong>resolution</strong></p>

\[\frac{p \lor q \quad \neg p \lor r}{q \lor r}\]

    <p>meaning that if $p\lor q$ and $\neg p \lor r$ is true, then it means either $q$ or $r$ has to be true. Hence the conclusion $q\lor r$ is true. You can again try to prove this formally $((p \lor q) \land (\neg p \lor r) \to q\lor r) \equiv T$</p>
  </li>
  <li>
    <p><strong>modus ponens</strong> (latin: mode that affirms)</p>

\[\frac{p \quad p \to q}{q}\]

    <p>is a <mark>very important law</mark>, as it means if $p \to q$ is true and $p$ happened, then $q$ must conclude.</p>
  </li>
  <li>
    <p><strong>modus tollens</strong> (latin: mode that denies)</p>

\[\frac{\neg q \quad p \to q}{\neg p}\]

    <p>very similar as above, as it means if $p \to q$ is true (e.g. raining $\to$ take umbrella) and $q$ did not happen (e.g. did not take umbrella), then $p$ did not happen (e.g. it is not raining).</p>
  </li>
  <li>
    <p><strong>transitivity</strong> this will be used a lot in proofs, so that basically if</p>

\[\frac{p}{q},\quad \frac{q}{r}\quad \text{are valid}\]

    <p>then</p>

\[\frac{p}{r}\quad \text{is valid}\]
  </li>
</ul>

<blockquote>
  <p>Inference is like implication except that it is (saying, since the premises are true, then this conclusion must be) <strong>always true</strong></p>
</blockquote>

<blockquote>
  <p>All <strong>laws of logic</strong> seen earlier can be written as <strong>rule of inference</strong>.</p>
</blockquote>

<p><em>For example</em>, you can transform $p \lor T \equiv T$ to inference as:</p>

\[\frac{p \lor T}{T} \text{    and  }  \frac{T}{p \lor T}\]

<p><em>Another example</em>: premise $p_1$=It’s not rainy but it’s nicer than yesterday. $p_2$=we will watch a movie only if it’s raining. $p_3$ we will go swimming if we do not watch a movie. $p_4$=if we go swimming, we will be home after sunset.</p>

<ol>
  <li>
    <p>Translate this into propositional logic (PL).</p>

    <p>let us use</p>

\[r:\text{rainy}\quad n:\text{nicer}\quad  w:\text{watch}\quad  h:\text{home}\quad  s:\text{swim}\quad\]

    <p>therefore this means</p>

    <ul>
      <li>$p_1 = \neg r \land n$</li>
      <li>$p_2 = w \to r$</li>
      <li>$p_3 = \neg w \to s$</li>
      <li>$p_4 = s \to h$</li>
    </ul>
  </li>
  <li>
    <p>Show that these premises lead to “we will be home after sunset” (premises are “true”)</p>

    <ol>
      <li>
        <p>first, we can simplify to get it is not raining:</p>

\[\frac{\neg r \land n}{\neg r}\]
      </li>
      <li>
        <p>then applying modus tollens</p>

\[\frac{w \to r \quad \neg r}{\neg w}\]
      </li>
      <li>
        <p>then applying modus ponens</p>

\[\frac{\neg w \to s \quad \neg w}{s}\]
      </li>
      <li>
        <p>finally</p>

\[\frac{s\quad s\to h}{h}\]
      </li>
    </ol>
  </li>
</ol>

<p><em>Another Example</em>: consider the whompus world where there are breezes $B$, pits $P$, and whompus $W$ such that $B_{11} \iff P_{12} \lor P_{21}$. And given that $\neg B_{11}$, show that $\neg P_{12}$</p>

<ol>
  <li>
    <p>we can break up the iff into $P_{12} \lor P_{21} \to B_{11}$ by simplification</p>
  </li>
  <li>
    <p>then apply modus ponens</p>

\[\frac{\neg B_{11}\quad P_{12} \lor P_{21} \to B_{11}}{\neg (P_{12} \land P_{21} )}\]
  </li>
  <li>
    <p>De Morgans law gives this means</p>

\[\neg (P_{12} \land P_{21}) = \neg P_{12} \land \neg P_{21}\]
  </li>
  <li>
    <p>finally, apply simplification</p>

\[\frac{\neg P_{12} \land \neg P_{21}}{\neg P_{12}}\]
  </li>
</ol>

<h2 id="first-order-logic">First Order Logic</h2>

<p>What if you want to say “there is no $W$ anywhere in the 5x5 cave”? Given current tools, this is not very convenient to do.</p>

<blockquote>
  <p><strong>First Order Logic</strong> (abbreviated as FOL), also known as <strong>predicate logic</strong>, combines quantifiers and predicates for a more powerful and compact formalism. So in a sense, PL is a <em>subset</em> of FOL.</p>
</blockquote>

<p>The idea is to:</p>

<ul>
  <li>instead of having just $p$, we consider $p(x)$, or $p(x,y)$, etc (i.e. predicates)</li>
  <li>and we add quantifiers such as $\forall, \exists$</li>
</ul>

<blockquote>
  <p><strong>Predicate</strong>: A predicate is a proposition whose truth value <mark>depends on one or more variables</mark>.</p>
</blockquote>

<blockquote>
  <p><strong>N-ary predicate</strong>: a predicate with $N$-variables</p>

\[\text{predicate}(\underbrace{x,y,z,...}_{\text{n variables}})\]

</blockquote>

<p>For example, this includes</p>

<ul>
  <li>(predicates) $x+2=5$; even$(x)$; $x+y &gt; 10$</li>
  <li>
    <p>i.e. they <em>can be true or false</em>, but it <em>depends</em> on the values of the variables</p>
  </li>
  <li>i.e. it is like a function that <mark>always evaluates to true or false</mark> given the “input values”</li>
</ul>

<blockquote>
  <p><strong>Quantifiers</strong></p>

  <ul>
    <li>universal quantifier: $\forall$ expresses such as “for all, for every, all of, for each, for any, any of, given any, for an arbitrary, etc.”</li>
    <li>existential quantifier: $\exists$ expresses such as “there exist, for some, for at least one, there is, there is at least one, etc.”</li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Universal Quantifier</strong> additionally requires a <em>variable name</em> and a <em>domain</em>.</p>

\[\forall \underbrace{x}_{\text{variable}}  \underbrace{ \in A}_{\text{a domain}}\]

  <p>then this can be combined with a proposition</p>

\[\forall \underbrace{x}_{\text{variable}}  \underbrace{ \in A}_{\text{a domain}}\,\,(\text{predicate}...)\]

</blockquote>

<p>and then you can say something like “all aliens are green”, by considering $A$=the set of aliens:</p>

\[\forall a \in A\,\, (green(a))\]

<p>(which may or may not be true). Another example: all integers are even:</p>

\[\forall a \in \mathbb{Z}\,\, (x\,\text{mod }2 = 0)\]

<blockquote>
  <p>One powerful/additional feature of FOL is that your predicate can contain essentially <strong>functions</strong>, introducing many new operators such as “mod”, “equality”, etc.</p>
</blockquote>

<p>More examples: “All Aliens are green and nice. Domain: Alien denoted $A$”</p>

\[\forall a \in A \quad (\text{green}(a) \land \text{nice}(a))\]

<blockquote>
  <p><strong>Existential Quantifier</strong>: he existential quantifier, denoted with the symbol $\exists$, expresses the statements: there exist, for some, for at least one, there is, there is at least one, etc. The application of this is the same as the “Universal Quantifier”</p>
</blockquote>

<p>For example: There exists an integer that is both even and prime</p>

\[\exists x \in \mathbb{Z} \quad (\text{even}(x) \land \text{prime}(x))\]

<p><mark>but how do we prove it</mark>? In this example, we can by just realizing that $x=2$ satisfies. But in general, see <a href="#FOL Statements and Proofs">FOL Statements and Proofs</a></p>

<blockquote>
  <p><strong>Negation</strong> of FOL statements:</p>

  <ul>
    <li>$\neg (\forall x \quad p(x))$ means $\exists x \quad (\neg p(x))$</li>
    <li>$\neg (\exists x \quad p(x))$ means $\forall x \quad (\neg p(x))$</li>
  </ul>
</blockquote>

<p>For example:</p>

\[\neg(\forall x \exist y\quad p(x,y)) \equiv \exists x \forall y \quad\neg p(x,y)\]

<p>where we abbreviated $\forall x (\exist y\quad p(x,y))$ to just $\forall x \exist y\quad p(x,y)$</p>

<blockquote>
  <p><strong>Distributivity of FOL</strong>: in short, they <mark>do not distribute</mark></p>

  <ul>
    <li>
      <p>consider $\forall$:</p>

\[\forall x \quad P(x) \lor Q(x) \neq (\forall x \quad P(x)) \lor (\forall x \quad Q(x))\]

      <p>e.g. consider $P(x)$=even(x) and $Q(x)$=odd(x). Then LHS = $T$, but RHS = $F\lor F=F$</p>
    </li>
    <li>
      <p>consider $\exists$:</p>

\[\exists x \quad P(x) \land Q(x) \neq (\exists x \quad P(x)) \land (\exists x \quad Q(x))\]

      <p>e.g. consider $P(x)$=prime(x) and $Q(x)$=notprime(x). Then LHS=$F$ but RHS=$T\land T=T$</p>
    </li>
  </ul>
</blockquote>

<h3 id="domain-of-fol">Domain of FOL</h3>

<p>On the <strong>importance</strong> of the domain:</p>

<ul>
  <li>
    <p>Suppose you want to express: “All birds fly”</p>

\[\forall b \in B\quad \text{fly}(b)\]
  </li>
  <li>
    <p>“All birds <mark>except</mark> penguins fly”. Naively:</p>

\[\forall b \in B \quad (\text{fly}(b)\land \neg \text{penguin}(b))\]

    <p>but this also means we are stating two things:</p>

\[[\forall b \in B \quad \text{fly}(b)]\quad \land \quad [\forall b \in B \quad \neg \text{penguin}(b)]\]

    <p>i.e. whenever $b$ is a penguin, this will be false $\neq$ our original statement. The <mark>correct way</mark> to express it is</p>

\[\forall b \in B \quad ( \neg \text{penguin}(b) \to \text{fly}(b) )\]

    <p>i.e “if it is not a penguin, then it flies”, i.e. the <em>only false case is “not penguin, and can’t fly”,</em> and we are not claiming anything else than that, which is consistent with the statement.</p>

    <ul>
      <li>
        <p>(<em>optional</em>) technically you can also interpret this as “penguins don’t fly”. Then you might have</p>

\[\forall b \in B \quad ( \neg \text{penguin}(b) \iff \text{fly}(b) )\]
      </li>
      <li>
        <p>one way to think about this type of problem is to convert it into code</p>

        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">birds</span><span class="p">:</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">penguin</span><span class="p">(</span><span class="n">a</span><span class="p">)):</span>
        <span class="n">fly</span>
    <span class="c1"># technically done
</span>    <span class="c1"># optionally:
</span>    <span class="k">if</span> <span class="n">penguin</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
        <span class="ow">not</span> <span class="n">fly</span>
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
</ul>

<p>Another example:</p>

<ul>
  <li>
    <p>“In the <strong>set of animals</strong>, all lions are fierce”</p>

\[\forall a \in A \quad \text{lion(a)} \to \text{fierce}(a)\]
  </li>
  <li>
    <p>“some lions are fierce”</p>

\[\exists a \in A \quad (\text{fierce}(x) \land \text{lion(a)})\]

    <p>is now correct.</p>
  </li>
</ul>

<blockquote>
  <p><strong>Note</strong>: this means <em>usually</em></p>

  <ul>
    <li>$\forall$ goes with $\to$ implications (because $\forall$ is a strong quantifier)</li>
    <li>$\exists$ goes with $\land$ conjunctions</li>
  </ul>
</blockquote>

<p><em>For example</em>: Consider the domain of Humans, you want to express “All kids has pets”</p>

\[\forall h \in H\quad \text{kid}(h) \to \text{has pet}(h)\]

<p>then another way to do this is</p>

\[\forall h \in H ( \text{kid}(h) \to \exists \underbrace{ a \in A \quad \text{pet}(a) \land \text{is his pet}(a,k)}_{\text{exists a pet that the kid has}})\]

<p><em>For example</em>: “there exists a class that’s taken by every student”. Consider two domains, “event” (e.g. classes, workshops, conferences, sport events, etc) and “students”</p>

\[\exists e \in \text{event}\quad \text{class}(e) \land (\forall s \in \text{students} \quad \text{take}(s,e))\]

<h3 id="mixing-quantifiers">Mixing Quantifiers</h3>

<p>Consider the statement “All integers are even”, and</p>

\[\forall x \in \mathbb{Z}\quad ( \exists y\in \mathbb{Z}\quad x=2y )\]

<p>which is like a <mark>"nested loop"</mark> of, taking a loop over $x \in \mathbb{Z}$, and each is a even number.</p>

<p>Another example: what are the differences between:</p>

<ul>
  <li>$\forall x \in \mathbb{Z}\quad ( \forall y\in \mathbb{Z}\quad x+y=0 )$ is false as, given an $x$, I can easily find a $y$ such that it does not hold</li>
  <li>$\forall x \in \mathbb{Z}\quad ( \exists y\in \mathbb{Z}\quad x+y=0 )$ is true, by picking $y = -x$ for any given $x$</li>
  <li>$\exists x \in \mathbb{Z}\quad ( \forall y\in \mathbb{Z}\quad x+y=0 )$ is false, as this says “given a $x$”, all $y+x=0$ for any $y \in \mathbb{Z}$</li>
  <li>$\exists x \in \mathbb{Z}\quad ( \exists y\in \mathbb{Z}\quad x+y=0 )$ is true</li>
</ul>

<h3 id="fol-statements-and-prelude-to-proofs">FOL Statements and Prelude to Proofs</h3>

<p>Consider we want to prove:</p>

<ol>
  <li>$\forall x \in D\quad p(x):true$ means that $p(x)$ for <strong>all</strong> elements in $D$</li>
  <li>$\forall x \in D\quad p(x):false$ means that there is at least <strong>one</strong> element for which $p(x)$ is false</li>
  <li>$\exists x \in D \quad p(x): true$ means there is at least <strong>one</strong> element in $D$ for which $p(x)$ is true</li>
  <li>$\exists x \in D \quad p(x):false$: means that for <strong>all</strong> elements in the domain $p(x)$ is false</li>
</ol>

<p>This means that:</p>

<table>
  <thead>
    <tr>
      <th> </th>
      <th>$\forall x \quad p(x)$</th>
      <th>$\exists x \quad p(x)$</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Prove</td>
      <td><strong>prove</strong> such as proof by contradiction, induction, etc.</td>
      <td>enough to find an <strong>example</strong></td>
    </tr>
    <tr>
      <td>Disprove</td>
      <td>enough to provide a <strong>counter example</strong></td>
      <td><strong>prove</strong> that $\forall x$ the predicate $p(x)$ is false, using …</td>
    </tr>
  </tbody>
</table>

<blockquote>
  <p><strong>Note</strong> that sometimes when a domain is “clear”, instead of $\forall x \in A\quad p(x)$ you can just write $\forall x \quad p(x)$.</p>
</blockquote>

<p><em>For example</em>: consider the FOLs, for which we will prove</p>

<ol>
  <li>
    <p>“Any even integer is divisible by 2”. Let domain be $\mathbb{Z}$</p>

\[\forall x \in \mathbb{Z}\quad (\text{even}(x) \implies 2|x)\]

    <p>where $2\vert x$ means 2 divides x. Note that technically “if it is divisible by 2, it is an even integer” is also true, so technically $\iff$ here would be correct. But since we <em>are focused on proofs</em>, we might not want to do extra work, i.e. prove both sides if using $\iff$.</p>
  </li>
  <li>
    <p>“An integer is even iff it is divisible by 2”</p>

\[\forall x \in \mathbb{Z} \quad (\text{even}(x) \iff 2|a )\]
  </li>
  <li>
    <p>“The sum of two even integers is an even integer”</p>

\[\forall x,y \in \mathbb{Z} \quad (\text{even}(x) \land \text{even}(y)) \implies \text{even}(x+y)\]

    <p>but don’t you need to specify that $\text{even}(x,y)$ is also an integer? This is not necessary here by the axiom of closure property (adding two elements in $\mathbb{Z}$ results still in $\mathbb{Z}$).</p>
  </li>
  <li>
    <p>“Let $r\in \mathbb{R}$. If $r$ is irrational, then $\sqrt{r}$ is also irrational”. We are allowed to also use the set of rationals $\Q$</p>

\[\forall r \in \mathbb{R} \quad  (r \notin \Q \to \sqrt{r} \notin \Q)\]
  </li>
  <li>
    <p>“If $x$ is even, then $x^2+x$ is even.” Domain is integer.</p>

\[\forall x \in \Z \quad (\text{even}(x) \to \text{even}(x^2+x))\]
  </li>
  <li>
    <p>“There are no pair of integers that satisfy the expression $5x+25y = 1723$”</p>

\[\neg (\exist x,y \in \mathbb{Z}\quad 5x+25y=1723)\]

    <p>or alternatively you can say</p>

\[\forall x,y \in \mathbb{Z}\quad 5x+25y\neq 1723\]
  </li>
</ol>

<blockquote>
  <p><strong>Challenge question:</strong> there exists a unique with the quantifier we already have, to express</p>

\[\exists ! x \quad p(x)\]

  <p>where $\exists !$ is used now as a shortcut to express <mark>exists a unique</mark></p>

\[\exists x \quad p(x) \land (\forall y \quad p(y) \to (y = x))\]

  <p>this hints at, to prove a uniqueness theorem, you just need to show that: 1) there exist a solution, and 2) any other working solution is the same as that solution.</p>
</blockquote>

<p>Note that it would be <strong>incorrect</strong> in this case to say</p>

\[\forall x \quad p(x) \implies (\forall y \quad p(y) \to (y = x))\]

<p>because then, it could be there is <em>no such $x$ such that $p(x)$</em>, i.e. the “exist a solution” part we wanted to express is no longer there!</p>

<h1 id="proofs">Proofs</h1>

<p>First we need to define a few jargon</p>

<blockquote>
  <p><strong>Axiom</strong>: An axiom is a proposition that is assumed to be True. You don’t need to prove them.</p>
</blockquote>

<blockquote>
  <p><strong>Lemma</strong>: A preliminary mathematical proposition for which there is/<mark>needs a proof</mark>. Generally, lemmas precede a bigger result and lay the ground to a theorem.</p>

  <ul>
    <li>a baby version of “theorem”, but still requires a proof</li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Theorem</strong>: A declarative mathematical statement for which there is/<mark>needs a proof</mark></p>

  <ul>
    <li>in greek this means “something needs to be proved”</li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Corollary</strong>: A proposition that <em>follows from a theorem</em> in just a few steps.</p>

  <ul>
    <li>i.e. once the theorem is proven, these come very naturally/can be proven easily</li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Conjecture</strong>: A strong mathematical result that is strongly believed to be true, but is <em>yet to be proven</em>.</p>
</blockquote>

<p>In general, you will be approaching them with:</p>

<p><img src="/lectures/images/2023-05-11-COMS3203_Discrete_Math/image-20230209112412432.png" alt="image-20230209112412432" style="zoom: 67%;" /></p>

<h2 id="proof-by-enumeration">Proof by Enumeration</h2>

<blockquote>
  <p>When the domain is small, we can verify the proposition <strong>for all values</strong>.</p>
</blockquote>

<p><em>For Example</em>: Proposition $\forall x \in \mathbb{Z}$ then $1 &lt; x &lt; 5 \implies (2\vert x) \lor (3\vert x)$</p>

<p><em>Proof</em>: we consider for each case $1&lt;x&lt;5$</p>

<ol>
  <li>when $x=2$, $2\vert x$ hence is true</li>
  <li>when $x=3$, $3\vert x$ is true hence true</li>
  <li>when $x=4$. $2\vert x$ is true hence true</li>
</ol>

<h2 id="direct-proof">Direct Proof</h2>

<p>Given a statement</p>

\[\forall x \in D\quad p(x) \implies q(x)\]

<p>Then in a direct proof you basically</p>

<blockquote>
  <p>Directly prove $p \implies q$ using definitions/axioms/logic. I.e. assuming $p$ is true, then $q$ is true.</p>
</blockquote>

<p><em>For Example</em>: $\forall a \in \mathbb{Z}$ and $\forall b \in \mathbb{Z}$ then</p>

\[\text{$a$ is even } \land \text{ $b$ is even } \implies (a+b) \text{ is even}\]

<p><em>Proof</em>: since we know $\text{$a$is even } \land \text{$b$is even }$</p>

<ol>
  <li>
    <p>this implies</p>

\[\exists k \in \mathbb{Z},\quad a=2k\\
\exists z \in \mathbb{Z},\quad b=2z\]
  </li>
  <li>
    <p>hence this means</p>

\[a+b = 2(k+z)\]
  </li>
  <li>
    <p>hence this means</p>

\[\exists t \in \mathbb{Z},\quad (a+b)=2t\]

    <p>e.g. by picking $t = (k+z)$</p>
  </li>
  <li>
    <p>therefore $(a+b)$ is even</p>
  </li>
</ol>

<blockquote>
  <p><em>Recall</em> that (we will use this quite often)</p>

  <ul>
    <li>$x$ is even $\iff$ $2\vert x$, or $\exists k \in \mathbb{Z},\  x = 2k$</li>
    <li>$x$ is odd $\iff$ $\neg 2\vert x$ or $\exists k \in \mathbb{Z},\  x = 2k+1$</li>
  </ul>
</blockquote>

<h2 id="proof-by-contradiction">Proof by Contradiction</h2>

<p>Consider a statement</p>

\[\forall x \in D \quad p(x) \implies q(x)\]

<blockquote>
  <p>Assume that the statement is not true, i.e.  $\neg ( p \implies q) = p \land \neg q$. Then show that this is impossible.</p>
</blockquote>

<p><em>For example</em>: prove $\forall a \in \mathbb{Z}$ and $\forall b \in \mathbb{Z}$ then</p>

\[\text{$a$ is even } \land \text{ $b$ is even } \implies (a+b) \text{ is even}\]

<p>by contradiction.</p>

<p><em>Proof</em>: assume that $p \land \neg q$</p>

<ol>
  <li>
    <p>this means we assume the following is true</p>

\[(\text{$a$ is even } \land \text{ $b$ is even })  \land \neg(a+b \text{ is even})\]

    <p><mark>notice this $\land$ induced by contradiction proof</mark>. This effectively allows us to use both LHS and RHS of the equation</p>
  </li>
  <li>
    <p>this means</p>

\[(\text{$a$ is even } \land \text{ $b$ is even })  \land (a+b \text{ is odd})\]
  </li>
  <li>
    <p>this implies</p>

\[\exists k \in \mathbb{Z},\quad a=2k\\
\exists z \in \mathbb{Z},\quad b=2z\]
  </li>
  <li>
    <p>but this means</p>

\[a+b = 2(k+z)\quad \text{is even}\]
  </li>
  <li>
    <p>yet we claimed $(a+b)$ is not even. Is a contradiction.</p>
  </li>
</ol>

<h2 id="proof-by-contrapositive">Proof by Contrapositive</h2>

<p>Given the statement</p>

\[\forall x \in D \quad p(x) \implies q(x)\]

<blockquote>
  <p>Prove by showing that $\forall x \quad \neg q(x) \implies \neg p(x)$, which <em>might be easier in times</em>.</p>

  <ul>
    <li>i.e. start with $\neg q(x)$, and conclude that $\neg p(x)$. e.g. by using a direct proof.</li>
    <li>this is useful usually when you realize the LHS of the original statement, i.e. $p(x)$ is <mark>hard to move forward</mark></li>
  </ul>
</blockquote>

<p><em>For Example</em>: prove that $\forall r \in \mathbb{R}$, if $r$ is irrational, then $\sqrt{r}$ is also irrational.</p>

<ul>
  <li>since this means $r \neq a/b$, which is hard to move forward. Hence we consider converting proof by contrapositive.</li>
</ul>

<p><em>Proof</em>: by contrapositive, then $\sqrt{r}$ is rational $\implies$ $r$ is rational. Using a direct proof</p>

<ol>
  <li>
    <p>since $\sqrt{r} \in \Q$, this means</p>

\[\exists a,b \in \mathbb{Z}, \quad \sqrt{r}=\frac{a}{b}\]
  </li>
  <li>
    <p>then this means</p>

\[r = \frac{a^2}{b^2}\]
  </li>
  <li>
    <p>this means</p>

\[\exists c,d \in \Z, \quad r = \frac{c}{d}\]

    <p>for example by letting $a^2=c$, $b^2=d$</p>
  </li>
  <li>
    <p>this means $r \in \Q$.</p>
  </li>
</ol>

<p><em>For Example</em>: let $a,b \in \Z$ prove that $a+b &gt; 100 \implies ((a &gt; 50) \lor (b &gt; 50))$</p>

<p><em>Proof</em>: We realize it is hard to move forward from $a+b &gt; 100$ as we have two numbers on LHS. Consider using the contrapositive</p>

\[((a \le 50) \land (b \le 50)) \implies a+b \le 100\]

<p>the rest is obvious by direct proof.</p>

<h2 id="proof-of-iff">Proof of IFF</h2>

<p>Consider the statement</p>

\[\forall x \in D\quad p(x) \iff q(x)\]

<p>Then essentially you need to</p>

<ul>
  <li>proof by any method that $p(x) \to q(x)$</li>
  <li>proof by any method that $q(x) \to p(x)$</li>
</ul>

<p><em>For Example</em>: prove that $\text{$x^2$is even} \iff \text{$x$is even}$. To prove this we need to prove both ways</p>

<p><em>Proof</em>. We can first prove the forward direction</p>

\[\text{$x$ is even}\implies\text{$x^2$ is even}\]

<ol>
  <li>since $x$ is even, then $x=2a$ for some $a \in \Z$</li>
  <li>therefore $x^2 = 4a^2$</li>
  <li>hence $x^2 = 2 (2a^2)$</li>
  <li>hence $x^2 = 2c$ for some $c \in \Z$</li>
  <li>so $x^2$ is even</li>
</ol>

<p>Now, we prove that</p>

\[\text{$x^2$ is even}\implies\text{$x$ is even}\]

<ol>
  <li>
    <p>its hard to do a direct proof, we can try instead contrapositive</p>

\[\text{$x$ is odd}\implies\text{$x^2$ is odd}\]
  </li>
  <li>
    <p>then this means $x = 2a+1$ for some $a \in \Z$</p>
  </li>
  <li>
    <p>hence $x^2 = 4a^2 + 2a + 1$</p>
  </li>
  <li>
    <p>hence $x^2 = 2(2a^2 + a) + 1$</p>
  </li>
  <li>
    <p>meaning $x^2 = 2c + 1$ for some $c \in \Z$</p>
  </li>
  <li>
    <p>so $x^2$ is odd</p>
  </li>
</ol>

<h2 id="proof-by-contradiction-1">Proof by Contradiction</h2>

<blockquote>
  <p>In a proof by contradiction, assume the opposite of what you are trying to prove. Then you make logical deductions until you arrive to a <strong>contradiction</strong>.</p>
</blockquote>

<p><em>For Example</em>: Prove by contradiction that there are no integer $x,y$ that satisfy $5x+25y = 1723$</p>

<p><em>Proof</em>: This means to prove that</p>

\[\forall x,y \in \Z \quad 5x + 25y \neq 1723\]

<p>By contradiction, we can first assume that this is false. Hence this means the below is true by assumption.</p>

\[\exists x,y \in \Z \quad 5x + 25y =1723\]

<ol>
  <li>
    <p>let this be true. Then this means</p>

\[5(x+5y) = 1723\]
  </li>
  <li>
    <p>hence</p>

\[x + 5y = \frac{1723}{5}\]
  </li>
  <li>
    <p>hence contradiction as LHS is integer, but RHS is not.</p>
  </li>
</ol>

<h2 id="proof-by-cases">Proof by Cases</h2>

<blockquote>
  <p>In proof by cases, try to break the proof into cases, if your starting point is too general. Make sure that your cases span <strong>all possibilities</strong></p>
</blockquote>

<p>So the general format would be to prove</p>

\[p_1 \lor \dots \lor p_n \implies q\]

<p>by proving for each $p_i \implies q$ by <em>proposition logic</em>.</p>

<hr />

<p><em>For Example</em>: Profe that for any integer $x$, $x^2 + x$ is even.</p>

<p><em>Proof</em> : this means that</p>

\[\forall x \in \Z\quad \text{$x^2+x$ is even} \equiv \forall x \in \Z\quad (x\in \Z \implies \text{$x^2+x$ is even} )\]

<p>this is straightforward using a direct proof, and essentially showing that $x(x+1)$ must include both an even number and an odd number.</p>

<p>To prove by cases, we can consider (inspired from the direct proof) that</p>

\[\forall x \in \Z\quad (\text{$x$ is even} \lor \text{$x$ is odd} \implies \text{$x^2+x$ is even} )\]

<ul>
  <li>case 1: $x$ is even, then $x = 2a$ for some $a \in \Z$
    <ul>
      <li>then $x^2 + x = 2(2a^2 + a)$ is even.</li>
    </ul>
  </li>
  <li>case 2: $x$ is odd, then $x=2a+1$
    <ul>
      <li>then $x^2 + x = 2(2a^2 + 3a + 1)$ is also even</li>
    </ul>
  </li>
  <li>therefore, $x^2 + x$ is even.</li>
</ul>

<h2 id="proof-by-counter-example">Proof by Counter Example</h2>

<blockquote>
  <p>Used to <strong>disprove</strong> some proposition, by finding an example such that the proposition is false.</p>
</blockquote>

<p>Usually you will disprove</p>

\[p \to q\]

<p>meaning to find an example such that $p$ is true but $q$ is false.</p>

<p>Some “tricks/hints” when you are stuck:</p>

<ol>
  <li>keep in mind of your domain</li>
  <li>try to create edge examples</li>
  <li>try to prove it (though you know it will not hold), so you can look for pattern when this will likely fail</li>
</ol>

<hr />

<p><em>For example</em>: disprove that $\forall a,b \in \Z\quad (a\vert b \land b\vert a)\implies a=b$</p>

<p><em>Proof</em>: counter example: $a=-b$, e.g. $a=2$ and $b=-2$. Then LHS is true, but RHS is false.</p>

<p>You can see how this edge case come about if you attempted a direct proof to “attempt to” show this is true</p>

<ol>
  <li>let $a\vert b \land b\vert a$ is true</li>
  <li>Then this means $a = xb$ and $b = ya$ for $x,y \in \Z$</li>
  <li>hence this means $a = xy \cdot a$ hence $xy = 1$</li>
  <li>but this means either $x = y = 1$ or $x=y=-1$.</li>
  <li>in the latter case, this implies $a=-b$, which means LHS is true but RHS is false</li>
</ol>

<blockquote>
  <p><strong>Note</strong> that this is <em>different</em> from proof by contradiction, from which it is a) used to <em>prove</em> instead of disprove; b) flipped the entire proposition</p>
</blockquote>

<h1 id="sets">Sets</h1>

<p>In general, we we refer to sets, we consider unordered sets</p>

<blockquote>
  <p>We will distinguish between two types of collections: <strong>unordered sets</strong> (in which, order does not matter) and <strong>ordered sets or lists</strong> (in which order matters).</p>
</blockquote>

<h2 id="unordered-sets">Unordered Sets</h2>

<blockquote>
  <p><strong>(Unordered) Set</strong>: is a collection of <mark>distinct</mark> object in which order does not matter.</p>
</blockquote>

<p>for example:</p>

\[p = \{ \text{eraser, pen, highlighter} \}\]

<p>or you can also have an infinite set</p>

\[\mathbb{Z} = \{ \dots, -2,-1,0,1,2,\dots \}\]

<p>for us, in general we assume that <mark>counting numbers start with $1$</mark></p>

\[\mathbb{N} = \{ 1,2,3,\dots \}\]

<p>though there are also some people considers $\mathbb{N}$ includes $0$. You can even have sets inside a set</p>

\[bp = \{ \text{notebook, laptop, } \{ \text{eraser, pen, highlighter} \} \}\]

<p>but if we the following is <strong>not a set</strong></p>

\[S = \{ 1,1,2,3 \}\]

<p>since you have duplicates. This becomes a <em>multiset</em>, which we will not cover in this class.</p>

<blockquote>
  <p><strong>Notation</strong>:</p>

  <ul>
    <li>
      <p>belongs to $\in$. Means is a <em>member/element</em> in a set is denoted as</p>

\[a \in \mathbb{Z}\]
    </li>
    <li>
      <p>empty set is denoted as either</p>

\[b = \{\},\quad\text{or}\quad b = \emptyset\]
    </li>
    <li>
      <p>does not belong to $\notin$:</p>

\[\text{fridge} \notin \text{backpack}\]

      <p>where backpack is a set.</p>
    </li>
  </ul>
</blockquote>

<p>some caution include that, let</p>

\[bp = \{ \text{notebook, laptop, } \{ \text{eraser, pen, highlighter} \} \}\]

<p>then technically</p>

<ul>
  <li>$\text{notebook} \in bp$</li>
  <li>$\text{pen} \notin bp$ because “pen” is technically <em>not a member</em> of the set, but ${ \text{eraser, pen, highlighter} } \in bp$</li>
</ul>

<blockquote>
  <p><strong>Subset</strong>: let $A,B$ be two sets. $A$ is a subset of $B$ provided that every element in $A$ is also an element in $B$. We denote that</p>

\[A \subseteq B\]

  <p>where this is “subset <em>or equal</em>”.</p>
</blockquote>

<p>Note that the difference between $\in$ and $\subseteq$ is that</p>

<ul>
  <li>$\in$ can be used <strong>with an element</strong> or set, since a set can be an element</li>
  <li>$\subseteq$ must only be used with a <strong>set</strong></li>
</ul>

<p>But note that we can <em>translate the definition of subset to FOL</em>:</p>

<p>Let $A,B$ be sets. Then</p>

\[A \subseteq B \iff (\forall a \in A\quad a \in B)\]

<p>(just as a practice) What if the domain is $\Z$, i.e. for both sets?</p>

\[A \subseteq B \iff (\forall a \in \Z \quad a \in A \implies a \in B)\]

<p><em>For Example</em>:</p>

<ul>
  <li>${4} \subseteq { 1,2,3,4 }$ is true</li>
  <li>${4} \nsubseteq { 1,2,3,{4} }$ since the element in LHS is $4$, whereas the element on RHS is ${4}$.</li>
  <li>${{4}} \subseteq { 1,2,3,{4} }$ is true</li>
  <li>${} \subseteq { 1,2,3,{4} }$ in fact, ${} \subseteq S$ for any set $S$.</li>
  <li>${} \notin { 1,2,3,{4} }$ as empty set is not a member of the RHS.</li>
</ul>

<blockquote>
  <p><strong>Equality between sets</strong>: two sets are equal $A = B$ provided</p>

\[A = B \iff A \subseteq B \land B \subseteq A\]

  <p>or we can write as FOL</p>

\[A = B \iff (\forall a \quad a \in A \iff a \in B)\]

</blockquote>

<p>note that the above strictly says “take any element $a$ in the universe, if $a \in A$ then $a \in B$ and vice versa”. Therefore the below is <strong>wrong</strong></p>

\[A = B \iff (\forall a \quad a \in A \land a \in B)\]

<p>this instead says “every element in the universe is both in $A$ and $B$”. But yuo can do something like (<strong>correct</strong>)</p>

\[A = B \iff (\forall a \in A \quad a \in B) \land (\forall a \in B \quad a \in A)\]

<p>which is basically saying $A \subseteq B \land B \subseteq A$.</p>

<blockquote>
  <p><strong>Proper Subset</strong>: being a subset <em>but not equal</em></p>

\[A \subset B \iff A \subseteq B \land A \neq B\]

</blockquote>

<p><em>For Example</em>: $\Z \subset \Q$ because</p>

\[\Z \subset \Q \iff \Z \subseteq \Q \land \Z \neq \Q\]

<p>and of course</p>

<ul>
  <li>${1} \subset {1,2}$</li>
  <li>${1} \subseteq {1,2}$</li>
  <li>but ${1,2} \subseteq {1,2}$ only</li>
</ul>

<blockquote>
  <p><strong>Universal Set</strong> denoted as $U$, which is the set of <strong>everything under consideration</strong>.</p>
</blockquote>

<p>(Barber’/Russell’s paradox: in general, whenever there is self-reference, there is typically a paradox)</p>

<blockquote>
  <p><strong>Power Set</strong>: the set of <em>all subsets</em> of a set $A$ is called a power set $P(A)$</p>
</blockquote>

<p>For example, let $S = {1,2}$, then</p>

\[P(S) = \{ \empty, \{1\}, \{2\}, \{1,2\} \}\]

<p>basically,  a set including $0$ elements on the set, $1$ element of the set, and then $2$ elements of the set.</p>

<p>This means <strong>empty set is an element of any powerset</strong>, so that</p>

\[P(\empty) = \{ \empty \}\]

<p>How many elements are there in a powerset? There are <mark>$2^k$ elements in the powerset $P(S)$</mark>, for $k$ is the number of elements in $S$.</p>

<ul>
  <li>
    <p>proof 1: For each element in $P(S)$, e.g. let $S={a,b,c}$, then any power set is essentially:</p>

    <table>
      <thead>
        <tr>
          <th> </th>
          <th>a</th>
          <th>b</th>
          <th>c</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>$\empty$</td>
          <td>F</td>
          <td>F</td>
          <td>F</td>
        </tr>
        <tr>
          <td>${a}$</td>
          <td>T</td>
          <td>F</td>
          <td>F</td>
        </tr>
        <tr>
          <td>${b}$</td>
          <td>F</td>
          <td>T</td>
          <td>F</td>
        </tr>
        <tr>
          <td>${c}$</td>
          <td>F</td>
          <td>F</td>
          <td>T</td>
        </tr>
        <tr>
          <td>${a,b}$</td>
          <td>T</td>
          <td>T</td>
          <td>F</td>
        </tr>
        <tr>
          <td>…</td>
          <td> </td>
          <td> </td>
          <td> </td>
        </tr>
      </tbody>
    </table>

    <p>so basically it is the number of combinations of the truth table</p>
  </li>
  <li>
    <p>proof 2: just use</p>

\[{0 \choose k} + {1 \choose k} + \cdots + {k \choose k} =2^k\]
  </li>
</ul>

<blockquote>
  <p><strong>Finite Set</strong>: a finite set is a set has $n$ elements for $n \in \Z^+$. Otherwise we call the set infinite.</p>
</blockquote>

<blockquote>
  <p><strong>Cardinality</strong>: let $A$ be a finite set, the number of elements in $A$ is called cardinality, denoted as $\vert A\vert$</p>
</blockquote>

<p>For example:</p>

<ul>
  <li>if $A$ has $n$ elements, then $\vert A\vert =n$.</li>
  <li>$S={1,2,3,…,20}$. Then $\vert S\vert =20$, and that $\vert P(S)\vert  = 2^{20}$.</li>
  <li>$\vert \Z\vert$ is then technically sloppy notation as $\Z$ is not a finite set, but we will use this later in functions.</li>
</ul>

<blockquote>
  <p>We have seen a lot of connections between FOL and sets. We will see how to build set using “<strong>set builders</strong>”, a compact way to define your set using FOL (and PL):</p>

\[S = \{ x | P(x) \}\]

  <p>where $P(x)$ is a FOL</p>
</blockquote>

<p><em>For Example</em>:</p>

<ul>
  <li>
    <p>instead of $S={1,2,3…,100}$, you can write</p>

\[S = \{ x | x \in \Z \land (1 \le x \le 100) \}\]

    <p>to avoid any ambiguity</p>
  </li>
  <li>
    <p>the set of even integers is then</p>

\[E = \{ x | x\in \Z \land 2|x \}\]

    <p>or more properly</p>

\[E = \{ x | x\in \Z \land (\exists a \in \Z \quad x=2a) \}\]
  </li>
  <li>
    <p>define the set of composite (non prime) number (excluding 1)</p>

\[S = \{ x | x\in \Z^+ \land \underbrace{(\exists a \in \Z^+ \quad (1&lt;a&lt;x) \land a|x)}_{\text{$a$ is non-prime}} \}\]

    <p>which basically says “every member in the set is (a positive integer AND is non-prime)”.</p>

    <p>note that it would be “incorrect” to write</p>

\[S = \{ x | x\in \Z^+ \quad {(\exists a \in \Z^+ \quad (1&lt;a&lt;x) \land a|x)}\}\]

    <p>because we are <em>not talking about $\forall x \in \Z^+$</em> or $\exists x \in \Z^+$, we are just letting $x\in \Z^+$ being a <strong>property of elements in this set.</strong></p>
  </li>
  <li>
    <p>define $S={1,4,9,16,…,100}$ by set builder:</p>

\[S=\{x|x\in Z\land (1\le x \le 100) \land (\exists a\in \Z \quad x=a^2 )\}\]

    <p>or you can</p>

\[S=\{x|x\in Z\land (1\le x \le 100) \land (\sqrt{x} \in \Z) \}\]

    <p>technically you can even omit $x\in \Z$ since by closure property this is implied by $\sqrt{x} \in \Z$.</p>
  </li>
</ul>

<blockquote>
  <p>Make sure that your set builder includes <strong>all the elements</strong> and <strong>only the elements intended</strong>, i.e. is correct and complete. This mean you should check</p>

\[\forall x \quad (x \in S \iff P(x))\]

  <p>so that forward is correctness, and backward is completeness (i.e. $\forall x \in U \quad P(x) \to x\in S$)</p>
</blockquote>

<h2 id="set-operations-and-properties">Set Operations and Properties</h2>

<blockquote>
  <p><strong>Set operations</strong> defined between 2 sets</p>

  <ul>
    <li>
      <p><strong>intersection</strong> of two sets:</p>

\[A \cap B = \{x | (x\in A) \land (x \in B) \}\]

      <p>basically conjunction in PL</p>
    </li>
    <li>
      <p><strong>union</strong> of two sets</p>

\[A \cup B = \{x | (x\in A) \lor (x \in B) \}\]
    </li>
    <li>
      <p><strong>difference</strong> between two sets</p>

\[A - B = \{x | (x\in A) \land (x \neq B) \}\]

      <p>in $A$ but no in $B$</p>
    </li>
    <li>
      <p><strong>complement</strong> (with respect to the universe)</p>

\[A^c = \bar{A} = \{x | x \notin A\}\]

      <p>where $x \in U$ part of the universe is assumed.</p>
    </li>
    <li>
      <p><strong>Cartesian product</strong> between two sets</p>

\[A\times B = \{ (a,b) | a\in A\land b \in B \}\]

      <p>for example $A={ c,d }$ and $B={e,f,g}$, then $A\times B={ (c,e),(c,f),(c,g),(d,e), (d,f),(d,g) }$. Therefore, this also means that the cardinality $\vert A \times B\vert  = \vert A\vert \cdot \vert B\vert$.</p>
    </li>
  </ul>
</blockquote>

<p>or even Venn Diagram</p>

<p><img src="/lectures/images/2023-05-11-COMS3203_Discrete_Math/image-20230223110701172.png" alt="image-20230223110701172" style="zoom: 50%;" /></p>

<p>Then of course, you also have certain <strong>properties <em>of those operations</em></strong></p>

<p><img src="/lectures/images/2023-05-11-COMS3203_Discrete_Math/image-20230223111557244.png" alt="image-20230223111557244" style="zoom:50%;" /></p>

<p><em>For Example</em>:: prove that $\overline{A \cap B} = \bar{A} \cup \bar{B}$ using <strong>set builders</strong></p>

<p>since by definition of set operations</p>

\[\overline{A \cap B} = \{ x | x \notin (A \cap B) \}\]

<p>then we can rewrite as</p>

\[\overline{A \cap B} = \{ x | \neg (x \in (A \cap B)) \}\]

<p>but we can then define $A \cap B$ by</p>

\[\overline{A \cap B} = \{ x | \neg (x \in A \land x \in B) \}\]

<p>then by De Morgan</p>

\[\overline{A \cap B} = \{ x | x \notin A \lor x\notin B \}\]

<p>then finally just put it into our target form</p>

\[\overline{A \cap B} = \{ x | x \in \bar{A} \lor x \in \bar{B} \}\]

<p>hence</p>

\[\overline{A \cap B} = \{ x | x \in \bar{A} \cup \bar{B} \}\]

<p>But in general, there will be multiple ways to prove this.</p>

<h2 id="proofs-on-sets">Proofs on Sets</h2>

<p>We have covered a bit of how to prove set equality in previous section in an example. Here we discuss <em>more techniques</em> that you can use for set proofs.</p>

<ol>
  <li><strong>To prove that $A \subseteq B$</strong>
    <ul>
      <li>let $x \in A$</li>
      <li>…</li>
      <li>therefore $x \in B$</li>
    </ul>
  </li>
  <li><strong>To prove $A = B$ by showing that $A \subseteq B \land B \subseteq A$</strong>
    <ul>
      <li>show that $A \subseteq B$ by showing $x \in A$ … therefore $x \in B$</li>
      <li>show that $B \subseteq A$ by showing $x \in B$ … therefore $x \in A$</li>
    </ul>
  </li>
</ol>

<blockquote>
  <p>To prove equality, you can use <strong>any of the three methods</strong></p>

  <ol>
    <li>(element level) use <strong>set builder</strong>
      <ul>
        <li>e.g. see previous section on proving $\overline{A \cap B} = \bar{A} \cup \bar{B}$</li>
      </ul>
    </li>
    <li>(element level) use the <strong>subset</strong> technique above, e.g. to prove $F=E$
      <ul>
        <li>i.e. you can either prove $x\in F \implies x\in E$, and then again for $x \in E \implies x\in F$</li>
        <li>or you can shorten the above and <mark>show that $x\in F \iff x \in E$</mark> (e.g. see the last example in <a href="#Relations">Relations</a>)</li>
      </ul>
    </li>
    <li>(set level) using <strong>set operations</strong>, e.g. distributivity, De Morgan, etc.</li>
  </ol>
</blockquote>

<p><em>For Example</em>: let $F$ and $E$ be two sets.</p>

\[F = \{z|z \in \Z \land z = a+b \land a\text{ is odd} \land b \text{ is odd}\}\]

\[E = \{ x | x \in \Z \land 2 |x \}\]

<p>Prove that $F=E$.</p>

<ul>
  <li>
    <p>Prove that $F \subseteq E$</p>

    <ol>
      <li>
        <p>let $x \in F$.</p>
      </li>
      <li>
        <p>Then this means $x = a + b$ for some $a,b\in \Z$ where $a,b$ is odd</p>
      </li>
      <li>
        <p>therefore this means</p>

\[x = (2t+1)+(2w+1)\]
      </li>
      <li>
        <p>we can rewrite this as</p>

\[x = 2(t+w+1)\]
      </li>
      <li>
        <p>so $x$ is even, and $2\vert x$</p>
      </li>
      <li>
        <p>therefore $x \in E$</p>
      </li>
    </ol>
  </li>
  <li>
    <p>Prove that $E \subseteq F$</p>

    <ol>
      <li>
        <p>let $x \in E$</p>
      </li>
      <li>
        <p>then this means $x=2t$ for some $t \in \Z$</p>
      </li>
      <li>
        <p>then we can rewrite this as</p>

\[x = (2t+1) - 1\]
      </li>
      <li>
        <p>therefore we can have $a = 2t+1$ and $b=-1$, meaning $a,b$ are odd</p>
      </li>
      <li>
        <p>therefore $x \in F$</p>
      </li>
    </ol>
  </li>
</ul>

<h2 id="size-of-the-union">Size of the Union</h2>

<blockquote>
  <p><strong>Size of the union</strong>: Let $A,B$ be two sets. Then</p>

\[|A\cup B| = |A| + |B| - |A \cap B|\]

  <p>But if $A,B$ are disjoint, then</p>

\[|A \cup B| = |A| + |B|\]

</blockquote>

<p>For example: What is $\vert A \cup B\cup C\vert$</p>

<p>Following the step above, we have</p>

\[\begin{align*}
&amp;\quad |A \cup B \cup C| \\
&amp;= |A \cup B| + |C| - |A \cup B \cap C| \\
&amp;= |A|+|B|-|A \cap B| + |C| - |(A \cup B) \cap C|
\end{align*}\]

<p>but notice that:</p>

\[(A \cup B) \cap C = (A\cap C) \cup (B \cap C)\]

<p>Hence</p>

\[|(A \cup B) \cap C| = |A\cap C| + |B \cap C| - |A \cap B \cap C|\]

<p>Hence we obtain</p>

\[|A \cup B \cup C| = |A|+|B|+|C| - |A \cap B| - |A \cap C| - |B \cap C| + |A \cap B \cap C|\]

<blockquote>
  <p>Note that this including and then excluding back will also be touched on in counting, called the <strong>Principle of Inclusion Exclusion</strong>.</p>
</blockquote>

<p><em>Another in class example</em>: Let there be 16 people taking DM, 16 taking AP, and 11 taking OS. We are also given that</p>

<ul>
  <li>5 taking both DM and OS, and among them 3 taking AP as well</li>
  <li>8 people taking AP only</li>
  <li>5 people taking OS only</li>
</ul>

<p>We want to know how many want to take DM only.</p>

<p>Here, we solve it using <strong>Venn Diagram</strong></p>

<p><img src="/lectures/images/2023-05-11-COMS3203_Discrete_Math/image-20230304232008190.png" alt="image-20230304232008190" style="zoom: 33%;" /></p>

<h2 id="ordered-setslists">Ordered Sets/Lists</h2>

<p>Now, we turn to ordered sets, where the order of the elements matter.</p>

<blockquote>
  <p><strong>A list</strong> is an <mark>ordered</mark> set of element, and <mark>elements can now repeat</mark>. This is often denoted using parenthesis</p>

\[(e_1,e_2, \dots, e_n)\]

</blockquote>

<p>For example:</p>

<ul>
  <li>
    <p>$(9,1,1)$ is a valid ordered list</p>
  </li>
  <li>
    <p>we actually touched on this before</p>

\[A\times B = \{ \underbrace{(a,b)}_{\text{a list}} | a\in A\land b \in B \}\]

    <p>where order mattered, so that $A \times B \neq B \times A$.</p>
  </li>
  <li>
    <p>binary representation of numbers are also lists, so that all of the below are <em>different lists</em>: $101,110,011$.</p>
  </li>
</ul>

<h1 id="relations">Relations</h1>

<p>Remember that for Cartesian product, we had</p>

\[A\times B = \{ (a,b) | a\in A\land b \in B \}\]

<p>so that let $S={A,D }$ being Annie and Daniel, and $C={DM, OS}$ being Discret Math and OS. Then</p>

\[S \times C = \{ (A,DM),(A,OS),(D,DM),(D,OS) \}\]

<p>but this doesn’t mean anything. Say we want to use this to represent “taking classes”</p>

<p>So we are taking <strong>subset</strong> to represent a <strong>meaningful relationship</strong>. i.e.</p>

\[R_{\mathrm{take class}} = \{ (A,DM),(D,DM) \}\]

<p>hence also $R_{\mathrm{take class}} \subseteq (S \times C)$</p>

<blockquote>
  <p><strong>Relation</strong>: let $A,B$ be two sets. We say that $R$ is a relation from $A$ to $B$ provided</p>

\[R \subseteq A \times B\]

  <p>and that $R$ is a <strong>set of pairs</strong>.</p>
</blockquote>

<p><em>For Example</em>:</p>

<ul>
  <li>
    <p>Let $A = {1,2}$. Then</p>

\[A \times A = \{ (1,1),(1,2),(2,1),(2,2) \}\]

    <p>consider a relation</p>

\[R = \{ (1,1),(1,2),(2,2) \}\]

    <p>then this $R$ means $\le$. in other words:</p>

\[(x,y)\in R \iff x&lt;y\]
  </li>
  <li>
    <p>Let $A = {1,2}$. Let $R_{even}$ be defined <strong>from $A$ to $A$</strong></p>

\[(x,y) \in R_{even} \iff x+y \text{ is even}\]

    <p>then this means</p>

\[R_{even} = \{ (1,1),(2,2) \}\]

    <p>or using set builders, this means</p>

\[R_{even} = \{ (x,y) | x\in A \land y \in A \land 2|(x+y) \}\]
  </li>
</ul>

<blockquote>
  <p>In general, we <strong>notate the relation</strong> as two ways</p>

\[(x,y) \in R_{even} \iff x+y \text{ is even}\]

  <p>or</p>

\[x  R_{even} y \iff x+y \text{ is even}\]

</blockquote>

<p><em>For Example</em>: Let $R$ be a relation on $\Z$, i.e. from $\Z$ to $\Z$.</p>

\[x R y \iff x \text{ divides }y\]

<p>then what is $R$? We can first list a few examples</p>

\[R = \{ (2,4),(2,6),(1,2), \dots \}\]

<p>meaning</p>

\[R = \{ (x,y) | x\in \Z \land y \in \Z \land x|y \}\]

<blockquote>
  <p>Note that a relation can involve <mark>two or more sets</mark>, i.e. n-ary relations.</p>
</blockquote>

<p><em>For Example</em>: a simple one</p>

\[R = \{ (a,b,c)| a \in A \land b \in B \land c \in C \}\]

<p>is a legit relation.</p>

<blockquote>
  <p><strong>Inverse of a Relation</strong>: let $R$ be a relation from $A$ to $B$. We define the inverse of $R$ denoted as $R^{-1}$ as follows</p>

\[\forall x \in A,\forall y\in B\qquad (x,y)\in R \iff (y,x) \in R^{-1}\]

  <p>so that $R^{-1}$ is a <strong>relation from $B$ to $A$</strong>.</p>
</blockquote>

<blockquote>
  <p><strong>Proposition: inverse of inverse is itself</strong></p>

\[R = (R^1)^{-1}\]

</blockquote>

<p><em>Proof</em> (using the subset technique):</p>

<ul>
  <li>prove $R \subseteq (R^{-1})^{-1}$:
    <ol>
      <li>let $(x,y) \in R$.</li>
      <li>then by definition of inverse $(y,x) \in R^{-1}$</li>
      <li>therefore $(x,y) \in (R^{-1})^{-1}$</li>
    </ol>
  </li>
  <li>prove $(R^{-1})^{-1} \subseteq R$:
    <ol>
      <li>let $(x,y) \in (R^{-1})^{-1}$.</li>
      <li>then by definition of inverse $(y,x) \in R^{-1}$</li>
      <li>therefore $(x,y) \in R$</li>
    </ol>
  </li>
</ul>

<p>But we notice that the step is <mark>symmetrical/same</mark> in both ways. Hence this proof <mark>can be proven in much fewer lines</mark></p>

\[(x,y) \in R \iff (y,x) \in R^{-1} \iff (x,y) \in (R^{-1})^{-1}\]

<h2 id="representation-of-relation">Representation of Relation</h2>

<p>We can visualize a relation using:</p>

<ol>
  <li><strong>Directed Graphs</strong> (DiGraphs)</li>
  <li><strong>Matrix</strong> (a boolean matrix)</li>
</ol>

<blockquote>
  <p><strong>Digraph</strong>: a visual representation of a relation with a set of nodes (vertices) connected by <mark>directed</mark> edges (arcs)</p>
</blockquote>

<p>For example: this relation is a subset of cross product $R \subseteq {1,2,3}\times {1,2,3}$</p>

<p><img src="/lectures/images/2023-05-11-COMS3203_Discrete_Math/image-20230302102725671.png" alt="image-20230302102725671" style="zoom: 40%;" /></p>

<p>notice that here <mark>each node is an element in the pair</mark>, and in general, the graph <mark>does not have to be connected</mark> (e.g. imagine $R={(1,1),(2,2)}$)</p>

<blockquote>
  <p><strong>Matrix</strong>: A relation $𝑅$ defined from set $𝐴$ to set $𝐵$ can be represented by a Boolean matrix in which the rows are elements of $𝐴$ and the columns are represented elements of $𝐵$ and each entry of the matrix at row $𝑖$ column $𝑗$ is 1 if there is a relation through $𝑅$ between the ith element in $𝐴$ and the jth element in $𝐵$, otherwise the entry is zero.</p>
</blockquote>

<p><img src="/lectures/images/2023-05-11-COMS3203_Discrete_Math/image-20230302103442944.png" alt="image-20230302103442944" style="zoom:50%;" /></p>

<p>Note that since essentially relations are <em>sets</em>:</p>

<blockquote>
  <p><strong>All the properties on set operations apply to relations as well.</strong> For instance, intersection is commutative for relations, and we have $R_1 \cap R_2 = R_2 \cap R_1$</p>
</blockquote>

<h2 id="properties-of-relations">Properties of Relations</h2>

<p>Some relations <em>can have</em> <mark>special</mark> properties, which would come useful later</p>

<ul>
  <li>
    <p><strong>Reflexivity</strong>: let $R$ be a relation defined on a set $A$. The relation is <strong>reflexive</strong></p>

\[R\text{ is reflexive}\iff \forall x \in A\quad (x,x)\in R\]

    <p>or you can also denote</p>

\[R\text{ is reflexive}\iff \forall x \in A\quad xRx\]

    <p>note that</p>

    <ul>
      <li>
        <p>graphically, it means for $\forall x\in A$, you have a self-loop</p>
      </li>
      <li>
        <p>the following would be incorrect: $R^{-1} = R$. e.g. let $R={(1,2),(2,1)}$</p>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>Not Reflexivity</strong>: then there exists a pair that is not in $R$:</p>

\[R\text{ is not reflexive}\iff \exists x \in A\quad (x,x)\notin R\]

    <p>or you can also denote</p>

\[R\text{ is not reflexive}\iff \exists x \in A\quad x\not R x\]
  </li>
  <li>
    <p><strong>Irreflexive</strong>: then basically <strong>no self-loops</strong>:</p>

\[R\text{ is irreflexive}\iff \forall x \in A\quad (x,x)\notin R\]

    <p>examples include “is parent of”, “&gt;”.</p>
  </li>
  <li>
    <p><strong>Symmetric</strong>: “all directed edges = undirected edges”</p>

\[R\text{ is symmetric}\iff \forall x,y \in A\quad (x,y)\in R \implies (y,x)\in R\]

    <p>e.g. $A={1,2,3}$, and a symmetric relation $R={(1,2),(2,1)}$</p>
  </li>
  <li>
    <p><strong>Not symmetric</strong>: negation of the above. There exist a pair that is not “reciprocal”  (including “self-reciprocity”)</p>

\[R\text{ is not symmetric}\iff \exists x,y \in A\quad (x,y)\in R \land (y,x)\notin R\]
  </li>
  <li>
    <p><strong>Antisymmetric</strong>: there is never reciprocity (except “self-reciprocity”)</p>

\[R\text{ is anti-symmetric}\iff \forall x,y \in A\quad xRy \land yRx \implies x=y\]

    <p>note that the this is <mark>different from the below</mark></p>

\[R\text{ is anti-symmetric}\iff \forall x,y \in A\quad (x,y)\in R \implies (y,x)\notin R\]

    <p>the upshot is that you can have a relation that is <mark>both symmetric and anti-symmetric</mark>, and also being both symmetric and not anti-sym.</p>
  </li>
  <li>
    <p><strong>Transitivity</strong>: very useful later</p>

\[R\text{ is transitive}\iff \forall x,y,z \in A\quad xRy \land yRz \implies xRz\]
  </li>
</ul>

<blockquote>
  <p>Note that when you have $\forall x\in A \quad \text{blablabla}$, be careful how <mark>$A$ is defined</mark></p>
</blockquote>

<p><em>For Example</em>: Consider the following relations defined by $A = {1,2,3}$</p>

<ul>
  <li>
    <p>$R_1= { (1,3),(3,3),(3,1),(2,2),(2,3),(1,1),(1,2) }$</p>

    <ul>
      <li>is reflexive: because $\forall x \in {1,2,3}\quad xRx$</li>
      <li>not symmetric: because $(2,3)\in R \land (3,2) \notin R$</li>
      <li>not anti-symmetric: because $1R3\land 3R1$ but $1\neq 3$</li>
      <li>not transitive: $2R3\land 3R1$ but $2 \not R1$ (better see this drawing a <strong>Digram</strong>)</li>
    </ul>

    <p><img src="/lectures/images/2023-05-11-COMS3203_Discrete_Math/image-20230302111414955.png" alt="image-20230302111414955" style="zoom:33%;" /></p>
  </li>
  <li>
    <p>$R_2 = { (1,1),(2,2),(3,3) }$ is symmetric and anti-symmetric</p>

    <ul>
      <li>is reflexive</li>
      <li>is symmetric: because for each element <em>in the relation</em>, $xRy \to yRx$</li>
      <li>is anti-symmetric: yes. Just proof by enumeration.</li>
      <li>is transitive: yes. Just proof by enumeration.</li>
    </ul>
  </li>
  <li>
    <p>$R_3={ (1,1),(1,2),(2,3),(3,1),(1,3) }$</p>

    <ul>
      <li>not irreflexive: because $(1,1)$ is there</li>
      <li>is symmetric: no</li>
      <li>is anti-symmetric: no, because $(1,3)$ and $(3,1)$ exists</li>
      <li>is transitive: no, because $(2,3)$ and $(3,1)$ but no $(2,1)$</li>
    </ul>
  </li>
  <li>
    <p>$R_4 = { (1,2),(2,3),(1,3) }$</p>

    <ul>
      <li>is irreflexive: no self-loops</li>
      <li>is anti-symmetric: yes, because there is no reciprocity whatsoever</li>
      <li>is transitive: yes, proof by enumeration</li>
    </ul>
  </li>
</ul>

<p>Consider the following $R$ acting on $\Z$:</p>

<table>
  <thead>
    <tr>
      <th>$R$</th>
      <th>reflexive</th>
      <th>irreflexive</th>
      <th>symmetric</th>
      <th>anti-symmetric</th>
      <th>transitive</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>$=$</td>
      <td>yes</td>
      <td>no</td>
      <td>yes</td>
      <td>yes</td>
      <td>yes</td>
    </tr>
    <tr>
      <td>$\le$</td>
      <td>yes</td>
      <td>no</td>
      <td>no</td>
      <td>yes</td>
      <td>yes</td>
    </tr>
    <tr>
      <td>$&lt;$</td>
      <td>no</td>
      <td>yes</td>
      <td>no</td>
      <td>yes</td>
      <td>yes</td>
    </tr>
  </tbody>
</table>

<p>where:</p>

<ul>
  <li>$R_=$ is symmetric because if $x=y \implies y=x$, and is transitive, since $x=y\land y=z \implies x=z$. Finally it is also anti-symmetric because $a=b\land b =a \implies a=b$ (different from transitive)</li>
  <li>$R_\le$ is  reflexive since $\forall x\in \Z\quad x\le x$. Hence this is also not irreflexive. It is also not symmetric since $1 \le 2$ but $2 \not \le 1$. By axioms $a \le b \land b \le a\implies a=b$ is anti-symmetric.</li>
  <li>$R_&lt;$ is anti-symmetric because of <em>benefit of doubt</em>: $a &lt; b \land b &lt; a\implies a=b$ is true because LHS is <em>always false</em>.</li>
</ul>

<blockquote>
  <p><strong>Equivalence Relation</strong>: Let $R$ be a relation on $A$. We call a relation an equivalence relation provided</p>

  <ol>
    <li>$R$ is reflexive</li>
    <li>$R$ is symmetric</li>
    <li>$R$ is transitive</li>
  </ol>
</blockquote>

<p>For example, let $R$ be a relation between sets “$R$: have same cardinality”. So that (<mark>notice now we are operating on sets)</mark> let $A,B$ be sets:</p>

\[A,B\subseteq S\quad ARB\iff |A| = |B|\]

<p>note that since we are operating on sets being subsets of $S$, this means our relations are $R\subseteq P(S)\times P(S)$ defined on power sets.</p>

<p>Then, we want to prove that $R$ is an equivalence relation:</p>

<ul>
  <li>is reflexive, since $\forall A \subseteq S\quad \vert A\vert =\vert A\vert$</li>
  <li>is symmetric, since $\forall A,B\subseteq S \quad \vert A\vert =\vert B\vert \implies \vert B\vert =\vert A\vert$</li>
  <li>is transitive, since $\forall A,B \subseteq S\quad \vert A\vert =\vert B\vert \land \vert B\vert =\vert C\vert \implies \vert A\vert =\vert C\vert$</li>
</ul>

<p>Why do we care about this property? Because</p>

<blockquote>
  <p><strong>Equivalence Classes</strong>: let $R$ be an equivalence relation on $A$. Then let $a\in A$. The equivalence class of $a$, denoted as $[a]$ is the set of <mark>all elements in $A$</mark>, related to $a$ <mark>through the relation $R$</mark>:</p>

\[[a] = \{ x | x\in A \land x Ra \}\]

  <p>notice that it is defined through a <strong><em>particular relation</em></strong>, and you will see <strong>$a$ itself will always belong to this set</strong></p>
</blockquote>

<blockquote>
  <p>Why do we care about equivalence sets? You will see that</p>

  <ul>
    <li>
      <p>objects in an equivalence sets share <em>similar properties</em></p>
    </li>
    <li>
      <p>can <em>partitions sets into equivalence classes</em> - cutting down the amount of cases necessary to prove something.</p>
    </li>
  </ul>
</blockquote>

<p>For example:</p>

<ul>
  <li>let $R$ being the cardinality of sets. Then $[\empty] = {\empty}$</li>
  <li>let $R$ be the relation “Have same parents as you” $[\text{you}] = {\text{you, your siblings}}$</li>
</ul>

<blockquote>
  <p><strong>Properties of Equivalence Classes</strong>: let $R$ be an equivalence class on $A$, then</p>

  <ol>
    <li>$a\in [a]$ is always there (because an equivalence class is reflexive)</li>
    <li>$\forall a \in A\quad [a]\neq \empty$ due to the above</li>
    <li>if I take the equivalence class of all elements, then $\bigcup_{a\in A}[a] = A$</li>
  </ol>
</blockquote>

<p>Proof for $\bigcup_{a\in A}[a] = A$. We notice that this is basically proving <strong>equality between sets</strong>. We can then do:</p>

<ul>
  <li>$\bigcup_{a\in A}[a] \subseteq A$:
    <ol>
      <li>let $x \in \bigcup_{a\in A}[a]$.</li>
      <li>then this means $x$ must belong to <em>some equivalence class</em> $\exists a\in A\quad x\in [a]$</li>
      <li>but we know $[a]\subseteq A$</li>
      <li>therefore $x \in A$</li>
    </ol>
  </li>
  <li>$A \subseteq \bigcup_{a\in A}[a]$
    <ol>
      <li>let $x\in A$</li>
      <li>then $x\in [x]$</li>
      <li>therefore $x \in \bigcup_{a\in A}[a]$.</li>
    </ol>
  </li>
</ul>

<p><em>For example</em>, consider $R$ be defined on a set of 2x2 board configuration $S$, so that:</p>

\[\text{board}_1\ R\ \text{board}_2 \iff \text{board 1 and board 2 can be obtained form each other by reflection or rotation}\]

<p>we can:</p>

<ol>
  <li>
    <p>show that this relation is an <strong>equivalence relation</strong> (i.e. is reflexive, symmetric, and transitive)</p>
  </li>
  <li>
    <p>we can find all its equivalence classes and realize they are <strong>partitions!</strong></p>

    <p><img src="/lectures/images/2023-05-11-COMS3203_Discrete_Math/image-20230307150928998.png" alt="image-20230307150928998" style="zoom: 33%;" /></p>
  </li>
</ol>

<h2 id="relation-of-congruence-modulo-n">Relation of congruence modulo n</h2>

<p>This is used a lot in cryptography, and number theory.</p>

<blockquote>
  <p><strong>Congruence modulo n</strong>: let $n$ be a positive integer. We say that two integers $x,y\in \Z$ are congruent modulo n:</p>

\[x \equiv y(\mathrm{mod}\ n)\]

  <p><mark>provided that $n$ divides the difference $n\vert (x-y)$</mark>. Note that In the context of relations, <strong>”$\equiv$” means congruent.</strong></p>
</blockquote>

<p><em>For example</em>,</p>

<ul>
  <li>$3\equiv 13 (\mathrm{mod}\ 10)$ reads as “$3$ is congruent to $13$ modulo $10$”</li>
  <li>$13\equiv 3 (\mathrm{mod}\ 10)$</li>
  <li>$3\not\equiv 22 (\mathrm{mod}\ 10)$</li>
</ul>

<blockquote>
  <p><strong>Theorem</strong>: let $n$ be a positive integer. The relation “congruent modulo $n$” is an <strong>equivalence relation</strong> on the set of integers</p>
</blockquote>

<p><em>Proof</em>:</p>

<ul>
  <li>
    <p>is reflexive. This means we want to show that</p>

\[\forall x \in \Z,\quad x\equiv x(\mathrm{mod}\ n)\]

    <p>by definition, this means $\iff$ $n\vert (x-x)$, which is true since $n\vert 0$.</p>
  </li>
  <li>
    <p>is symmetric. This means we want to show that</p>

\[\forall x,y \in \Z,\quad x\equiv y(\mathrm{mod}\ n)\implies y\equiv x(\mathrm{mod}\ n)\]

    <p>then</p>

    <ol>
      <li>let $x\equiv y(\mathrm{mod}\ x)$. This means $n\vert (x-y)$</li>
      <li>so $n\vert -(x-y)$</li>
      <li>hence $n\vert (y-x)$</li>
      <li>therefore $y\equiv x(\mathrm{mod}\ y)$</li>
    </ol>
  </li>
  <li>
    <p>is transitive. This means to prove that</p>

\[\forall x,y,z\in \Z,\quad x\equiv y(\mathrm{mod}\ n)\land y\equiv z(\mathrm{mod}\ n) \implies x\equiv z(\mathrm{mod}\ n)\]

    <p>then</p>

    <p><img src="/lectures/images/2023-05-11-COMS3203_Discrete_Math/image-20230307111950238.png" alt="image-20230307111950238" style="zoom: 50%;" /></p>
  </li>
</ul>

<blockquote>
  <p><strong>Partition</strong>: a partition of a set is a collection of non-empty pairwise-disjoint subset of $S$, so that the union gives $S$</p>
</blockquote>

<p><em>For example</em> ,consider the congruence modolo $2$ of $\Z$ is</p>

\[\forall a,b\in \Z,\quad a \equiv b(\mathrm{mod}\ 2)\]

<p>where basically $a \equiv b(\mathrm{mod}\ 2)$is $aRb$.</p>

<ul>
  <li>
    <p>then we have</p>

\[[0] = \{ x | x \in \Z \land 0 \equiv x \text{ (mod 2)} \} = \{ ..., -4,-2,0,2,4,... \}\]
  </li>
  <li>
    <p>continuing</p>

\[[1] = \{ x | x \in \Z \land 1 \equiv x \text{ (mod 2)} \} = \{...-3,-1,1,3,... \}\]
  </li>
  <li>
    <p>but eventually you will realize</p>

\[[2] = \{ x | x \in \Z \land 2 \equiv x \text{ (mod 2)} \} = \{ ..., -4,-2,0,2,4,... \}\]

    <p>which is same as $[0]$!</p>
  </li>
  <li>
    <p>and you can show that also $[3] = [1]$.</p>
  </li>
</ul>

<p>As a result , this creates a <strong>partition of $\Z$ into two partitions</strong>, even and odd numbers (if you consider equivalences for $\mod 4$, you get 4 partitions, etc.)</p>

<blockquote>
  <p>Proposition: let $n \in \Z ^+$ and $a,b \in \Z$. Then</p>

\[a \equiv b (\mathrm{mod}\ n) \iff a\ \mathrm{mod}\ n = b\ \mathrm{mod}\ n\]

  <p>which you can try to prove as an exercise.</p>

  <ul>
    <li>note that in general, proofs with relation are <strong>essentially set proofs</strong>. See HW6 Q6 or recitation 8 for example.</li>
  </ul>
</blockquote>

<h1 id="functions">Functions</h1>

<p><img src="/lectures/images/2023-05-11-COMS3203_Discrete_Math/image-20230321104019461.png" alt="image-20230321104019461" style="zoom: 50%;" /></p>

<p>It can be seen also as a type of <strong>relation</strong> where you basically have ${(x,f(x))}$. For example, if $f(x)=x^2$, then on the set of integers:</p>

\[f=\{(0,0),(1,1), (-1,1), (2,4), (-2,4),...\}\]

<blockquote>
  <p><strong>Functions</strong>: let $A,B$ be two sets. A function $f$ from $A$ to $B$ denoted</p>

\[f:A \to B\]

  <p>so $f \subseteq A \times B$ where <mark>each</mark> element of $A$ appears <mark>exactly once</mark> as a first element of the ordered pairs of $f$. (i.e. <mark>vertical line test</mark>). So that</p>

\[\text{$f$ is a function from $A$ to $B$}\iff \forall a \in A\quad \exists! b \in B \quad b = f(a)\]

  <p>i.e. there is <mark>only one $b$ for each $f(a)$</mark>.</p>
</blockquote>

<p>Some terminology to be used here. Let $f:A \to B$. Then</p>

<ul>
  <li>$A$ is called the <strong>domain</strong></li>
  <li>$B$ is the <strong>co-domain</strong></li>
  <li>$b\in B$ is called the <strong>image</strong> of $a$</li>
  <li>$a\in A$ is called the <strong>pre-image</strong> of $b$</li>
</ul>

<blockquote>
  <p>More formally, the set of all second elements of the pairs of $f$ is called the <strong>image of $f$:</strong></p>

\[\mathrm{image}(f) = \{ b | b \in B \land \exists a \in A\land  f(a)=b \}\]

  <p>so that $\mathrm{image}(f) \subseteq B$</p>
</blockquote>

<p><em>For example</em>: let $A = {1,2,3,4}$ and $B={1,2,3,4,7,10,12}$.</p>

<ul>
  <li>let $f={(1,2),(2,3),(4,3),(3,1)}$. This is a <em>valid</em> function as <em>each input $a\in A$ has a unique output</em>.
    <ul>
      <li>the image of $f$ is then ${2,3,1}$.</li>
    </ul>
  </li>
  <li>let $f={(1,2),(2,3),(4,3)}$. This is a <em>not valid</em> function as $a=3$ has undefined output.</li>
</ul>

<hr />

<p>One way to visualize functions is <strong>bipartite graph</strong>. For example the function</p>

\[f=\{(1,2),(2,3),(4,3),(3,1)\}\]

<p>can be visualized as</p>

<p><img src="/lectures/images/2023-05-11-COMS3203_Discrete_Math/image-20230321110509355.png" alt="image-20230321110509355" style="zoom: 33%;" /></p>

<p>so that the “vertical line test” in discrete function is that each $a\in A$ has <mark>only one edge going out</mark>.</p>

<p><em>For example</em>, let $f:{0,1}\times {0,1} \to \N \cup {0}$</p>

<ul>
  <li>
    <p>so that basically $A={(0,0),(0,1),(1,0),(1,1)}$, and $B={0,1,2,3,…}$</p>
  </li>
  <li>
    <p>and you are given:</p>

    <p><img src="/lectures/images/2023-05-11-COMS3203_Discrete_Math/image-20230321111129449.png" alt="image-20230321111129449" style="zoom: 33%;" /></p>
  </li>
  <li>
    <p>is this a valid function? Yes, <em>every</em> $a\in A$ has a <em>unique</em> (only one) output.</p>
  </li>
  <li>
    <p>and also $\mathrm{image}(f)={0,1,2} \subseteq \N \cup {0}$.</p>
  </li>
</ul>

<h2 id="properties-of-functions">Properties of Functions</h2>

<blockquote>
  <p><strong>Onto/surjective function</strong>: let $f:A \to B$ be a function. $f$ is onto IFF <strong>every element of $B$</strong> has a pre-image. You can translate this into FOL</p>

\[\forall b \in B \quad (\exists a \in A\quad  b=f(a))\]

  <p>as a result, $\mathrm{image}(f)=B$. For example, $A={(0,0),(0,1),(1,0),(1,1)}$, $B={0,1,2}$:</p>

  <p><img src="/lectures/images/2023-05-11-COMS3203_Discrete_Math/image-20230321111129449.png" alt="image-20230321111129449" style="zoom: 33%;" /></p>

  <p>so every element in $B$ receives <mark>at *least* one 1 pre-image</mark>.</p>

  <ul>
    <li>for example, $f(x)=x^2$ for $x \in \Z$ is <em>not</em> onto since $5 \in \Z$ but there is no integer with $x^2 = 5$</li>
    <li>and observe that $\text{$f$is onto\ }\implies \vert A\vert  \ge \vert B\vert$</li>
    <li>is visually is also the <strong>pigeon hole principle</strong> ($A$ are the pigeons)</li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>One-to-one/injection function</strong>: $f$ is one to one IFF no two elements of $A$ has the same image in $B$, i.e. every element in $B$ receives <mark>at *most* 1 pre-image</mark>. Note that this means one-to-one function <em>does not have to be onto functions</em>, i.e. you <em>DON’T</em> need $\mathrm{image}(f)=B$. Into FOL we have:</p>

\[\forall a_1,a_2 \in A\quad a_1 \neq a_2 \implies f(a_1) \neq f(a_2)\]

  <p>or you can re-write this as contrapositive</p>

\[\forall a_1,a_2 \in A\quad f(a_1) = f(a_2) \implies a_1 = a_2\]

  <p>which would be easier to use during proofs.</p>

  <p><img src="/lectures/images/2023-05-11-COMS3203_Discrete_Math/image-20230323104803922.png" alt="image-20230323104803922" style="zoom: 33%;" /></p>

  <ul>
    <li>for example, $f(x)=x^2$ for $x \in \Z$ is <em>not</em> one-to-one since you can have $4=(+2)^2 = (-2)^2$.</li>
    <li>and observe that $\text{$f$is one-to-one\ }\implies \vert A\vert  \le \vert B\vert$</li>
  </ul>
</blockquote>

<p>This means:</p>

<ul>
  <li><strong>to prove a function is onto</strong>: take an arbitrary element $b \in B$, show it has a pre-image in $A$</li>
  <li><strong>to prove a function is one-to-one</strong>: take two arbitrary elements $a_1, a_2 \in A$, show that (e.g. direct proof) $f(a_1) = f(a_2) \implies a_1 = a_2$</li>
</ul>

<p><em>For Example</em>: let a function $f: \Q \to \Q$, and $f(x)=2x+1$.</p>

<ul>
  <li>prove that $f$ is onto.
    <ul>
      <li>let $b \in \Q$ be an arbitrary element</li>
      <li>then $b=2(x+1) \implies x = (b-1)/2$</li>
      <li>but since $b\in \Q$, therefore $x \in \Q$</li>
      <li>hence there is a pre-image $x\in \Q$ such that $f(x)=b$.</li>
      <li>so $f$ is onto</li>
    </ul>
  </li>
  <li>prove that $f$ is one-to-one</li>
  <li>let $a_1,a_2 \in \Q$ and that $f(a_1)=f(a_2)$</li>
  <li>then this $\implies 2a_1 + 1 = 2a_2 + 1$</li>
  <li>so $\implies a_1= a_2$</li>
  <li>therefore $f$ is one-to-one</li>
</ul>

<blockquote>
  <p><strong>Bijection</strong>: let $f:A \to B$ be a function that is <strong>both onto and one-to-one</strong>, then $f$ is a bijection, i.e. every element in $B$ receives <mark>exactly one pre-image</mark></p>

  <p><img src="/lectures/images/2023-05-11-COMS3203_Discrete_Math/image-20230323105025411.png" alt="image-20230323105025411" style="zoom: 25%;" /></p>

  <ul>
    <li>and observe that $\text{$f$is a bijection\ }\implies \vert A\vert  = \vert B\vert$</li>
  </ul>
</blockquote>

<p><em>For Example</em>: consider</p>

<ul>
  <li>
    <p>let $f_1 : \Z^+<em>{odd} \to Z^+</em>{even}$ and $f_1(x)=x+1$ is a bijection as it is both onto (each $b$ has a pre-image) and one-to-one (every $b$ has at most one). This implies, intuitively, that $\vert Z^+<em>{odd}\vert  = \vert Z^+</em>{even}\vert$</p>
  </li>
  <li>
    <p>let $f_2 : \Z^+ \to Z^+<em>{even}$ and $f_1(x)=2x$ is also bijection. But this unintuitively implies $\vert Z^+\vert  = \vert Z^+</em>{even}\vert$! <mark>in general for infinite sets, "cardinality" doesn't really exist</mark>.</p>
  </li>
</ul>

<h2 id="composition-of-functions">Composition of Functions</h2>

<p>Consider two functions:</p>

<ul>
  <li>$f: A \to B$ and $g: C \to D$</li>
  <li>let $\mathrm{image}(f) \subseteq C$</li>
</ul>

<p><img src="/lectures/images/2023-05-11-COMS3203_Discrete_Math/image-20230323110521659.png" alt="image-20230323110521659" style="zoom:50%;" /></p>

<blockquote>
  <p><strong>Composition</strong>: let $f: A \to B$ and $g: C \to D$, and $\mathrm{image}(f) \subseteq C$. The composition of functions $f$ and $g$ is defined as</p>

\[g\circ f: A \to D,\quad g\circ f (x) = g(f(x))\]

  <p>note that we need $\mathrm{image}(f) \subseteq C$, not necessarily $B \subseteq C$.</p>
</blockquote>

<p><em>For example</em>: let $f:\Z \to \Z$ and $g : \Z \to \Z$</p>

<ul>
  <li>let $f(x) = x^2+1$ and $g(x)=2x-3$. THen $g\circ f(x) = g(x^2+1) = 2(x^2+1)-3=2x^2-1$</li>
</ul>

<blockquote>
  <p><strong>Composition of Functions preserve the property</strong> of $f,g$ if they share the same property. If $f,g$ have different properties, it is more complicated.</p>

  <ul>
    <li>e.g. $f$ is many-to-one and $g$ is one-to-one then $f\circ g$ is many-to-one</li>
  </ul>
</blockquote>

<h2 id="inverse-of-functions">Inverse of Functions</h2>

<blockquote>
  <p><strong>Identity Function</strong>: the identity function denoted $I_A$ is <strong>defined on $A$</strong> to have:</p>

\[I_A: A \to A,\quad I_A(a)=a\]

</blockquote>

<blockquote>
  <p><strong>Inverse Function</strong>: let $f: A\to B$. If there exists a function $g: B \to A$ such that</p>

\[g\circ f = I_A,\quad  f\circ g = I_B\]

  <p>then $g$ is called the inverse of $f$, called $g=f^{-1}$.</p>

  <ul>
    <li>basically you want $f \circ f^{-1} = I_B$. and $f^{-1}\circ f = I_A$.</li>
  </ul>
</blockquote>

<p><em>For Example</em></p>

<ul>
  <li>let $f(x)=3x-2$. What is $f^{-1}$ Essentially we are <strong>finding $x$</strong> from $y=f(x)$, therefore $f^{-1}(x)=(x+2)/3$</li>
</ul>

<p>Note that <strong>inverse $f^{-1}$ might not exist</strong>, i.e. not a function. E.g. $f(x)={(1,a),(2,a)}$, then $f^{-1}={(a,1),(a,2)}$!</p>

<blockquote>
  <p><strong>Theorem</strong>: let $f:A \to B$ be a function. Then $f^{-1}:B\to A$ exists provided $f$ is a <strong>bijection</strong>.</p>

  <ul>
    <li>need to be one-to-one, so that when reversed each input has only one image</li>
    <li>need to be on-to, so that when reversed each input has an image</li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>Theorem</strong>: let $f:A\to B$ be a bijection. Then $f^{-1}$ is <strong>unique</strong>.</p>
</blockquote>

<p><em>Proof</em>: By contradiction, suppose there are two inverse functions $f^{-1}_1$ and $f_2^{-1}$</p>

<ul>
  <li>then this means there is an element $f^{-1}_1(b) \neq f^{-1}_2(b)$</li>
  <li>but this means $f(f^{-1}_1(b)) \neq f(f^{-1}_2(b))$</li>
  <li>by definition, both $f_1^{-1},f_2^{-1}$ are inverse of $f$, so this cannot be right as we get $b \neq b$</li>
  <li>therefore, this is a contradiction and there can only be one unique inverse of $f$.</li>
</ul>

<h2 id="pigeon-hole-principle">Pigeon Hole Principle</h2>

<p>Given a function $f:A\to B$, recall that <strong>if $\vert A\vert  &gt; \vert B\vert$,</strong> then it <strong>must be some of the elements in $A$ going into the same image</strong></p>

<blockquote>
  <p><strong>PHP</strong>: if $p$ pigeons fly in $h$ holes, and $p &gt; h$, then at least one of the hole contains two or more pigeons.</p>
</blockquote>

<p><em>For example</em>:</p>

<ul>
  <li>
    <p>We know that there are 8M people in NYC. We know that each person can have a maximum number of 300,000 hair strands. Then by PHP this means there are people having the same number of fair strands.</p>
  </li>
  <li>
    <p>Let there be three pairs of socks, B, G, R. How many socks do I need to blindly pick so that I get at least one pair?</p>

    <p><img src="/lectures/images/2023-05-11-COMS3203_Discrete_Math/image-20230401010148088.png" alt="image-20230401010148088" style="zoom:15%;" /></p>
  </li>
  <li>
    <p>in a group of $n$ people, there will be always two people who <em>have the same number of friends</em>. Assume each person has at least one friend in this group. (Hint: the key is to realize the holes need to be “<em>the number of friends</em>”, and the maximum number of friends you can have is $n-1$)</p>
  </li>
  <li>
    <p>let $A = {1,2,3,4,5,6,7,8}$. If I <em>pick 5 random numbers</em>, will there be at least a pair of number that sums to $9$?</p>

    <p>the pigeons can be any <em>five numbers</em> $n_1,n_2,n_3,n_4,n_5$, the holes can be the pairs/the ways that sums to $9$.</p>
  </li>
</ul>

<blockquote>
  <p><strong>Generalized PHP</strong>: Given $p$ pigoens and $h$ holes. If $p &gt; h$ then at least a hole contains:</p>

\[\lceil \frac{p}{h} \rceil \text{\ pigeons}\]

  <p>(the ceiling of $p/h$).</p>
</blockquote>

<p>This also covers the PHP, because let $p=n$ and $h=n-1$. THen by GPHP we have $\lceil n/(n-1) \rceil = 2$ meaning at least one hole contains 2 pigeons.</p>

<h2 id="infinity-and-countability">Infinity and Countability</h2>

<p>The aim is to discuss the size of a set who is infinite, but we saw in previous sections that if $f:A\to B$ is a bijection, then $\vert A\vert  = \vert B\vert$</p>

<blockquote>
  <p><strong>Countability</strong>: we say that set $S$ is countable $\iff$ there exists a bijection between $S$ and $\N$ (or some subset of $\N$).</p>

  <ul>
    <li>i.e. a set is countable, if you can <em>enumerate</em> all the elements without missing any</li>
  </ul>
</blockquote>

<p>For example:</p>

<ul>
  <li>
    <p>let $S={10,20,30,40,50}$. This is countable, since we can take the image being ${1,2,3,4,5}$</p>
  </li>
  <li>
    <p>let $S={2,4,6,8,…}$. This is countable, as you as enumerate them as is.</p>
  </li>
  <li>
    <p>let $S={\frac{a}{b}\vert a,b\in \Z \land b \neq 0}$. How do you enumerate the values of fractions? George Cantor showed this $\Q$ is countable using <strong>diagonalization</strong>.</p>

    <p>First, we show $\Q+$ is countable</p>

    <table>
      <thead>
        <tr>
          <th> </th>
          <th>1</th>
          <th>2</th>
          <th>3</th>
          <th>…</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>1</td>
          <td>1/1</td>
          <td>1/2</td>
          <td>1/3</td>
          <td>…</td>
        </tr>
        <tr>
          <td>2</td>
          <td>2/1</td>
          <td>2/2</td>
          <td>2/3</td>
          <td>…</td>
        </tr>
        <tr>
          <td>3</td>
          <td>3/1</td>
          <td>3/2</td>
          <td>3/3</td>
          <td>…</td>
        </tr>
        <tr>
          <td>…</td>
          <td>…</td>
          <td>…</td>
          <td>…</td>
          <td>…</td>
        </tr>
      </tbody>
    </table>

    <ul>
      <li>so I cannot enumerate by row, as I will never come back from a row. same reason for column</li>
      <li>but I can go by a diagonal</li>
    </ul>

    <p><img src="/lectures/images/2023-05-11-COMS3203_Discrete_Math/image-20230330101348980.png" alt="image-20230330101348980" style="zoom:33%;" /></p>

    <p>therefore:</p>

\[\{ 1/1, \quad 2/1, \quad 1/2, \quad 3/1,\quad 2/2, \quad1/3, ... \}\]

    <p>so essentially countability can be seen as to <strong>find a strategy to enumerate it</strong> = can find a bijection from $\N$ by just corresponding each element here to a number in $\N$ (you do not need to know what that function is, but it can be enumerated).</p>

    <p>Finally to get $\Q$, we just need to insert each number’s negative in between.</p>
  </li>
</ul>

<blockquote>
  <p><strong>Theorem</strong>: the set of real numbers $\R$ is <em>not</em> countable.</p>
</blockquote>

<blockquote>
  <p><strong>Corollary</strong>: the set of real numbers in $[0,1]$ is also <em>not countable</em>.</p>
</blockquote>

<p><em>Proof</em>: by contradiction using diagonalization.</p>

<ul>
  <li>assume I can list all the real numbers in $[0,1]$, so that ${r_1, r_2, r_3, …}$, e.g.
    <ul>
      <li>$r_1 = 0.4513201…$</li>
      <li>$r_2=0.3351238…$</li>
      <li>$r_3 = 0.1234223…$</li>
      <li>…</li>
    </ul>
  </li>
  <li>we can show that this is <em>missing at least one real number</em>, by
    <ul>
      <li>let $\text{decimal}<em>i(r</em>{new})$ be the $i$-th decimal number of $r_{new}$. E.g. $\text{decimal}<em>3(r</em>{1})=1$ above.</li>
      <li>I can invent a $r_{new}$ to be $\text{decimal}<em>i(r</em>{new}) \neq \text{decimal}<em>i(r</em>{i})$ for every $i$! e.g. $r_{new}=0.544…$</li>
    </ul>
  </li>
  <li>and the key is this $r_{new}\in R$! (therefore this won’t work with proving $\Q$ being uncountable, though we already know it is not)</li>
</ul>

<h1 id="advanced-proofs">Advanced Proofs</h1>

<p>Here we cover more techniques to prove things. We will cover</p>

<ul>
  <li>proof by mathematical induction (PMI)</li>
  <li>proof by smallest counter example (PSCI)</li>
  <li>proof by strong mathematical induction (PSMI)</li>
</ul>

<h2 id="proof-by-induction">Proof by Induction</h2>

<p>Consider proving propositions that look like</p>

\[\forall n\quad p(n),\quad n \in \Z^+\]

<p>The idea is to consider:</p>

<ol>
  <li>
    <p><a href="**prove** that the following is true">base case</a> show $p(a)$ is true</p>
  </li>
  <li>
    <p>if we can show $p(k) \implies p(k+1)$.</p>
  </li>
  <li>
    <p>then $\forall k \ge a \implies p(k)$. It is like a “chain reaction”.</p>

    <p><img src="/lectures/images/2023-05-11-COMS3203_Discrete_Math/image-20230330102531524.png" alt="image-20230330102531524" style="zoom: 25%;" /></p>
  </li>
  <li>
    <p>hence we have shown that $\forall n \in \Z^+ \quad n\ge a \implies p(n)$</p>
  </li>
</ol>

<blockquote>
  <p><strong>Proof Template for Induction</strong></p>

  <ol>
    <li>
      <p>write the proposition clearly</p>

\[\forall n \quad p(n)\]
    </li>
    <li>

\[p(a),\quad \text{a is the smallest case of n}\]
    </li>
    <li></li>
    <li>
      <p>[inductive step] <strong>prove</strong> that <strong>“all the next steps/domino” are true</strong> given $p(k)$</p>

\[p(k) \implies p(k+1)\]

      <p>here is when you can <em>technically</em> use all the different proof techniques (e.g. by contrapositive). But often we just do direct proofs.</p>
    </li>
    <li>therefore, $p(k)$ is true $\forall k \ge a$</li>
  </ol>
</blockquote>

<p><em>For Example</em>: prove that $\forall n \in \Z^+$</p>

\[p(n): 1+2+3+ \dots + n = \frac{n(n+1)}{2}\]

<p>Proof by induction: the proposition is already written in the “standard” format</p>

<ol>
  <li>
    <p>base case is $p(1)$.  This is true because</p>

\[p(1): 1 = \frac{1\cdot 2}{2}\]

    <p>is true</p>
  </li>
  <li>
    <p>inductive hypothesis that for $k \ge 1$, we assume $p(k)$ is true</p>

\[p(k):1+2+3+\cdots + k = \frac{k(k+1)}{2}\]
  </li>
  <li>
    <p>inductive step so $p(k+1):1+2+3+\cdots + k + k+1= \frac{k+2(k+2)}{2}$ and it requires you to <strong>prove that $p(k+1)$ is true by</strong></p>

\[p(k) \implies p(k+1)\]

    <p>we can consider a <strong>direct proof</strong></p>

    <ol>
      <li>
        <p>let $p(k)$. This means this is true</p>

\[1+2+3+\cdots + k = \frac{k(k+1)}{2}\]
      </li>
      <li>
        <p>then this means</p>

\[1+2+3+\cdots + k + k+1 = \frac{k(k+1)}{2} + k+1\]

        <p>this step can be interpreted in two ways (both valid)</p>

        <ul>
          <li>smudging the entire $p(k)$ to look like $p(k+1)$</li>
          <li>just want to see what does RHS look like by $1+2+3+\cdots + k + k+1 = p(k)+k+1$</li>
        </ul>
      </li>
      <li>
        <p>rewriting the RHS we get</p>

\[1+2+3+\cdots + k + k+1 = \frac{(k+2)(k+1)}{2}\]

        <p>which is exactly $p(k+1)$</p>
      </li>
      <li>
        <p>hence, we have shown that $p(k+1)$ is true assuming $p(k)$, i.e. $p(k)\implies p(k+1)$</p>
      </li>
    </ol>
  </li>
</ol>

<p><em>For example</em>: prove that $\forall n \in \Z, n \ge 1$</p>

<p>we want to show that</p>

\[1+3+5+\dots+(2n-1) = n^2\]

<p>Visually, this looks like</p>

<p><img src="/lectures/images/2023-05-11-COMS3203_Discrete_Math/image-20230330105520061.png" alt="image-20230330105520061" style="zoom:33%;" /></p>

<p><em>Proof by induction</em>:</p>

<ol>
  <li>
    <p>base case is $p(1)$. This is easily true since $1=1^2$</p>
  </li>
  <li>
    <p>inductive hypothesis: assume $p(k)$ is true</p>

\[1+3+5+\dots+(2k-1) = k^2\]
  </li>
  <li>
    <p>inductive step: want to show that $p(k+1)$ is true given $p(k)$, so that considering direct proof</p>

    <ol>
      <li>
        <p>let $p(k)$ be true, hence</p>

\[1+3+5+\dots+(2k-1) = k^2\]
      </li>
      <li>
        <p>then moving to $p(k+1)$ we get</p>

\[1+3+5+\dots+(2k-1)+(2k+1) = k^2 + 2k+1\]
      </li>
      <li>
        <p>the RHS can be reformatted to be</p>

\[1+3+5+\dots+(2k-1)+(2k+1) = (k+1)^2\]
      </li>
      <li>
        <p>this is basically $p(k+1)$</p>
      </li>
    </ol>
  </li>
</ol>

<blockquote>
  <p><strong>Well-ordering principle</strong>: every set of non-negative integers <mark>has a starting element (i.e. a beginning)</mark></p>

  <ul>
    <li>The induction process is possible thanks to the principle of <strong>well-ordering principle</strong>.</li>
    <li>this does <mark>not necessarily have to be the smallest element</mark>. e.g. prove in the domain of only negative numbers you can start with the largest element, and prove $p(k)\implies p(k-1)$</li>
  </ul>
</blockquote>

<p><em>For example</em>:</p>

<ul>
  <li>is well-ordering: $\N={1,2,3,…}$, $S={4,5,6,…}$</li>
  <li><em>not</em> well-ordering: $\R$, $\Q$, or even $\R^+$.</li>
</ul>

<h2 id="proof-by-smallest-counter-example">Proof by Smallest Counter Example</h2>

<p>To compare this with what you</p>

<p>PMI: essentially proves the purple ones</p>

<p><img src="/lectures/images/2023-05-11-COMS3203_Discrete_Math/image-20230330120500591.png" alt="image-20230330120500591" style="zoom: 7%;" /></p>

<p>PSCI: aims to prove the red one being false, hence there cannot be a CE:</p>

<p><img src="/lectures/images/2023-05-11-COMS3203_Discrete_Math/image-20230330120615053.png" alt="image-20230330120615053" style="zoom:9%;" /></p>

<blockquote>
  <p><strong>Proof Template for PSCI</strong></p>

  <ol>
    <li>
      <p>write in $\forall n \quad p(n)$</p>
    </li>
    <li>
      <p><strong>prove</strong> base case</p>
    </li>
    <li>
      <p><strong>assume</strong> that there exist exceptions/counter examples. <mark>Let $x$ be the smallest so $p(x)$ is False</mark>. Notice that this <strong>also means $p(x-1)$ is true</strong></p>
    </li>
    <li>
      <p><strong>prove</strong> that this is a <strong>contradiction, hence $p(x)$ cannot exist</strong>. i.e. this cannot hold.</p>

\[p(x)\text{ is False } \land\,\,  p(x-1)\text{ is True }\]
    </li>
    <li>
      <p>if there is no SCE, then there is <mark>no CE at all given the well-ordering principle</mark>. Hence the proposition is true.</p>
    </li>
  </ol>
</blockquote>

<p><em>Proof by SCE</em>: show that</p>

\[p(n): 1+2+3+ \dots + n = \frac{n(n+1)}{2}\]

<ol>
  <li>
    <p>base case $p(1)$ is true since $1=1\times 2/2$</p>
  </li>
  <li>
    <p>by contradiction, <strong>assume that $\exists x &gt; 1$ such that $p(x)$ is False, for $x$ is the smallest counter example</strong></p>
  </li>
  <li>
    <p>then we can show that this is a contradiction that this cannot happen. So that given</p>

\[p(x):1+2+3+ \dots + x \neq \frac{x(x+1)}{2}\]

    <p>but that</p>

\[p(x-1):1+2+3+ \dots + x-1 = \frac{x(x-1)}{2}\]

    <p>cannot hold.</p>
  </li>
  <li>
    <p>therefore, there is no SCE, meaning essentially</p>

\[\neg (\exist x &gt; 1 \quad p(x) \text{ is False})\]

    <p>so that for $n \in \Z^+$</p>

\[\forall n \quad p(n)\]
  </li>
</ol>

<p><em>Proof by SCE:</em> prove by SCE that</p>

\[\forall n \in \Z, \quad n&gt;0 \to 4|(5^n-1)\]

<ol>
  <li>
    <p>base case $n=1$ works easily</p>
  </li>
  <li>
    <p>by contradiction, assume $x$ the S.C.E such that $p(x)$ is false. i.e. $4$ does not divide $5^x-1$</p>

\[4 \nmid (5^x-1)\]
  </li>
  <li>
    <p>now we want to show that this is a contradiction: $p(x)$ is false and $p(x-1)$ is true cannot hold</p>

    <ol>
      <li>
        <p>since $p(x-1)$ is true, this means $4\vert (5^{x-1}-1)$</p>
      </li>
      <li>
        <p>this means $5^{x-1}-1=4\times q$, where $q \in \Z$. We want to move towards contradiction that $4 \nmid (5^x-1)$</p>
      </li>
      <li>
        <p>multiply by 5, we get</p>

\[5^x-4-1 = 4\times (5 \times 1)\]

        <p>hence</p>

\[5^x-1 = 4 \times( 5 \times q + 1)\]

        <p>meaning that $4 \vert  (5^x-1)$</p>
      </li>
    </ol>
  </li>
  <li>
    <p>therefore, there is no such $x$ such that $p(x)$ is false. Hence the proposition is true.</p>
  </li>
</ol>

<p><em>Proposition</em>: Every Integer is either odd or even.</p>

<p>Note that now we are considering $\forall n \in\Z$, meaning there is <em>technically</em> not a “well-ordering set”. But there can be a trick:</p>

<ol>
  <li>
    <p><strong>first prove by SCE</strong> that this holds when $\forall n \in \Z^+$</p>
  </li>
  <li>
    <p><strong>extend</strong> your above proof to the negative domain, since</p>

\[n \in \Z,n &lt; 0 \implies n = -m, m\in \Z^+\]

    <p>basically flipping the sign</p>
  </li>
</ol>

<h2 id="proof-by-strong-induction">Proof by Strong Induction</h2>

<p>The difference with proof by induction is:</p>

<ul>
  <li>could have many base cases</li>
  <li>making stronger assumptions that all cases from the base cases until $p(k)$ are true. Prove $p(k+1)$</li>
</ul>

<p>Graphically, it looks like:</p>

<table>
  <thead>
    <tr>
      <th>Method</th>
      <th style="text-align: center">Visual</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>normal Induction</td>
      <td style="text-align: center"><img src="/lectures/images/2023-05-11-COMS3203_Discrete_Math/image-20230404164715165.png" alt="image-20230404164715165" style="zoom:7%;" /></td>
    </tr>
    <tr>
      <td>strong induction</td>
      <td style="text-align: center"><img src="/lectures/images/2023-05-11-COMS3203_Discrete_Math/image-20230404164747333.png" alt="image-20230404164747333" style="zoom:15%;" /></td>
    </tr>
  </tbody>
</table>

<p>and finally this also means base case for strong induction has to look like:</p>

<p><img src="/lectures/images/2023-05-11-COMS3203_Discrete_Math/image-20230404164821701.png" alt="image-20230404164821701" style="zoom:10%;" /></p>

<blockquote>
  <p>Therefore, this is useful when the result <strong>for $n = k+1$ depends on the result for some smaller value of $n$ (e.g. $n=k-4$), but it’s not the immediately previous value $k$.</strong></p>
</blockquote>

<blockquote>
  <p><strong>Proof Template for PSI</strong>: consider proving some $\forall n \quad p(n)$</p>

  <ol>
    <li>
      <p><strong>base case</strong>: prove the base cases (you will need to experiment to find out how many you need)</p>

\[p(a),p(a+1),p(a+2),...,p(a+z)\]
    </li>
    <li>
      <p><strong>inductive hypothesis</strong>: assume $p(k)$ hold for <mark>all numbers</mark> less than or equal to an arbitrary $k$, i.e. all the below are true</p>

\[p(a) \land p(a+1)\land \dots p(k)\]

      <p>(i.e. the purple window above)</p>
    </li>
    <li>
      <p><strong>inductive step</strong>: now it becomes</p>

\[p(a) \land p(a+1)\land \dots p(k) \implies p(k+1)\]

      <p>essentially to prove $p(k+1)$ you have a <strong>range of choices/assumptions to choose from</strong>. (see example below)</p>

      <ul>
        <li>The difference is actually only superficial compared to normal induction proofs, and the two proof techniques are equivalent.</li>
        <li>you can see this more in the example below</li>
      </ul>

      <p><mark>and you want to make sure $p(a+z+1)$ can be proven using this inductive step</mark> (where $p(a+z)$ you already show to be true in step 1)</p>

      <ul>
        <li>this usually depends on, say $p(k+1)$ required $p(k-3)$ to be true.</li>
        <li>so this means you need $p(k), p(k-1),p(k-2),p(k-3)$ to be true = <strong>need 4 base cases</strong> in step 1 for arbitrary $k$ to hold</li>
      </ul>
    </li>
    <li>
      <p><strong>conclusion</strong>: repeatedly apply the above proof to increase the purple window until all $\forall n$ are covered. (same as normal induction)</p>
    </li>
  </ol>
</blockquote>

<p><em>Example:</em> Stamping Problem. Prove that any amount of postage $\ge 2$ cent can be made with 2 cents or 3 cents stamp.</p>

<p>Let’s first attempt using simple induction.</p>

<ol>
  <li><strong>base case:</strong> I can make $p(2)$ with one stamp of 2 cent</li>
  <li><strong>inductive hypothesis:</strong> it is possible to make a postage worthy of $k$ cent using 2 or 3 cents stamp</li>
  <li><strong>inductive step:</strong> prove $p(k+1)$, show that you can make $k+1$ cent
    <ul>
      <li>case 1: $p(k)$ has only 2 cents stamp. Take a 2 away and replace by 3 cents.</li>
      <li>case 2: $p(k)$ has only 3 cents stamp. Take a 3 away and replace by two 2 cents.</li>
      <li>case 3: $p(k)$ has both 2 cents and 3 stamps. Take a 2 away and replace by 3, or take a 3 and replace by two 2 cents.</li>
    </ul>
  </li>
  <li>done.</li>
</ol>

<p>Let’s see how strong induction would prove this:</p>

<ol>
  <li>
    <p><strong>base case</strong>: we will see how many cases we need. First prove (skipped) that $p(2),p(3),p(4),p(5)$ are true</p>
  </li>
  <li>
    <p><strong>inductive hypothesis</strong>: by assumption then let the following until $k$ be true</p>

\[p(1) \land ... p(6) \land p(7)\dots p(k)\]
  </li>
  <li>
    <p>inductive step: to prove $p(k+1)$ all I need is to show</p>

\[p(1) \land ... p(6) \land p(7)\dots p(k) \implies p(k+1)\]

    <p>realize that</p>

\[p(k+1) = p(k-2+3)=p(k-2)+3\]

    <p>i.e. <mark>adding</mark> a 3 cent in the solution for $p(k-2)$. Since $p(k-2)$ is true by inductive hypothesis, we are done.</p>

    <ul>
      <li>This also means we need at least <mark>3 base cases</mark>, that $p(2),p(3),p(4)$ is already proven (it is)</li>
      <li>since we need the <em>left boundary of our purple window at $2 \le k-2$</em>, so $k\ge 4$. Therefore we needed base case up to $p(k=4)$</li>
    </ul>
  </li>
  <li>
    <p>therefore $p(k+1)$ is true.</p>
  </li>
</ol>

<blockquote>
  <p>Notice that we <mark>needed to directly prove (a minimum of) three base cases</mark>, since we needed to <mark>reach back three integers in our inductive step</mark>. It’s <strong>not always obvious how many base cases are needed until you work out the details</strong> of your inductive step.</p>
</blockquote>

<h1 id="number-theory">Number Theory</h1>

<p>Here we will discuss topics including</p>

<ul>
  <li>divisibility</li>
  <li>GCD/GCF (greatest common divisor/factor)</li>
  <li>fundemental theorem of arithmetic</li>
  <li>factoring</li>
  <li>modular arithmetic (clock arithmetic)</li>
  <li>introduction to cryptography</li>
</ul>

<h2 id="divisibility">Divisibility</h2>

<p>In the 1880, Peano’s axioms of natural numbers (converted into natural language):</p>

<ol>
  <li>
    <p>there is a starting point of numbers $x \in \N$, and it starts at 1</p>
  </li>
  <li>
    <p>let $s$ be a successor function. Every natural number has a successor:</p>

\[\forall n \in \N, \quad s(n) \in \N\]
  </li>
  <li>
    <p>and 1 is not a successor of any natural number, so that $1 \neq s(n)$</p>
  </li>
  <li>
    <p>let $s(n)$ is a one-to-one function., so that each number has a different successor.</p>
  </li>
  <li>
    <p>there is no other set of natural numbers.</p>
  </li>
</ol>

<p>These requirements enabled a “massive production of numbers”, and they have some interesting consequences</p>

<blockquote>
  <p><strong>Divisibility Theorem</strong>: let $a,b \in \Z$, and $b &gt; 0$, then there exist a <mark>unique</mark> pair $(q,r)$ such that</p>

\[a = bq +r,\quad 0 \le r &lt; b\]

  <p><mark>note that $r,b$ is positive.</mark></p>
</blockquote>

<p>for example:</p>

<ul>
  <li>$25 = 10\times 2 +5$, where $25=a$, $b=10$, etc.</li>
  <li>$-25 = 10 \times -3 +5$. Note that both $b$ and $r$ are positive.</li>
</ul>

<p>for example: prove that every integer is either odd or even</p>

<ol>
  <li>
    <p>by the divisibility theorem, there is a unique pair $(q,r)$, such that</p>

\[n = 2q + r,\quad 0 \le r &lt;2\]
  </li>
  <li>
    <p>i.e. if I divide by 2, the remainder can only be zero or one! then,</p>

    <ul>
      <li>if $r=0$, this means $n=2q$ hence $n$ is even</li>
      <li>if $r=1$, this means $n=2q+1$ hence $n$ is odd.</li>
    </ul>
  </li>
</ol>

<blockquote>
  <p><strong>Div and Mod Operators</strong>: let $a,b \in \Z, b &gt; 0$. We know that $a = bq +r,\quad 0 \le r &lt; b$ .Then</p>

\[\exists (q,r) \in \Z \times (\Z^+ \cup \{0\})\]

  <p>and then we define the operators</p>

  <ul>
    <li>$a \mathrm{\ div\ }b = q$</li>
    <li>$a \mathrm{\ mod\ }b = r$</li>
  </ul>
</blockquote>

<h3 id="least-common-multiple-and-greatest-common-divisor">Least Common Multiple and Greatest Common Divisor</h3>

<blockquote>
  <p><strong>Proposition</strong>: let $a,b \in \Z$,. Let let $d\in \Z^+$ means</p>

\[d|a \land d |b \implies d|(a+b) \land d|(a-b)\]

  <p>i.e. $d$ also <mark>divides any linear combination of $a,b$</mark>. This is very useful as it means, for example:</p>

\[gcd(a,b)≡gcd(−a,b)≡gcd(a,−b)≡gcd(−a,−b)≡gcd(∣a∣,∣b∣)\]

</blockquote>

<p>The above comes useful in later proofs. This proposition is itself relatively easy to prove, since:</p>

<ul>
  <li>to prove $d\vert (a+b)$ you can rewrite $a+b=dq_1 + dq_2=d(q_1+q_2)$ since $d\vert a \land d\vert b$</li>
  <li>to prove $d\vert (a-b)$ you can rewrite $a-b=dq_1 - dq_2=d(q_1-q_2)$ since $d\vert a \land d\vert b$</li>
</ul>

<blockquote>
  <p><strong>Greatest Common Factor/Divisor</strong>: let $a,b \in \Z$. We call $d$ the greatest common factor IFF</p>

  <ol>
    <li>$d \vert  a \land d\vert b$ (i.e. is a divisor)</li>
    <li>$\forall e \in \Z, \quad e\vert a \land e \vert b \implies e \le d$ (i.e. is the biggest)</li>
  </ol>
</blockquote>

<p><em>For example</em>: there are 28 roses, 14 daisies. What is the greatest number of identical bouquet of flowers can you make with no flowers left?</p>

<ul>
  <li>let there be $k$ bouquet of flowers. Realize this $k$ must be a divisor such that $k\vert 28$ and $k\vert 14$</li>
  <li>to have the most $k$, you basically need to find the greatest common divisor. In this case you can find by inspection, giving $14$.</li>
</ul>

<blockquote>
  <p><strong>Properties of GCD</strong></p>

  <ul>
    <li>$\mathrm{GCD}(a,0)=a$, since divisor for $0$ includes all numbers</li>
    <li>$\mathrm{GCD}(0,0)$ is undefined</li>
    <li>$\mathrm{GCD}(a,b)=\mathrm{GCD}(b,a)$</li>
    <li>$\mathrm{GCD}(a,b)=\mathrm{GCD}(\vert a\vert ,\vert b\vert )$</li>
    <li>$\mathrm{GCD}(a,b,c)=\mathrm{GCD}(a,\mathrm{GCD}(b,c))$.</li>
  </ul>
</blockquote>

<p><strong>But how do we find GCD</strong>?</p>

<p>Naive GCD: without loss of generalization, let $a \ge b$. Then</p>

<ol>
  <li>for each $d=1$ to $b$ (in case of co-prime, $\mathrm{GCD}(a,b)=1$ )
    <ol>
      <li>if $d\vert a\land d\vert b$ then $g=d$</li>
    </ol>
  </li>
  <li>return $g$</li>
</ol>

<p>Before we discuss a more efficient algorithm: <mark>observe: let $a,b\in \Z^+$. Realize that $\mathrm{GCD}(a,b)=\mathrm{GCD}(b,a \mod b)$.</mark></p>

<ul>
  <li>$\mathrm{GCD}(75, 63)=\mathrm{GCD}(63, 12)$
    <ul>
      <li>note that if you started with $\mathrm{GCD}(63, 75)\to\mathrm{GCD}(75, 63)$ since $63 \mod 75=63$ gets automatically swapped.</li>
    </ul>
  </li>
  <li>but you can continue: $\mathrm{GCD}(63, 12)=\mathrm{GCD}(12, 3)=\mathrm{GCD}(3, 0)$</li>
  <li>then you are done. GCD is 3!</li>
</ul>

<p>Graphically:</p>

<p><img src="/lectures/images/2023-05-11-COMS3203_Discrete_Math/image-20230406102803913.png" alt="image-20230406102803913" style="zoom: 33%;" /></p>

<p>Essentially at each iteration you managed to cut the “search space”!</p>

<blockquote>
  <p><strong>Euclid GCD Algorithm</strong>: let $a,b\in \Z^+$. Realize that $\mathrm{GCD}(a,b)=\mathrm{GCD}(b,a \mod b)$ as shown above (proof later). Then the algorithm becomes</p>

  <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">recursive_gcd</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">):</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">a</span> <span class="n">mod</span> <span class="n">b</span>
    <span class="k">if</span> <span class="n">r</span> <span class="o">=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">b</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">recursive_gcd</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">r</span><span class="p">)</span>
</code></pre></div>  </div>

  <p>but you can of course write this into an iterative version</p>

  <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">iterative_gcd</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">):</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">a</span> <span class="n">mod</span> <span class="n">b</span>
    <span class="k">while</span> <span class="n">r</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">b</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">r</span>
        <span class="n">r</span> <span class="o">=</span> <span class="n">a</span> <span class="n">mod</span> <span class="n">b</span>
    <span class="k">return</span> <span class="n">b</span>
</code></pre></div>  </div>
</blockquote>

<p><em>Proof of Euclid’s divisibility</em>. The key is to utilize divisiblity that, consider $\mathrm{GCD}(a,b)$ then</p>

<ul>
  <li>$a=bq +r$, with $0 \le r &lt;b$ by divisibility</li>
  <li>hence $r=a-bq$ i.e. by definition, $r$ is basically $a \mod b$</li>
</ul>

<p>Therefore, the proof looks like</p>

<ol>
  <li>let $d$ be a divisor of $a$ and $b$. Then $r=a-bq$ means that
    <ol>
      <li>$d\vert a \implies a=d\cdot q_1$, and $d\vert b \implies b = d\cdot q_2$</li>
      <li>hence $r=dq_1 - qdq_2 = d(q_1 - qq_2)\implies d\vert r$</li>
      <li>so <strong>any divisor of $a,b$ is also a divisor of $r$</strong></li>
    </ol>
  </li>
  <li>let $c$ be a divisor of $b$ and $r$. Then $a=bq + r$ means that
    <ol>
      <li>similarly you can show that $c\vert a$</li>
      <li>so <strong>any divisor of $b,r$ is also a divisor of $a$</strong></li>
    </ol>
  </li>
  <li>form the above two conclusions, <mark>$a,b$ and $b,r$ have the same common divisors</mark>. (e.g. let $k$ be a common divsor for $a,b$ but not for $b,r$. Then this means $k \nmid r$, which cannot be due to our proof above!)</li>
  <li>Hence $\mathrm{GCD}(a,b)$ ad $\mathrm{GCD}(b,r)$ must be the same/share the same GCD!</li>
</ol>

<h2 id="prime-numbers-and-factorization">Prime Numbers and Factorization</h2>

<p>The idea is that</p>

\[\N = \{1,2,3,\dots\} = \{1\}\cup \text{primes}\cup \text{composites}\]

<p>and that interestingly:</p>

<ul>
  <li>primes are more “dense” when small</li>
  <li>there is an infinity amount of prime numbers</li>
</ul>

<blockquote>
  <p><strong>Fundemental theorem of arithmetic</strong>: let $n \in \Z \land n \ge2$. There is a <strong>unique</strong> factorization of $n$ into a product of primes. i.e. $n$ is either a prime of a product of primes (composites).</p>
</blockquote>

<p>To prove the above, you will need to show that</p>

<ol>
  <li>there <em>exists</em> a prime factoriazation for any $n \ge 2$</li>
  <li>this factorization is <em>unique</em> (this can get quite complicated to prove, see Gauss’s proof)</li>
</ol>

<p><em>Proof</em>: there exists a prime factorization. Proof by <strong>strong induction</strong></p>

<ol>
  <li>base case: let us use $p(2)=2,p(3)=3,p(4)=2\times 2$ have a prime factorization.</li>
  <li>inductive step: every number between $2$ and $k\ge 5$ can be factored into primes</li>
  <li>prove $k+1$: realize either that $k+1$ is a prime or a composite.
    <ul>
      <li>if $k+1$ is a prime, then $p(k+1)=k+1$, done.</li>
      <li>if $k+1$ is a composite
        <ul>
          <li>then $k+1 = a\times b$ for some factors $a,b&lt;k+1$. (technically this can be even strong that $a,b&lt; (k+1)//2$, but it is not necessary)</li>
          <li>but realize that we have assumed $p(a)$ and $p(b)$ are both having a prime factorization</li>
          <li>hence $k+1$ also has a prime factorization</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>therefore, $k+1$ also has a prime factorization.</li>
</ol>

<blockquote>
  <p><strong>Theorem</strong>: there is an infinite number of prime numbers.</p>
</blockquote>

<p><em>Kumer’s proof</em>: proof by <strong>contradiction</strong>. Suppose there is a <em>finite</em> number of primes:</p>

\[p_1 &lt; p_2 &lt; \dots &lt; p_r\]

<p>where $p_r &lt; \infty$ is finite. Then</p>

<ol>
  <li>$x=p_1\times p_2 \times \dots \times p_r$ is a composite included <strong>all possible primes</strong></li>
  <li>consider $x+1=p_1\times p_2 \times \dots \times p_r+1$
    <ul>
      <li>if $x+1$ is prime
        <ul>
          <li>we already get a <em>contradiction</em> $x+1 &gt; p_r$</li>
        </ul>
      </li>
      <li>if $x+1$ is a composite
        <ul>
          <li>then since $x$ is a composite including all primes, $x$ and $x+1$ <strong>must share at least a prime</strong>, let’s call this $p_i$</li>
          <li>then $p_i\vert x$ and $p_i \vert  (x+1)$, so that $x=p_iq_1$ and $x+1 = p_i q_2$</li>
          <li>$x+1-x=p_i q_2 -p_iq_1$ hence $1 = p_i(q_2-q_1)$</li>
          <li>but $p_i\vert 1$ cannot be true as the smallest prime number is $2$!</li>
          <li>this is a <em>contradiction</em></li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Hence, by contradiction there is an infinite number of primes.</li>
</ol>

<blockquote>
  <p><strong>Sieve of Fratosthenes</strong>: what is a good way to find all primes until $n$? E.g. let us find all primes less than $n=20$</p>

  <ol>
    <li>write down every integer $2,3,\dots,20$</li>
    <li>for $i$ each of the above integer that is <em>not crossed out</em>
      <ol>
        <li>cross out all multiples of $i$</li>
        <li>stop at $\lfloor \sqrt{n} \rfloor$, because the biggest <em>possible</em> factor is $\lfloor \sqrt{n} \rfloor$</li>
      </ol>
    </li>
    <li>whatever not crossed out are the primes</li>
  </ol>
</blockquote>

<p>Graphically, if you pick $n=41$:</p>

<p><img src="/lectures/images/2023-05-11-COMS3203_Discrete_Math/image-20230406112112752.png" alt="image-20230406112112752" style="zoom:25%;" /></p>

<p>Finally, <strong>prime factorization</strong> can be used as a good way to find GCD by hand:</p>

<p><img src="/lectures/images/2023-05-11-COMS3203_Discrete_Math/image-20230406112659314.png" alt="image-20230406112659314" style="zoom:43%;" /></p>

<p>so basically all you need to do is to pick the minimum power. This would be useful when you need to find GCD by hand/both $a,b$ are relatively small. Otherwise using the Euclid algorithm should be much faster.</p>

<blockquote>
  <p>Note: what is the relationship between $a \mod b$ and $a-b$?</p>

  <ul>
    <li>since $a=qb + r$, this means $a \mod b = a - b -b -b \dots -b$ with $q$ number of $b$s</li>
    <li>this also means if $a/2 &lt; b$, then $q=1$, hence $a \mod b = a - b$</li>
  </ul>
</blockquote>

<h2 id="modular-arithmetic">Modular Arithmetic</h2>

<p>In many applications such as clock, month, cryptography in $\Z_n = {0,1,2,\dots, n-1}$, we need a “new” type of arithmetic to say something like $n+3 \to 2$  (e.g. 14pm is the same as 2pm)</p>

<ul>
  <li>
    <p>this should remind you of the congruence modulo $n$</p>
  </li>
  <li>
    <p>for example, clock would have $\Z_{12}={0,1,2,\dots, 11}$ and has 12 equivalence classes</p>
    <ul>
      <li>e.g. $\dots, -24,-12,0,12,24,\dots$ (given any number outside of the range, either plus 12 or minus12 until you get back into $\Z_{12}$)</li>
      <li>e.g. $\dots, -23,-11,1,13,25,\dots$</li>
    </ul>
  </li>
</ul>

<p>Then defining the “arithmetics”:</p>

<ul>
  <li>
    <p><strong>addition</strong> in $\Z_{n}$: let $a,b\in \Z_{n}$, then</p>

\[a \oplus b \equiv (a+b) \bmod {n}\]

    <p>e.g. let $n=10$, then $12\oplus 12 = 24 \bmod 10 = 4$.</p>
  </li>
  <li>
    <p><strong>multiplication</strong>: same thing, let $a,b\in \Z_{n}$,</p>

\[a \otimes b \equiv (a\times b ) \bmod n\]
  </li>
  <li>
    <p><strong>subtraction</strong>: now the problem is with $a,b\in \Z_{n}$, you can get negative numbers in the sense that:</p>

    <ul>
      <li>if $a - b &gt; 0$, then $a \ominus b = (a-b)\bmod n$</li>
      <li>if $a - b &lt; 0$, then $a \ominus b = (a-b)+n$ (i.e. add as many $n$ until you get back into $\Z_{n}$, in this case since $a,b\in \Z_n$, add once is enough)
        <ul>
          <li>e.g. let $n=10$, then $1-4 = -3 + 10 = 7$</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>division</strong>: same setup, but recall that</p>

    <ul>
      <li>
        <p>in normal arithmetic we have $a / b = a \times b^{-1}$, where the reciprocal $b^{-1} = 1/ b$.</p>
      </li>
      <li>
        <p>here, we want to consider</p>

\[a \oslash b = a \otimes b^{-1}\]

        <p>and that by definition, the reciprocal <strong>has to satisfy $b^{-1}\otimes b = 1$</strong>. <mark>Any element in $\Z_n$ that has a reciprocal is called invertible in $\Z_n$)</mark>. Therefore, this division only <mark>exists when $b$ is invertible</mark>.</p>

        <ul>
          <li>for example, for $\Z_{10}$, only the following ${1,3,7,9}$ has inverse.</li>
          <li>you will see how this is related to coprimes.</li>
        </ul>
      </li>
    </ul>

    <p>How do we find the inverse in this new arithmetic?</p>

    <ul>
      <li>e.g. let $n=10$. Then $2 \oslash 7 = 2 \otimes 7^{-1} = 2 \otimes 3 = 6$, because $7^{-1}\times 3 = 21 \bmod 10 = 1$ is invertible!</li>
    </ul>
  </li>
</ul>

<p>Is there a systematic/mathematical way to find the inverse?</p>

<blockquote>
  <p><strong>Coprime</strong>: let $a,b\in Z^+$. We call $a,b$ being coprimes IFF $\gcd(a,b)=1$. We denote this with $a \perp b$.</p>

  <ul>
    <li>this is a generic definition for all $\Z^+$</li>
    <li>in the case of modular arithmetic, the only <strong>invertible</strong> elements in $\Z_n$ are the <mark>coprimes with $n$</mark></li>
  </ul>
</blockquote>

<p>Then, to find the inverse you can use:</p>

<blockquote>
  <p><strong>Extended GCD Algorithm</strong>: let $a,b,d \in \Z^+$. It turns out that if</p>

\[d|a \land d |b \land d= ax+by,\quad \text{for some $x,y\in \Z$}\]

  <p>then</p>

\[\gcd(a,b) = d\]

  <p>in other words, you can <mark>always write $\gcd(a,b)$ as $\gcd(a,b)=ax+by$!</mark></p>
</blockquote>

<p>How can this be true? Proof:</p>

<ul>
  <li>for any common divisor $d\vert a \land d \vert b$, so $d \le gcd(a,b)$ obviously</li>
  <li>but I also said $d = ax+by$. So any common divisor of $a,b$ must divide $d$. This means $gcd(a,b)$ divides $d$, hence $d \ge gcd(a,b)$
    <ul>
      <li>i.e. $d$ = any common divisor times something positive.</li>
    </ul>
  </li>
  <li>since $gcd(a,b) \le d$ and $\gcd(a,b) \ge d$, hence $gcd(a,b)=d$</li>
</ul>

<p><em>For example:</em> considering finding $\gcd(41,43)$, and show $\gcd(41,43)=41x+43y$</p>

<p><img src="/lectures/images/2023-05-11-COMS3203_Discrete_Math/image-20230411233913776.png" alt="image-20230411233913776" style="zoom: 20%;" /></p>

<p>we want to show $\gcd(a,b)=ax+by$.</p>

<ul>
  <li>
    <p>since $\gcd(41,43)=1$ in the last step</p>
  </li>
  <li>
    <p>If I take the second and third step, we have $43= 41\times 1 + 2 \implies 2 = 43 - 41 \times 1$, and $41=2\times 20 + 1 \implies 1 = 41 - 2 \times 20$.</p>
  </li>
  <li>
    <p>hence I just substitute them in $1 = 41 - (43 - 41)\times 20 = 21 \times 41 - 43 \times 20$, hence</p>

\[\gcd(43,41) = 1 = 43 \times (-20) + 41 \times (20) = ax + by\]
  </li>
</ul>

<blockquote>
  <p><strong>Modulus Division</strong>: this is a consequence of extended GCD + all invertible elements in $\Z_n$ are coprimes. Therefore, take any invertible element in $\Z_n$ we have:</p>

\[\gcd(a,n)=1 = ax + ny\]

  <p>therefore, notice that in modular arithmetic $ny$ goes away, hence:</p>

\[a\otimes x = 1\implies x = a^{-1}\]

  <p>finally, you want to <strong>be careful that $x \in \Z_n$ by mapping it back</strong>.</p>
</blockquote>

<p>For example,</p>

<ul>
  <li>
    <p>what is $41^{-1}$ for $\Z_{43}$? We know that</p>

\[\gcd(43,41) = 1 = 43 \times (-20) + 41 \times (20)\]

    <p>therefore, $41^{-1}=20$.</p>
  </li>
  <li>
    <p>what is $3^{-1}$ for $\Z_{40}$? Given that</p>

\[\gcd(3, 40) = 1 =  3 \times (-13) + 40 \times (1)\]

    <p>therefore, $3^{-1}=13 + 40=27$</p>
  </li>
</ul>

<h2 id="public-key-cryptography">Public Key Cryptography</h2>

<p>Here we discuss the basics of RSA</p>

<ol>
  <li>
    <p>Bob will pick two large  prime numbers $p,q$, such that $n=p \times q$</p>
  </li>
  <li>
    <p>Bob chooses an $e$ that is coprime with $(p-1)$ and $(q-1)$ so that</p>

\[\gcd(e, (p-1)(q-1)) =1\]

    <p>and also knows $d=e^{-1}$ is invertible (and easy to find knowing $p,q$). This is the <strong>secret key.</strong></p>
  </li>
  <li>
    <p>the public key is invertible, $n,e$ is sent to Alice (and everybody can see the two). This is <strong>public key</strong>.</p>
  </li>
  <li>
    <p>Alice then prepares the encrypted message and encrypt it with $e$ to get $E(m)=m^e \bmod n$</p>
  </li>
  <li>
    <p>Bob then inverts this by, recall that $e\otimes d=1$, hence</p>

\[E^{-1}(E(m)) = (m^e)^d \bmod n = m\]

    <p>decodes it back.</p>
  </li>
</ol>

<blockquote>
  <p>So the key idea is you need $d$ to decode, but finding $d=e^{-1}$ will take years to compute if you don’t know it (or $p,q$) in advance.</p>
</blockquote>

<h1 id="counting">Counting</h1>

<p>Here we will talk about</p>

<ol>
  <li>counting lists: arrangements, permutations, anagrams</li>
  <li>counting sets: combination, pascal triangle, binomial coefficients</li>
</ol>

<h2 id="counting-lists">Counting Lists</h2>

<blockquote>
  <p><strong>Multiplication Theorem</strong>: the number of lists of length $k$ where elements can be chosen from a set of $n$ possible elements is</p>

\[\begin{cases}
n^k, &amp; \text{if repetitions are allowed}\\
(n)_k \equiv n!/(n-k)!, &amp; \text{if repetitions not allowed}
\end{cases}\]

  <p>where $(n)_k$ is called the <em>fallen factorial</em> because it does not go all the way down to $1$. This is basically <mark>permutations</mark>.</p>
</blockquote>

<p>Essentially we are constructing <em>lists</em> = order matters = permutations.</p>

<p>For example:</p>

<ul>
  <li>making phone numbers (list of length $10$) from all numbers $0\sim 9$ <em>with repetition</em> is $10^{10}$.</li>
  <li>making phone numbers (list of length $4$) from all numbers <em>without repetition</em> is $(10)_4 = 10! / 6!$</li>
  <li>if you have $5$ shirts, $3$ pants, and $4$ pairs of shoes, how many outfits can you make? $5\times 3\times 4$.</li>
</ul>

<blockquote>
  <p><strong>Anagrams</strong>: a permutation of the letters in a word, without repetition.</p>
</blockquote>

<p>for example:</p>

<ul>
  <li>how may anagrams can you create from “math”? $4!=24$ ways</li>
  <li>what about from “momo”? We need to be careful of duplicates created by repeating “m” ($2!$ ways) and “o” ($2$! ways). Therefore $4!/(2!\times 2!)$</li>
</ul>

<p>We can write the above process in a general formula:</p>

\[\frac{n!}{n_1!\times n_2!\times \dots \times n_k!} = \frac{n!}{\Pi_{i=1}^k n_i!}\]

<p>where there are $k$ unique letters, and each of those letters repeated $n_k$ times.</p>

<h2 id="counting-sets">Counting Sets</h2>

<p>Now, we want <mark>combinations</mark> of $k$ elements taken from a set of $n$ possible element. Since we are counting sets = <strong>order does not matter</strong></p>

<blockquote>
  <p><strong>Combination</strong>: the set of $k$ elements <mark>sets</mark> of $n$ elements of an $n$-element set such that $0 &lt; k \le n$ is called a combination</p>
</blockquote>

<blockquote>
  <p><strong>Binomial Coefficient</strong>: let $n,k&gt;0$. A binomial coefficient denoted as</p>

\[{n \choose k} = \frac{n!}{(n-k)!k!} = \frac{(n)_k}{k!}\]

  <p>is the number of combinations of choosing (sets of $k$ elements) from $n$ elements. $k!$ represents, given a permutation $[a,b,c]$, the number of ways you can <em>double count</em> if you are counting combinations.</p>
</blockquote>

<p>Why is it called binomial coefficients? Consider $(x+y)^k$. Then essentially you get</p>

\[(x+y)^k = \underbrace{xx...xxx}_{\text{length $k$}} + xx...xxy + xx..xyy  + \dots + yy...yyy\]

<p>therefore, to <em>collect</em> terms into $x^iy^{k-i}$, it becomes a combination problem $k\choose i$. Therefore you also get</p>

<blockquote>
  <p><strong>Binomial Theorem</strong>: let $n\in \N$, then</p>

\[(x+y)^n = \sum_{k=0}^n {n \choose k} x^{n-k}y^k\]

</blockquote>

<p>Pascal’s triangle: <em>visually</em> you can decompose a combination $n \choose k$ into two terms:</p>

<p><img src="/lectures/images/2023-05-11-COMS3203_Discrete_Math/image-20230423025442744.png" alt="image-20230423025442744" style="zoom:50%;" /></p>

<p>For example, we have on the 3rd row ${3 \choose 0}=1$ and ${3 \choose 1}=3$, etc, but realize that:</p>

\[{3 \choose 1}= {2 \choose 0}+ {2 \choose 1}\]

<blockquote>
  <p><strong>Pascal’s Identity</strong>: for $n,k\in \Z$, and $0 &lt; k &lt; n$ is positive</p>

\[{n \choose k} = {n-1 \choose k-1} + {n-1 \choose k}\]

  <p>Intuitively, this works because:</p>

  <ul>
    <li>first ${n \choose k}$ represents finding <strong>sets of size $k$</strong> out of $n$ distinct elements</li>
    <li>let there be a “special element $sp$” amongst the $n$ element. The ${n \choose k}$ means “sets of size $k$ that includes $sp$” + “sets of size $k$ that exludes $sp$”. Hence we get:
      <ul>
        <li>“sets of size $k$ that (already) includes $sp$”  = choosing $k-1$ elements out of $n-1$</li>
        <li>“sets of size $k$ that exludes $sp$” = choosing $k$ elements out of $n-1$</li>
      </ul>
    </li>
  </ul>
</blockquote>

<p>From the above you also see the symmetry of combinations</p>

<blockquote>
  <p><strong>Rabbit property</strong>: the following are equivalent</p>

\[{n \choose k} = {n \choose n-k}\]

  <p>this makes sense because, say you are choosing a team of $k$ members out of $n$ people. Then for each team of $k$ you choose, you <strong>also implicitly chose a team of $n-k$</strong>. Since there is a one-to-one mapping of the teams you choose/left out = equality.</p>
</blockquote>

<h2 id="inclusion-exclusion-principle">Inclusion Exclusion Principle</h2>

<p>This is essentially used to count <strong>size of union sets</strong> with arbitrarily large number of sets.</p>

<p>For example, let there be 4 sets,</p>

<p><img src="/lectures/images/2023-05-11-COMS3203_Discrete_Math/image-20230423032103704.png" alt="image-20230423032103704" style="zoom:23%;" /></p>

<p>and you want to figure out the <strong>union size</strong> $\vert G \cup P \cup V \cup F\vert$?</p>

<p>The finding is that (without proof), let $A_1, …,A_n$ be finite sets, then</p>

<p><img src="/lectures/images/2023-05-11-COMS3203_Discrete_Math/image-20230423032434999.png" alt="image-20230423032434999" style="zoom: 33%;" /></p>

<p>so the sign is alternating. This leads to a general formula</p>

<blockquote>
  <p><strong>Principle of Inclusion/Exclusion</strong> (PIE): there is an alternating sign as the number of sets $\cap$ increases. Hence</p>

\[\left| \bigcup_{i=1}^n A_i \right| = \underbrace{\sum_{i=1}^n |A_i|}_{\text{n choose 1 terms}} - \underbrace{\sum_{1\le i &lt;j\le n} |A_i \cap A_j|}_{\text{n choose 2 terms}} + ...+\underbrace{(-1)^{n-1}|A_1 \cap ... A_n|}_{\text{n choose n terms}}\]

  <p>basically a formulaic way if there are large number of sets so that <em>Venn diagram is not drawable</em>.</p>
</blockquote>

<p><em>For example:</em> At the music academy, there are 43 students taking piano $A_P$, 57 students taking violin $A_V$, 29 students taking guitar $A_G$, and 18 taking flute $A_F$. There are 10 students in any two of these courses, 5 students in any three of them and 2 taking all courses. How many students are taking at least one course at the music academy?</p>

<p>This is equivalent of answering $\vert A_P\cup A_V\cup A_G \cup A_F\vert$, hence we get from PIE</p>

<ul>
  <li>
    <p>add $\vert A_P\vert  + \vert A_V\vert + \vert A_G\vert + \vert A_F\vert$ already known</p>
  </li>
  <li>minus $(\vert A_P\cap A_V\vert  + \vert A_P \cap A_G\vert  + …)$. Since “there are 10 students in any two of these courses” and there are 4 choose 2 ways to choose the two groups we get $10 \times {4 \choose 2}$</li>
  <li>add $(\vert A_P \cap A_V \cap A_G\vert + …)$ etc.</li>
</ul>

<p>So we have</p>

\[|A_P\cup A_V\cup A_G \cup A_F| = \underbrace{43+57+29+18}_{\text{1 term}} - \underbrace{10 \times {4 \choose 2}}_{\text{2 terms}} + \underbrace{5 \times {4 \choose 3}}_{\text{3 terms}} - \underbrace{2}_{\text{4 terms}} = 105\]

<h1 id="graph-theory">Graph Theory</h1>

<blockquote>
  <p>We will focus on simple graphs, that are <strong>undirected</strong>, has <strong>no loops</strong> (but can have cycle), and has <strong>no parallel edges</strong> (cycle of two nodes). So</p>

  <ul>
    <li><mark>at most one</mark> edge can exist for a pair of nodes</li>
    <li>should look simple as well</li>
  </ul>
</blockquote>

<p>Some definitions:</p>

<p><img src="/lectures/images/2023-05-11-COMS3203_Discrete_Math/image-20230423035411986.png" alt="image-20230423035411986" style="zoom: 25%;" /></p>

<blockquote>
  <p><strong>Graph</strong>: A graph consists of a set of vertices and edges:</p>

\[G=(V,E)\]

  <p>in the example above, this graph can be denoted as</p>

\[G=(\{u,v,w,x,y,z\},\{e_1,...,e_8\})\]

</blockquote>

<blockquote>
  <p><strong>Edge</strong>: An edge in a graph joints two vertices (e.g. $u,v$). This edge can be denoted either as $uv$, ${u,v}$, or you can name it $e_1$.</p>
</blockquote>

<p>More definitions</p>

<ul>
  <li>
    <p><strong>adjacent</strong>: two <em>nodes</em> $u$ and $v$ are adjacent if there is an edge directly connecting them. Denoted as $u \sim v$.</p>
  </li>
  <li>
    <p><strong>neighborhood</strong>: the <em>set</em> of nodes that has an edge directly connecting it. Denoted as</p>

\[\mathcal{N}(x)=\{ v \in V | v \sim x \}\]
  </li>
  <li>
    <p><strong>degree</strong>: The number of neighbors of a vertex is called its degree, denoted</p>

\[d(x) = |\mathcal{N}(x)|\]

    <p>for example, $d(w)=2$ in the above figure as there are two connections. Furthermore, we denote</p>

    <ul>
      <li><strong>max degree of a graph</strong> as $\Delta(G)$. In the above figure $\Delta(G)=5$</li>
      <li><strong>min degree of a graph</strong> as $\delta(G)$. In the above figure $\delta(G)=1$</li>
    </ul>
  </li>
</ul>

<p>Observe that in the above example</p>

<p><img src="/lectures/images/2023-05-11-COMS3203_Discrete_Math/image-20230423041224774.png" alt="image-20230423041224774" style="zoom: 33%;" /></p>

<p>So why twice? The proof is quite intuitive</p>

<ul>
  <li>adding each edge adds a total degree of 2 to the graph</li>
  <li>if there are $\vert E\vert$ edges, then total degree is $2\vert E\vert$.</li>
</ul>

<blockquote>
  <p><strong>Handshaking</strong>: The sum of the degrees of each vertex in a graph $G=(V,E)$ is equal to twice the number of edges.</p>

\[\sum_{u\in V}d(v) = 2|E|\]

  <p>(this holds for non-simple graphs as well, if you treat a loop as an edge)</p>
</blockquote>

<p>This also means that <mark>a graph's total degree must be even</mark>.</p>

<h2 id="isomorphism">Isomorphism</h2>

<p>Now, we move to studying isomorphism between graphs, which arises when two graphs have the “<strong>same form.</strong>”</p>

<blockquote>
  <p><strong>Isomorphism</strong>: Two graphs $G=(V_G, E_G)$ and $H=(V_H, E_H)$ are isomorphic (“same-form”) if and only if there exists a bijective function (i.e. <strong>mapping of vertices</strong>) representing an isomorphism of $G$ to $H$:</p>

\[f:V_G \to V_H\]

  <p>such that</p>

\[\forall u,v \in V_G, \quad u \sim v \text{ in $G$} \iff f(u) \sim f(v) \text{ in $H$}\]

  <p>i.e. it requires <mark>adjacency between vertices is the same</mark></p>
</blockquote>

<p>Below would be an example</p>

<p><img src="/lectures/images/2023-05-11-COMS3203_Discrete_Math/image-20230423115306098.png" alt="image-20230423115306098" style="zoom:33%;" /></p>

<p>But below is not</p>

<p><img src="/lectures/images/2023-05-11-COMS3203_Discrete_Math/image-20230423115405904.png" alt="image-20230423115405904" style="zoom:33%;" /></p>

<p>because realize that the left graph has an edge connecting a vertex with (degree = 1) with (degree = 3), but the right graph only has (degree = 2) with (degree = 3).</p>

<p>In general:</p>

<ul>
  <li><strong>to prove isomorphism</strong>: find a bijection and show that the adjacency property (edge to endpoints) is preserved
    <ul>
      <li>this is generally considered a hard problem, as there is <em>no efficient algorithm</em> to find the bijection.</li>
    </ul>
  </li>
  <li><strong>to prove non-isomorphism</strong>: if adjacency are preserved, then there <strong>will be some invariant properties</strong> such as degrees. Therefore, if some properties are violated then they cannot be isomorphic</li>
</ul>

<p><img src="/lectures/images/2023-05-11-COMS3203_Discrete_Math/image-20230423115939111.png" alt="image-20230423115939111" style="zoom:33%;" /></p>

<h2 id="types-of-graphs">Types of Graphs</h2>

<p>some common types of graphs, which can have some useful properties.</p>

<blockquote>
  <p><strong>Null graph</strong>: A graph that does not have edges. So you have $G=(V, {})$. This is also often denoted as</p>

\[L_n = \text{null graph with n nodes}\]

  <p>e.g $L_1$ is one vertex zero edge, $L_2$ is two vertex zero edge, …</p>
</blockquote>

<blockquote>
  <p><strong>Complete graph</strong>: A graph with <strong>every possible pair of vertices</strong> has an edge. We use $K_n$ to denote a complete graph with $n$ vertices.</p>
</blockquote>

<p>for example:</p>

<p><img src="/lectures/images/2023-05-11-COMS3203_Discrete_Math/image-20230423121353025.png" alt="image-20230423121353025" style="zoom:37%;" /></p>

<p>notice that</p>

<ul>
  <li>$K_1 = L_1$!</li>
  <li>for <mark>every vertex $v$,  it has $\deg(v)=n-1$!</mark></li>
</ul>

<blockquote>
  <p><strong>Path graph</strong>: A path graph has vertices ${v_1,…,v_n}$ and edges ${e_1,…,e_{n-1}}$  such that <strong>an edge $e_k$ joins ${v_k, v_{k+1}}$</strong>. We use $P_n$ to denote path graphs with $n$ vertices.</p>
</blockquote>

<p>For example</p>

<p><img src="/lectures/images/2023-05-11-COMS3203_Discrete_Math/image-20230423121642105.png" alt="image-20230423121642105" style="zoom: 33%;" /></p>

<p>notice that $\vert V\vert -1=\vert E\vert$.</p>

<blockquote>
  <p><strong>Cycle Graph</strong>: A path graph has vertices ${v_1,…,v_n}$ and edges ${e_1,…,e_{n}}$  such that an edge $e_k$ joins ${v_k, v_{k+1}}$ <strong>where $k+1$ is “$\bmod n$”</strong>. We use $C_n$ to denote path graphs with $n$ vertices.</p>
</blockquote>

<p>For example:</p>

<p><img src="/lectures/images/2023-05-11-COMS3203_Discrete_Math/image-20230423122142344.png" alt="image-20230423122142344" style="zoom:33%;" /></p>

<p>where notice that:</p>

<ul>
  <li><mark>all vertex has exactly degree 2</mark></li>
  <li>and $\vert V\vert =\vert E\vert$.</li>
</ul>

<blockquote>
  <p><strong>Regular Graph</strong>: A graph is regular provided <strong>every vertex has the same degree</strong></p>

  <ul>
    <li>so a $C_n$ is a regular graph of degree 2</li>
    <li>a $K_n$ complete graph is also regular of degree $n-1$</li>
    <li>a $L_n$ is also a regular of degree 0.</li>
  </ul>
</blockquote>

<h2 id="properties-of-graphs">Properties of Graphs</h2>

<p>Now we can talk about certain properties. First a few more definitions.</p>

<blockquote>
  <p><strong>Walk</strong>: A walk in $G$ is just <mark>any</mark> sequence of vertices where each vertex is adjacent to the next vertex (i.e. you can physically walk on the graph given this sequence).</p>
</blockquote>

<p>For example, given this graph</p>

<p><img src="/lectures/images/2023-05-11-COMS3203_Discrete_Math/image-20230423123320755.png" alt="image-20230423123320755" style="zoom:43%;" /></p>

<p>where:</p>

<ul>
  <li>$(u,v,w,v,x)$ is a walk of length 4.</li>
  <li>$(v)$ is a walk of length 0.</li>
  <li>$(u,u,x,v,w)$ is NOT a walk because $u$ does not have a connection to $u$</li>
</ul>

<blockquote>
  <p><strong>Path</strong>: A path in a graph is a <strong>walk</strong> in which <mark>no vertex</mark> is repeated. We denote a path of length $n-1$ with $n$ vertices as $P_n$.</p>

  <p>Additionally, we denote <strong>$(u,v)$-path</strong> is a path that starts at vertex $u$ and ends at vertex $v$.</p>
</blockquote>

<p>Then we can define</p>

<blockquote>
  <p><strong>Connected Graph</strong>: A graph $G=(V,E)$ is called a connected graph provided <mark>each pair of vertices is connected by a path</mark> (i.e. you can reach any vertex from some random vertex). Formally:</p>

\[\forall u, v \in V,\quad \exists (u,v)\text{-path}\]

</blockquote>

<table>
  <thead>
    <tr>
      <th style="text-align: center">connected</th>
      <th style="text-align: center">disconnected</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="https://www.tutorialspoint.com/discrete_mathematics/images/connected_graph.jpg" alt="Connected vs Disconnected Graphs" style="zoom:50%;" /></td>
      <td style="text-align: center"><img src="https://www.tutorialspoint.com/discrete_mathematics/images/unconnected_graph.jpg" alt="Connected vs Disconnected Graphs" style="zoom:50%;" /></td>
    </tr>
  </tbody>
</table>

<h2 id="trees">Trees</h2>

<blockquote>
  <p><strong>Tree</strong>: Let $T=G=(V,E)$. $G$ is a tree iff it is connected and <strong>has no cycle (acyclic)</strong>. A cycle can be seen as a path in which the first and last variables are the same. A graph that is acyclic contains <mark>no such paths</mark>.</p>
</blockquote>

<p><img src="https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20171027092037172-0306:9781316105450:08931fig2_1.png?pub-status=live" alt="Shapes of Graphs: Trees to Triangles (Chapter 2) - Applying Graph Theory in  Ecological Research" style="zoom:33%;" /></p>

<p>some properties of trees include:</p>

<ul>
  <li>there is <mark>exactly one path</mark> to reach from one vertex to another (since there is no cycle)</li>
  <li>for a tree <mark>$\vert V\vert  = \vert E\vert +1$</mark> (which can be proven by induction)</li>
  <li>A graph is a tree if and only if it a <mark>minimal connected</mark> (if you take out one edge, it becomes disconnected)</li>
</ul>

<blockquote>
  <p><strong>Leaf</strong>: let $G=(V,E)$, then a vertex of <strong>degree 1</strong> is called a leaf in a tree. And if you take out any of the leaf nodes, you <strong>still have a tree</strong></p>
</blockquote>

<blockquote>
  <p><strong>Theorem</strong>: let $G=(V,E)$. $G$ is tree provided that</p>

\[\forall u,v \in V \quad \exists!\text{u-v path}\]

</blockquote>

<blockquote>
  <p><strong>Theorem</strong>: for a tree $\vert V\vert =\vert E\vert +1$</p>
</blockquote>

<p><em>Proof</em>: by induction.</p>

<ul>
  <li>
    <p>base case: $\vert V\vert =1$ with $\vert E\vert =0$ holds with tree of 1 vertex</p>
  </li>
  <li>
    <p>inductive hypothesis: suppose $T_k$ is a tree with $k$ vertices. Suppose the proposition holds for $T_k$.</p>

\[|E_{T_k}| = |V_{T_k}| - 1\]

    <p>i.e. it has <strong>$k$ vertices with $k-1$ edges</strong>.</p>
  </li>
  <li>
    <p>inductive step: it works for a tree $T_{k+1}$, because $T_{k+1}$ must be $T_k$ <strong>plus a leaf node</strong>. So suppose we derach one leaf of $T_{k+1}$, we get a tree $T_k$. Therefore it <strong>means $T_{k+1}$ has one extra edge than $T_k$</strong> (and one leaf node).</p>

\[|E_{T_{k+1}}|=k=(k+1)-1\]

    <p>holds</p>
  </li>
</ul>

<blockquote>
  <p><strong>Hamiltonian Path</strong>: is a <mark>path</mark> containing <mark>all vertices</mark> (recall that a path walk <mark>without repeating vertices</mark>).</p>
</blockquote>

<p><img src="/lectures/images/2023-05-11-COMS3203_Discrete_Math/image-20230425123039505.png" alt="image-20230425123039505" style="zoom:13%;" /></p>

<ul>
  <li>
    <p>How many walks are there between $a,b$? There is an <strong>infinity of walks</strong> since there are cycles</p>
  </li>
  <li>
    <p>How many paths are there between $a,b$? There are $4\times 2= 8$. How?</p>
    <ul>
      <li>it is equivalent to #ways to reach $a_7$ from $a$ times #ways to reach from $a_7$ to $b$.</li>
    </ul>
  </li>
</ul>

<p>There is no Hamiltonian path between $a$ and $b$. (complicated, in this case by enumeration)</p>

<p><em>For Example</em>: let $K_n$ be a complete graph with $n\ge 2$. How many Hamiltonian paths are there <strong>in total</strong>, between any pair of vertices?</p>

<ul>
  <li>notice that a complete graph is one for <em>every pair of vertex there is an edge</em>.
    <ul>
      <li>for $K_2$, since you can reach any from any other, there are two boxes = $2!$ ways (<code class="language-plaintext highlighter-rouge">ab</code> and <code class="language-plaintext highlighter-rouge">ba</code>)</li>
      <li>for $K_3$, you have $3!$ ways (<code class="language-plaintext highlighter-rouge">abc</code>, <code class="language-plaintext highlighter-rouge">acb</code>, <code class="language-plaintext highlighter-rouge">bac</code>, <code class="language-plaintext highlighter-rouge">bca</code>, <code class="language-plaintext highlighter-rouge">cab</code>, <code class="language-plaintext highlighter-rouge">cba</code>)</li>
      <li>for $K_4$, you have $4!$ ways</li>
    </ul>
  </li>
  <li><strong>so in total $n!$ Hamiltonian path for $K_n$</strong></li>
</ul>

<h2 id="eulerian-graphs">Eulerian Graphs</h2>

<blockquote>
  <p><strong>Eulerian trail</strong>: a <mark>walk</mark> in $G=(V,E)$ is called an eulerian trail provided it traverses every <mark>edge exactly once</mark>.</p>
</blockquote>

<blockquote>
  <p><strong>Eulerian tour</strong>: if an Eulerian trail start and end at the same vertex, it is called an Eulerian tour.</p>
</blockquote>

<blockquote>
  <p><strong>Eulerian graph</strong>: A graph with an Eulerian tour is called an Eulerian graph.</p>
</blockquote>

<p><em>For example</em>: consider the following graphs</p>

<p><img src="/lectures/images/2023-05-11-COMS3203_Discrete_Math/image-20230425105112462.png" alt="image-20230425105112462" style="zoom:33%;" /></p>

<ul>
  <li>for graph $H$, we can
    <ul>
      <li>have an Eulerian trail from<code class="language-plaintext highlighter-rouge">x</code> to <code class="language-plaintext highlighter-rouge">y</code>: $x-v-u-w-v-y-w-x-y$.</li>
      <li>there is <em>no Eulerian tour</em> in $H$.</li>
    </ul>
  </li>
  <li>for graph $G$, we can
    <ul>
      <li>no Eulerian tour nor Eulerian trail in $G$</li>
    </ul>
  </li>
</ul>

<p>How do we justify? Realize if you have even one <strong>vertex with odd degrees</strong>, then there cannot be an Eulerian tour.</p>

<ul>
  <li>because to go out and get back, you in general must do <code class="language-plaintext highlighter-rouge">out</code> and <code class="language-plaintext highlighter-rouge">in</code>. So the degree <mark>has to be even</mark>.</li>
</ul>

<blockquote>
  <p>Theorem: let $G$ be a connected graph. If <strong>every vertex $v\in V(G)$ has even degree</strong>, then there is an Eulerian <mark>tour</mark> that begins and ends at (every) $v$</p>
</blockquote>

<blockquote>
  <p>Theorem: let $G$ be a connected graph with <strong>exactly two vertices of odd degree $u,v$.</strong> Then $G$ has a Eulerian <mark>trail</mark> that begins at $u$ and ends at $v$.</p>
</blockquote>

<p><em>For Example</em>: how many non-isomorphic graph with $n$ vertices are there? Given $n=4$,</p>

<ul>
  <li>
    <p>there are ${4 \choose 2}=6$ possible edges to place into a graph of 4 nodes.</p>
  </li>
  <li>
    <p>for every graph, you can choose to <strong>have the edge or not</strong>. Hence <mark>$2^6$ possible graphs</mark> (including isomorphic)</p>

\[\square \square \square \square \square \square\]
  </li>
  <li>
    <p>for non-isomorphic graph, you will need to draw all the equivalence groups/isomorphism</p>
  </li>
  <li>
    <p>there you will find there are 11 of them/non-isomorphic graph</p>
  </li>
</ul>

<blockquote>
  <p>There is an formula for this, but in the course we pretend we don’t know, and we have to count.</p>
</blockquote>

<h2 id="planar-graphs">Planar Graphs</h2>

<p>Is it possible to feed every house with utility without a cable (edge) crossing other edges?</p>

<blockquote>
  <p><strong>Planar Graph</strong>: A graph is a planar graph if it can be drawn in a <strong>two-dimensional space</strong> with <strong>no crossing edges</strong>. A planar graph divides the plane into areas called <strong>faces</strong>.</p>
</blockquote>

<p><em>For Example</em>: square graph being planar v.s. not planar.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">non-planar</th>
      <th style="text-align: center">planar</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2023-05-11-COMS3203_Discrete_Math/image-20230425123212482.png" alt="image-20230425123212482" style="zoom: 10%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2023-05-11-COMS3203_Discrete_Math/image-20230425123422760.png" alt="image-20230425123422760" style="zoom:10%;" /></td>
    </tr>
  </tbody>
</table>

<p>where the planar graph no the right has “non-overlapping” faces.</p>

<blockquote>
  <p>Theorem: For <strong>every connected planar graph</strong>, we have:</p>

\[v+f = e+2\]

  <p>where $v$ is the number of vertices, $e$ the number of edges, and $f$ the number of faces.</p>
</blockquote>]]></content><author><name></name></author><category term="2022@Columbia" /><summary type="html"><![CDATA[Discrete Math Logistics]]></summary></entry><entry><title type="html">PHYS3008 EM n Optics</title><link href="/lectures/2022@columbia/PHYS3008_EM_n_Optics.html/" rel="alternate" type="text/html" title="PHYS3008 EM n Optics" /><published>2023-05-11T00:00:00+00:00</published><updated>2023-05-11T00:00:00+00:00</updated><id>/lectures/2022@columbia/PHYS3008_EM_n_Optics</id><content type="html" xml:base="/lectures/2022@columbia/PHYS3008_EM_n_Optics.html/"><![CDATA[<h1 id="recap">Recap</h1>

<h2 id="electrostatics">Electrostatics</h2>

<p>charges stationary $\rho(\vec{r})$ independent of time</p>

<table>
  <thead>
    <tr>
      <th>Condition/Name</th>
      <th>Equation</th>
      <th>Comments</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Basic facts about electric field</td>
      <td>$\oint \vec{E}\cdot d\vec{a} = \frac{Q_{enc}}{\epsilon_0}$</td>
      <td>Useful when there is symmetry, so that $\oint \vec{E}\cdot d\vec{a}$ is easy to figure out</td>
    </tr>
    <tr>
      <td> </td>
      <td>$V(\vec{r}) = - \int_O^r \vec{E}\cdot d\vec{l}$</td>
      <td>Useful when you <strong>already know $\vec{ E}$</strong></td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>Careful for regions when $\vec{E}$ is <strong>not continuous</strong>. Then you may need to split your integral.</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\vec{\nabla}\times \vec{E}=\vec{0}$</td>
      <td>Conservation of field/charge. Proven from showing that $\oint \vec{E}\cdot d\vec{l}=\int \vec{\nabla}\times \vec{E}\cdot d\vec{S}=0$ for a single point charge, then superposition.</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>A common approach to <strong>prove starting from a single point charge</strong>, then just use superposition</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\oint \vec{E}\cdot d \vec{l} = 0$</td>
      <td>from the above.</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\vec{E}=-\vec{\nabla}V$</td>
      <td>Useful for <strong>finding</strong> out $\vec{E}$, since $V$ is easier to compute</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\nabla^2 V = \rho / \epsilon_0$</td>
      <td>Poisson’s equation. Useful to <strong>solve when inside vacuum region</strong> such that $\rho = 0$ globally in that region.</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>In side vacuum, $\nabla^2 V = 0$ is the Laplace Equation</td>
    </tr>
    <tr>
      <td>Over <strong>all space</strong></td>
      <td>$W=\frac{\epsilon}{2}\int \vert \vec{E}\vert ^2d^3r’$</td>
      <td><strong>Easier to compute</strong>, often used.</td>
    </tr>
    <tr>
      <td>Perfect Conductor</td>
      <td>$\vec{E}<em>{meat}=0$, $\rho</em>{meat}=0$</td>
      <td>Charges free to move, will redistribute until $\vec{E}_{meat}=0$. Hence all charges are <strong>on the surface</strong></td>
    </tr>
    <tr>
      <td> </td>
      <td>$V_{surf}=V_0$, $\vec{E}_{surf}={E}^\perp \hat{n}$</td>
      <td>$V(b)-V(a)=-\int_a^b \vec{E}\cdot d\vec{l}=0$ if on the surface, since $\vec{E}=0$ inside</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>$V_{meat}=V_0$ as well since there is no field</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>Those conditions are often used as <mark>constraints</mark> in a problem</td>
    </tr>
    <tr>
      <td>Capacitance</td>
      <td>$C \equiv \frac{Q}{\Delta V}$</td>
      <td>$Q=+Q$ of the <strong>two conductors,</strong> is the <strong>charge stored</strong></td>
    </tr>
    <tr>
      <td> </td>
      <td>$\Delta V =- \int_a^b \vec{E}\cdot d\vec{l}$ commonly used</td>
      <td>$\Delta V$ is the potential difference across the two conductor = <strong>how much $\Delta V$</strong> needed to store $Q$</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>Should be purely <strong>geometric</strong>, in unit $\epsilon \cdot \text{Length}$</td>
    </tr>
    <tr>
      <td>Energy Stored in Conductor</td>
      <td>$W=\frac{1}{2}\frac{Q^2}{C}=\frac{1}{2}CV^2$</td>
      <td>Think of it being same as energy needed to <strong>charge up conductor</strong> = <strong>work done</strong> to move all the charges over</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>Proven because $dW = \Delta V(q)dq$ to move a charge $dq$ over, and then since $C=\frac{q}{\Delta V(q)}$ is geometric, perform $W=\int dW$</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td> </td>
    </tr>
    <tr>
      <td>Summary</td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230125154805806.png" alt="image-20230125154805806" /></td>
      <td> </td>
    </tr>
  </tbody>
</table>

<h2 id="magnetostatics">Magnetostatics</h2>

<p>when you have a <mark>steady current</mark>, but as it is current, changes are moving $\implies$ magnetic field</p>

<table>
  <thead>
    <tr>
      <th>Condition/Name</th>
      <th>Equation</th>
      <th>Comments</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Biot-Savart Law Generic</td>
      <td>$\vec{B}(\vec{r}) = \int \frac{\mu_0}{4\pi} \frac{\vec{J}(\vec{r}’)\times(\vec{r}-\vec{r’})}{\vert \vec{r}-\vec{r’}\vert ^3}\,d^3r’$</td>
      <td>True if $J$ is independent of time, i.e. steady</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\vec{E}(\vec{r}) = \int \frac{1}{4\pi \epsilon_0} \frac{\vec{\rho}(\vec{r}’)\cdot(\vec{r}-\vec{r’})}{\vert \vec{r}-\vec{r’}\vert ^3}\,d^3r’$</td>
      <td>parallel to the $\vec{E}$ field, basically $J \to \rho$</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\mu_0 = 1/(\epsilon_0 c^2)$</td>
      <td> </td>
    </tr>
    <tr>
      <td>Biot-Savart if Steady current</td>
      <td>$\vec{B}(\vec{r}) = \frac{\mu_0 I}{4\pi} \int \frac{d\vec{l}(\vec{r}’)\times(\vec{r}-\vec{r}’)}{\vert \vec{r}-\vec{r}’\vert ^3}$</td>
      <td>basically we have here $\vec{J} = \vec{I}\delta^2(\vec{r}-\vec{r}’)$ and that $\vec{I}dl = Id\vec{l}$</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>works if constant current so $\vec{I}dl = Id\vec{l}$ holds</td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230125155110733.png" alt="image-20230125155110733" style="zoom: 50%;" /></td>
      <td>Integrates $dl’$ <mark>only</mark> over where $\vec{r}’ \neq 0$</td>
    </tr>
    <tr>
      <td>Magnetric Field of a Straight line wire</td>
      <td>$\vec{B} = \frac{\mu_0 I}{2\pi r} \hat{e}_\phi$</td>
      <td>Found either using Biot-Savart for current, or using the symmetry hence $\oint \vec{B}\cdot d\vec{l} = \mu_0 I_{enc}$</td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230125155135485.png" alt="image-20230125155135485" style="zoom:50%;" /></td>
      <td>Graphically it circulates the current</td>
    </tr>
    <tr>
      <td>Field of a Toroid</td>
      <td>$B = \frac{\mu N I}{2 \pi s}$</td>
      <td>and $0$ outside. $s$ is basically the radial distance</td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230126222238405.png" alt="image-20230126222238405" style="zoom:20%;" /></td>
      <td> </td>
    </tr>
    <tr>
      <td>Divregence of B</td>
      <td>$\vec{\nabla}_{\vec{r}} \cdot \vec{B}(\vec{r})=0$</td>
      <td>for E field we had $\vec{\nabla}\cdot \vec{E}= \rho/\epsilon_0$</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\oint \vec{B}\cdot d\vec{S}=0$</td>
      <td>for E field we had Gaussian surface $\oint \vec{E}\cdot d\vec{S}=Q_{enc}/\epsilon_0$!</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>derived using $\int \vec{\nabla}\cdot\vec{B} d\tau = \oint \vec{B}\cdot d\vec{S}$</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>not very useful for B field calculation</td>
    </tr>
    <tr>
      <td>Curl of B</td>
      <td>$\vec{\nabla}_{\vec{r}} \times \vec{B}(\vec{r})=\mu_0 \vec{J}(\vec{r})$</td>
      <td>for E field we had this is 0</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\oint \vec{B}\cdot d\vec{l}=\mu_0 I_{enc}$</td>
      <td>very useful for B field calculation if we have symmetry in $J$ or $I$ setup!</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>called <strong>Ampere Loops</strong></td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>derived using $\int \vec{\nabla}\times \vec{B}\cdot d\vec{S} = \oint \vec{B}\cdot d\vec{l}$</td>
    </tr>
    <tr>
      <td>Field of Solenoid with $n$ turns per unit legnth</td>
      <td>$\vec{B} = \mu_0 n I \hat{e}_z$</td>
      <td>if inside the solenoid</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\vec{B}=0$</td>
      <td>if outside</td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230125155158303.png" alt="image-20230125155158303" style="zoom: 67%;" /></td>
      <td>Essentially solved by drawing Amphere loops</td>
    </tr>
    <tr>
      <td>Magnetic Vector Potential</td>
      <td>$\vec{\nabla}\times \vec{A} = \vec{B}$</td>
      <td>so that $\vec{A}$ is easier to compute</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>from $\vec{E}= - \vec{\nabla}V$ for $V$ is easier to compute</td>
    </tr>
    <tr>
      <td>Gauges for $\vec{A}$ due to above definition</td>
      <td>$\nabla(\nabla \cdot \vec{A})-\nabla^2\vec{A} = \mu_0 \vec{J}$</td>
      <td>if $\vec{\nabla}\times \vec{A} = \vec{B}$, and we know $\nabla \times \vec{B} = \mu_0 \vec{J}$</td>
    </tr>
    <tr>
      <td> </td>
      <td>if $\nabla \cdot \vec{A} = 0$</td>
      <td>Colomb’s Gauge, used by this course</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\vec{A}’ = \vec{A}+ \nabla\lambda$ results in the same $B$ field</td>
      <td>therefore we can always force $\nabla \cdot \vec{A} = 0$ by choosing $\lambda$</td>
    </tr>
    <tr>
      <td>Magnetic Vector Potential Definition</td>
      <td>$\vec{A} = \frac{\mu_0}{4\pi}\int \frac{\vec{J}(\vec{r}’)}{\vert \vec{r}-\vec{r}’\vert }d^3r’$</td>
      <td>derived from the above with $\nabla^2 \vec{A}=-\mu_0 \vec{J}$, so that each compontent $A_x,A_y,A_z$ essentially is an analog version of $\nabla^2 V = - \rho / \epsilon_0$ and we know the solution $V$ from using $\rho$</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>this means that $\vec{A}$ is usually in the <strong>same direction</strong> as current!</td>
    </tr>
    <tr>
      <td> </td>
      <td>Technically $\vec{A} = \frac{\mu_0}{4\pi}\int \frac{\vec{J}(\vec{r}’)}{\vert \vec{r}-\vec{r}’\vert }d^3r’ + \vec{A}(0)$</td>
      <td>for $\vec{A}(0)$ is a reference point</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>usually use $\vec{A}(\infty)=0$</td>
    </tr>
  </tbody>
</table>

<h2 id="polarization-and-magnetization">Polarization and Magnetization</h2>

<blockquote>
  <p>Basically consider $E$ and $B$ Field inside Matter themselves (e.g. after providing an external $\vec{E}<em>{ext}$ or $\vec{B}</em>{ext}$)</p>
</blockquote>

<p>first, we show $E$ fields in matter, i.e. polarization $\vec{P}$, and we are <mark>only interested in what field this material will produce</mark>, and do not discuss how we get there.</p>

<table>
  <thead>
    <tr>
      <th>Condition/Name</th>
      <th>Equation</th>
      <th>Comments</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Electric Dipole</td>
      <td> </td>
      <td>when a piece of diaelectric material is placed under $\vec{E}_{ext}$, those little dipoles align themselves and form $\vec{P}$</td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230130144401254.png" alt="image-20230130144401254" style="zoom:40%;" /></td>
      <td> </td>
    </tr>
    <tr>
      <td>Polarization</td>
      <td>$\vec{P}\equiv$dipole moment per unit volume</td>
      <td>when a piece of dielectric material is placed under $\vec{E}_{ext}$, those little dipoles align themselves and form $\vec{P}$</td>
    </tr>
    <tr>
      <td>Potential due to Polarization $\vec{P}$</td>
      <td>$V(\vec{r}) = \frac{1}{4\pi \epsilon}\frac{\vec{p}]\cdot\hat{r}}{r^2} + O(\frac{1}{r^3})$</td>
      <td>multi-pole expansion of electric potential</td>
    </tr>
    <tr>
      <td> </td>
      <td>$V(\vec{r}) = \frac{1}{4\pi \epsilon_0} \oint_\Omega \frac{\sigma_b}{\vert \vert \vec{r} - \vec{r}’\vert \vert }dA’+ \frac{1}{4\pi \epsilon_0} \int_V \frac{\rho_b}{\vert \vert \vec{r} - \vec{r}’\vert \vert }dV’$</td>
      <td>derived from $V(\vec{r})$ above but <mark>only</mark> consisting of dipole terms</td>
    </tr>
    <tr>
      <td> </td>
      <td>$V(\vec{r})=V(\text{from$\sigma_b, \rho_b$})$</td>
      <td>i.e. you can <strong>treat</strong> the dielectric as having $\sigma_b$ on the surface and $\rho_b$ inside.</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>if $\rho_b = 0$, $V(\text{from$\sigma_b,\rho_b$})$ can be solved using <strong>Laplacian $\nabla^2 V = 0$</strong> with boundary of $\sigma_b$</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\sigma_b \equiv \vec{P}\cdot \hat{n}$</td>
      <td>$\hat{n}$ points from the surface having dielectric to vaccum/non-dielectric place</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\rho_b\equiv - \nabla \cdot \vec{P}$</td>
      <td> </td>
    </tr>
    <tr>
      <td>Interpretation of Bound Charge due to $\vec{P}$</td>
      <td>$\sigma_b \equiv \vec{P}\cdot \hat{n}$</td>
      <td>$\sigma_b$ comes from lining up dipoles so that only ends matter</td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230130205559197.png" alt="image-20230130205559197" style="zoom: 33%;" /></td>
      <td> </td>
    </tr>
    <tr>
      <td> </td>
      <td>$\rho_b\equiv - \nabla \cdot \vec{P}$</td>
      <td>$\rho_b$ considers if dipole in between is not cancelled out, then the flux of polarization would relate to charge: $-\oint \vec{P}\cdot d\vec{A} =\int_V \rho_b \,d^3r’$</td>
    </tr>
    <tr>
      <td>Displacement Field</td>
      <td>$\nabla \cdot \vec{E}_{total} = (\rho_f+\rho_b) / \epsilon_0$</td>
      <td>since now the polarization also produces field, we want to know a “general” equation for $\vec{E}$ field</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\nabla \cdot (\epsilon \vec{E}_{total}+\vec{P}) = \rho_f$</td>
      <td>use $\rho_b\equiv - \nabla \cdot \vec{P}$</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\vec{D}\equiv \epsilon \vec{E}_{total}+\vec{P}$</td>
      <td> </td>
    </tr>
    <tr>
      <td>Gauss Law for Electric Displacement Field</td>
      <td>$\nabla \cdot \vec{D} = \rho_f$</td>
      <td>derived from above</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\oint \vec{D}\cdot d\vec{A} = Q_{free_{enc}}$</td>
      <td>integral form</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>if have symmetry can use <strong>Gaussian surfaces</strong></td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>used for proving boundary conditions for $\vec{D}$</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\vec{\nabla} \times \vec{D} = \vec{\nabla} \times \vec{P}$</td>
      <td> </td>
    </tr>
    <tr>
      <td> </td>
      <td>$\oint \vec{D}\cdot d\vec{r}=\oint \vec{P}\cdot d\vec{r}$</td>
      <td>Stokes’ Theorem, derived from above</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>used for proving boundary conditions for $\vec{D}$</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>the above is <strong>true for any dielectric</strong></td>
    </tr>
    <tr>
      <td>$\vec{D}$ and $\vec{E}$ relation</td>
      <td>$\vec{\nabla}\cdot \vec{E}<em>{tot} = \rho</em>{tot} / \epsilon_0 \to \vec{E}<em>{tot} = \frac{1}{4\pi \epsilon_0} \int \frac{\rho</em>{tot}}{\symscr{r}} \hat{\symscr{r}}\,d^3r’$</td>
      <td>because $\vec{\nabla}\times \vec{E}_{tot} = 0$</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\vec{\nabla}\cdot \vec{D}= \rho_{free} \not\to \vec{D} = \frac{1}{4\pi } \int \frac{\rho_{free}}{\symscr{r}} \hat{\symscr{r}}\,d^3r’$</td>
      <td>because $\vec{\nabla} \times \vec{D} \neq 0$ often, hence $\vec{D}$ might not have a potential</td>
    </tr>
    <tr>
      <td>Linear Dielectric</td>
      <td>$\vec{P} = \epsilon_0 \chi_e \vec{E}_{tot}$</td>
      <td>$\chi_e$ is electric susceptibility, $\epsilon_0$ is permittivity of free space</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>if $\vec{E}<em>{applied}$ is given, we are stuck because it will produce $\vec{P}$, which produces $\vec{E}</em>{resp}$ hence affects $\vec{E}_{tot}$, which relates to $\vec{P}$…</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\vec{D} = \epsilon_0(1+\chi_e)\vec{E}<em>{tot}\equiv \epsilon \vec{E}</em>{tot}$</td>
      <td>$\epsilon$ is permittivity of material</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>can use this to <strong>break from the loop</strong> if we can find $\vec{D}$ from Gaussian surface</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\epsilon_r \equiv \epsilon / \epsilon_0 = 1+\chi_e$</td>
      <td>relative permittivity, $\chi_e=0$ in free space.</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>also called <strong>dielectric constant</strong></td>
    </tr>
    <tr>
      <td> </td>
      <td>$\vec{\nabla}\times \vec{D} = \vec{\nabla} \times (\epsilon \vec{E}_{tot}) \neq 0$</td>
      <td>because $\epsilon$ could vary in different position</td>
    </tr>
    <tr>
      <td>Space filled with homogenous Linear Dielectric $\chi_e$</td>
      <td>$\vec{\nabla} \times \vec{D} = 0$, $\vec{\nabla} \cdot \vec{D}= \rho_{free}$</td>
      <td>inside the homogenous linear dielectric, $\epsilon$ is constant</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\vec{D} = \epsilon_0 \vec{E}_{free}$</td>
      <td>$\vec{E}_{free}$ is field produced by free charges</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>because now $\vec{\nabla}\cdot \vec{D}= \rho_{free} \to \vec{D} = \frac{1}{4\pi } \int \frac{\rho_{free}}{\symscr{r}} \hat{\symscr{r}}\,d^3r’$ holds</td>
    </tr>
  </tbody>
</table>

<p><em>Application of Bound Charges</em></p>

<p>Consider a slab of dielectric with thickness $d$ carrying polarization $\vec{P} = k[1+(x/d)]\hat{x}$ :</p>

<p><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20220314163908686.png" alt="image-20220314163908686" /></p>

<p>we do not care yet what external field is needed to produce this polarization. We want to know the electric field <strong>produced by</strong> this given polarization.</p>

<p>First, we can find the bound charges to be:</p>

\[\sigma_b = \vec{P}\cdot \hat{n} = \begin{cases}
2k, &amp; x =d\\
-k, &amp; x=0
\end{cases}\\
\rho_b = -\nabla \cdot \vec{P} = -\frac{k}{d},\quad 0&lt;x&lt;d\]

<p>Then, we can <em>treat this as real charges</em> to compute $V(\vec{r})$ due to the correctness of:</p>

\[V(\vec{r}) = \frac{1}{4\pi \epsilon_0} \oint_\Omega \frac{\sigma_b}{||\vec{r} - \vec{r}'||}dA'+ \frac{1}{4\pi \epsilon_0} \int_V \frac{\rho_b}{||\vec{r} - \vec{r}'||}dV'\]

<p>Now, since we know the charge distribution, we can exploit the symmetry and save doing the above extra integrals:</p>

<ul>
  <li>
    <p>drawing Gaussian surfaces inside/outside the slab gives:</p>

\[\vec{E}_&lt; = \vec{E}_&gt;\\
(\vec{E}_{inside}-\vec{E}_{&lt;})\cdot \hat{x} = \frac{k}{\epsilon_0}\left(1+\frac{x}{d}\right)\]
  </li>
  <li>
    <p>but notice that the net charge is zero, hence:</p>

\[\vec{E}_&lt; = \vec{E}_&gt; = \vec{0}\\
\vec{E}_{inside} = -\frac{k}{\epsilon_0}\left( 1+ \frac{x}{d} \right)\]
  </li>
</ul>

<p>the result is consistent if you compute from $\vec{D}$ and use $\vec{D}=\epsilon \vec{E}_{tot}$.</p>

<hr />

<p><em>Treating $\sigma_b,\rho_b$ as real charges</em>:</p>

<p>Basically it works due to the proof that</p>

\[V(\vec{r}) = \frac{1}{4\pi \epsilon_0} \oint_\Omega \frac{\sigma_b}{||\vec{r} - \vec{r}'||}dA'+ \frac{1}{4\pi \epsilon_0} \int_V \frac{\rho_b}{||\vec{r} - \vec{r}'||}dV'\]

<p>Then, consider finding $V(r)$ for $r &lt; a$ in the setup below:</p>

<p><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20220314173419462.png" alt="image-20220314173419462" /></p>

<p>where $Q$ is a point charge sitting at origin. Then, we first can easily figure out $\vec{D}$ by:</p>

\[\int \vec{D}\cdot d\vec{S} = Q_{free_{enc}} = Q,\quad \text{true for all space}\]

<p>hence we get:</p>

\[\vec{D} = \frac{Q}{4 \pi r^2}\hat{r}\to \vec{E}_{tot} = \frac{Q}{4\pi \epsilon r^2}\hat{r}\]

<p>for $\epsilon$ <mark>actually changes in regions</mark>, so that:</p>

<ul>
  <li>$\epsilon=\epsilon_0$ in vacuum hence $r &lt; a$ or $r &gt; b$</li>
  <li>$\epsilon =\epsilon_r \epsilon_0$  inside dielectric</li>
</ul>

<p>Though we can proceed easily to find $V(\vec{r})$ now, but we can show that we obtain the same result if we <strong>treating $\sigma_b,\rho_b$ as real charges</strong>:</p>

<ul>
  <li>
    <p>to find $\sigma_b, \rho_b$, first we need to find $\vec{P}$:</p>

\[\vec{P} = \epsilon_0 \chi_e \vec{E}_{tot} = \frac{\epsilon_0 \chi_e  Q}{4\pi \epsilon r^2}\hat{r}\]
  </li>
  <li>
    <p>then find $\sigma_b, \rho_b$:</p>

\[\sigma_b =\vec{P}\cdot \hat{n} = \begin{cases}
-\frac{\epsilon_0 \chi_e  Q}{4\pi \epsilon a^2} , &amp; x =a\\
\frac{\epsilon_0 \chi_e  Q}{4\pi \epsilon b^2} , &amp; x =b
\end{cases}\\
\rho_b = -\nabla \cdot \vec{P} =0,\quad a&lt;x&lt;b\]
  </li>
</ul>

<p>Then we can consider $\vec{E}_{tot}$ from those charges while using symmetry:</p>

\[\begin{cases}
\vec{E}_{&lt;} = \frac{Q}{4 \pi \epsilon_0 r^2} \hat{r}, &amp; r &lt; a\\
\vec{E}_{inside} = \frac{Q+Q_b(a)}{4 \pi \epsilon_0 r^2} \hat{r}= \frac{Q}{4 \pi \epsilon_0(1+\chi_e) r^2} \hat{r}, &amp; a&lt;r &lt;b\\
\vec{E}_{&gt;} = \frac{Q}{4 \pi \epsilon_0 r^2} \hat{r}, &amp; r &gt; b
\end{cases}\]

<p>using $\oint \vec{E}\cdot d\vec{A} = Q_{enc}/\epsilon_0$, where:</p>

<ul>
  <li>$Q_b(a)$ is the bound charges at $r=a$, which is $4 \pi a^2 \sigma_b(a)$.</li>
  <li>this is consistent with $\vec{E}_{tot} = \frac{Q}{4\pi \epsilon r^2}\hat{r}$.</li>
</ul>

<p>Finally, finding $V(\vec{r})$ for $r &lt; a$ is just doing the integral:</p>

\[V(\vec{r}) = -\int_\infty^r \vec{E}\cdot d\vec{r} = -\int_\infty^b \vec{E}_&lt;\cdot d\vec{r}-\int_b^a \vec{E}_{inside}\cdot d\vec{r}-\int_a^r \vec{E}_&gt;\cdot d\vec{r}\]

<p>for $d\vec{r}=dr \hat{r}+ rd\theta \hat{\theta}$.</p>

<hr />

<p><strong>Magnetization</strong> in matter is <em>essentially the same</em> as polarization, but here due to <em>tiny current loops</em>:</p>

<table>
  <thead>
    <tr>
      <th>Condition/Name</th>
      <th>Equation</th>
      <th>Comments</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Magnetic Dipoles</td>
      <td>$\vec{m} = I \int d\vec{A}$</td>
      <td>magnetic dipole of a small current loop</td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230130142357629.png" alt="image-20230130142357629" style="zoom:33%;" /></td>
      <td>derived from multi-pole expansion of $\vec{A}$, and since the mono-pole term is zero, the first order term is dipole.</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>if you look into any material, electron orbit themselves/spinning = constitute <strong>tiny current loops = dipole</strong>. However, most material has “no magnetization” because those dipoles are randomly oriented</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>But when an external field $\vec{B}_{\mathrm{ext}}$ is supplied, you get some net orientations = net magnetization $\vec{M}$</td>
    </tr>
    <tr>
      <td>Magnetic Moment $\vec{M}(\vec{r})$</td>
      <td>$\vec{M}(\vec{r})\approx \sum \vec{m}$</td>
      <td>think of $\vec{M}$ as specifying a collection of tiny dipoles $\vec{m}$</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\vec{M}\equiv$ dipole moment per unit volume</td>
      <td>for continuous case</td>
    </tr>
    <tr>
      <td>$\vec{A}$ from $\vec{M}$</td>
      <td>$\vec{A}=\frac{\mu_0}{4\pi} \sum_{i} \frac{\vec{m}\times \hat{r}}{\vert \vec{r}-\vec{r}_i’\vert }$</td>
      <td>discrete case</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\vec{A}=\frac{\mu_0}{4\pi} \int \frac{\vec{M}\times \hat{r}}{\vert \vec{r}-\vec{r}’\vert }d^3r’$</td>
      <td>continuous case</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>note that $\hat{r}=\vec{r}/\vert \vec{r}\vert$</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\vec{A}_{dip} = \frac{\mu_0}{4\pi} \frac{\vec{m}\times \hat{r}}{\vert \vec{r}-\vec{r}’\vert }$</td>
      <td>derived because we know the field of a single dipole</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>Most generic form of finding $\vec{B}$ from given $\vec{M}$</td>
    </tr>
    <tr>
      <td>$\vec{A}$ from $\vec{M}$ using bound currents</td>
      <td>$\vec{A}=\frac{\mu_0}{4\pi} \int_{all} \frac{\vec{J}_{b}}{\vert \vec{r}-\vec{r}’\vert }d^3r’+\frac{\mu_0}{4\pi}\oint \frac{\vec{K}_b}{\vert \vec{r} - \vec{r}’\vert }dA’$</td>
      <td>mathematically same as above, derived from the continuous case</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\vec{J}<em>b \equiv \nabla \times \vec{M},\quad \vec{K}</em>{b} \equiv \vec{M}\times \hat{n}$</td>
      <td>for $\hat{n}$ points from the magnetized material to vacuum</td>
    </tr>
    <tr>
      <td>Physical Interpretation of Bound Charges</td>
      <td>$\vec{K}_b = \vec{M}\times \hat{n}$</td>
      <td>surface current = current on the surface of material = treat as normal current and compute $\vec{B}$</td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230130143248855.png" alt="image-20230130143248855" style="zoom: 33%;" /></td>
      <td>imagine uniform magnetized material = uniform tiny current loops</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>Hence inner loops cancel, we only have net outer current</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\vec{J}_b = \nabla \times \vec{M}$</td>
      <td>If non-uniform magnetized material, then net $\vec{J}_b$ comes from difference in current loops</td>
    </tr>
    <tr>
      <td>Auxiliary Field $\vec{H}$</td>
      <td> </td>
      <td>same motivation as $\vec{D}$, now in magnetism we have both contributions from $J_f$ and $J_b$</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\vec{H}=\frac{1}{\mu_0}\vec{B}-\vec{M}$</td>
      <td>more useful than $\vec{B}$ when we have magnetized material</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>$\vec{H}$ often in the <strong>same direction</strong> as $\vec{B}$ and $\vec{M}$</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>The magnetic parallel of $\vec{E}$ field. ($\vec{B}$ would be a parallel to $\vec{D}$ instead)</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\nabla \times \vec{B} = \mu_0 \vec{J}<em>{total} = \mu_0 (\vec{J}_b + \vec{J}</em>{free})$</td>
      <td>derivation from Ampere’s Law, then use $\vec{J}_b = \nabla \times \vec{M}$</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>true in general</td>
    </tr>
    <tr>
      <td>Differential and Integral form of $\vec{H}$</td>
      <td>$\nabla \times \vec{H} = \vec{J}_{free}$</td>
      <td>follows from the above</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\oint \vec{H}\cdot d\vec{l} =\int \vec{J}<em>{free} \cdot d\vec{A}=I</em>{free_{enc}}$</td>
      <td>very useful when we have symmetry</td>
    </tr>
    <tr>
      <td>Linear Material</td>
      <td>$\vec{M} \equiv \chi_m \vec{H}$</td>
      <td>$\vec{J}<em>{free} \to \vec{B}</em>{free}\to \vec{M}$ if material is magnetizable</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\vec{B}= \mu_0 (1+ \chi_m)\vec{H}=\mu \vec{H}$</td>
      <td>derived from $\vec{H}=\frac{1}{\mu_0}\vec{B}-\vec{M}$</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\mu = \mu_r \mu_0 \equiv \mu_0(1 + \chi_m)$</td>
      <td> </td>
    </tr>
  </tbody>
</table>

<p><em>Calculate $\vec{B}$ from Bound Currents</em></p>

<p>Suppose you are given a material with frozen in magnetization such that $\vec{M}=M\hat{e}_z$ inside the cylinder. The question is what is the magnetic field everywhere.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Setup</th>
      <th style="text-align: center">Setup with Bound Currents</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230130210609692.png" alt="image-20230130210609692" style="zoom: 67%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230130210622916.png" alt="image-20230130210622916" style="zoom:67%;" /></td>
    </tr>
  </tbody>
</table>

<p>We know we can get $\vec{B}$ either:</p>

<ul>
  <li>calculate $\vec{A}$ then do $\vec{B}=\nabla \times \vec{A}$. You wil see that we have many ways to find $\vec{A}$
    <ul>
      <li>if finite currents to integrate through, consider treating them as rotating charge = current loops $\vec{A}<em>{dip} = \int d\vec{A}</em>{dip}^{loop}$</li>
      <li>or compute $\vec{A}$ from the bound charges using the generic formula above (a lot of work)</li>
    </ul>
  </li>
  <li>calculate $\vec{B}$ directly by treating bound currents as currents (faster here)</li>
  <li>calculate using $\vec{H}$, and then convert back with $\vec{H}=\frac{1}{\mu_0}\vec{B}-\vec{M}$ (works, left to you as a mental exercise)
    <ul>
      <li>furthermore, if $\vec{J}_b=0$ and $\nabla \cdot \vec{M}=0$, then can use $\vec{H}=-\nabla W$ and solve laplacian</li>
    </ul>
  </li>
</ul>

<p>We first compute the bound currents and notice that:</p>

\[\begin{align*}
\vec{J}_b &amp;= \nabla \times \vec{M} = \vec{0}\\
\vec{K}_b &amp;= \vec{M}(\vec{r})|_{surf}\times \hat{n} = \begin{cases}
0, &amp; \text{at top/bottom with }\hat{n} = \hat{e}_z\\
M\hat{e}_\phi &amp; \text{at sides with }\hat{n} = \hat{e}_r
\end{cases}
\end{align*}\]

<p>With this we have the graph on the right, for currents going around the cylinder. In this case, we know that $\vec{B}=B_z\hat{e}_z$, which makes the computation straightforward.</p>

<p>Then we can easily compute $\vec{B}$ given this current by drawing ampere loop:</p>

\[\oint \vec{B}\cdot d\vec{l} = \mu_0 I_{enc}\]

<p>Knowing that $\vec{B}_{outer}=\vec{0}$ from a solenoid, we have:</p>

\[B_z(r)L - 0 = \mu_0 L K_b = \mu_0LM\]

<p>Hence we obtain</p>

\[\vec{B}(\vec{r}) = \begin{cases}
\mu_0 M \hat{e}_z, &amp; r &lt; a\\
0, &amp; r &gt; a
\end{cases}\]

<p>which makes sense by right hand rule.</p>

<hr />

<p><em>Calculate field using $\vec{H}$ from given $\vec{M}$</em>:</p>

<p>Consider given that $\vec{M} = kr^2 \hat{e}_{\phi}$ inside a cylinder</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Setup</th>
      <th style="text-align: center">Ampere Loop</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230130211413434.png" alt="image-20230130211413434" style="zoom:67%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230130211426797.png" alt="image-20230130211426797" style="zoom: 67%;" /></td>
    </tr>
  </tbody>
</table>

<p>Then we first know that the field $\vec{B},\vec{H}$ would therefore also be in $\hat{e}_{\phi}$ direction (do not confuse $\vec{M}$ with bound currents here). Hence drawing a Ampere loop inside:</p>

\[\oint \vec{H}\cdot d\vec{l} = 2\pi r H_\phi(r)= I_{free_{enc}} = 0\]

<p>Hence we easily get $\vec{H}=0$ everywhere. Finally using $\vec{H}=\frac{1}{\mu_0}\vec{B}-\vec{M}$ we get back $\vec{B}$ field by:</p>

\[\vec{B} = \begin{cases}
\mu_0 kr^2 \hat{e}_\phi, &amp; r &lt; a\\
0, &amp; r &gt; a
\end{cases}\]

<p>since we know $\vec{M}$ as they are given.</p>

<ul>
  <li>an exercise of this would be to compute using bound currents and arrive at the same solution here.</li>
</ul>

<hr />

<p><em>When to use $\vec{H}$</em></p>

<p>In general, we can do ampere loops with $\vec{B}$ if we are sure we know all contributions (e.g. from current and from $\vec{M}<em>{induced}$). But consider the case where you have a <strong>magnetizable cylinder</strong> with some external currents $\vec{J}</em>{free} = I/(\pi R^2)\hat{e}_z$ following through</p>

<p><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20220503013832964.png" alt="image-20220503013832964" style="zoom:67%;" /></p>

<p>The finding $\vec{B}$ naively using the loop above would give wrong result:</p>

\[2\pi B_\phi(r) = \mu_0 I \pi \left( \frac{r}{R}\right)^2\]

<p>but then you have ignored $\vec{M}_{induced}$ which could cause other components in $\vec{B}$. Therefore, the correct way is to consider $\vec{H}$:</p>

\[2\pi H_\phi(r) = I \pi \left( \frac{r}{R}\right)^2\]

<p>then using $\vec{H}=\frac{1}{\mu_0}\vec{B}-\vec{M}$ we get $\vec{B}$ (assuming $\vec{M}$ is linear)</p>

<h1 id="chapter-7-electrodynamics">Chapter 7 Electrodynamics</h1>

<table>
  <thead>
    <tr>
      <th>Condition/Name</th>
      <th>Equation</th>
      <th>Comments</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Ohm’s Law</td>
      <td>$\vec{J}=\sigma \vec{E} = nq\vec{v}$</td>
      <td>when you here you have a conductor, this applies</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\vec{J}=\sigma \vec{f}=\sigma(\vec{E}+\vec{v}\times \vec{B})$</td>
      <td>how the above comes about = charges move given the force $\gets$ $\vec{B}$ is generally ignored</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>consistent with perfect conductor $\vec{E}_{meat}=0$, which refers to steady state position</td>
    </tr>
    <tr>
      <td>Mean free path $\lambda$</td>
      <td>$\bar{v} = \frac{1}{2}at = {a \lambda}/{2v_{thermo}}$</td>
      <td>why is current $\propto \vec{E}$ consistent with $\vec{F}=m\vec{a}\propto \vec{E}$? Because electrons zig-zags in material</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>hence what mattered is their average velocity $\propto \vec{E}$</td>
    </tr>
    <tr>
      <td>Resistance (easy)</td>
      <td>$R=\frac{l}{A\sigma}=\rho\frac{l}{A}$</td>
      <td> </td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230301002643207.png" alt="image-20230301002643207" style="zoom:33%;" /></td>
      <td>derived from $\vec{J}=I/A=\sigma \vec{E}$ in wire, then since $\vec{E}l=V$, you get $I(A/l)=\sigma V$</td>
    </tr>
    <tr>
      <td>EMF</td>
      <td>$\varepsilon = \oint {\vec{F}_{source}}/{q}\cdot dl$</td>
      <td> </td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230301003229532.png" alt="image-20230301003229532" style="zoom:33%;" /></td>
      <td>fundamentally comes from why current is uniform: there are two forces acting on the electrons: $F_{total}=F_{ext}+ qE$</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>then if we consider the <em>net effect over the entire loop</em> $\oint \vec{E}\cdot d\vec{l}=0$</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>an example of $F_{ext}$ could be battery providing chemical power/”force”</td>
    </tr>
    <tr>
      <td>Motional EMF</td>
      <td>$\varepsilon = -d\Phi / dt$</td>
      <td>insight from below. Same physics as Lorentz force</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\varepsilon = \oint (qvB/q) \ dl=vBl$</td>
      <td>because magnetic force $q\vec{v}\times \vec{B}$ contributes to $F_{total}$, but integral over a loop is non-zero</td>
    </tr>
    <tr>
      <td>Induced Electric Field/Faraday’s Law</td>
      <td>$\nabla \times \vec{E} = -\partial \vec{B} / dt$</td>
      <td> </td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230301004446864.png" alt="image-20230301004446864" /></td>
      <td>all three methods create moving charges = current, but only the first one is due to magnetic force (Lorentz)</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>In the second and third, charges are static but we know they still moved $\gets$ there is an <em>induced electric field</em></td>
    </tr>
    <tr>
      <td> </td>
      <td>$-d\Phi /dt = \oint \vec{E}\cdot d\vec{l}=\varepsilon$ (by definition)</td>
      <td>changing magnetic field <em>induce electric field $\vec{E}$</em></td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>from this $\varepsilon$ you can find the induced current</td>
    </tr>
    <tr>
      <td>Lenz’ Law</td>
      <td>nature abhors change in flux</td>
      <td>used to determine the direction of induced current from Faraday’s law</td>
    </tr>
    <tr>
      <td>Mutual Inductance</td>
      <td>$\Phi_1 = M_{12}I_2$</td>
      <td>$M_{12}$ would be the coefficient for the $\vec{B}_{21}$ field produced (from 2 on 1) as a function of $I_2$</td>
    </tr>
    <tr>
      <td> </td>
      <td>$M_{12}=M_{21}$</td>
      <td>purely geometric, <mark>independent of current</mark></td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230301010355036.png" alt="image-20230301010355036" style="zoom:33%;" /></td>
      <td>an example would be realizing $\Phi_1$ for the inner loop is just some geometric factor $\times I_2$. (recall that $B=\mu_0 n I$ for solenoid)</td>
    </tr>
    <tr>
      <td>Self Inductance</td>
      <td>$\Phi = LI$</td>
      <td>because its own current creates magnetic field</td>
    </tr>
    <tr>
      <td>Inductance</td>
      <td>$\Phi_1 = L_1 I_1 +M_{12}I_2$</td>
      <td>but in general we assume $I_2 » I_1$</td>
    </tr>
    <tr>
      <td>Back EMF</td>
      <td>$\varepsilon_{back} = -L dI/dt$</td>
      <td>derived from $\Phi=LI$</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>therefore, $L$ is like <mark>inertia mass</mark>: the higher it is, harder for current to move/start moving</td>
    </tr>
    <tr>
      <td>Energy in circuit with $L$</td>
      <td>$U=(1/2)L I^2$</td>
      <td>derived from $W_q = -\varepsilon_{back}q$ which is the work done needed to push charges one loop when I tuned on the circuit</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>then take $/dt$ on both sides, and integrate get $\int dU = L \int IdI$</td>
    </tr>
    <tr>
      <td>Energy stored in magnetic field</td>
      <td>$U_B = (1/2\mu) \int_{\text{all space}} \vert B\vert ^2 dV$</td>
      <td>derived from the above, and using $LI = \Phi =  \int \vec{B}\cdot d\vec{A}$</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>consistent with the above. Hence can also be used to find $L$.</td>
    </tr>
    <tr>
      <td>Maxwell’s Equation</td>
      <td><mark>replacing the below</mark> to have $\nabla \times \vec{B}=\mu_0 \vec{J} +\mu_0 \epsilon_0 \frac{\partial \vec{E}}{\partial t}$</td>
      <td> </td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230301013726090.png" alt="image-20230301013726090" /></td>
      <td>realizing this form before is inconsistent if you test $\nabla \cdot (\nabla \times \vec{B})$ in case of <em>electrodynamics</em>, i.e. $d\rho /dt \neq 0$</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>now, this means changing $\vec{B}$ will change $\vec{E}$, and <strong>also vice versa</strong></td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>essentially, these equations tells you how <mark>charges/currents produce fields</mark>.</td>
    </tr>
    <tr>
      <td>Change in polarization $\vec{P}$ cause new current</td>
      <td>$\frac{\partial \vec{P}}{dt}=\vec{J}_p$</td>
      <td> </td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230301112055421.png" alt="image-20230301112055421" style="zoom: 50%;" /></td>
      <td>if $\vec{P}$ increased, then it means we also have changed $\sigma_b$: $dI = \frac{\partial \sigma_b}{dt}dA$</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>since $\sigma_b = \vec{P}\cdot \hat{n}$, we get $dI/da = \partial \vec{P}/dt$</td>
    </tr>
    <tr>
      <td>Current and Charge in material</td>
      <td>$\rho_{total} = \rho_{free} + \rho_b = \rho_{free} - \nabla\cdot\vec{P}$</td>
      <td>since we can only control free charge, we want to express field <em>only as a function of free charge</em></td>
    </tr>
    <tr>
      <td> </td>
      <td>$\vec{J}<em>{total} = \vec{J}</em>{free} + \vec{J}<em>b + \vec{J}_p = \vec{J}</em>{free}+\nabla\times \vec{M} + \frac{\partial \vec{P}}{\partial t}$</td>
      <td>then we just plug those in Maxwell’s equation, which holds for $\vec{E}<em>{total}$ and $\vec{B}</em>{total}$</td>
    </tr>
    <tr>
      <td>Maxwell’s Equation in <strong>Material</strong></td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230301112719153.png" alt="image-20230301112719153" /></td>
      <td>why is there a difference? Inside material we need to also consider effect from polarization $\vec{P}$ and magnetization $\vec{M}$</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>$\vec{D}=\epsilon_0\vec{E}+\vec{P}$<br />$\vec{H}=\frac{1}{\mu_0}\vec{B}-\vec{M}$</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>compared to the one in vacuum, there is an <em>extra</em> term $\partial D / \partial t\equiv \vec{J}_D$ named to be displacement current</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>e.g. inside a <strong>conducting material</strong>, you will have $\vec{J}_{f}=\sigma\vec{E}$ free charges moving and another $\vec{J}_D=\partial \vec{D}/dt$ if there is a change in field.</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>summarizes the fields to <em>include contribution from polarization and magnetization</em>, but as a function of <em>free charges and current</em></td>
    </tr>
    <tr>
      <td>linear material</td>
      <td>$\vec{D}=\epsilon \vec{E}$; $\vec{H} = \frac{1}{\mu}\vec{B}$</td>
      <td>often used to simplify Maxwell’s equations in material to get only E and B</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>if you insert this into Maxwell’s equation in material and use $\mu \to \mu_0, \epsilon\to \epsilon_0$, you <mark>get back the equation in vaccum</mark>!</td>
    </tr>
    <tr>
      <td>Integral form of Maxwell’s Equations</td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230304000201785.png" alt="image-20230304000201785" /></td>
      <td>can be used to calculate fields</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>also for later chapters, essentially determines the <strong>boundary conditions</strong> when solving equations</td>
    </tr>
    <tr>
      <td>Boundary Conditions</td>
      <td>$D^\perp_1 - D^\perp_2 = \sigma_{free}$<br />$B^\perp_1 - B^\perp_2 = 0$</td>
      <td>derived using the geometry below</td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230304000717046.png" alt="image-20230304000717046" style="zoom:33%;" /></td>
      <td> </td>
    </tr>
    <tr>
      <td> </td>
      <td>$\vec{E}^\parallel_1 - \vec{E}^\parallel_2 = 0$<br />$\vec{H}^\parallel_1 - \vec{H}^\parallel_2 = \vec{K}_{free}\times \hat{n}$</td>
      <td>derived using the geometry below.</td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230304000742426.png" alt="image-20230304000742426" style="zoom: 33%;" /></td>
      <td>$\vec{K}<em>{free}$ comes from the possibility $I</em>{f_{enc}}\neq0$, and $\times \hat{n}$ is due to the direction requirement that $I_{f_{enc}} = \vec{K}_f \cdot (\hat{n}\times \vec{l})=(\vec{K}_f \times \hat{n})\cdot \vec{l}$</td>
    </tr>
    <tr>
      <td>Boundary Conditions for Linear Media</td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230304001455829.png" alt="image-20230304001455829" /></td>
      <td>simply when $\vec{D}=\epsilon \vec{E}$; $\vec{H} = \frac{1}{\mu}\vec{B}$</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>used quite often as we almost always have a linear media and this form is <strong>only in $\vec{E}$ and $\vec{B}$</strong></td>
    </tr>
  </tbody>
</table>

<p><em>Connection between electrostatics, magnetostatics, induced field:</em></p>

<table>
  <thead>
    <tr>
      <th>Electrostatics</th>
      <th>Magnetostatics</th>
      <th>Faraday’s Induced E field</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>$\nabla \cdot \vec{E}=0$</td>
      <td>$\nabla \cdot \vec{B}=0$</td>
      <td>$\nabla \cdot \vec{E}=0$</td>
    </tr>
    <tr>
      <td>$\nabla \times \vec{E}=0$</td>
      <td>$\nabla \times \vec{B}=\mu_0 \vec{J}$</td>
      <td>$\nabla \times \vec{E} = -\partial \vec{B} / dt$</td>
    </tr>
    <tr>
      <td>$\oint \vec{E}\cdot d\vec{l}=0$</td>
      <td>$\oint \vec{B}\cdot d\vec{l}=\mu_{0} I_{enc}$</td>
      <td>$\oint \vec{E}\cdot d\vec{l}=-d\Phi / dt$</td>
    </tr>
  </tbody>
</table>

<hr />

<p><em>Transformer</em> and using Inductance.</p>

<p><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230301011348391.png" alt="image-20230301011348391" style="zoom:33%;" /></p>

<p>Consider the task is to find out (a) show that $V_1/V_2 = N_1/N_2$, (b) that $M^2=L_1L_2$, and (c) the differential equation to solve for $I_1(t),I_2(t)$</p>

<ul>
  <li>
    <p>let the magnetic flux for a single turn be $\Phi_0 = \vert \vec{B}\vert A$. Then we get</p>

\[\varepsilon_1 = N_1 \frac{d\Phi_0}{dt},\quad \varepsilon_2 = N_2 \frac{d\Phi_0}{dt}\]

    <p>then just divide</p>
  </li>
  <li>
    <p>We know that also</p>

\[\Phi_1 = L_1I_1 + M_{12}I_2 = N_1 \Phi_0\\
\Phi_2 = L_2I_2 + M_{21}I_1 = N_2 \Phi_0\]

    <p>then eliminating $\Phi_0$, and find</p>

\[\frac{L_1}{N_1}I_1 + \frac{M_{12}}{N_1}I_2 = \frac{L_2}{N_2}I_1 + \frac{M_{21}}{N_2}I_1\]

    <p>but <mark>as $M$ is purely geometric</mark>, this should hold even if $I_1=0$ and when $I_2=0$. From which you can show that $M_{12}M_{21}=L_1L_2$</p>
  </li>
  <li>
    <p>Let there be an external power giving $V_1\cos(\omega t)$ at $\varepsilon_1$. Then for this to hold, we must have:</p>

\[\varepsilon_1 = -\frac{d\Phi_1}{dt} = -(L_1\dot{I_1} + M_{12}\dot{I}_2) = -V_1 \cos(\omega t)\]

    <p>so basically ODE with $dI/dt$ but coupled</p>
  </li>
</ul>

<hr />

<p><em>How do you find inductance $L$</em>?</p>

<p>One trick is to realize that</p>

\[\Phi = LI = \int \vec{B}\cdot d\vec{A}\]

<p>then you just need to massage the RHS to have $(\text{something})\cdot I$.</p>

<p>Another trick is to use energy. Since energy stored of the circuit = energy of the fields, e.g. for a solenoid</p>

\[U = \frac{1}{2\mu_0}\int |B|^2 dV = \frac{1}{2}LI^2\]

<p>and there are no electric fields as wires are charge neutral.</p>

<hr />

<p><em>Using Maxwell’s Fix on Ampere’s Law</em></p>

<p>Consider finding $\int BdA$ given this Amperian loop.</p>

<p><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230301110149680.png" alt="image-20230301110149680" style="zoom: 50%;" /></p>

<p>From $\nabla \times \vec{B}=\mu_0 \vec{J} +\mu_0 \epsilon_0 \frac{\partial \vec{E}}{\partial t}$, this means</p>

<ol>
  <li>
    <p>using the circular disk are:</p>

\[\oint \vec{B}\cdot d\vec{l} = \mu_0 I_{enc} = \mu_0 I\]
  </li>
  <li>
    <p>if we use the version $\nabla \times \vec{B}=\mu_0 \vec{J}$, then we will get $0$. But:</p>

\[\oint \vec{B}\cdot d\vec{l} = \mu_0 I_{enc} + \mu_0 \epsilon_0 \int_S \frac{\partial \vec{E}}{\partial t}\cdot d\vec{A}\]

    <p>since there is no $I_{enc}=0$, but the electric field within the gap is changing as $\vec{E}(t)=\sigma(t)/\epsilon_0$:</p>

\[\oint \vec{B}\cdot d\vec{l} = \mu_0 \epsilon_0 \int_S \frac{\partial }{\partial t}\frac{Q(t)}{\epsilon_0 A}\cdot d\vec{A}\]

    <p>since $dQ/dt=I$, we recover the same expression as 1.</p>
  </li>
</ol>

<h1 id="chapter-8-conservation-laws">Chapter 8 Conservation Laws</h1>

<p>Basically <strong>how we get energy and momentum from fields themselves</strong> = found that in order for conservation of energy/momentum to work, <em>we need to attach energy and momentum to fields</em>. How do we know things <em>are conserved</em>?</p>

<ul>
  <li>if energy $U$ is conserved, then $dU/dt=0$</li>
  <li>if momentum $\vec{p}$ is conserved, then $d\vec{p}/dt = 0$</li>
</ul>

<table>
  <thead>
    <tr>
      <th>Condition/Name</th>
      <th>Equation</th>
      <th>Comments</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Work Energy Theorem in Electrodynamics</td>
      <td>$\frac{dW}{dt}=-\frac{\partial}{\partial t}\int_{V}\underbrace{\left[ \frac{1}{2}\epsilon_0 E^2 + \frac{1}{2\mu_0}B^2\right]}<em>{u</em>{EM}}dV - \int_{\partial V}\underbrace{\frac{1}{\mu_0}(\vec{E}\times \vec{B})}_{\vec{S}}\cdot d\vec{a}$</td>
      <td>$dW$ here represent work done <strong>by EM field</strong> on <strong>charges</strong> in a volume $V$</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>fundamentally, think about how to make charges move = $F=q(\vec{E}+\vec{v}\times \vec{B})$, when find $dW/dt$ in terms of fields.</td>
    </tr>
    <tr>
      <td> </td>
      <td>$u_{EM} = \frac{1}{2}(\epsilon_0 E^2 + \frac{1}{\mu_0}B^2)$</td>
      <td>$u_{EM}$ represent energy stored in the field in $V$</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>$\vec{S}$ represent energy per unit area per time = energy flux going <strong>out</strong> of $V$ since $d\vec{a}$ points out</td>
    </tr>
    <tr>
      <td> </td>
      <td>$dW = \vec{F}\cdot d\vec{r} =q\vec{E}\cdot{\vec{v}}dt$, then $dW/dt = \int \vec{J}\cdot \vec{E}dV$ for a density of current</td>
      <td>derivation</td>
    </tr>
    <tr>
      <td>Poynting Vector</td>
      <td>$\vec{S}=\frac{1}{\mu_0}\vec{E}\times \vec{B}$</td>
      <td>energy flux, and also the <strong>direction of energy flowing</strong></td>
    </tr>
    <tr>
      <td> </td>
      <td>$\frac{\partial }{\partial t}\int_V u dV = - \int_{\partial V}{\frac{1}{\mu_0}(\vec{E}\times \vec{B})}\cdot d\vec{a}$</td>
      <td>why? Consider energy is conserved, $dW/dt=0$. Then if LHS decreases, energy is flowing <strong>out</strong> and $\vec{S}$ is positive if $\vec{S}$ also points out</td>
    </tr>
    <tr>
      <td>Need for Maxwell’s Stress Tensor</td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230304014504261.png" alt="image-20230304014504261" style="zoom:33%;" /></td>
      <td>Consider the instantaneous fields produced causing those forces. Note that net force $\neq 0$</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>so momentum is <em>naively not conserved</em> (need to take the fields into account)</td>
    </tr>
    <tr>
      <td>Property of 2D Tensor</td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230304020412812.png" alt="image-20230304020412812" style="zoom:33%;" /></td>
      <td>one way to visualize $\overleftrightarrow{T}$</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\vec{v}=\begin{bmatrix} v^1\v^2\v^3 \end{bmatrix}=v^i$</td>
      <td>upper index is like a vector component (e.g. $\vec{r} = \begin{bmatrix} x\y\z \end{bmatrix}$)</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>in our use, upper index often represents <strong>coordinate</strong></td>
    </tr>
    <tr>
      <td> </td>
      <td>$w_i = [w_1, w_2, w_3]$</td>
      <td>lower index usually row vector, or for convenience</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>in our use, lower index often represents <strong>derivative of a coordinate</strong></td>
    </tr>
    <tr>
      <td>Einstein’s Summation Notation</td>
      <td>sum over repeated index</td>
      <td> </td>
    </tr>
    <tr>
      <td> </td>
      <td>$\left( \vec{a} \cdot \overleftrightarrow{T} \right)<em>j = \sum</em>{i}a_i T_{ij}$ = a vector</td>
      <td>basically we want the $j$-th vector after this dot product.</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>in the above visualization, $\vec{a}$ dots into $\overleftrightarrow{T}$ vertically</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\nabla \cdot \vec{T}^x = \partial_j T^{xj}$</td>
      <td>an example, so $\vec{T}^x$ is the horizontal vector</td>
    </tr>
    <tr>
      <td>Maxwell’s Stress Tensor</td>
      <td>$T^{ij}=\epsilon_0(E^iE^j - \frac{1}{2}\delta_{ij}E^2)+\frac{1}{\mu_0}(B^iB^j - \frac{1}{2}\delta_{ij}B^2)$</td>
      <td>so $T$ is a 2D tensor (matrix)</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\vec{F}_{\text{EM on charges}} = \oint \overleftrightarrow{T}\cdot d\vec{a} - \mu_0 \epsilon_0 \frac{d}{dt}\int_V \vec{S}dV$</td>
      <td>explains why we need the stress tensor</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>in my practice, even though this is used more often then the differential form, it is <mark>better to start your thinking with the differential form</mark></td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230304015205849.png" alt="image-20230304015205849" style="zoom:33%;" /></td>
      <td>derived from considering <strong>force acting on charges</strong> due to EM fields, so $\vec{F}=q(\vec{E}+ \vec{v}\times \vec{B})=\int_V (\rho \vec{E}+\vec{J}\times \vec{B})dV$</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>$T_{ij}$ represents force acting in the i-th direction on surface oriented in $j$</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\vec{F}_{EM}=\oint \overleftrightarrow{T}\cdot d\vec{a}$</td>
      <td>why? if there is no change in fields $d\vec{S}/dt =0$. Then we have this</td>
    </tr>
    <tr>
      <td>Momentum of Fields (and conservation)</td>
      <td>$\frac{d}{dt}\vec{P}<em>{\text{mechanical}} = - \frac{d}{dt}\int_V \underbrace{\epsilon_0\mu_0\vec{S}}</em>{\vec{g}<em>{EM}}dV + \oint_S \underbrace{\overleftrightarrow{T}}</em>{\text{momentum flux}}\cdot d\vec{a}$</td>
      <td>re-written the same force formula from Maxwell’s Stress Tensor</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\frac{d\vec{g}<em>{mech}}{\partial t}=\vec{f}</em>{mech} = \nabla \cdot \overleftrightarrow{T} - \frac{\partial \vec{g}_{EM}}{\partial t}$</td>
      <td>differential form of the above</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\frac{d\vec{g}<em>{mech}^i}{\partial t}=\vec{f}</em>{mech}^i = \partial_jT^{ij} - \frac{\partial \vec{g}_{EM}^i}{\partial t}$</td>
      <td>equation for each component (e.g $i=x,y,z$)</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>the integral form is used more in practice, but this may be easier to remember and better to start with</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\frac{d}{dt}\int_V {\epsilon_0\mu_0\vec{S}}dV = \oint_S {\overleftrightarrow{T}}\cdot d\vec{a}$</td>
      <td>how do you interpret this? When there is no change in momentum of charges:</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\vec{g}_{EM} = \mu_0 \epsilon_0 \vec{S}$</td>
      <td>therefore $\overleftrightarrow{T}$ represents momentum flux <strong>passing through</strong> an area; then naturally $\epsilon_0\mu_0\vec{S}$ is the <strong>momentum density inside</strong> volume $V$</td>
    </tr>
    <tr>
      <td>Angular momentum of Fields</td>
      <td>$\vec{l}<em>{EM} = \vec{r}\times \vec{g}</em>{EM}$</td>
      <td>since it has momentum, the the laws apply</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\vec{L}_{EM} = \int_V \vec{l}dV$</td>
      <td>integral form, angular momentum in a volume</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>questions on this usually involve some charged body <em>starts spinning</em> after there is a change in E or B field (e.g. switched off). This can be explained using the $\vec{l}_{EM}$ in fields</td>
    </tr>
  </tbody>
</table>

<p><em>Example using Poynting Vector</em></p>

<p>Consider a current flowing down a wire. What is the power in this wire using Poynting vector? Hint: $P=$energy per unit time delivered</p>

<p><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230304013033237.png" alt="image-20230304013033237" style="zoom:33%;" /></p>

<p>Well, if we know the $\vec{E}$ and $\vec{B}$ field <em>just on the boundary</em>, then</p>

\[\int \vec{S}\cdot d\vec{a} = \text{energy flowing out of }\mathcal{V}\]

<p>since since we know $\vec{E}=V/L$, $\vec{B}<em>{surf} = \mu_oI / 2\pi a \,\, \hat{r}</em>\phi$, we get:</p>

\[\vec{S}_{surf} = \frac{VI}{L 2\pi a}\ \text{inwards}\]

<p>therefore, energy flows inwards, with power:</p>

\[P = \int Sda = \frac{VI}{L2\pi a}2\pi a L = VI\]

<hr />

<p><em>A summary of work-energy and momentum equations</em></p>

<p>Perhaps the differential form is easier to remember:</p>

\[\begin{align*}
\text{work-energy conservation}\qquad &amp;\frac{dw_{mech}}{dt} = -\nabla \cdot \vec{S} - \frac{\partial u_{EM}}{dt}\\
\text{momentum conservation}\qquad &amp; \frac{dg_{mech}^x}{\partial t} = \nabla \cdot \overleftrightarrow{T}^x - \frac{\partial g_{em}^x}{dt}\\
&amp; \frac{dg_{mech}^y}{\partial t} = \nabla \cdot \overleftrightarrow{T}^y - \frac{\partial g_{em}^y}{dt}\\
&amp; \frac{dg_{mech}^z}{\partial t} = \nabla \cdot \overleftrightarrow{T}^z - \frac{\partial g_{em}^z}{dt}\\
\text{charge conservation}\qquad &amp;0 = \nabla \cdot \vec{J} + \frac{\partial \rho}{\partial t}
\end{align*}\]

<p>where note that</p>

<ul>
  <li>$w_{mech}$ is the work density, i.e. $W_{mech}=\int w_{mech}dV$</li>
  <li>each equation above <strong>returns a scalar</strong></li>
  <li>$\overleftrightarrow{T}^x$ would represent the first <strong>row</strong> of the stress tensor, so that $\nabla \cdot \overleftrightarrow{T}^x = \partial_i T^{xi}$</li>
</ul>

<blockquote>
  <p>The take away message here is that <strong>field itself has momentum and energy $u_{EM}$ and $g_{EM}$</strong></p>
</blockquote>

<hr />

<p><em>Example of using Stress Tensor</em>: Calculate the <strong>force</strong> acting on the upper hemisphere of a uniformly charged sphere:</p>

<p><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230304151816115.png" alt="image-20230304151816115" style="zoom:50%;" /></p>

<p>Well, since this is about force, we can consider</p>

\[\vec{F}_{\text{EM on charges}} = \oint \overleftrightarrow{T}\cdot d\vec{a} - \mu_0 \epsilon_0 \frac{d}{dt}\int_V \vec{S}dV\]

<p>then this means the closed surface is bowl + disk. First since there is no time dependence, and since we know the net force <em>will be in $\hat{z}$</em>:</p>

\[\vec{F}_{\text{EM on charges}} = \oint \overleftrightarrow{T}\cdot d\vec{a} \quad\to\quad  {F}_{z} = \oint \overleftrightarrow{T}^z\cdot d\vec{a} = \oint T^{zi} da_i\]

<ul>
  <li>
    <p>force on bowl: the area vector is in spherical coordinate</p>

\[d\vec{a} = R^2 \sin(\theta)d\theta d\phi\ \hat{e}_r\]

    <p>and using the formula for $T^{ij}$:</p>

\[T^{ij}=\epsilon_0(E^iE^j - \frac{1}{2}\delta_{ij}E^2)+\frac{1}{\mu_0}(B^iB^j - \frac{1}{2}\delta_{ij}B^2)\]

    <p>since $B=0$, and you know that $\vec{E}$ on the surface is, again in spherical coordinate:</p>

\[\vec{E} = \frac{1}{4\pi \epsilon_0}\frac{Q}{R^2}\ \hat{e}_r,\quad \hat{e}_r=\sin\theta \cos\phi\hat{e}_x + \sin\theta \sin\phi\hat{e}_y + \cos\theta\hat{e}_z\]

    <p>then compute:</p>

\[T^{zi}da_i = T^{zx}da_x + T^{zy}da_y + T^{zz}da_z\]

    <p>and do the integral</p>
  </li>
  <li>
    <p>repeat for the disk, using the fact that field inside should go, in polar coordinate:</p>

\[\vec{E}_{disk}=\frac{1}{4\pi \epsilon_0}\frac{Qr}{R^3}\hat{r}\]

    <p>and</p>

\[d\vec{a} = -r drd\phi \hat{z}\]
  </li>
</ul>

<p>but you will see a trick if you <strong>start thinking with</strong> the local form</p>

\[\vec{f}_{mech} = \nabla \cdot \overleftrightarrow{T} - \frac{\partial \vec{g}_{EM}}{\partial t}\]

<p>so that, since <strong>outside the sphere there is no charge</strong>, $\vec{f}_{mech}=0$. Hence we can consider <strong>integrating over a different surface</strong></p>

<p><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230304153829185.png" alt="image-20230304153829185" style="zoom:33%;" /></p>

<p>where if we stretch this to be very big, $E\to 0$ at the bowl. Hence we <strong>only have the horizontal disk component to integrate</strong></p>

<ul>
  <li>
    <p>force on the outer disk (not touching the charge): in the radial direction</p>

\[\vec{E}_{outer} =\frac{1}{4\pi \epsilon_0}\frac{Q}{r^2}\hat{r}\]

    <p>with area for $F_z$</p>

\[d\vec{a} = -r drd\phi \hat{z}\]

    <p>this is much easier then to compute and integrate</p>

\[T^{zi}da_i = T^{zx}da_x + T^{zy}da_y + T^{zz}da_z = T^{zz}da_z\]
  </li>
  <li>
    <p>repeat for the inner disk, which is the same as our previous method</p>
  </li>
</ul>

<hr />

<p><em>Example of Conservation of Angular Momentum</em> (see example 8.4 on textbook) consider a very long solenoid with $n$ turns per length, and inside/outside of it are two cylindrical shell of length $l$ with radius $a,b$, charged with $Q,-Q$ respectively. When $I$ in the solenoid is <strong>switched off</strong> $I \to 0$, the two cylinders will start to <strong>spin</strong>. Physically why did this happen? Is angular momentum conserved?</p>

<p><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230304155019677.png" alt="image-20230304155019677" style="zoom:33%;" /></p>

<p>The key mechanism is that there is a <em>change</em> in $B$ field as a result of switching off. Hence:</p>

<ul>
  <li>
    <p><strong>mechanism</strong>: there is a change in $B$, hence we get an induced electric field which would act on the charges</p>

\[\nabla \times \vec{E} = -\frac{\partial \vec{B}}{\partial t} \quad \to \quad \oint \vec{E}\cdot d\vec{l} = -\frac{\partial }{\partial t}\int \vec{B}\cdot  d\vec{A}\]

    <p>and since the current is changing, you will get something like:</p>

\[\vec{E}_{s&gt;R} = - \frac{1}{2}\mu_0n\frac{dI}{dt} \frac{R^2}{s}\ \hat{e}_\phi\\
\vec{E}_{s&lt;R} = - \frac{1}{2}\mu_0n\frac{dI}{dt} s\ \hat{e}_\phi\]

    <p>notice that this field is in the $\phi$ direction, hence the two charged cylinder will feel a torque</p>

\[\vec{N}_b = \vec{r}\times (-Q\vec{E})= \frac{1}{2}\mu_0n QR^2 \frac{dI}{dt} \ \hat{e}_z\]

    <p>then the angular momentum it has at the end is therefore, using $\vec{N}=d\vec{L}/dt$</p>

\[\vec{L}_{final}-0 = \int_0^t \frac{1}{2}\mu_0n QR^2 \frac{dI}{dt} dt\]

    <p>then do the same for $\vec{N}_a$ of the smaller cylinder.</p>
  </li>
  <li>
    <p><strong>conservation of angular momentum</strong>: you will see from above that $\vec{L}_a + \vec{L}_b$ in the end is not zero. So in the beginning there must be something that is spinning, the field:</p>

\[\vec{l}_{EM} = \vec{r}\times \vec{g}_{EM}\]

    <p>since the fields in the beginning is:</p>

\[\vec{E} = \frac{Q}{2\pi \epsilon_0 l} \frac{1}{s}, \quad a &lt; s &lt; b \\
\vec{B} = \mu_0 n I\ \hat{e}_z,\quad s&lt;R\]

    <p>therefore $\vec{g}_{EM}$ is only non-zero inside the solenoid $s &lt; R$. Hence</p>

\[\vec{g}_{EM} = - \frac{\mu_0 n I Q}{2\pi ls} \hat{e}_\phi\]

    <p>and since we only care about angular momentum in the z-direction:</p>

\[L_{EM}^z = \int_{\text{inside solenoid}} l_{EM}^z\ dV =  \int_{\text{inside solenoid}} (\vec{r} \times \vec{g}_{EM})_z \ dV\]

    <p>you will find this matches up with the angular momentum you found in part 1.</p>
  </li>
</ul>

<hr />

<p><strong>List of good questions:</strong></p>

<ul>
  <li>Problem 8.2: deal with Poynting vector</li>
  <li>Problem 8.7
    <ul>
      <li>(a),(b) also involves $da_{x},da_y$</li>
      <li>(c) = one way to interpret $T^{ij}$</li>
    </ul>
  </li>
</ul>

<h1 id="chapter-9-em-waves">Chapter 9 EM Waves</h1>

<p>Charges and current produce $E$ and $B$ field. The main idea is that in vacuum/material, <strong>field themselves need to obey wave equation</strong> if we were to also consider the <strong>time component</strong> of the field = propagate like waves.</p>

<ul>
  <li>
    <p>we will show that in many physical scenarios, solutions have to obey <strong>wave equation</strong>, e.g. in 1D</p>

\[\frac{\partial^2 y}{\partial x^2} - \frac{1}{v^2}\frac{\partial^2 y}{\partial t^2} = 0\]
  </li>
  <li>
    <p>one common solutions is sinusoidal (and you can do Fourier theorem with it to get other functions), and this chapter basically <strong>focus on sinusoidal solutions in complex notation</strong>, e.g.</p>

\[y(x,t)=\mathrm{RE}[\tilde{A}e^{i(kz-\omega t)} + \tilde{B}e^{i(-kz-\omega t)}]\]
  </li>
  <li>
    <p>therefore the <strong>physics</strong> lies in finding $\tilde{A},\tilde{B},k$ using <mark>boundary conditions</mark> derived from physical principles (e.g. $B^\perp_1 -B^{\perp}_2=0$)</p>
  </li>
</ul>

<h2 id="plane-waves-without-rho-and-vecj">Plane Waves without $\rho$ and $\vec{J}$</h2>

<ul>
  <li>Plane waves is a simple case of having the amplitudes being a constant in space, e.g. $\tilde{A}$</li>
  <li>without $\rho,\vec{J}$ means we are in vacuum for a good <em>insulator</em></li>
</ul>

<table>
  <thead>
    <tr>
      <th>Condition/Name</th>
      <th>Equation</th>
      <th>Comments</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Using Complex Notation</td>
      <td>$I(t) = \mathrm{RE}[\tilde{I}_0e^{i\omega t}]$</td>
      <td>if you know the solution of $I(t)$ is <strong>in the form of cosine/sine</strong>, then using this will <strong>almost always</strong> make math simpler</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\tilde I_0=a+ib = I_0e^{i\phi}$</td>
      <td>so that if $\tilde{I}_0$ is complex, this means we have <strong>phase shifts!</strong> $\omega t \to \omega t + \phi$</td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230304165436626.png" alt="image-20230304165436626" style="zoom:33%;" /></td>
      <td> </td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>this form is also the nicest if you want to take the real part in the end, which becomes just $I_0 \cos(\omega t + \phi)$</td>
    </tr>
    <tr>
      <td>Wave “Definition”</td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230304165920613.png" alt="image-20230304165920613" /></td>
      <td>a “fixed” shape traveling at some velocity $v$</td>
    </tr>
    <tr>
      <td> </td>
      <td>e.g. $y(x-vt)$, traveling to the right</td>
      <td>the fixed shape would be $y(x)$</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>e.g. $y(x-vt) = Ae^{-b(x-vt)^2}$ is a valid wave</td>
    </tr>
    <tr>
      <td>Wave on String</td>
      <td>$\frac{\partial^2 y}{\partial x^2} - \frac{1}{T/\mu}\frac{\partial^2 y}{\partial t^2} = 0$</td>
      <td>so that solution is in the form of $y(x,t)=f(x-vt)+g(x+vt)$ for any function $f,g$</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td><strong>as a result</strong>, $v^2 = T/\mu$ is the wave’s traveling speed</td>
    </tr>
    <tr>
      <td> </td>
      <td>$F_y = T\sin(\theta’)-T\sin(\theta) = (\mu\Delta z) \frac{\partial^2 y}{\partial t^2}$</td>
      <td>derivation, consider force acting on a small section $\Delta z$ of the string, and using $F_y=ma_y$</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\tan(\theta(x)) = \frac{\partial y}{\partial x}\vert _x$</td>
      <td>then using small angle approx $\sin \approx \tan$, we obtain the wave equation</td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230304170338866.png" alt="image-20230304170338866" style="zoom:50%;" /></td>
      <td> </td>
    </tr>
    <tr>
      <td>Sinusoidal Wave</td>
      <td>$y(x,t)=A\cos[k(x - vt)+\delta]$</td>
      <td>for waves in physics, sinusoidal form for $f,g$ is considered mostly because (a) it works well with B.C. and (b) any function can be built from them = Fourier theorem</td>
    </tr>
    <tr>
      <td> </td>
      <td>$y(x,t)=\mathrm{RE}[\tilde{A}e^{i(kz-\omega t)}]$</td>
      <td>in complex form</td>
    </tr>
    <tr>
      <td> </td>
      <td>$g(x,t)=\mathrm{RE}[\tilde{B}e^{i(-kz-\omega t)}]$</td>
      <td>traveling to the left</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>hence $k$ <mark>indicates direction of propagation</mark></td>
    </tr>
    <tr>
      <td>Important quantities by definition</td>
      <td>$\lambda = 2\pi / k$</td>
      <td>by considering $x\to x+(2\pi/k)$</td>
    </tr>
    <tr>
      <td> </td>
      <td>$kv=\omega$, and $\tilde{A}=Ae^{i\delta}$</td>
      <td><mark>wave/phase velocity $v$</mark>!</td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230304172127708.png" alt="image-20230304172127708" /></td>
      <td> </td>
    </tr>
    <tr>
      <td>start of physics stuff</td>
      <td> </td>
      <td> </td>
    </tr>
    <tr>
      <td>B.C. simple reflection and transmission</td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230304173941953.png" alt="image-20230304173941953" /></td>
      <td>string extends to infinity at both ends, and given $\tilde{A}_I$, want to know $\tilde{A}_R,\tilde{A}_T$</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>assume $\omega$ is the same on both string, hence $\omega=v_1k_1 = v_2k_2$ since velocity has to be different</td>
    </tr>
    <tr>
      <td> </td>
      <td>$y_&lt;=\tilde{A}_I e^{i(k_1x-\omega t)}+\tilde{A}_R e^{i(-k_1x-\omega t)}$</td>
      <td>waves at $x&lt;x_B$</td>
    </tr>
    <tr>
      <td> </td>
      <td>$y_&gt; =\tilde{A}_T e^{i(k_2x-\omega t)}$</td>
      <td>waves at $x&gt;x_B$</td>
    </tr>
    <tr>
      <td> </td>
      <td>$y(0<em>-, t)=y(0</em>+,t)$, $\frac{\partial y}{\partial x}(0<em>-,t)=\frac{\partial y}{\partial x}(0</em>+,t)$</td>
      <td>no B.C. but <mark>continuity constraints</mark>!</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\tilde{A}_R = \frac{k_1 - k_2}{k_1 + k_2}\tilde{A}_I$</td>
      <td>solve and find</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\tilde{A}_T = \frac{2k_1}{k_1 + k_2}\tilde{A}_I$</td>
      <td> </td>
    </tr>
    <tr>
      <td> </td>
      <td>$\delta_I=\delta_T$, then if $\mu_1 &gt; \mu_2$, $\delta_R = \delta_I$. Otherwise $\delta_R = \delta_I + \pi$</td>
      <td>this has to be <mark>given</mark> by knowing that $\mu_2 » \mu_1$ gives a standing wave like solution.</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>In later questions/setups we will also be able to compute the phase shift $\delta$.</td>
    </tr>
    <tr>
      <td>Wave Equation for EM in vacuum</td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230304180459157.png" alt="image-20230304180459157" style="zoom:50%;" /></td>
      <td>derived from Maxwell’s eq assuming $\rho=\vec{J}=0$</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>so $v^2= 1/\mu_0\epsilon_0=c^2$, so EM waves propagate at speed of light</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>notice that this is 3D wave equation. In reality, we will see that when <mark>assuming plane waves solution</mark>, $E,B$ will be <mark>transverse</mark> = this reduces to a 1D wave equation</td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230304181007050.png" alt="image-20230304181007050" style="zoom:33%;" /></td>
      <td>derivation of the above</td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230304181024088.png" alt="image-20230304181024088" style="zoom:33%;" /></td>
      <td> </td>
    </tr>
    <tr>
      <td>Monochromatic Plane Waves</td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230304181731013.png" alt="image-20230304181731013" style="zoom: 50%;" /></td>
      <td>assuming that the amplitude vector <strong>is constant</strong> in all space, i.e. wave looks like a plane</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>$\mathbf{\tilde{E}}_0$ means it is a <em>constant <strong>vector</strong> but is complex</em></td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230304183205944.png" alt="image-20230304183205944" /></td>
      <td><mark>almost always the form to start with when solving plane waves question</mark></td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>derived using the “Property of Plane Waves”</td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230304181630251.png" alt="image-20230304181630251" style="zoom: 25%;" /></td>
      <td>up and down is modulated by $e^{i(kz-\omega t)}$ term</td>
    </tr>
    <tr>
      <td>Property of Plane Waves</td>
      <td>$\tilde{E}_z=\tilde{B}_z = 0$</td>
      <td>because $\nabla \cdot \vec{E}=\nabla \cdot \vec{B}=0$</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>so EM plane waves are <strong>transverse</strong> (w.r.t direction of propagation $z$)</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\mathbf{\tilde{B}}_0 = \frac{1}{c}\hat{z}\times \mathbf{\tilde{E}}_0$</td>
      <td>if $\hat{z}$ is the direction of propagation. So $\mathbf{B}$ is perpendicular to $\mathbf{E}$ and to $\hat{z}$</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>derived from $\nabla \times \mathbf = -\frac{\partial \mathbf}{\partial t}$</td>
    </tr>
    <tr>
      <td>Wave vector and polarization vector of Plane Waves</td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230304183620251.png" alt="image-20230304183620251" style="zoom:50%;" /></td>
      <td>$\hat{n}$ is the polarization vector, and $\vec{k}=k\hat{k}$ is the <mark>wave/propagation vector</mark></td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230304181450411.png" alt="image-20230304181450411" /></td>
      <td>e.g. $\hat{k}=k\hat{z}$</td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230304184252710.png" alt="image-20230304184252710" style="zoom:50%;" /></td>
      <td>when you want to know $\vec{E}(\vec{r})$ everywhere in space</td>
    </tr>
    <tr>
      <td>Visualization of Longitudinal Wave</td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230304182209963.png" alt="image-20230304182209963" /></td>
      <td>this will be useful when considering wave guides = EM waves are not longer purely transverse. But, they are always <strong>transverse w.r.t direction of energy propagation $\vec{S}$</strong></td>
    </tr>
    <tr>
      <td>Energy in EM Waves</td>
      <td>$\lang u_{EM}\rang = \frac{1}{4}(\epsilon_0 \mathbf{\tilde{E}}\mathbf{\tilde{E}}^* + \frac{1}{\mu}\mathbf{\tilde{B}}\mathbf{\tilde{B}}^*)$</td>
      <td>assumes $\mathbf{E}=\mathbf{\tilde{E}}(x,y,z)e^{i(kz-\omega t)}$ and $\mathbf{B}=\mathbf{\tilde{B}}(x,y,z)e^{i(kz-\omega t)}$</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>time average $\lang u_{EM} \rang = \frac{1}{T}\int_0^T u_{EM}\ dt$ ends up a $1/2$ in front due to $\int \cos^2 dt$</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\lang \vec{S} \rang = \frac{1}{2}\mathrm{RE}(\mathbf{\tilde{E}}\times \mathbf{\tilde{B}}^*)\equiv I$</td>
      <td><strong>Intensity</strong> is fact the “average power (E/t) per unit area”!</td>
    </tr>
    <tr>
      <td> </td>
      <td>$u_{EM} = \frac{1}{2}(\epsilon_0 E^2 + \frac{1}{\mu_0}B^2)$</td>
      <td>both of the above are derived from the following</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\vec{S}=\frac{1}{\mu_0}\vec{E}\times \vec{B}$</td>
      <td>previously derived only from Maxwell’s eq, so still holds<br />$E^2 =\vec{E}<em>{total}\cdot \vec{E}</em>{total}$<br />$B^2 =\vec{B}<em>{total}\cdot \vec{B}</em>{total}$</td>
    </tr>
    <tr>
      <td>Energy in Monochromatic Plane Waves</td>
      <td>$\lang u_{EM} \rang = \frac{1}{2}\epsilon_0 E_o^2$</td>
      <td>simpler case since we get $\mathbf{E}=\tilde{E}_0e^{i(kz-\omega t)}\hat{x}$ and $\mathbf{B}=(\tilde{E}_0/c)e^{i(kz-\omega t)}\hat{y}$</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\lang \vec{S}_{EM}\rang = \frac{1}{2}c\epsilon_0 E_0^2 \hat{z}$</td>
      <td> </td>
    </tr>
    <tr>
      <td>EM Wave Equation in Matter</td>
      <td>$\nabla^2 \mathbf{E} - \epsilon\mu\frac{\partial^2 \mathbf{E}}{\partial t^2}=0, \nabla^2 \mathbf{B} - \epsilon\mu\frac{\partial^2 \mathbf{B}}{\partial t^2}=0$</td>
      <td> </td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230304204811146.png" alt="image-20230304204811146" style="zoom: 50%;" /></td>
      <td>derived from realizing the difference between this set of Maxwell’s eq and the vacuum is just replacing $\epsilon_0\mu_0 \to \epsilon\mu$</td>
    </tr>
    <tr>
      <td> </td>
      <td>$v^2 = 1/\epsilon\mu &lt; c^2$</td>
      <td>but now <strong>velocity</strong> is different</td>
    </tr>
    <tr>
      <td> </td>
      <td>$v\equiv c/n$</td>
      <td>$n$ is <mark>index of refraction</mark></td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>other than the above (and the B.C.), things are the same (e.g. $v=\omega k$)</td>
    </tr>
    <tr>
      <td>B.C. for EM Wave in Matter</td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230304205332821.png" alt="image-20230304205332821" /></td>
      <td>B.C. when <strong>crossing from medium 1 to medium 2</strong>, assuming both are linear material</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>was the one from Maxwell Eq linear material in <a href="#Chapter 7 Electrodynamics">Chapter 7 Electrodynamics</a></td>
    </tr>
    <tr>
      <td>Setup for EM Wave in Matter + Oblique Incidence</td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230304211511742.png" alt="image-20230304211511742" /></td>
      <td>still plane waves, but $\mathbf{\tilde{E}}<em>{0_I} = \tilde{E}</em>{0<em>I} \hat{n}</em>{I}$ and we <mark>need to consider $\vec{r}$</mark></td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230304211518571.png" alt="image-20230304211518571" style="zoom:50%;" /></td>
      <td> </td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230304211629030.png" alt="image-20230304211629030" style="zoom:50%;" /></td>
      <td> </td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230304211416722.png" alt="image-20230304211416722" style="zoom:50%;" /></td>
      <td> </td>
    </tr>
    <tr>
      <td>B.C. for EM Wave in Matter + Oblique Incidence</td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230304213207452.png" alt="image-20230304213207452" style="zoom:50%;" /></td>
      <td>derived from the B.C. in material + realizing <em>all</em> the exponential cancels out (see below)</td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230304211823199.png" alt="image-20230304211823199" style="zoom:50%;" /></td>
      <td>additional conclusion for the oblique case, derived by realizing the B.C. yields<img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230304212820953.png" alt="image-20230304212820953" /></td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>so imagine needing the below to hold for all $\vec{r}$ $A\cos(k_I\cdot \vec{r})+B\cos(k_R\cdot \vec{r})=C\cos(k_T\cdot \vec{r})$</td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230304212103599.png" alt="image-20230304212103599" /></td>
      <td>hence at $z=0$ this has to be true for $\forall x,y$</td>
    </tr>
    <tr>
      <td> </td>
      <td>$(k_I)_y=(k_R)_y=(k_T)_y$</td>
      <td>from letting $y=0$,</td>
    </tr>
    <tr>
      <td> </td>
      <td>$(k_I)_x=(k_R)_x=(k_T)_x$</td>
      <td>from letting $x=0$</td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230304212035659.png" alt="image-20230304212035659" /></td>
      <td>derived then aligning $E_I$ into the x-z plane such that $(k_I)_y=0$. Then all other $(k_I)_y=(k_R)_y=(k_T)_y=0$, i.e. all are in x-z plane</td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230304212007096.png" alt="image-20230304212007096" /></td>
      <td>from $(k_I)_x=(k_R)_x$, and then realizing that $k_I = k_R$ since $\omega = kv$, both $v,\omega$ is the same for $k_I, k_R$</td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230304212016744.png" alt="image-20230304212016744" /></td>
      <td>from $(k_I)_x=(k_T)_x$, and using $v=c/n$</td>
    </tr>
    <tr>
      <td>Solution for EM Wave in Matter + Oblique Incidence</td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230304213350101.png" alt="image-20230304213350101" style="zoom:50%;" /></td>
      <td>$\alpha= \cos\theta_T/\cos \theta_I$, $\beta = (\mu_1v_1)/(\mu_2v_2)$</td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230304213423495.png" alt="image-20230304213423495" style="zoom:50%;" /></td>
      <td>derived from this and below + Snell’s law, which comes from the B.C., <em>assuming</em> $\vec{E},\vec{B}$ are also in the x-z plane (see below)</td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230304213427917.png" alt="image-20230304213427917" style="zoom:50%;" /></td>
      <td> </td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230307200713584.png" alt="image-20230307200713584" style="zoom:50%;" /></td>
      <td> </td>
    </tr>
    <tr>
      <td>Brewster’s angle $\theta_B$</td>
      <td>$\theta_I$ such that there is <strong>no reflected wave</strong></td>
      <td>e.g. in the case above, when $\alpha=\beta$</td>
    </tr>
    <tr>
      <td>Total Internal Reflection</td>
      <td>$\theta_I$ such that there is <strong>no transmitted energy</strong></td>
      <td> </td>
    </tr>
    <tr>
      <td>Reflection and Transmission index</td>
      <td>$R=\frac{I_R}{I_I}, T=\frac{I_T}{I_I}$</td>
      <td>$I=\lang S\rang_z=c\epsilon_0 E_0^2$ for plane waves <strong>striking the area</strong></td>
    </tr>
    <tr>
      <td> </td>
      <td>$R+T=1$</td>
      <td>basically the <strong>input energy = output energy</strong>, $I_I=I_R+I_T$</td>
    </tr>
  </tbody>
</table>

<p><em>Complex Notation in Circuits</em>: consider a given circuit as follows:</p>

<p><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230304164428685.png" alt="image-20230304164428685" style="zoom:33%;" /></p>

<p>we want to know $I$ flowing in this circuit, if $V=V_0\cos(\omega t)$. We know that the differential equation for $V$ must be</p>

\[V_0\cos(\omega t) - L \frac{dI}{dt} - IR=0\]

<p>so $I$ will be sinusoidal in form, and relates to the driving frequency $\omega$. Hence we can consider $I(t)=\tilde{I}_0e^{i\omega t}$:</p>

\[V_0 e^{i\omega t} = L \frac{d}{dt}\tilde{I}_0e^{i\omega t} + R\tilde{I}_0e^{i\omega t}\]

<p>then solving you will find:</p>

\[\tilde{I}_0 = \frac{V_0}{i\omega L +R} = \frac{V_0}{\sqrt{\omega^2L^2 + R^2}e^{i\phi}} = = \frac{V_0}{\sqrt{\omega^2L^2 + R^2}}e^{-i\phi}\]

<p>note that from this step, we realize that:</p>

<ul>
  <li>having $L$ in circuit just means a <mark>resistance of $i\omega L$</mark></li>
  <li>having capacitance $C$ in circuit, as you will see later, just means a <mark>resistance of $i C/\omega$</mark>.</li>
  <li>with the above, you can solve circuits without touching differential equations at all, by just treating them as resistors.</li>
</ul>

<p>for $\tan(\phi)=\omega L/R$, by visualizing $a+ib$ in complex plane. Then you are essentially done since:</p>

\[I(t)= \mathrm{RE}[\tilde{I}_0e^{i\omega t}] =\frac{V_0}{\sqrt{\omega^2L^2 + R^2}}\cos(\omega t - \phi)\]

<hr />

<p><em>Standing Wave</em>: given a boundary condition that both ends of a wall has to be zero, e.g. $y(x,0)=A\sin (\pi x/L)$</p>

<p><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230304172216985.png" alt="image-20230304172216985" style="zoom:33%;" /></p>

<p>and obviously since this is a string, it needs to satisfy the wave equation</p>

\[\frac{\partial^2 y}{\partial x^2} - \frac{1}{v^2}\frac{\partial^2 y}{\partial t^2} = 0\]

<p>then you should <strong>guess</strong> that the solution $y(x,t)=f(x-vt)+g(x+vt)$ is superposition to two waves:</p>

\[y(x,t) = \frac{A}{2}\left\{ \sin\left[\frac{\pi}{L}(x-vt)\right] +\sin\left[\frac{\pi}{L}(x+vt)\right] \right\}\]

<p>How does this work? Two oppositely traveling waves with <em>same frequency</em> forms standing waves = has <mark>fixed points</mark>!</p>

<table>
  <tbody>
    <tr>
      <td>![Visualizing RF Standing Waves</td>
      <td>Hackaday](https://hackaday.com/wp-content/uploads/2015/08/350px-standing_wave_2.gif)</td>
    </tr>
  </tbody>
</table>

<hr />

<p><em>EM Wave in Matter</em>: consider the simple example of reflection + transmission for <em>plane waves</em>. Find all amplitudes as a function of $\tilde{E}_I$</p>

<p><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230304210203014.png" alt="image-20230304210203014" style="zoom: 50%;" /></p>

<p>Since these are plane waves, we have</p>

\[\begin{align*}
\mathbf{E}_{I}(z,t)&amp;={\tilde{E}}_Ie^{i(k_1z-\omega t)}\hat{x}\\
\mathbf{E}_{R}(z,t)&amp;={\tilde{E}}_Re^{i(-k_1z-\omega t)}\hat{x}\\
\mathbf{E}_{T}(z,t)&amp;={\tilde{E}}_Te^{i(k_2z-\omega t)}\hat{x}
\end{align*}\]

<p>then the tricky part is realize the <strong>$\vec{B}_R$</strong> direction has to be consistent such that $\vec{S}=\frac{1}{\mu_0}\vec{E}\times \vec{B}$ gives $\vec{v}_R$:</p>

\[\begin{align*}
\mathbf{B}_{I}(z,t)&amp;=\frac{1}{v_1}{\tilde{E}}_Ie^{i(k_1z-\omega t)}\hat{y}\\
\mathbf{B}_{R}(z,t)&amp;=\frac{\textcolor{red}{-1}}{v_1}{\tilde{E}}_Re^{i(-k_1z-\omega t)}\hat{y}\\
\mathbf{B}_{T}(z,t)&amp;=\frac{1}{v_2}{\tilde{E}}_Te^{i(k_2z-\omega t)}\hat{y}
\end{align*}\]

<p>then just put them into the B.C. at $z=0$ you get</p>

\[\begin{align*}
\vec{E}^{\parallel}_1 - \vec{E}^{\parallel}_2 &amp;= 0 \implies \tilde{E}_I + \tilde{E}_R =\tilde{E}_T \\
\frac{1}{\mu_1}{B}^{\perp}_1 - \frac{1}{\mu_2}{B}^{\perp}_2 &amp;= 0 \implies \frac{1}{\mu_1v_1}\tilde{E}_I -\frac{1}{\mu_1v_1} \tilde{E}_R =\frac{1}{\mu_2v_2}\tilde{E}_T
\end{align*}\]

<p>then to solve $\tilde{E}_R, \tilde{E}_T$, you can realize that letting $k_i \gets \frac{1}{\mu_iv_i}$ gives you the same set of equations to solve for wave on a string.</p>

<h2 id="plane-waves-with-vecj">Plane Waves with $\vec{J}$</h2>

<p>Up to here, we have discussed solutions to wave equations derived</p>

<ul>
  <li><strong>assuming no charges/currents</strong>: now we will have <em>another term</em> in Maxwell’s eq, resulting in a <em>damping term</em> in wave equation (and that $\vec{B}$ is out of phase with $\vec{E}$). You will see this results in $k$ $\to$ $\tilde{k}=k+i\kappa$, so that waves are decaying/not propagating!</li>
  <li><strong>assuming wave $v$ (or rather $\epsilon$) is independent of $\omega$</strong> in material. Before we had $v^2=1/(\epsilon\mu)$ $\to$ you will see $v^2=1/(\tilde{\epsilon}(\omega)\mu)$. Hence this will also affect wave vector $k \to k(\omega)$. In this case, even in a <em>non-conducting material</em> we end up with <em>damping term in solution</em>!</li>
</ul>

<table>
  <thead>
    <tr>
      <th>Condition/Name</th>
      <th>Equation</th>
      <th>Comments</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Maxwell’s Equation inside a conductor</td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230305003116097.png" alt="image-20230305003116097" style="zoom:50%;" /></td>
      <td>basically we have a $\rho_f$ and a $\vec{J}_{free}=\sigma\vec{E}$ inside conductor</td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230301112719153.png" alt="image-20230301112719153" style="zoom:50%;" /></td>
      <td>derived from this using linear media</td>
    </tr>
    <tr>
      <td>Wave Equation used Inside Conductor</td>
      <td>$\nabla^2\mathbf{E} = \mu\epsilon \frac{\partial^2 \mathbf{E}}{\partial t^2}+\underbrace{\mu\sigma \frac{\partial \mathbf{E}}{\partial t}}_{\text{damping term}}$</td>
      <td> </td>
    </tr>
    <tr>
      <td> </td>
      <td>$\nabla^2\mathbf{B} = \mu\epsilon \frac{\partial^2 \mathbf{B}}{\partial t^2}+\underbrace{\mu\sigma \frac{\partial \mathbf{B}}{\partial t}}_{\text{damping term}}$</td>
      <td> </td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230305003353475.png" alt="image-20230305003353475" style="zoom: 50%;" /></td>
      <td>this is <em>technically</em> derived from this, i.e. assuming charges has disappeared to boundary</td>
    </tr>
    <tr>
      <td>Charge inside conductor</td>
      <td>$\rho_f(t) = \rho_f(0)e^{-t/\tau}$</td>
      <td>hence the $\rho_f$ term is ignored (only) when deriving the wave equation</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>derived from the continutiy equation $-\partial\rho_f / \partial t = \nabla \cdot \vec{J}_f$, then using $\vec{J}_f = \sigma \vec{E}$ and $\nabla \cdot \vec{D} = \rho_f$</td>
    </tr>
    <tr>
      <td>B.C. inside conductor</td>
      <td>$\epsilon_1E^{\perp}_1 - \epsilon_2E^{\perp}_2 = \sigma_f$, etc.</td>
      <td>derive from the Maxwell’s equation in material, with the presence of both $\rho_f$ and $\vec{J}_f$</td>
    </tr>
    <tr>
      <td>Solution for Wave in Conductor</td>
      <td>$\tilde{k}=k+i\kappa$</td>
      <td>found by plugging our usual solution $\mathbf{\tilde{E}}(z,t)=\tilde{E}_0e^{i(kz-\omega t)}\hat{x}$ into wave equation, and found that $k$ needs to be complex</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\mathbf{\tilde{E}}(z,t)=\tilde{E}_0e^{-\kappa z}e^{i(kz-\omega t)}\hat{x}$</td>
      <td> </td>
    </tr>
    <tr>
      <td> </td>
      <td>$\mathbf{\tilde{B}}(z,t)=\tilde{B}_0e^{-\kappa z}e^{i(kz-\omega t)}\hat{y}=\frac{\tilde{k}}{\omega}\tilde{E}_0e^{-\kappa z}e^{i(kz-\omega t)}\hat{y}$</td>
      <td>notice the coefficient $\tilde{k}/\omega$ is complex, i.e. $\vec{B}$ is <mark>out of phase</mark> with $\vec{E}$. This is derived simply from $\nabla\times \vec{E} = -\partial \vec{B}/\partial t$</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>phase difference of $\phi\gets$ converting $\tilde{k}/\omega =Ae^{i\phi}$</td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230305004919734.png" alt="image-20230305004919734" style="zoom:33%;" /></td>
      <td> </td>
    </tr>
    <tr>
      <td> </td>
      <td>$d\equiv 1/\kappa$</td>
      <td><strong>skin depth</strong>, i.e. an indicator of how far wave can penetrate into conductor</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\alpha \equiv 2\kappa$</td>
      <td><strong>absorption coefficient</strong>, because intensity is proportional to $E^2$</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\omega = kv$ holds for the real part of $\tilde{k}$</td>
      <td>because the propagation part is $e^{i(kz-\omega t)}$</td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230305004856356.png" alt="image-20230305004856356" /></td>
      <td>if you need to know</td>
    </tr>
    <tr>
      <td>Modeling electron’s motion given a driving field</td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230305010538065.png" alt="image-20230305010538065" style="zoom:33%;" /></td>
      <td> </td>
    </tr>
    <tr>
      <td> </td>
      <td>$m\frac{d^2x}{dt^2}=\vec{F}<em>{electron}=\vec{F}</em>{E}+\vec{F}<em>{damping}+\vec{F}</em>{SHO}$</td>
      <td>where $\vec{F}<em>E = q\vec{E}</em>{ext}$, damping term $-m\gamma \frac{dx}{dt}$, and SHO force due to the <em>atomic attraction</em> for restoration $\vec{F}_{SHO}=-m\omega_0^2x$</td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230305010958944.png" alt="image-20230305010958944" style="zoom:50%;" /></td>
      <td>the equation of motion</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>$\omega_0$ will be different for each electron config/also relevant to <mark>resonance</mark>!</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\tilde{x}(t)=\tilde{x}_0e^{-i\omega t}$ and $\tilde{x}=\frac{q/m}{\omega_0^2-\omega-i\gamma \omega}E_0$   is complex</td>
      <td>solution, by plugging in the steady state $\tilde{x}(t)=\tilde{x}_0e^{-i\omega t}$</td>
    </tr>
    <tr>
      <td>Modeling Polarization given a driving field</td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230305011452197.png" alt="image-20230305011452197" style="zoom:50%;" /></td>
      <td>notice that $E_0e^{-i\omega t}=\mathbf{\tilde{E}}$ that we supplied</td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230305011538023.png" alt="image-20230305011538023" style="zoom:50%;" /></td>
      <td>since $\mathbf{P}=N\tilde{p}$, and $N$ is number of molecules per volume</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>$\omega_j$ comes from $\omega_0$ being different for different electrons. $f_j$ is the number of electrons having the same $\omega_j$</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\mathbf{\tilde{P}}=\epsilon_0\tilde{\chi}_E(\omega)\tilde{E}$</td>
      <td>rewrite the entire wierd term into $\chi_E$</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\tilde{\epsilon}=\epsilon_0(1+\tilde{\chi}_E) = \epsilon_0\left[ 1+\frac{Nq^2}{m\epsilon_0}\sum_j \frac{f_j}{\omega_j^2 - \omega^2 - i \omega \gamma} \right]$</td>
      <td><mark>after all efforts, the net result is that $\epsilon$ becomes complex</mark> and is <mark>a function of $\omega$</mark></td>
    </tr>
    <tr>
      <td>Wave Equation after all these</td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230305012418254.png" alt="image-20230305012418254" style="zoom:50%;" /></td>
      <td> </td>
    </tr>
    <tr>
      <td> </td>
      <td>$\mathbf{\tilde{E}}(z,t)=\mathbf{\tilde{E}}_0e^{-\kappa z}e^{i(kz-\omega t)}$</td>
      <td>derived from plugging in $\mathbf{\tilde{E}}(z,t)=\mathbf{\tilde{E}}_0e^{i(kz-\omega t)}$ and realizing $\tilde{k} = \sqrt{\tilde{\epsilon}\mu_0}\omega=k+i\kappa$</td>
    </tr>
    <tr>
      <td>Resonance frequency</td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230305012926612.png" alt="image-20230305012926612" style="zoom: 33%;" /></td>
      <td>so that at $\omega = \omega_j$, absorption peaks = <mark>amplitudes of electron oscillation becomes huge</mark></td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230305013027929.png" alt="image-20230305013027929" style="zoom: 40%;" /></td>
      <td> </td>
    </tr>
    <tr>
      <td>The above is a dispersive medium</td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230305013243995.png" alt="image-20230305013243995" style="zoom:40%;" /></td>
      <td>$n\to n(\omega)$ <mark>index of refraction depends on input wave frequency</mark></td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>derived from $\omega = kv,v=c/n$</td>
    </tr>
  </tbody>
</table>

<h2 id="wave-in-wave-guide">Wave in Wave Guide</h2>

<p>No longer plane wave. Now we consider the form</p>

\[\mathbf{E}=\textcolor{red}{\tilde{\mathbf{E}}_0(x,y)}e^{i(kz-\omega t)}\]

<p>which has two changes:</p>

<ul>
  <li>
    <p>our old boundary conditions + now the amplitude is a function of $(x,y)$ results in $E$ and $B$ <strong>cannot both be perpendicular to $\hat{z}$</strong></p>
  </li>
  <li>
    <p>amplitude as a result also has terms:</p>

\[\mathbf{\tilde{E}}_0(x,y) = \tilde{E}_x(x,y)\hat{x} +  \tilde{E}_y(x,y)\hat{y} +  \tilde{E}_z(x,y)\hat{z}\]
  </li>
</ul>

<p>The net result is that the amplitudes/solution becomes more complicated, e.g. TE waves:</p>

<p><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230305014934219.png" alt="image-20230305014934219" style="zoom:33%;" /></p>

<p>but notice that $\vec{E}$ and $\vec{B}$ still perpendicular to each other</p>

<table>
  <thead>
    <tr>
      <th>Condition/Name</th>
      <th>Equation</th>
      <th>Comments</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Setting up Wave Equation <mark>inside Wave Guides</mark></td>
      <td>$\mathbf{E}(x,y,z,t)=\textcolor{red}{\tilde{\mathbf{E}}_0(x,y)}e^{i(kz-\omega t)}$</td>
      <td> </td>
    </tr>
    <tr>
      <td> </td>
      <td>$\mathbf{B}(x,y,z,t)=\textcolor{red}{\tilde{\mathbf{B}}_0(x,y)}e^{i(kz-\omega t)}$</td>
      <td> </td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230305015419912.png" alt="image-20230305015419912" style="zoom:33%;" /></td>
      <td>why this change? assuming the <mark>wave guide is a perfect conductor</mark>.</td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230305015540452.png" alt="image-20230305015540452" style="zoom:40%;" /></td>
      <td>then this B.C. means we cannot have plane waves (e.g. try to draw it with a rectangular wave guide)</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>why this B.C (on the inner surface)? Because $E_{meat}=B_{meat}=0$ for conductor. Then use the usual B.C. from Maxwell’s eq you will get this.</td>
    </tr>
    <tr>
      <td>Generic Solution for Wave in Wave Guide</td>
      <td>$\mathbf{\tilde{E}}_0(x,y) = \tilde{E}_x(x,y)\hat{x} +  \tilde{E}_y(x,y)\hat{y} +  \tilde{E}_z(x,y)\hat{z}$</td>
      <td>our task is <em>just to solve the coefficients</em></td>
    </tr>
    <tr>
      <td> </td>
      <td>$\mathbf{\tilde{B}}_0(x,y) = \tilde{B}_x(x,y)\hat{x} +  \tilde{B}_y(x,y)\hat{y} +  \tilde{B}_z(x,y)\hat{z}$</td>
      <td> </td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230305015732193.png" alt="image-20230305015732193" style="zoom:50%;" /></td>
      <td>by plugging the above into Maxwell’s equation in vacuum. Notice that <mark>all are a function $E_z,B_z$</mark></td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230305015937140.png" alt="image-20230305015937140" /></td>
      <td>so our only task becomes to solve $E_z,B_z$ from this + specific B.C. in a problem</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>the above is again found in Maxwell Eq.</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>so <strong>why not transverse wave</strong> = $E_z=B_z=0$? Then we would get both the $\nabla \cdot E=0,\nabla \times E=0$, hence $E=-\nabla \phi$ inside. <br />But a conductor has $\vec{E}^{\parallel}<em>{inner}=0$ since $\vec{E}</em>{meat}=0$. Therefore on the surface $\phi=$constant. <br />Then since this satisfies Laplace equation = both mean and max on surface, $\phi$=constant inside as well. Hence $E=0$ entirely.</td>
    </tr>
    <tr>
      <td>$TE_{MN}$ waves in Rectangular Wave Guide</td>
      <td>$B_z=B_0\cos(k_xx)\cos(k_yy)=B_0\cos(m\pi\frac{x}{a})\cos(n\pi\frac{y}{b})$</td>
      <td>TE because $E_z=0$ hence $E$ is $T$ransverse</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>once $E_z=0$ and $B_z$ is solved, we can solve everything else</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>$m=0,1,2,3…$, $n=0,1,2,3,…$, but at least one non-zero so that the solution is not trivial</td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230305020803974.png" alt="image-20230305020803974" style="zoom:50%;" /></td>
      <td>derived from using $B_z(x,y)=X(x)Y(y)$ and plugging into the  eq for $B_z$</td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230305021240165.png" alt="image-20230305021240165" style="zoom:50%;" /></td>
      <td>since the first term is only a function of $x$, second only a function of $y$</td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230305021309163.png" alt="image-20230305021309163" style="zoom:50%;" /></td>
      <td> </td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230305020749636.png" alt="image-20230305020749636" style="zoom:50%;" /></td>
      <td>B.C. is in this case is<br />$B_y(y=0)=B_y(y=b)=0$ and $B_x(x=0)=B_x(x=a)=0$</td>
    </tr>
    <tr>
      <td>Properties of $TE_{MN}$ wave above</td>
      <td>$k^2 = \frac{\omega^2}{c^2}\left[ 1-\frac{\omega_{mn}^2}{\omega^2} \right]$, so $\omega_{mn}\equiv \omega_{cutoff}$</td>
      <td>since if $\omega_{cutoff}&gt;\omega$, then $k$ becomes complex and your wave decays in $\hat{z}$/does not propagate</td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230305021905239.png" alt="image-20230305021905239" style="zoom: 33%;" /></td>
      <td>derived from the equation of $k^2$ from the previous concept</td>
    </tr>
    <tr>
      <td> </td>
      <td>$v=\omega/k = c/\sqrt{1-(\omega/\omega_{mn})^2}$</td>
      <td>this is $v&gt;c$? Because $v=v_{phase}$. The actual $v_g$ of <strong>energy propagation</strong> has $v_g &lt;c$</td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230305022049463.png" alt="image-20230305022049463" style="zoom:50%;" /></td>
      <td>one way to derive the above is $v_g=c\cos(\theta)$, and $v_{phase}=c/\cos\theta$, with knowing $\cos\theta = k/\vert \vec{k}’\vert$</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>and $\vec{k}^\prime=k_x\hat{x}+k_y\hat{y}+k\hat{z}$</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>shows what does $k_x,k_y$ represent!</td>
    </tr>
    <tr>
      <td>Group Velocity as velocity of energy transfer</td>
      <td>$v_g \equiv d\omega /dk$</td>
      <td>in principle represents velocity of a <strong>wave packet</strong></td>
    </tr>
    <tr>
      <td> </td>
      <td>$v_g = \frac{\int \lang S\rang_z\cdot d\vec{a} }{\int \lang u\rang_z da}=\frac{\text{energy/time}}{\text{energy/length}}$</td>
      <td>an intuitive “verification” using poynting vector/energy density</td>
    </tr>
    <tr>
      <td> </td>
      <td>$Ae^{i(k+\Delta k/2)z-(\omega + \Delta \omega /2)t}+Ae^{i(k-\Delta k/2)z-(\omega - \Delta \omega /2)t}$<br />$=Ae^{i(kz-\omega t)}\cos(\frac{\Delta k}{2}z-\frac{\Delta \omega}{2}t)$<br />$=Ae^{i(kz-\omega t)}\cos (k(z-v_gt))$</td>
      <td>where it actually comes from = superposing two waves in a specific wave forms a <strong>wave packet traveling at $v_g$</strong> (see visualization in the examples section)</td>
    </tr>
    <tr>
      <td> </td>
      <td>$v_g = \Delta \omega /\Delta k$</td>
      <td>in this example</td>
    </tr>
  </tbody>
</table>

<p><em>Group Velocity v.s. Phase Velocity</em>:</p>

<p>In this example, $v_g&gt;v_{phase}$, but in general, most physical systems will have $v_g &lt; v_{phase}$</p>

<p><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/Recording 2023-03-05 at 01.40.38.gif" style="zoom:33%;" /></p>

<hr />

<p><strong>List of good questions</strong></p>

<ul>
  <li>Problem 9.7
    <ul>
      <li>(b)(c) dealt with understanding more the B.C. and wave equation</li>
      <li>(d) deals with understanding the complex amplitude $\tilde{A}$</li>
    </ul>
  </li>
  <li>
    <p>Problem 9.17: solid question in understanding B.C. and $\vec{E}$ and $\vec{B}$ with directional $\vec{k}\cdot \vec{r}$.</p>
  </li>
  <li>Problem 9.39
    <ul>
      <li>(f) is magical, about total internal reflection</li>
    </ul>
  </li>
  <li>Problem 9.30: what does velocity of “energy propagation” mean, and why group velocity is relevant</li>
</ul>

<h1 id="chapter-10-retarded-potentials-and-fields">Chapter 10 (Retarded) Potentials and Fields</h1>

<p>The goal is to find $\vec{E}$ and $\vec{B}$ given some <strong>really arbitrary $\rho, \vec{J}$</strong>. (Before, we only looked at when $\rho=0$, or when $\vec{J}_f=\sigma\vec{E}$ in a conductor when solving the wave equations.)</p>

<p>In general this is difficult, so here the idea is (like before)</p>

<ul>
  <li>
    <p>solve instead for $\phi, \vec{A}$ under the Lorentz Gauge:</p>

\[\exists \chi,\quad \nabla \cdot \vec{A} + \frac{1}{c^2}\frac{\partial \phi}{\partial t} = 0\]

    <p>then $\phi, \vec{A}$ satisfies:</p>

\[\begin{cases}
\square^2 \phi = - \rho / \epsilon_0\\
\square^2 \vec{A} =  - \mu_0 \vec{J}
\end{cases}\]

    <p>where LHS is <mark>only the sources</mark>, and $\square^2 \equiv \nabla^2 - \frac{1}{c^2} \frac{\partial^2}{\partial t^2}$. Then the solution of $\phi,\vec{A}$ can be <mark>guessed</mark>:</p>

\[\phi(\vec{r},t) = \frac{1}{4\pi\epsilon_0} \int \frac{\rho(\vec{r}',t_r')}{|\vec{r} - \vec{r}'|} d^3r'\\
\vec{A}(\vec{r},t) = \frac{\mu_0}{4\pi} \int \frac{\vec{J}(\vec{r}')}{|\vec{r} - \vec{r}'|} d^3r'\]

    <p>where $t_r = t - \vert \vec{r} - \vec{r}’\vert /c$  is the retarded time.</p>
  </li>
  <li>
    <p>convert to $\vec{E},\vec{B}$ by $\vec{E} =- \nabla \phi - \frac{\partial \vec{A}}{\partial t}$ and $\vec{B}=\nabla \times \vec{A}$</p>
  </li>
</ul>

<table>
  <thead>
    <tr>
      <th>Condition/Name</th>
      <th>Equation</th>
      <th>Comments</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Potential of Fields in electrodynamics</td>
      <td>$\vec{E} =- \nabla \phi - \frac{\partial \vec{A}}{\partial t}$</td>
      <td>before in electrostatics we had $\vec{E} =- \nabla \phi$ (from $\nabla \times \vec{E} = 0$)but this no longer works if you consider $\nabla \times \vec{E} = - \partial \vec{B} / \partial t$</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\vec{B}=\nabla \times \vec{A}$</td>
      <td>unchanged</td>
    </tr>
    <tr>
      <td>Inhomogenous Wave Equation for $\vec{E},\vec{B}$ given generic $\rho,\vec{J}$</td>
      <td>$\nabla^2 \phi - \frac{1}{c^2} \frac{\partial^2 \phi}{\partial t^2} = - \rho / \epsilon_0$<br />$\nabla^2 \vec{A} - \frac{1}{c^2} \frac{\partial^2 \vec{A}}{\partial t^2} = - \mu_0 \vec{J}$</td>
      <td>the first derived from $\nabla \cdot \vec{E}=-\rho / \epsilon_0$, the second derived from $\nabla\times \vec{B}$ and Lorentz Gauge transformation (see below)</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>or equivalently  $\square^2 \equiv \nabla^2 - \frac{1}{c^2} \frac{\partial^2}{\partial t^2}$</td>
    </tr>
    <tr>
      <td> </td>
      <td>derived from<br />$\nabla^2 \vec{A} - \frac{1}{c^2}\frac{\partial^2 \vec{A}}{\partial t^2} - \nabla(\nabla \cdot \vec{A} + \frac{1}{c^2}\frac{\partial \phi}{\partial t}) = -\mu\vec{J}$</td>
      <td>which comes from $\nabla \times (\nabla \times \vec{A}) = \nabla \times \vec{B}$ and expand $\vec \times \vec{B}$ using Maxwell’s Eq and $\vec{E} =- \nabla \phi - \frac{\partial \vec{A}}{\partial t}$</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\vec{A}’ = \vec{A} + \nabla \chi$, and $\phi’ = \phi-\frac{\partial \chi}{\partial t}$</td>
      <td>for some $\chi$ such that the <mark>corresponding $\vec{E}'=E$ and $\vec{B}'=\vec{B}$ is unchanged</mark></td>
    </tr>
    <tr>
      <td>Lorentz Gauge</td>
      <td>$\chi$ such that $\nabla \cdot \vec{A} + \frac{1}{c^2}\frac{\partial \phi}{\partial t} = 0$</td>
      <td>then you easily get $\nabla^2 \vec{A} - \frac{\partial^2 \vec{A}}{\partial t^2} = - \mu_0 \vec{J}$ using the result 2 cells above</td>
    </tr>
    <tr>
      <td>Retarded Potential</td>
      <td>$\phi(\vec{r},t) = \frac{1}{4\pi\epsilon_0} \int \frac{\rho(\vec{r}’,t_r’)}{\vert \vec{r} - \vec{r}’\vert } d^3r’$</td>
      <td>guessed from the Wave equation, just as we guessed from electrostatics<br /><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230507170523791.png" alt="image-20230507170523791" /></td>
    </tr>
    <tr>
      <td> </td>
      <td>$\vec{A}(\vec{r},t) = \frac{\mu_0}{4\pi} \int \frac{\vec{J}(\vec{r}’)}{\vert \vec{r} - \vec{r}’\vert } d^3r’$</td>
      <td> </td>
    </tr>
    <tr>
      <td> </td>
      <td>$t_r = t - \vert \vec{r} - \vec{r}’\vert /c$</td>
      <td>retarded time, or better seen from $\vert \vec{r} - \vec{r}’(t_r)\vert  = c(t-t_r)$</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230507170950514.png" alt="image-20230507170950514" style="zoom:13%;" /></td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>has relation to relativity since time is a concern, i.e. in another frame, this retarded time would be different</td>
    </tr>
    <tr>
      <td>Lienard-Wiechert Potentials</td>
      <td>$\phi(\vec{r},t) = \frac{1}{4\pi \epsilon_0} \frac{q}{1 - \hat{\mathcal{R}}\cdot \vec{v}(t_r)/c}$</td>
      <td>where $\vec{\mathcal{R}} \equiv \vec{r} - \vec{w}(t_r)$ and $\vec{v}(t_r)$ both are at retarded time</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\vec{A}(\vec{r},t) = \frac{\vec{v}(t_r)}{c}\phi(\vec{r},t)$</td>
      <td>derived from length contraction when seomthing is moving towards you, hence $\tau’ = \tau / (1 - \hat{\mathcal{R}}\cdot \vec{v}(t_r)/c)$ is the volume <em>appears to you</em></td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>generic for a point charge moving in any trajectory $\vec{w}(t)$</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230507173613747.png" alt="image-20230507173613747" style="zoom:23%;" /></td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>so that $\vert \vec{r}- \vec{w}(t_r)\vert  = c(t-t_r)$</td>
    </tr>
    <tr>
      <td>Fields of a moving point charge</td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230507175541022.png" alt="image-20230507175541022" /></td>
      <td>where $\vec{u}\equiv c \hat{\mathcal{R}}-\vec{v}$</td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230507175955450.png" alt="image-20230507175955450" style="zoom:70%;" /></td>
      <td>derived from the above, since we can compute $\vec{E} = -\nabla \phi - \frac{\partial \vec{A}}{\partial t}$ and $\vec{B} = \nabla \times \vec{A}$</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>generic for any trajectory</td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230507175913539.png" alt="image-20230507175913539" style="zoom:15%;" /></td>
      <td>velocity field because when $\vert \vec{v}(t)\vert =v$ is constant, then $\vec{E}$ points to its present location <img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230507180250215.png" alt="image-20230507180250215" style="zoom: 50%;" /></td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>visually:<img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230507180131681.png" alt="image-20230507180131681" style="zoom:13%;" /></td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>radiation field because that <mark>term $\propto 1/r$,</mark> hence will dominate at large distances (other terms go like $1/r^2$)</td>
    </tr>
  </tbody>
</table>

<p><em>Example Calculation using Lienard-Wiechert Potentials</em>:</p>

<p>Consider a trajectory of a point charge with constant velocity $\vec{w} = vt$. What is its potential $\phi(\vec{r},t)$?</p>

<p>The idea is to express:</p>

\[\phi(\vec{r},t) = \frac{1}{4\pi \epsilon_0} \frac{q}{1 - \hat{\mathcal{R}}\cdot \vec{v}(t_r)/c}\]

<p>in terms of $q,v, t$, so that we need to figure out what is $\hat{\mathcal{R}}$. Graphically, we know that it is the position of the charge at $t_r$:</p>

<p><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230507173613747.png" alt="image-20230507173613747" style="zoom:23%;" /></p>

<ol>
  <li>
    <p>find out when is $t_r$:</p>

\[|\vec{r} - vt_r| = c(t-t_r)\]

    <p>and solve for $t_r$</p>
  </li>
  <li>
    <p>find $\hat{\mathcal{R}}$ since we know $t_r$ and $\vec{w}$:</p>

\[\hat{\mathcal{R}} = \hat{\mathcal{R}}(t_r) = \frac{\vec{r} - vt_r}{c(t-t_r)}\]
  </li>
  <li>
    <p>done.</p>
  </li>
</ol>

<p>Surprisingly, you will find in the case of constant velocity <mark>the corresponding $\vec{E}$</mark> points to the <mark>current position of the charge</mark>.</p>

<p><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230507180131681.png" alt="image-20230507180131681" style="zoom: 23%;" /></p>

<hr />

<p><em>Thought Experiment of Velocity Field</em>. Consider a point charge moving at $v$ but suddenly stopped at $T$. You are at $\vec{r}$ and that information hasn’t reach you <em>yet</em>. What would the E field look like in space?</p>

<ol>
  <li>Since the information that the charge has stopped hadn’t yet reach me (such information propagates as speed of light), then I would experience a field as if the charge is still moving with $v$</li>
  <li>The field when charge has stopped will be simple, and that will propagate at the speed of light</li>
</ol>

<p><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230507180720556.png" alt="image-20230507180720556" style="zoom: 33%;" /></p>

<p>so you get a lot of “kinks”</p>

<hr />

<p>List of good questions:</p>

<ul>
  <li>10.17 = draw the space-time diagram version.</li>
  <li>10.21 = mind boggling with field of charge at constant velocity.</li>
</ul>

<h1 id="chapter-11-radiation">Chapter 11 Radiation</h1>

<p>Radiation studies the parts of $\vec{E},\vec{B}$ that goes like $1/r$, such that even for $r\to \infty$ we get $I=\int \vec{S}\cdot d\vec{A} \neq 0$ meaning energy is <strong>radiated and never comes back</strong> = permanently lost.</p>

<p>One example of such a field is the “radiation field” discussed in the previous section. This section will basically focus on studying that field.</p>

<table>
  <thead>
    <tr>
      <th>Condition/Name</th>
      <th>Equation</th>
      <th>Comments</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Electric Dipole Radiation</td>
      <td>$\vec{E}_{\text{dipole radiation}} = - \frac{\mu_0 p_0 \omega^2}{4\pi}\frac{\sin(\theta)}{r}\cos(\omega(t-r/c))\hat{\theta}$</td>
      <td>where $p_0 = q_0d$ is electric dipole</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>derived from considering an oscillating dipole constructed with $q(t)=q_0e^{i\omega t}$</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230507182443127.png" alt="image-20230507182443127" style="zoom:50%;" /></td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>then find its potential $\phi$, discard terms containing any $1/r$, and then compute field $\vec{E}$ to only keep $1/r$ terms</td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230507182611809.png" alt="image-20230507182611809" style="zoom:50%;" /></td>
      <td>by figuring out $\vec{B}$ as well, then $\vec{S} = (1/\mu_0)\vec{E}<em>{\text{rad}}\times \vec{B}</em>{\text{rad}}$</td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230507182750881.png" alt="image-20230507182750881" /></td>
      <td>total power radiated = energy permanently lost per second</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>this power is 1) frequency dependent and 2) is consistent with future derivation of generic radiation loss</td>
    </tr>
    <tr>
      <td>Magnetic Dipole Radiation</td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230507192144887.png" alt="image-20230507192144887" style="zoom:67%;" /><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230507192154553.png" alt="image-20230507192154553" style="zoom:67%;" /></td>
      <td>derived from considering a current loop such that $\vec{m}(t) = \pi b^2I_0\cos(\omega t)\hat{z}$</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230507192050613.png" alt="image-20230507192050613" /></td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>then find its retarded potential $\vec{A}$<br /><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230507192324974.png" alt="image-20230507192324974" style="zoom:50%;" /></td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>and since we know $\phi=0$ , can compute $\vec{E},\vec{B}$ by taking derivatives after knowing $\vec{A}$</td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230507192434482.png" alt="image-20230507192434482" style="zoom: 67%;" /></td>
      <td>derived from finding $\vec{S}$ and taking integral.</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>very similar to power radiated by electric dipole, but it is much smaller due to $c^3$ term.</td>
    </tr>
    <tr>
      <td>Radiation from <strong>Arbitrary</strong> Source</td>
      <td>$\vec{E}_{\mathrm{rad}}(\vec{r},t) = \frac{\mu_0}{4\pi r}[\hat{r}\times (\hat{r}\times \ddot{\vec{p}})]$</td>
      <td>where $\vec{p}$ is dipole moment for arbitrary distribution $\int r’\rho\,\, d^3r’$</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\vec{B}_{\mathrm{rad}}(\vec{r},t) = \frac{\mu_0}{4\pi rc}[\hat{r}\times \ddot{\vec{p}}]$</td>
      <td> </td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230507192728975.png" alt="image-20230507192728975" /></td>
      <td>derived from expand the retarded potentials to contain dipole terms (see left), and discard other terms higher than $1/r$</td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230507193136550.png" alt="image-20230507193136550" style="zoom:67%;" /></td>
      <td>finally, the power radiated is given by $\oint \vec{S}\cdot d\vec{a}$</td>
    </tr>
  </tbody>
</table>

<h2 id="radiation-of-point-charges">Radiation of Point Charges</h2>

<p>Now we focus on the specific case of point charges. Since we already know the fields of point charges in <a href="#Chapter 10 (Retarded) Potentials and Fields">Chapter 10</a>, essentially we use $\vec{E},\vec{B}$ from there but focus on $1/r$ terms.</p>

<table>
  <thead>
    <tr>
      <th>Condition/Name</th>
      <th>Equation</th>
      <th>Comments</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Larmor’s Formula</td>
      <td>$P_{\mathrm{rad}} = \frac{\mu_0 q^2 a^2}{6\pi c}$</td>
      <td>derived from assuming $v=0$ at $t_r$ so that $\vec{u}=c \hat{\mathcal{R}}$, but actuallly <mark>holds well for $v \ll c$</mark></td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>derived from having a point charge moving with trajectory $\vec{w}$, and only taking $\vec{E}<em>{\mathrm{rad}}$ term to compute $\vec{S}</em>{\mathrm{rad}} = (1/\mu_0 c) E_{\mathrm{rad}}^2$</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>then finally $P_{\mathrm{rad}} = \oint \vec{S}_{\mathrm{rad}}\cdot d\vec{A}$</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td><mark>this formula is used most often</mark> as long as it’s not specified we are at relativistic conditions</td>
    </tr>
    <tr>
      <td>Lienard’s Generalization of Larmor’s Formula</td>
      <td>$P_{\mathrm{rad}} = \frac{\mu_0 q^2}{6\pi c}\gamma^6 (a^2 - \left\vert  \frac{\vec{v}\times \vec{a}}{c} \right\vert ^2)$</td>
      <td>takes care of the case when $v\approx c$.</td>
    </tr>
    <tr>
      <td>Radiation Reaction Force</td>
      <td>$\vec{F}_{\mathrm{rad}} = \frac{\mu_0 q^2}{6\pi c}\dot{\vec{a}}$</td>
      <td>derived from realizing that $P_{rad}$ loss needs to be taken away from the <strong>kinetic energy</strong> of a particle. Hence try to find $\vec{F}<em>{rad}\cdot \vec{v} = -P</em>{loss}=-P_{rad}$</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>since $P_{loss} = \oint \vec{S}\cdot d\vec{A}$ where $\vec{S}$ includes both velocity field and radiation field, here we <em>assume</em> that $P_{loss}=P_{rad}$ by considering a “periodic motion” of the particle os that at $t_2$ it restores its velocity field</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230507195052305.png" alt="image-20230507195052305" style="zoom:8%;" />finally substitute in the Larmor’s formula and find $\vec{F}_{rad}$</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>note that this force is $\propto \dddot{r}!$</td>
    </tr>
  </tbody>
</table>

<p><em>Using Radiation Reaction to find EoM</em>: since this essentially relates energy loss back to change in acceleration/velocity/position, we can use this if find EoM of an object.</p>

<p>Consider radiation damping of a SHO object, attached to some spring with $\omega_0$ and subject to driving force at $\omega$. Then its EoM look like:</p>

\[m \ddot{x} = F_{\mathrm{spring}} + F_{\mathrm{rad}} + F_{\mathrm{drive}} = - m\omega_0^2 x + m \tau \ddot{x} + F_{\mathrm{drive}}\]

<p>where $\tau = \frac{\mu_0 q^2}{6\pi mc}$ from Larmor’s fomula. Then since the solution should be oscillatory, let $x(t) = x_0 \cos(\omega t + \delta)$ to find</p>

\[\ddot{x} = -\omega \dot{x}\]

<p>putting this back the EoM becomes</p>

\[m \ddot{x}+ \underbrace{m \omega\tau \dot{x}}_{\text{damping term}} + m\omega_0^2 x  = F_{\mathrm{drive}}\]

<p>which makes sense as radiation losses energy.</p>

<hr />

<p>List of good questions:</p>

<ul>
  <li>11.14 = how radiation $P_{rad}$ relates to “physical” change in a system</li>
  <li>11.18 = a bit more into how to use $F_{\mathrm{rad}}$ for energy calculation
    <ul>
      <li>(a) try to derive the EoM and the solution</li>
    </ul>
  </li>
  <li>11.19 = normal EoM using $F_{rad}$</li>
</ul>

<h1 id="chapter-12-electrodynamics-and-relativity">Chapter 12 Electrodynamics and Relativity</h1>

<p>Iin previous chapters, we understand how to find $\vec{E},\vec{B}$ in some frame. In this chapter we consider, after knowing some $\vec{E},\vec{B}$, <strong>how do they transform</strong>.</p>

<p>In this chapter you will realize how $\vec{E},\vec{B}$ (and other related quantities such as $\phi, \vec{A}$) can <mark>transform into each other</mark> when you boost into some inertial frame. Some key findings include</p>

<ul>
  <li><strong>space-time diagram</strong> essentially encodes all features of relativity such as time dilation, length contraction, etc</li>
  <li>
    <p><strong>four vectors and four matrices</strong> are keys to help you perform transformations easily</p>
  </li>
  <li><strong>Maxwell’s Eq is already consistent</strong> with relativity</li>
</ul>

<h2 id="special-relativity-and-space-time">Special Relativity and Space Time</h2>

<p>Because speed of light is <strong>universal in any frame</strong>, this basically:</p>

<ul>
  <li>screwed up spontaneity</li>
  <li>screwed up length = length contration</li>
</ul>

<p>and all of the above can be intuitively shown using a space-time diagram.</p>

<table>
  <thead>
    <tr>
      <th>Condition/Name</th>
      <th>Equation</th>
      <th>Comments</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>space time coordinate</td>
      <td>$(ct,x,y,z)=(x^0,x^1,x^2,x^3)$</td>
      <td> </td>
    </tr>
    <tr>
      <td>Invariant in space time/hyperbolic space</td>
      <td>$(ct)^2 - x^2 = (ct’)^2 - x’^2$</td>
      <td>signifies length in hyperbolic space uses this minus sign (instead of $x^2 + y^2 = x’^2 + y’^2$ normally)</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>hence define $x^0 \equiv ct$</td>
    </tr>
    <tr>
      <td>Lorentz Transformation with Hyperbolic Functions</td>
      <td>$x^{0’}=\cosh(u)x^0 - \sinh(u)x$<br />$x^{‘}=-\sinh(u)x^0 + \cosh(u)x$<br />$v/c = \tanh(u)$</td>
      <td>where $x=x^1$ above, assuming the $S’$ frame is moving at $v$. $u$ is also called <mark>rapidity</mark></td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230507201339283.png" alt="image-20230507201339283" style="zoom: 15%;" /></td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>e.g. transform <strong>into a Bob’s frame moving at $v$</strong></td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td><mark>this is the more fundamental equations</mark>, and makes math also simpler</td>
    </tr>
    <tr>
      <td>Visualization of Rapidity</td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230507202354910.png" alt="image-20230507202354910" style="zoom:15%;" /></td>
      <td>derived from thinking about “where to put Bob’s $x^{0^{‘}}$axis” in Alice’s set of axes</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>basically found that $v/c = \mathrm{slope} = \tanh(u)$</td>
    </tr>
    <tr>
      <td>Lorentz Transformation</td>
      <td>$\sinh(u) = \frac{v/c}{\sqrt{1-v^2/c^2}} = \frac{v}{c}\gamma$<br />$\cosh(u) = \frac{1}{\sqrt{1-v^2/c^2}} =\gamma$</td>
      <td>derived from $v/c = \tanh(u)$</td>
    </tr>
    <tr>
      <td> </td>
      <td>$t’ = \gamma (t - \frac{v}{c}x)$<br />$x’ = \gamma (x-vt)$</td>
      <td>same Lorentz transformation as above</td>
    </tr>
    <tr>
      <td>Velocity Addition</td>
      <td>$v_{\mathrm{total}}/c = \tanh(u_{\mathrm{total}})=\tanh(u_1+u_2)$</td>
      <td>when you want to find the velocity $v_2$ relative to you, but only given $v_1$ relative to you and $v_2$ relative to $v_1$</td>
    </tr>
    <tr>
      <td> </td>
      <td>$v_{\mathrm{total}} = \frac{v_1+ v_2}{1 + v_1v_2/c^2}$</td>
      <td>same as above, because<img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230507202142746.png" alt="image-20230507202142746" style="zoom:15%;" /></td>
    </tr>
    <tr>
      <td>Consequences of living in hyperbolic space</td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230507202552035.png" alt="image-20230507202552035" style="zoom: 33%;" /></td>
      <td>lines of same lengths becomes wierd</td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230507202637041.png" alt="image-20230507202637041" style="zoom: 25%;" /></td>
      <td>vector decomposition in a primed/transformed frame</td>
    </tr>
    <tr>
      <td>Relativity of Simultaneity</td>
      <td>two events that are simulatenous to one inertial frame are not, in general, simultaneous in another frame</td>
      <td> </td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230507203244450.png" alt="image-20230507203244450" style="zoom:25%;" /></td>
      <td>event $A,B$ are simultaneous to the unprimed frame, but to the primed frame the two events happened at time $b,c$ respectively</td>
    </tr>
    <tr>
      <td>Length Contraction</td>
      <td>Things look longer when moving towards you</td>
      <td> </td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230507204037680.png" alt="image-20230507204037680" style="zoom:33%;" /></td>
      <td>note that for things like “length”, we need information to traverse through time, hence the additional photon line</td>
    </tr>
    <tr>
      <td>Lorentz Transformation with Matrix</td>
      <td>$\begin{bmatrix}x^{0^{‘}}\x^{1^{‘}}\x^{2^{‘}}\x^{3^{‘}}\end{bmatrix} = \begin{bmatrix}\cosh(\theta) &amp; -\sinh(\theta) &amp; 0 &amp; 0\-\sinh(\theta) &amp; \cosh(\theta) &amp; 0 &amp; 0\0 &amp; 0 &amp; 1 &amp; 0\0 &amp; 0 &amp; 0 &amp; 1\\end{bmatrix}\begin{bmatrix}x^{0}\x^{1}\x^{2}\x^{3}\end{bmatrix}$</td>
      <td> </td>
    </tr>
    <tr>
      <td> </td>
      <td>$\begin{bmatrix}x^{0^{‘}}\x^{1^{‘}}\x^{2^{‘}}\x^{3^{‘}}\end{bmatrix} = \begin{bmatrix}\gamma &amp; -\gamma\beta &amp; 0 &amp; 0\-\gamma\beta &amp; \gamma &amp; 0 &amp; 0\0 &amp; 0 &amp; 1 &amp; 0\0 &amp; 0 &amp; 0 &amp; 1\\end{bmatrix}\begin{bmatrix}x^{0}\x^{1}\x^{2}\x^{3}\end{bmatrix}$</td>
      <td>where $\beta = v/c$</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>visually, boosting from $S$ to the moving$S’$<img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230507204437944.png" alt="image-20230507204437944" style="zoom: 50%;" /></td>
    </tr>
    <tr>
      <td>“Inverse” Lorentz Transformation</td>
      <td>$\begin{bmatrix}x^{0}\x^{1}\x^{2}\x^{3}\end{bmatrix} = \begin{bmatrix}\cosh(\theta) &amp; \sinh(\theta) &amp; 0 &amp; 0\\sinh(\theta) &amp; \cosh(\theta) &amp; 0 &amp; 0\0 &amp; 0 &amp; 1 &amp; 0\0 &amp; 0 &amp; 0 &amp; 1\\end{bmatrix}\begin{bmatrix}x^{0^{‘}}\x^{1^{‘}}\x^{2^{‘}}\x^{3^{‘}}\end{bmatrix}$</td>
      <td>equivalent of the above but $S$ moving to the left relative to $S’$</td>
    </tr>
    <tr>
      <td>Four vectors</td>
      <td>$x^\mu \equiv \begin{bmatrix}x^{0}\x^{1}\x^{2}\x^{3}\end{bmatrix}$</td>
      <td>(same as above cell, but different representation)</td>
    </tr>
    <tr>
      <td> </td>
      <td>$x^{\mu^{‘}} = \Lambda_\nu^\mu x^\nu \equiv \sum_\nu \Lambda_\nu^\mu x^\nu$</td>
      <td>where $\nu$ is row, $\mu$ is column of the matrix.</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>in this case, the <mark>summation notation is equivalent to perform matrix multiplication</mark></td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td><mark>any valid four vectors need to satisfy this transformation rule</mark></td>
    </tr>
    <tr>
      <td>Minkovski metric</td>
      <td>$\Delta x_\mu = \eta_{\mu\nu}\Delta x^\nu$</td>
      <td>lowering index</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\Delta x^\mu \cdot \Delta x^\mu = \Delta x_\mu \Delta x^\mu = \text{invariant} = (c^2t^2 - d^2)$</td>
      <td>where $d^2 = x^2 + y^2 + z^2$ (as mentioned before, this is length in space-time)</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\eta_{\mu\nu} = \begin{bmatrix}1 &amp; 0 &amp; 0 &amp; 0\0 &amp; -1 &amp; 0 &amp; 0\0 &amp; 0 &amp; -1 &amp; 0\0 &amp; 0 &amp; 0 &amp; -1\\end{bmatrix}$</td>
      <td>mostly negative convention, called the <strong>metric</strong></td>
    </tr>
    <tr>
      <td> </td>
      <td>$\eta_{\mu\nu}=\eta^{\mu\nu}$</td>
      <td>the RHS is used to raise the index</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>visually, $I$ is the invariant:<img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230507210223862.png" alt="image-20230507210223862" style="zoom: 15%;" /></td>
    </tr>
    <tr>
      <td>Time like events</td>
      <td>when $I=(c^2t^2-d^2) &gt; 0$</td>
      <td> </td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230507210335755.png" alt="image-20230507210335755" style="zoom:33%;" /></td>
      <td>if $A$ happened before $B$ in one frame, this order <strong>must hold in any other frame</strong> = <strong>causality is maintained</strong></td>
    </tr>
    <tr>
      <td>Space like events</td>
      <td>when $I=(c^2t^2-d^2) &lt; 0$</td>
      <td> </td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230507210401599.png" alt="image-20230507210401599" style="zoom:25%;" /></td>
      <td>no causality, and the order of event is no longer absolute</td>
    </tr>
  </tbody>
</table>

<p><em>Graphical Example of Time Dilation</em></p>

<p>In a primed frame, let an event happened at $\Delta t’ = 1$ hour. The same event to an unprimed frame would have happened at $\Delta t &gt; \Delta t’$:</p>

<p><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230507202901028.png" alt="image-20230507202901028" style="zoom: 25%;" /></p>

<h2 id="relativistic-mechanics">Relativistic Mechanics</h2>

<p>Now, we focus on how “definitions” of <mark>energy, momentum</mark>, and conservation principles <strong>“changed” when we consider relativity</strong>, i.e. do they hold when I transformed into another inertial frame? In sum:</p>

<ul>
  <li>
    <p>energy/momentum redefined through <em>proper time</em></p>
  </li>
  <li>
    <p><em>relativistic energy and momentum</em> is conserved</p>
  </li>
</ul>

<p>why need to “redefine”? It turns out using proper time = can write those quantities into four vectors = much easier to transform = nice properties follows such as conservation of relativistic energy.</p>

<table>
  <thead>
    <tr>
      <th>Condition/Name</th>
      <th>Equation</th>
      <th>Comments</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Transforming ordinary velocity</td>
      <td>$v_x = v^1 = \frac{\Delta x^1}{\Delta t} = c\frac{\Delta x^1}{\Delta t} = c \frac{\cosh(\theta)\Delta x^{0’} + \sinh(\theta) \Delta x^{1’}}{\sinh(\theta)\Delta x^{0’} + \cosh(\theta) \Delta x^{1’}}$</td>
      <td>given $v^{1’}$ to figure out $v^1$ needs to transform both $\Delta x^1\gets \Delta x^{1’}$ and $\Delta t \gets \Delta t’$</td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230507213334706.png" alt="image-20230507213334706" style="zoom: 50%;" /></td>
      <td>“consequence” of using ordinary velocities</td>
    </tr>
    <tr>
      <td>Proper Time</td>
      <td>$\Delta \tau$ instead of $\Delta t$</td>
      <td> </td>
    </tr>
    <tr>
      <td> </td>
      <td>$\Delta x_\mu \Delta x^\mu \equiv \Delta s^2 \equiv (c\Delta \tau)^2$</td>
      <td>$\Delta \tau$ is time for a photon to travel $\Delta s$, which is <strong>invariant under transformation</strong></td>
    </tr>
    <tr>
      <td> </td>
      <td>$\Delta \tau = \Delta t / \gamma$</td>
      <td>derived from realizing $\Delta \vec{x}\cdot \Delta \vec{x} = (v\Delta t)^2$, and that $\Delta x_\mu \Delta x^\mu = c^2\Delta t^2 - \Delta \vec{x}\cdot \Delta \vec{x}$</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td><mark>this is actually quite useful later on since it means $d \tau / dt = 1/\gamma$</mark></td>
    </tr>
    <tr>
      <td>Four velocity</td>
      <td>$\frac{\Delta x^\mu}{\Delta \tau}\equiv u^\mu = \gamma (c, \vec{v})$</td>
      <td>is a four vector and transforms with $u^{\mu^{‘}} = \Lambda_\mu^\mu u^\nu$</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>$\vec{v}$ is <strong>ordinary velocity</strong></td>
    </tr>
    <tr>
      <td> </td>
      <td>$u_\mu u^\mu = \gamma^2(c^2 - v^2)=c^2$ is invariant</td>
      <td> </td>
    </tr>
    <tr>
      <td>Four momentum</td>
      <td>$P^\mu \equiv c\cdot m u^\mu$</td>
      <td>we put an extra $c$ so that we get the below</td>
    </tr>
    <tr>
      <td> </td>
      <td>$P^\mu = (\gamma mc^2 , c \gamma \vec{p}) = (E_{relat}, c\vec{p}_{relat})\equiv (E, c \vec{p})$</td>
      <td><mark>relativistic</mark> energy and momentum</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>you can show that $E_{rela} = \gamma mc^2$ includes both $mc^2$ and $(1/2)mv^2$ by expanding $\gamma$. It really is <strong>“total energy”</strong></td>
    </tr>
    <tr>
      <td> </td>
      <td>$P_\mu P^\mu = (mc^2)^2$ is invariant</td>
      <td> </td>
    </tr>
    <tr>
      <td>Mass-Energy equivalence</td>
      <td>$P_\mu P^\mu = E^2 - p^2c^2 = m^2c^4$</td>
      <td>all comes naturally using four vector</td>
    </tr>
    <tr>
      <td>Energy/Momentum of Photon</td>
      <td>$E=pc$</td>
      <td>special case since $m = 0$, then the formula $E=mc^2 \gamma$ doesn’t work as both numerator and denominator has zero</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>hence comes from Mass-energy equivalence</td>
    </tr>
    <tr>
      <td>Conservation of relativistic energy and momentum</td>
      <td>$P^\mu_{\mathrm{IN}}=P^\mu_{\mathrm{OUT}}$</td>
      <td>note that being invariant has nothing to do with being conserved (e.g. mass is invariant but not conserved = some goes into energy)</td>
    </tr>
    <tr>
      <td>Center of mass energy</td>
      <td>find by $P_\mu P^\mu  = P_{CM_\mu} P_{CM}^\mu =E_{CM}^2$</td>
      <td>where $P_{CM}^\mu = (E_{CM},0)$</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>utilizing the fact that $P_\mu P^\mu$ is invariant in <em>any frame</em></td>
    </tr>
    <tr>
      <td>Relativistic Force</td>
      <td>$\vec{F} = \frac{d\vec{P}_{relat}}{dt} = \frac{d}{dt} \frac{m\vec{v}}{\sqrt{1-v^2/c^2}}$</td>
      <td>we use the relativistic momentum <strong>but ordinary time</strong></td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>as a result, transformation looks somewhat ugly</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>but only <em>this form</em> is consistent with the force in $\vec{F}=q(\vec{E}+\vec{v}\times \vec{B})$</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>can use this to compute trajectory of particles under some force</td>
    </tr>
  </tbody>
</table>

<p><em>Mass is not conserved</em>:</p>

<p><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230507215614936.png" alt="image-20230507215614936" style="zoom: 67%;" /></p>

<hr />

<p><em>Conservation of Energy and Momentum using Four vectors</em></p>

<p><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230507220130230.png" alt="image-20230507220130230" /></p>

<p><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230507220041890.png" alt="image-20230507220041890" style="zoom: 33%;" /></p>

<p><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230507220153432.png" alt="image-20230507220153432" style="zoom: 18%;" /></p>

<hr />

<p><em>Trajectory of a particle given some force</em>. Let an object move from rest at $t=0$ under <em>constant force</em>. what is $x(t)$ over time?</p>

<p>The key is to think that $\vec{F} = d\vec{p}_{relat}/dt$, which tells you what is $\vec{v}(t)$, then you can integrate to get $x(t)$</p>

<p><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230507221355367.png" alt="image-20230507221355367" style="zoom:33%;" /></p>

<p><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230507221417439.png" alt="image-20230507221417439" style="zoom:30%;" /></p>

<h2 id="relativistic-electrodynamics">Relativistic Electrodynamics</h2>

<p>Here you will see that:</p>

<ul>
  <li>magnetic process is a relativistic effect of electric process, i.e. you can have magnetic field in one frame, <strong>boost in another frame</strong>, and obtain no magnetic field but electric field (in the end <strong>what matters is the actual force = affecting particles’ motion</strong>)</li>
  <li>Maxwell’s equation is naturally relativistic</li>
  <li>we will show the above by <strong>re-writing</strong> (no new physics) every related Maxwell quantities in <strong>four vector/matrix formation</strong></li>
</ul>

<table>
  <thead>
    <tr>
      <th>Condition/Name</th>
      <th>Equation</th>
      <th>Comments</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Example of mixing $\vec{E}$ and $\vec{B}$</td>
      <td>$F_M = \frac{1}{\gamma} F_E’$</td>
      <td> </td>
    </tr>
    <tr>
      <td> </td>
      <td>frame $S$:<img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230507222315675.png" alt="image-20230507222315675" style="zoom:15%;" /></td>
      <td>a charge moving with $v$. Wire is charge neutral hence $\vec{E}=0$</td>
    </tr>
    <tr>
      <td> </td>
      <td>frame $S’$:<img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230507222340931.png" alt="image-20230507222340931" style="zoom:15%;" /></td>
      <td>boost into the charge’s frame, now $\vec{v}\times \vec{B}=0$, but $\vec{E}\neq 0$ now!</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>because the charge density changes: $\rho = #\text{charges}/(\Delta x \Delta y \Delta z)$, and one of the dimension experience Lorentz contraction</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>as a result line density $\lambda = (\rho_+’ - \rho_-‘)A \neq 0$ in frame $S’$, hence obtain electric field</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>essentially, what changed under boosts are the <mark>charge densities</mark></td>
    </tr>
    <tr>
      <td>Transformation of $E,B$ field</td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230507222905638.png" alt="image-20230507222905638" /></td>
      <td>when boosting into some frame with $v$</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>derived from parallel plate, and arguing how surface charge <em>density</em> is the only thing that changed</td>
    </tr>
    <tr>
      <td>Transformation of $E,B$ field in Tensor Notation</td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230507223148861.png" alt="image-20230507223148861" style="zoom:15%;" /></td>
      <td>equivalent of the above!!</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>note that this summation is different from matrix multiplication</td>
    </tr>
    <tr>
      <td>Field Tensor</td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230507223216187.png" alt="image-20230507223216187" /></td>
      <td> </td>
    </tr>
    <tr>
      <td> </td>
      <td>$F^{\mu\nu’} =\Lambda^{\mu}<em>\lambda \Lambda</em>{\sigma}^{\nu}F^{\lambda \sigma}$</td>
      <td>in summation notation</td>
    </tr>
    <tr>
      <td> </td>
      <td>$F^{\mu\nu} F_{\mu\nu}= 2(E^2/c^2 - B^2)$ is invariant</td>
      <td> </td>
    </tr>
    <tr>
      <td>Dual of Field Tensor</td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230507223345979.png" alt="image-20230507223345979" /></td>
      <td> </td>
    </tr>
    <tr>
      <td>Four current and conservation of charges</td>
      <td>$J^\mu \equiv (c\rho, \vec{J})$</td>
      <td> </td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230507223748095.png" alt="image-20230507223748095" /></td>
      <td>is equivalent of <img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230507223836807.png" alt="image-20230507223836807" style="zoom: 67%;" /></td>
    </tr>
    <tr>
      <td>(helpers) Transformation of Derivatives</td>
      <td>$\frac{\partial }{\partial x^\mu} \equiv (\frac{\partial }{\partial x^0}, \frac{\partial }{\partial x^1}, \frac{\partial }{\partial x^2}, \frac{\partial }{\partial x^3}) \equiv \partial_\mu$</td>
      <td>lower derivatives for upper index</td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230507224333843.png" alt="image-20230507224333843" style="zoom: 6%;" /></td>
      <td><em>transformation</em> of derivatives</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>derived from <img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230507224244738.png" alt="image-20230507224244738" style="zoom: 5%;" /></td>
    </tr>
    <tr>
      <td> </td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230507224353232.png" alt="image-20230507224353232" style="zoom:33%;" /></td>
      <td><em>raising</em> derivatives</td>
    </tr>
    <tr>
      <td>Derivatives to D’ Lambertian</td>
      <td><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230507224513593.png" alt="image-20230507224513593" style="zoom:8%;" /></td>
      <td> </td>
    </tr>
    <tr>
      <td>Re-Expressing Maxwell’s equation</td>
      <td>$\frac{\partial F^{\mu\nu}}{\partial x^\nu} = \partial_\nu F^{\mu\nu} = \mu_0 J^\mu$<br />$\frac{\partial G^{\mu\nu}}{\partial x^\nu} = \partial_\nu G^{\mu\nu} = 0$</td>
      <td>same as all four of Maxwell’s equation</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>for example<img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230507224812071.png" alt="image-20230507224812071" style="zoom:15%;" /></td>
    </tr>
    <tr>
      <td>Re-Expressing Lorentz Force</td>
      <td>$K^\mu \equiv \frac{dp^\mu}{d\tau}$</td>
      <td>proper force (instead of $\vec{F} = \frac{d\vec{P}_{relat}}{dt}$)</td>
    </tr>
    <tr>
      <td> </td>
      <td>$K^\mu = q u_\nu F^{\nu\mu}$</td>
      <td>equivalent of $\vec{F}= q(\vec{E} + \vec{v}\times \vec{B})$</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>for example<img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230507225102436.png" alt="image-20230507225102436" style="zoom:15%;" /></td>
    </tr>
    <tr>
      <td>Re-Expressing Potentials</td>
      <td>$A^\mu = (\phi/c, \vec{A})$</td>
      <td>four potential</td>
    </tr>
    <tr>
      <td> </td>
      <td>$F^{\mu\nu} = \frac{\partial A^\nu}{\partial x_\mu}-\frac{\partial A^\mu}{\partial x_\nu} = \partial^\mu A^\nu - \partial^\nu A^\mu$</td>
      <td>equivalent to $\vec{E} =- \nabla \phi - \frac{\partial \vec{A}}{\partial t}$ and $\vec{B}=\nabla \times \vec{A}$</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>notice that this is upper index derivative. In a <strong>mostly positive metric</strong> you get an extra minus sign for $x^0$ term:<img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230507230017010.png" alt="image-20230507230017010" style="zoom: 15%;" /></td>
    </tr>
    <tr>
      <td>Re-expressing Gauges and “Wave Equation”</td>
      <td>$A^\mu \to A^\mu + \frac{\partial \chi}{\partial x_\mu}$</td>
      <td>the above hints at Gauge transformation, won’t change $F^{\mu\nu}$</td>
    </tr>
    <tr>
      <td> </td>
      <td>$\partial^\nu\partial_\mu A^\mu = \square^2 A^\mu = -\mu_0 J^\mu$</td>
      <td>equivalent to<br />$\square^2\phi = - \rho / \epsilon_0$<br />$\square^2 \vec{A} = - \mu_0 \vec{J}$</td>
    </tr>
  </tbody>
</table>

<p>List of good questions:</p>

<ul>
  <li>
    <p>12.6 = need to understand the consequence of $t\neq t’$</p>
  </li>
  <li>
    <p>12.8 = not entirely sure how space-time works, potentially needed to deal with hyperbolic space</p>

    <ul>
      <li>one take-away from this is: let me be traveling at $v$ w.r.t. some stationary observer. <strong>When I travelled $d’ = v \Delta t’$ for $\Delta t’$ in my frame,</strong> to other people they <strong>think I travelled $d=v \Delta t \neq d’$!</strong> The “real distance” should be $d’=v\Delta t’$.</li>
    </ul>
  </li>
  <li>
    <p>12.13 = how to draw simultanoues event</p>

    <ul>
      <li>two events simultaneous on a reference frame $\neq$ an observer will see them simultaneously (i.e. no light ray)</li>
    </ul>
  </li>
  <li>
    <p>12.36 = get object <em>velocity</em> from relativistic <em>energy</em></p>
  </li>
  <li>
    <p>professor added question: how <em>rapidity</em> can be used with energies</p>

    <p><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230413202735577.png" alt="image-20230413202735577" style="zoom:33%;" /></p>
  </li>
  <li>
    <p>professor added question: Lorentz transfomation and what does a free-fall trajectory look like</p>

    <p><img src="/lectures/images/2023-05-11-PHYS3008_EM_n_Optics/image-20230413225600385.png" alt="image-20230413225600385" style="zoom: 33%;" /></p>
  </li>
  <li>
    <p>professor added question of how to transform momentum</p>
  </li>
  <li>
    <p>12.51: $F_{\mu\nu}F^{\mu\nu}$ is really just summing index, not matrix multiplication</p>
  </li>
</ul>]]></content><author><name></name></author><category term="2022@Columbia" /><summary type="html"><![CDATA[Recap]]></summary></entry><entry><title type="html">POLS1201 Intro to American Politics</title><link href="/lectures/2022@columbia/POLS1201_Intro_to_American_Politics.html/" rel="alternate" type="text/html" title="POLS1201 Intro to American Politics" /><published>2023-05-11T00:00:00+00:00</published><updated>2023-05-11T00:00:00+00:00</updated><id>/lectures/2022@columbia/POLS1201_Intro_to_American_Politics</id><content type="html" xml:base="/lectures/2022@columbia/POLS1201_Intro_to_American_Politics.html/"><![CDATA[<p>Note that a lot of content comes from relevant publications and the <a href="https://openstax.org/books/american-government-3e/pages/1-introduction">OpenStax book</a> (Krutz, G., &amp;  Waskiewicz, S. (2021). <em>American Government 3e</em>. Houston, Texas: OpenStax.)</p>

<h1 id="logistics-and-introduction">Logistics and Introduction</h1>

<ul>
  <li>no recording</li>
  <li>occasional attendance pools/quizzes</li>
  <li>two midterms (02/20 and 03/29) and a cumulative final</li>
  <li>data assignment</li>
</ul>

<p><strong>Approaches within American Politics:</strong></p>

<ul>
  <li>the study of <em>political behavior</em>:
    <ul>
      <li>what does the public actually want?</li>
      <li>how do interest group influence policy?</li>
      <li>what influence who wins an election?</li>
    </ul>
  </li>
  <li>studying specific kinds of organizations - <em>institutions</em>
    <ul>
      <li>Why does congress do so little (or so much)?</li>
      <li>What predicts how the Supreme Court will rule in a lawsuit?</li>
      <li>What pushes state governments to adopt policies?</li>
    </ul>
  </li>
  <li>Yet there is a also a “separate” branch on <em>race, ethnicity, and politics</em>.
    <ul>
      <li>technically those considerations should be embedded into the first two approaches, yet from a developmental perspective this is not what happened</li>
    </ul>
  </li>
</ul>

<p><strong>Approaches in this course</strong>:</p>

<ul>
  <li><em>methodological individualism</em>: explain political phenomenon as a result of (aggregates of) <strong>individual decisions</strong></li>
  <li><em>individual rationality</em>: explain political phenomena as product of people pursuing <strong>subjective interest</strong>
    <ul>
      <li>but of course in reality, <em>what</em> are their “subjective interest” is unknown. (e.g. poor voters voting for candidates could make them even poorer)</li>
      <li>also accidents happen, hence it can be difficult to study only a single event, v.s. <strong>comparing across a category of events</strong> = inference by <strong>drawing parallels</strong> with other similar events!</li>
    </ul>
  </li>
</ul>

<p><strong>Key questions we will ask</strong>:</p>

<ul>
  <li>often decisions are based on a few important actors. Who are they?</li>
  <li>What do they want?</li>
</ul>

<h1 id="theoretical-frameworks-and-political-traditions">Theoretical Frameworks and Political traditions</h1>

<p>Course sign-up and a <strong>prisoner’s dilemma</strong>: because students can choose to sign-up for “shopping” classes</p>

<table>
  <thead>
    <tr>
      <th> </th>
      <th>$S_2$ No Extra Classes</th>
      <th>$S_2$  Extra Classes</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>$S_1$ No Extra Classes</td>
      <td>Low Churn (2,2)</td>
      <td>$S_2$ exploits (4,1)</td>
    </tr>
    <tr>
      <td>$S_1$ Extra Classes</td>
      <td>$S_1$ exploits (1,4)</td>
      <td>High Churn (3,3)</td>
    </tr>
  </tbody>
</table>

<p>In this setup:</p>

<ul>
  <li>the numbers indicate rankings for each, e.g. for $S_2$: 1) $S_2$ exploit, 2) low churn, 3) high churn, 4) $S_1$ exploits.</li>
  <li>Signing up for extra classes are <em>always individually rational</em> (at the expense of others)</li>
</ul>

<p>But what if: social norm solution: signing up extra cause social isolation?</p>

<blockquote>
  <p><strong>Model</strong>: a system of concepts that relates series of observable phenomenon to one another. “A way to navigate more efficiently through those concepts”. How is it useful in social science?</p>

  <ul>
    <li>brief summary of existing knowledge/factors and allow for <em>accumulation of additional knowledge easier</em> (e.g. understand what questions/factors are relevant in order to understand novel scenarios)</li>
    <li>can be tested</li>
    <li>can be used to <em>guide decisions</em> we make</li>
  </ul>
</blockquote>

<h2 id="politics-as-collective-action">Politics as Collective Action</h2>

<p>All political action is ultimately <strong>individual action</strong>. However, only when groups of individuals come together to take <strong>collective action</strong> can they make political decisions that lead to change</p>

<h3 id="background">Background</h3>

<blockquote>
  <p><em>Recall</em> that</p>

  <ul>
    <li><strong>Left-wing</strong>: Left-wing believes in that they believe society is best served with an expanded role for the <strong>government</strong>.</li>
    <li>
      <p><strong>Conservative</strong>: People on the right believe that the best outcome for society is achieved when <strong>individual rights</strong> and civil liberties are paramount and the role of gov is minimized</p>
    </li>
    <li>
      <p><strong>Liberal</strong>: Left-wing, federalist. Prefer more regulation and services like free universal health care to be provided by the government to all citizens.</p>
    </li>
    <li><strong>Conservative</strong>: Right-wing, anti-federalist, Prefer smaller government, less regulation, most services to be provided by the private sector in a free market, and a literal interpretation of the Constitution
      <ul>
        <li>conservatives desire security, predictability and authority more than liberals do, and liberals are more comfortable with novelty, nuance and complexity.</li>
        <li>so conservatives opposes gay marriage, abortion and embryonic stem cell research.</li>
      </ul>
    </li>
    <li><strong>Federalists</strong> wanted a <em>stronger national government</em> and the ratification of the Constitution to help properly manage the debt and tensions</li>
  </ul>

  <p>Last but not least</p>

  <table>
    <thead>
      <tr>
        <th style="text-align: center">Democrats</th>
        <th style="text-align: center">Republics</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td style="text-align: center">In a democracy, the <mark>community of people</mark> are considered to hold power over how they are governed. Kings and tyrants are seen as threats to the innate rights of the people. As such, all eligible citizens get equal say in decisions.</td>
        <td style="text-align: center">Republics are in opposition to rulership by a single person. All eligible citizens get equal say in decisions through <mark>elected representatives</mark>. Unalienable rights of individuals are protected by law to safeguard against a majority abusing the minority</td>
      </tr>
    </tbody>
  </table>
</blockquote>

<p><strong>Ideas/Insights from “Tragedy of Commons”</strong></p>

<ul>
  <li><strong>morality</strong> of an act is a function of the state of the system at the time it is performed (i.e. time and context dependent).
    <ul>
      <li>As a result, it is very difficult to make laws persistent. Hence the current epicyclic solution is, by law we delegate to bureaus</li>
    </ul>
  </li>
  <li><strong>mutual coercion</strong>. the social arrangement that produce <em>responsibility</em> are arrangements that create coercion
    <ul>
      <li>on tax systems: Who enjoys taxes? We all grumble about them. But we accept compulsory taxes because we recognize that voluntary taxes would favor the conscienceless. We institute and support taxes and other coercive devices to <em>escape the horror of the <strong>commons</strong></em>.</li>
      <li>another example: band-robbing. We thereby <em>infringe on the freedom</em> of would-be robbers we neither deny nor regret.</li>
      <li>“individuals locked into the logic of the commons are free only to bring on universal ruin (i.e. deplete themselves); once they see the ncessity of mutual coecion, they become free to pursue other goals” $\implies$ “Freedom is the recognition of necessity”</li>
    </ul>
  </li>
  <li>why is it so hard for <strong>reforms</strong> to happen? Automatic rejection of proposed is based on two unconscious assumptions a) that the status quo is perfect; b) that the choice we face is between reform and no action $\implies$ <em>no action at all while we wait for the perfect proposal</em>. But to be fair, we should see the status quo <em>as an action</em>, and then we can make better comparison.</li>
  <li>“perhaps the simplest summary of this analysis of man’s population problems is this: the commons is justifiable only under conditions of low population density” $\gets$ we abandoned commons n food gathering, enclosing farms and restricting pastures; somewhat later we saw that the commons as a place for waste disposal would also have to be abandoned $\implies$ humans (<strong>in a large scale</strong>) can’t establish self-organization to make a commons work/sustainable</li>
</ul>

<p><strong>How People become political</strong>?</p>

<ul>
  <li>
    <p>The gradual process of developing values and beliefs, of people becoming who they are as adults, is <strong>socialization</strong>, and the slow development of who a person becomes as a political being is <strong>political socialization</strong>. This process shapes your current political belief, and is influenced by countless factors including partly your genetics but also the <em>environment</em> (e.g. your hometown, school, etc.).</p>

    <p>Your social and physical environments <mark>do not determine</mark> your political personality, but they can have an important influence.</p>
  </li>
  <li>
    <p>The <strong>family</strong> is usually considered the most important influence on both a person’s overall socialization and their political socialization.</p>

    <ul>
      <li>but this could also be a complicated factor. How these changing family structures and living conditions impact political socialization?
        <ul>
          <li>e.g. As of 2016, a higher percentage (52 percent) of 18-to-29-year-olds in the <mark>United States</mark> were living with their parents than at any time since 1900. Among wealthy countries, the percentage of 15-to-29 year-olds living with their parents varied from about 80 percent in <mark>Italy</mark> to 30 percent in <mark>Canada</mark>.</li>
        </ul>
      </li>
      <li>but also broader family environment could affect your political view: In China, <em>caring for one’s parents</em> is a <em>sacred</em> duty; in Norway, it is more often seen as an <em>obligation of the government</em>.</li>
    </ul>
  </li>
  <li>
    <p>Another important factor is <strong>your peers</strong>, especially when you grow older/more mature, people tend to <strong>spend more time with your peers than parents</strong></p>

    <ul>
      <li>To the extent that young people, and indeed all individuals, can <em>choose</em> their social networks rather than being placed in them by virtue of their location, it is more likely that peer networks will <strong>reinforce existing beliefs</strong>, attitudes, and behaviors rather than change them.</li>
      <li>One complicating factor is that now, your peers/social network can be <strong>virtual</strong>, hence “a young person’s peers can be almost anywhere in the world”. In this case, political scientists are still trying to decipher what this means for political socialization.</li>
    </ul>
  </li>
  <li>
    <p>Other interesting factors include:</p>

    <ul>
      <li><strong>Ethnicity</strong>: people from dominant ethnic group may assume that politics and government should favor their interests, as they are the majority. Ethnic minorities, in contrast, may be socialized to feel the sting of discrimination and to view the government as no friend.</li>
      <li><strong>Religion</strong>: atheists are more likely to believe that governmental policy should not be based on religious principles.</li>
    </ul>
  </li>
  <li>
    <p>As people are socialized, they become part of larger groupings of individuals with <strong>common characteristics</strong>. The next sections discuss these larger groupings.</p>
  </li>
</ul>

<p><strong>How people express their political identity</strong></p>

<ul>
  <li>The shared <em>political</em> attitudes, values, goals, and practices common to members of a political group, such as a country, a party, or any other political organization or grouping, is the group’s <strong>political culture</strong>.</li>
  <li>A country’s political culture frames how individuals in that society see themselves, as well as their relation to gov.
    <ul>
      <li>e.g. researchers asked <strong>Americans</strong> and <strong>Europeans</strong>, “What’s more important in our society, that everyone can be free to pursue their life’s goals without interference from the state or that the state plays an active role in society so as to guarantee that nobody is in need?” Almost six in 10 Americans surveyed responded that <em>individual freedom</em> was more important, while nearly eight in 10 Lithuanians, whose country was a part of the collectivist Soviet Union for nearly 50 years, responded that the state’s active role was more important.</li>
      <li>therefore, people from United States <mark>*tend*</mark> to <strong>prioritize personal freedom and individual responsibility over more community-centered values</strong>. Of course, not all Americans favor individual freedom over state intervention = <mark>no stereotyping!</mark></li>
    </ul>
  </li>
  <li>Those within a society who, by virtue of their wealth, status, position, and power, have the <strong>greatest influence over the country’s political agenda</strong>, its policy decisions, and its decision-making cadre are the society’s <strong>political elite</strong>.
    <ul>
      <li>The <em><strong>degree</strong> of influence and domination</em> of elite culture varies from country to country.
        <ul>
          <li>At the extreme, in <mark>North Korea</mark>, the ruling class, led by Supreme Leader Kim Jong-un, controls every aspect of political life.</li>
          <li>At the other side would be <mark>New Zealand</mark>. But even the relatively egalitarian New Zealand, however, those with money, status, and power tend to set the agenda, influence policy decisions, and dominate the decision-making process.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>The broadest culture within a country is its <strong>mass culture</strong> (e.g. what movies you like to watch). The lines between elite and mass cultures are not always distinct.
    <ul>
      <li>Prior to the rise of newspapers, radio, and television, <em>mass culture (including political culture) did not exist</em>. All culture was local.</li>
    </ul>
  </li>
  <li>However, as media options proliferate, mass culture diminishes and <strong>minority cultures flourish</strong>. Mass culture, including mass political culture, is <strong>weakening</strong>.
    <ul>
      <li>e.g. About 60 percent of the adult population in America watched the presidential debates between Nixon and Kennedy in 1960. In 2020, even during a highly contentious presidential campaign between President Donald Trump and former Vice President Joe Biden, fewer than 30 percent of adults watched the debates</li>
    </ul>
  </li>
</ul>

<h2 id="collective-dilemma">Collective Dilemma</h2>

<blockquote>
  <p><strong>Key question</strong>: thinking through a collective action framework: How do people organize themselves and behave?</p>
</blockquote>

<p><em>Examples of Collective Actions</em>:</p>

<ul>
  <li>
    <p>Speaker of the House Election in 2023</p>
  </li>
  <li>
    <p>Columbia/Barnard course enrollment</p>
  </li>
</ul>

<p><strong>Making Group Decisions and Collective Dilemma</strong>:</p>

<ul>
  <li>If all people agreed on everything, there would be no collective dilemmas. But because individuals do have differing needs, preferences, and goals, they have to overcome challenges to make a decision. Whenever two or more individuals need to make a plan or resolve a conflict and those involved do not agree on the solution, there is a <strong>collective dilemma</strong>.
    <ul>
      <li>e.g. For 18 days in 2013 and then again for 35 days in 2018–2019, the US government shut down because Congress and the president could not agree on ways to fund federal operations.</li>
    </ul>
  </li>
  <li>causes of collective dilemma include
    <ol>
      <li>
        <p>The first is when the participants disagree because they have <strong>irreconcilable</strong> preferences/differences.</p>

        <ul>
          <li>e.g. reduce debt increase or aid to Ukraine</li>
        </ul>
      </li>
      <li>
        <p>(<strong>coordination problem</strong>) when participants generally agree on what they want to do but <strong>disagree over the details.</strong> Collective action will success only if you <em>do get people doing it</em></p>

        <ul>
          <li>protest march: a million people protested <em>on the same day/time</em></li>
          <li>political institutions make public decision can be seen as a solution to this problem</li>
        </ul>
      </li>
      <li>
        <p>when individual motivations are contrary to the groups’ mutual interests = <strong>collective action problem</strong>. E.g. individuals, acting rationally in pursuit of their <strong>self-interest,</strong> have incentives to make decisions that are harmful to the interests of others</p>
        <ul>
          <li>
            <p>note that the first two can be seen as some kind of <em>coordination costs</em>. This problem, like with prisoner’s dilemmas, is that individuals have strong incentives to do things that are not socially beneficial.</p>
          </li>
          <li>
            <p>this problem can be broadly categorized into:</p>
            <ol>
              <li>
                <p><strong>tragedy of the commons</strong>: depletion of a resource available to all (e.g. threats to environment/health);relevant to a resource that can be <em>exhausted</em></p>

                <ul>
                  <li>e.g. fresh water</li>
                  <li>if everyone has access to a commons, then there is an incentive for them to take more than needed $\implies$ can sell this scarce resource $\implies$ benefit today without consideration of future consequences (depletion)
                    <ul>
                      <li>i.e. users ignores cost imposed on others, focus on own short-term benefits</li>
                    </ul>
                  </li>
                  <li><em>too rapid inclusion of others</em>: new users do not share a similar understanding of how a resource work $\implies$ members of the initial community may feel threatened and hence start to join race to exploit the resource</li>
                </ul>
              </li>
              <li>
                <p><strong>free riding</strong>: not participating in a group activity nonetheless benefit from the <em>public activity</em>; also really hard to <em>exclude people</em> from using it, and <em>not exhausted by use</em></p>

                <ul>
                  <li>
                    <p>e.g. Columbia protest for increasing of pay, where many people can benefit without joining the protest</p>
                  </li>
                  <li>in small groups, this might be fine through mutual peer pressure and you care about others feelings. In larger political world, the problem of free riding is much harder to spot and manage</li>
                  <li>e.g. to help climate change, the Paris Climate Accord of 2015, the agreement of 197 countries to limit global warming. However, in reality only a few really implemented those changes. As a result, change is difficult to achieve, given its tendency to <strong>favor the status quo</strong>. (to suggest that climate change politics are only a matter of free riding would be an oversimplification.)</li>
                </ul>
              </li>
              <li>
                <p><strong>prisoner’s dilemma</strong>: individuals act strategically in ways that ultimately harm themselves, demonstrates why it can be challenging to get allies to work together.</p>

                <ul>
                  <li>
                    <p>consider two people being caught by the police, and is asked separately to point out if the others committed crime:</p>

                    <p><img src="/lectures/images/2023-05-11-POLS1201_Intro_to_American_Politics/image-20230121155451809.png" alt="image-20230121155451809" style="zoom:30%;" /></p>

                    <p>This is the prisoner’s dilemma: individuals, acting strategically in their own self-interest (want to accuse others), have incentives that lead them to take actions that result in unnecessarily negative outcomes for both parties.</p>
                  </li>
                  <li>
                    <p>an example in real life is: Two opposing political candidates may each prefer to run only positive campaign ads, but each fears the other will “go negative” to gain an advantage. Both candidates consequently <strong>run negative ads</strong>, which tarnish the reputations of each.</p>
                  </li>
                  <li>
                    <p>one key feature of prisoner’s dilemma is that the <mark>optimal policy for one person $\neq$ the optimal policy for the entire group</mark></p>
                  </li>
                </ul>
              </li>
            </ol>

            <blockquote>
              <p>The tragedy of the commons and the prospect of free riding are especially relevant for slow-growing crises like climate change.</p>
            </blockquote>
          </li>
        </ul>
      </li>
    </ol>
  </li>
</ul>

<p>Note that in practice, a bunch of these problems could come up combinatorially.</p>

<h3 id="potential-solutions-to-collective-dilemma">Potential Solutions to Collective Dilemma</h3>

<p><mark>Solutions</mark> to those collective dilemma include include:</p>

<ol>
  <li>
    <p><strong>rules for making a decision</strong> when there is <mark>irreconcilable</mark> preference, e.g. majority vote.</p>

    <ul>
      <li>majority voting: more than 50% agreed</li>
      <li>plurality voting: proposal with most votes</li>
      <li>super-majority: requires sometimes 60%, 67%, or even 75% to agree. Otherwise status-quo = no change
        <ul>
          <li>e.g. supermajority is found in most <strong>US</strong> courtrooms = decide if to jail a person</li>
          <li>e.g. constitutional changes subject to supermajority votes and laws changeable by a simple majority.
            <ul>
              <li>A constitution typically outlines the government’s general powers and duties, while laws fill in the specifics regarding these matters.</li>
            </ul>
          </li>
          <li>One sensible rationale is that the greater the consequences of a decision, the greater the need for a supermajority to guard against making rash or incorrect decisions.</li>
        </ul>
      </li>
      <li>Whenever a <strong>supermajority</strong> rule exists, the status quo is more difficult to change.</li>
    </ul>
  </li>
  <li>
    <p><strong>delegate decision making to a person</strong>, or <strong>do everything by group decision</strong> when there is disagreement over details</p>

    <ul>
      <li>Delegating power to a single person reduces <strong>transaction costs</strong> but increases <strong>conformity costs</strong>. Group decision-making is likely to reduce conformity costs but to increase transaction costs.</li>
      <li><strong>transactional costs</strong>: how much time and effort to make a decision/implement the solution
        <ul>
          <li>e.g. decide amongst 300 people to agree on where to eat = high transactional cost</li>
          <li>e.g. If you are deeply committed to maintain the status quo, then you just need to raise the transaction costs high enough so that no changes can be enacted.</li>
        </ul>
      </li>
      <li><strong>conformity costs</strong> are the “price” those who do not get what they want must
        <ul>
          <li>e.g. in primary/secondary school, high conformity cost as everyone needs to study the same curriculum. In college, lower as you can choose your major/minor, but higher transactional costs as it takes additional registration effort</li>
        </ul>
      </li>
    </ul>

    <p>Political Institutions as solutions to those Problems of Collective Behavior!</p>

    <blockquote>
      <p><strong>Institutions</strong>: a social structure, rule or pattern than can <mark>influence collective behavior</mark>. For example, the supreme court, or the university registrar (determines rule of how you can join the class if you are on the waitlist)</p>
    </blockquote>
  </li>
  <li>
    <p>the most difficult amongst all</p>

    <ol>
      <li>
        <p>resolving tragedy of commons</p>

        <ul>
          <li>
            <p><strong>for small groups</strong>: Each of the three main types of collective action problems is easier to solve, at least in principle, when the problems arise within small groups of people (such as families or tribal units) in which the members know each other well</p>

            <ul>
              <li>provide suitable rewards and enforce appropriate punishments are the keys to avoiding or mitigating collective action problems.</li>
            </ul>
          </li>
          <li>
            <p><strong>for large groups</strong>: collective action problems involving large numbers of people cannot rely on personal relationships</p>

            <ul>
              <li>central institution (the government) the authority to protect the commons through <strong>force</strong>. Alternatively, <strong>privatize</strong> them. But there are also problems</li>
              <li>however, gov may use the resource for the benefits of the elites</li>
              <li>The more politically powerful the group previous exploiting the commons, the more <em>difficult</em> it is for elected officials to protect the resource through privatization. Even if no pressure, it is difficult to set the right price “if the government sets the prices (of fishing permits) too low, the resource will be depleted, and if it sets the prices too high, the community will be deprived of a valuable resource.”</li>
            </ul>
          </li>
          <li>
            <p><strong>for communities</strong>: member roughly know each other</p>

            <ul>
              <li>
                <p>previous solutions are somewhat <em>pessimistic</em> of human’s ability to device long-term, sustainable institutions. In practice, there are a lot of instances when human self-organizations are effective</p>

                <ul>
                  <li>groups of people who can identify one another (e.g. via media) are more likely to draw on trust and reciprocity.</li>
                  <li>e.g. those with reciprocity gain a positive reputation, and others become willing to cooperate = <strong>evolved norms</strong></li>
                  <li>lower the perceived cost: users understand the dynamics of the commons, and hence <strong>value its sustainability</strong></li>
                </ul>
              </li>
              <li>
                <p>Nobel prize winner Elinor Ostrom proposed a relatively effective solution without sovereign or privatization.</p>

                <ol>
                  <li>First, the community must engage in collective decision-making so that all relevant interests can participate.</li>
                  <li>Second, the rules the community makes must be clear so that members know what is allowed and what is not.</li>
                </ol>

                <p>If these conditions are in place, the decisions the community makes are likely to be wise and enforceable</p>
              </li>
            </ul>
          </li>
        </ul>
      </li>
      <li>
        <p>resolving free rider: <strong>disincentivize free riders</strong></p>

        <ol>
          <li>e.g. keep groups small, or give punishments to those who don’t. However, this requires additional monitoring cost</li>
          <li>e.g. social solidarity: pay taxes because that is what good, patriotic citizens do.</li>
        </ol>
      </li>
      <li>
        <p>resolving prisoners’ dilemma: <strong>make them cooperate</strong></p>

        <ul>
          <li>A participant is least likely to defect when they know that the other participant will punish them if they do. (e.g. if they each know they will be punished if they defect, then they are <em>more likely to remain silent</em>.)</li>
          <li>Once one of the parties defects in a prisoner’s dilemma setting, it is not easy to get the participants to cooperate later.
            <ul>
              <li>As in the persistent conflict between <mark>Israelis</mark> and <mark>Palestinians</mark>, cases where any two groups are locked in intractable disagreements exemplify how tit-for-tat retaliation dominates any possibility of mutual agreement.</li>
              <li>Avoiding this outcome requires a <strong>third party</strong> that can enforce cooperation or punish those who defect to induce future cooperation.</li>
            </ul>
          </li>
        </ul>
      </li>
    </ol>
  </li>
</ol>

<p><em>Example</em>: How does <strong>policing</strong> help solve collective action problem by intervention?</p>

<p>Consider for a normal <em>individual</em> to intervene and prevent a bad action $A$ to happen:</p>

<table>
  <thead>
    <tr>
      <th> </th>
      <th>Positive</th>
      <th>Negative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Intervene</td>
      <td>prevent action (A), gain pride (P)</td>
      <td>takes effort (E), may be harmed (H), may face retaliation (R)</td>
    </tr>
    <tr>
      <td>No Intervention</td>
      <td> </td>
      <td>Action occurs</td>
    </tr>
  </tbody>
</table>

<p>Therefore, a rational person will intervene if</p>

\[\text{intervene if:  }\quad P -  E - \pi_1 R - \pi_2 H - (1-\pi_3)A &gt; -A\]

<p>where $\pi_1$ is prob of retaliation happens, $\pi_2$ is when that person is harmed, etc.</p>

<p>But if we have <em>coordination</em>, what could change? (e.g. a group of people intervening at the same time)</p>

<ul>
  <li>probabilities would change (e.g. less likely to be retaliated). $\pi_1,\pi_2 \downarrow$, $\pi_3 \uparrow$</li>
  <li>benefit/costs would change (e.g. less effort needed $E$)</li>
</ul>

<blockquote>
  <p><strong>Written laws</strong> can provide this “improvement”, as it can help people <em>coordinate</em> enforcement.</p>

  <ul>
    <li>but of course, don’t forget <em>conformity</em> cost such as make some people particularly prone to punishments</li>
  </ul>
</blockquote>

<p>What’s different for <strong>designated specialist</strong> (e.g. having a police department)? They can <em>still</em> be modeled as individuals we had before, but</p>

<table>
  <thead>
    <tr>
      <th> </th>
      <th>Positive</th>
      <th>Negative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Intervene</td>
      <td>prevent action (A), gain pride (P)</td>
      <td>takes effort (E), may be harmed (H), may face retaliation (R)</td>
    </tr>
    <tr>
      <td>No Intervention</td>
      <td> </td>
      <td>Action occurs, <mark>Discipline (D)</mark></td>
    </tr>
  </tbody>
</table>

<ul>
  <li>probabilities change (e.g. $\pi_3$ increases as they are trained)</li>
  <li>you get an extra cost of enforcers, hence <mark>more likely</mark> the action being prevented to happen!</li>
</ul>

\[\text{intervene if:  }\quad P -  E - \pi_1 R - \pi_2 H - (1-\pi_3)A &gt; -A\textcolor{red}{-D}\]

<p>like providing public goods, a good solution is to <em>“force”</em> the production, i.e.</p>

<blockquote>
  <p><strong>Institutions as solutions</strong> to collective action problem. A single institution can solve/raise multiple “problems”:</p>

  <ul>
    <li>e.g. (-) police enforcers can preserve group inequality, e.g. more south American drinking alcohol $\implies$ being policed more often $\implies$ treats unequal treatments to south American $\implies$ being checked on/cautioned more than other ethnic groups</li>
    <li>e.g. (+) written laws can coordinate enforcement AND protect property</li>
  </ul>
</blockquote>

<p>But this beg several questions/understandings:</p>

<ul>
  <li>when and why do institutions change?</li>
  <li>When are they <em>resistant</em> to change?</li>
  <li>How are institutions chosen?</li>
</ul>

<h2 id="institutional-change">Institutional Change</h2>

<blockquote>
  <p>Political Institutions can be modeled as <strong>increasing returns processes</strong>. As a result:</p>

  <ol>
    <li>a wide range of outcomes can result from same initial conditions</li>
    <li>small actions at the right time can gave large implications for institutional form</li>
    <li>when an event occur matter! (esp. <em>early changes</em> matters)</li>
    <li>once begun, change is difficult (hard to <em>reverse</em>, i.e. <em>path dependence</em>)</li>
  </ol>
</blockquote>

<p>What is increasing returns and path dependence? From “Increasing Returns, Path Dependence, and the Study of Politics” by Paul Pierson</p>

<ul>
  <li>
    <p>the concept of <strong>Path Dependence</strong> can be used in various ways. Here, the author means</p>

    <ol>
      <li>specific patterns of timing and sequence matter;</li>
      <li>large consequences may result from relatively “small” or contingent events; (also see <em>increasing returns</em>)</li>
      <li>particular courses of action, once introduced, can be virtually impossible to reverse; (also see <em>increasing returns</em>)</li>
    </ol>

    <p>those are different from other prominent modes of argument and explaination in political science $\implies$ attribute “large” outcomes to “large” causes</p>
  </li>
  <li>
    <p><strong>Increasing returns</strong>, or self-reinforcing process, refers to the case that “preceding steps in a particular direction <strong>induce further movement in the same direction</strong>”. As a result, the relative benefits of the current activity (or the cost of switching) compared with other possible options <strong>increase over time</strong>.</p>

    <ul>
      <li>e.g. the Polya urn process in which each time you pick a ball, you need to add a ball of the same color into the urn $\implies$ <em>small</em>/random picks in the <em>beginning</em> gives a <em>large</em> effect to the <em>final</em> equilibrium configuration of balls.</li>
      <li>therefore, <strong>sequence is crucial</strong> (path dependent), and <mark>earlier events matter much more than later ones</mark></li>
    </ul>
  </li>
  <li>
    <p>insights from increasing returns in <em>economics</em></p>

    <ul>
      <li>
        <p>the most prominent example is perhaps on <strong>technology</strong>: a particular technology may achieve a decisive advantage over competitors, although it is <mark>not necessarily the most efficient alternative</mark> in the long run. This is because when it is subject to increasing returns (higher pay-off when more user uses it), being the <em>fastest out of the gate</em> becomes critical. Then, once positive feedback effects kick in, competitors are excluded and people are locked in this technology (e.g. “QWERTY” keyboard)</p>

        <p>However, not all technologies work like this. Arthur (1994) listed the four criteria</p>

        <ol>
          <li><strong>large set-up/fixed costs</strong>: so that a) it becomes smaller for the company when production increases b) individual users have incentive to stick with a single option</li>
          <li><strong>learning effects</strong>: the more you use it, the more knowledge gained in this system, and this loop continues/spur further innovations (e.g. plugin system)</li>
          <li><strong>coordination effects</strong>: benefits an individual receives from a particular activity increase as others adopt the same option.</li>
          <li><strong>adaptive expectations</strong>: users are willing to <em>adapt their behaviors</em> towards their future expectation of a product (even if it is bad)</li>
        </ol>
      </li>
      <li>
        <p>examples that worked like this include</p>

        <ul>
          <li>initial <em>centers of economic activity</em> may act like a magnet and influence the locational decisions and investments of other economic actor (e.g. silicon valley)</li>
          <li>(North 1990a, 95) <mark>new institutions</mark> often entail high fixed or start-up costs, and they involve considerable learning effects, coordination effects, and adaptive expectations. Established institutions generate powerful inducements that reinforce their own stability and further development.</li>
          <li>Additionally, <mark>institutional arrangements</mark> induce complementary organizational forms, which in turn may generate new complementary institution</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>how/why is <strong>political science</strong> related to this idea of increasing returns?</p>

    <ul>
      <li><strong>collective nature of politics</strong> in economics, I make individual decisions (e.g. switch firms) and the outcome is aggregated by the market. In politics, your decision depend to a considerable degree on your confidence that <em>a large number of other people will do the same</em> $\implies$ positive feedback frequently due to <em>adaptive expectations</em>
        <ul>
          <li>recall that in politics, <strong>creating conditions favorable to collective action</strong> is a principal issue in political life</li>
        </ul>
      </li>
      <li><strong>institutional density of politics</strong>. Institutions and policies may encourage individuals and organizations to invest in specialized skills, deepen relationships with other individuals and organizations, and develop particular political and social identities. These activities <em>increase attractiveness of existing institutional arrangements</em> relative to hypothetical alternatives</li>
      <li><strong>political authority and power asymmetries</strong>. relatively small disparities in political resources (e.g. power) among contending groups may <em>widen dramatically</em> over time as positive feedback sets in. For example, a group with slightly more power could change rules of the game <strong>designed to enhance their power</strong></li>
      <li><strong>complexity and opacity of politics</strong>. in economics, there is often a clear metric (e.g. market price) on how good you/your company is performing. Politics is a <strong>far, far murkier</strong> environment.
        <ul>
          <li>researchers argue that actors who operate in a social context of high complexity and opacity are heavily biased in the way they <em>filter information</em> into existing “mental maps” $\implies$ confirming information is incorporated/dis-confirming is filtered out $\implies$increasing returns</li>
          <li><strong>harder to “reverse course”</strong> in politics than in economics $\implies$ path dependent
            <ul>
              <li>unlike <strong>competition</strong> in economics that would allow a sub-optimal firm eventually be replaced, political institutions rarely confront a <em>dense</em> environment of competing institutions that will instantly capitalize on inefficient performance</li>
              <li><strong>short-time horizon of political actors</strong>. many actors are interested in short-term consequences because the decision of voters are take in the short turn $\implies$ pay little attention to long term consequences</li>
              <li><strong>power asymmetry</strong>. political actors may create rule that make preexisting arrangement hard to reverse (e.g. to protect themselves); and there is often high barriers of reform (e.g. unanimity requirement in EU)</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<blockquote>
  <p><em>“Research Idea”</em>: how can tech such as VR change the density problem</p>
</blockquote>

<h2 id="research-design">Research Design</h2>

<p>An overview:</p>

<ul>
  <li>
    <p>In legal practice, law determines what facts are relevant, but you have to decide what (e.g. numbers) to demonstrate</p>
  </li>
  <li>in advocacy sector, people care the <em>effect</em> of a proposed policy</li>
  <li>in consulting, what changes would affect certain variables in a system</li>
</ul>

<p>In a quantitative study, you may want to:</p>

<ol>
  <li>come up with a model for a key concept (e.g. poverty)</li>
  <li>develop variables to measure the key concept</li>
  <li>develop hypotheses how variables should relate, and other competing models</li>
  <li>collect data</li>
  <li>test (statistically) whether the relationship holds in your data</li>
</ol>

<p>Keep in mind when you are measuring quantities</p>

<ul>
  <li>
    <p>e.g. annual reports released by institutions might be understating; survey results depend on who you asked</p>
  </li>
  <li>e.g. how to measure democratic participation? e.g. voter turn outs, protest participation, watching presidential debates. All of them measure <em>slightly different things</em>, and you need to be clear if your method is <strong>justified</strong>.</li>
  <li>certain data could be <em>biased</em>. e.g. posters showing low support for a president could be due to only people dislike him is in the pool</li>
</ul>

<p>How do you fix the above problems? Consider a candidate claiming election is going to be fraudulent</p>

<ul>
  <li>gather data on many elections where one candidate claims it will be fraudulent, compare them</li>
  <li>gather data on many elections where one candidate claims it will be fraudulent <mark>and some without</mark>, compare them</li>
</ul>

<blockquote>
  <p>Statements about <mark>causation</mark> make claims about what happens with and without some factor, so must define <mark>both kinds of cases</mark></p>
</blockquote>

<p><em>More Examples</em>: a report of studying 173 mass violence happened in US in the past few years</p>

<ul>
  <li>found in those 173 mass violences in common = at some point had suffered from mental illness $\implies$ <mark>does not mean mental illness will cause those violences!</mark></li>
  <li>also does not teach us about how these acts can be prevented</li>
</ul>

<h1 id="institutions-in-us">Institutions in US</h1>

<p>How successful/unsuccessful <strong>institutions can be</strong> at solving the collective action problem?</p>

<blockquote>
  <p><strong>Origin of Separation of Power</strong>: the US separation of power can be traced back to colonial governments by the British. Why did British monarch create strong legislature (alongside the local governments) in it $N$ American colonies?</p>

  <ul>
    <li>purpose of colonies was resource extraction; but governors have the incentive to pocket more than efficient for the crown</li>
    <li>then, this is used as a way for the crown to <mark>control/constrain those local elites</mark></li>
  </ul>

  <p>so it is lodged in the economic reason of those colonial power</p>
</blockquote>

<p>First of all, several key terms</p>

<blockquote>
  <ul>
    <li>
      <p><strong>confederation</strong> = each state is loosely related, like its separate countries = <em>high degree of freedom/autonomy</em></p>
    </li>
    <li><strong>unitary</strong> = power is concentrated in the hands of the central government, while <em>provinces and regions do not enjoy large autonomy</em>
      <ul>
        <li>has nothing to do with democracy/monarchy</li>
      </ul>
    </li>
    <li>
      <p><strong>federal</strong> = federal government as sovereign entity, but also given <em>lower level units (states) to have their own laws</em></p>

      <p><img src="https://openstax.org/apps/archive/20221219.191545/resources/df7dffd16667f5c2ff8a13c934b26b0dc1afa256" alt="A flow chart depicts the three general systems of government: the unitary system, the federation, and the confederation. The unitary system flowchart starts with the National Government, which flows down to the States. Below the chart, it says, “Authority is concentrated in the central government. Examples: United Kingdom, Japan, Sweden.” The Federation flow chart starts with the People on top. The flow branches down and splits between two boxes; the states, and the National Government. Below this chart, it says, “Authority is divided between central and state governments and is derived from the people. Examples: Canada, India, United States under the Constitution”. The Confederation flow chart starts with the States on top, with an arrow flowing down to the National Government. Under this chart, it says “Authority is concentrated in states. Example: United States under the Articles of Confederation”." style="zoom:33%;" /></p>
    </li>
    <li>
      <p><strong>unicameral</strong> legislature has only one chamber, or body, that makes decisions.</p>
    </li>
    <li><strong>bicameral</strong> legislature has two chambers, often with different procedures and powers, that ultimately must work together to make policy and exercise other legislative powers and responsibilities.</li>
  </ul>
</blockquote>

<h2 id="the-us-constitution-basics">The US Constitution Basics</h2>

<blockquote>
  <p><strong>The US Constitution</strong> The Constitution of the United States established America’s national government and fundamental laws, and guaranteed certain basic rights for its citizens.</p>

  <ul>
    <li>
      <p>Its 7 sections (or <em>Articles</em>) detail the core components of how the framers wanted the government to run the country. For example, no the duties of the three main parts of government: the <em>Executive Branch</em>, the <em>Legislative Branch</em>, and the <em>Judicial Branch</em></p>
    </li>
    <li>
      <p><em>The Bill of Rights</em> were <em>first</em> 10 amendments guaranteeing basic individual protections, such as freedom of speech and religion, that became part of the Constitution in 1791. To date, there are 27 constitutional amendments.</p>
    </li>
  </ul>
</blockquote>

<p>Some short historical facts about it:</p>

<ul>
  <li>
    <p>Under America’s first governing document, the Articles of Confederation, the national government was weak and states operated like independent countries.</p>
  </li>
  <li>
    <p>At the 1787 convention, delegates devised a plan for a stronger federal government with three branches—executive, legislative and judicial—along with a system of checks and balances to ensure no single branch would have too much power. This is the US Constitutional Convention in Philadelphia, signed on September 17, 1787.</p>
  </li>
</ul>

<p>Its content in summary (from https://www.pbs.org/newshour/classroom/app/uploads/2013/11/summary-of-the-US-Constitution.pdf)</p>

<ol>
  <li>Article 1: <strong>Legislative Branch</strong>: the <mark>U.S. Congress</mark> makes the laws for the United States. Congress has two parts, called “<mark>Houses</mark>,” the House of Representatives and the Senate.</li>
  <li>Article 2: <strong>Executive Branch</strong>: the President, Vice-President, Cabinet, and Departments under the Cabinet Secretaries carry out the laws made by Congress.</li>
  <li>Article 3: <strong>Judicial Branch</strong>: the <em>Supreme Court</em> decides court cases according to US Constitution. The courts under the Supreme Court decide criminal and civil court cases according to the correct federal, state, and local laws.</li>
  <li>Article 4: <strong>States’ powers</strong>: States have the power to make and carry out their own laws. State laws that are related to the people and problems of their area. States respect other states laws and work together with other states to fix regional problems.</li>
  <li>Article 5: <strong>Amendments</strong>: The Constitution can be changed. New amendments can be added to the US Constitution with the approval by a <mark>two-thirds vote</mark> in each house of Congress (67, 281) and <mark>three-fourth</mark> vote by the states (38).</li>
  <li>Article 6: <strong>Federal powers</strong>: The Constitution and federal laws are higher than state and local laws. All laws must agree with the US Constitution.</li>
  <li>Article 7: <strong>Ratification</strong>: The Constitution was presented to George Washington and the men at the Constitutional Convention on September 17, 1787, Representatives from twelve out of the thirteen original states signed the Constitution. From September 1787 to July 1788, the states meet, talked about, and finally voted to approve the Constitution</li>
</ol>

<p>A few selected amendments which is important/interesting (IMO):</p>

<ul>
  <li>2nd People have the right to <strong>have a weapon to protect themselves</strong>.</li>
  <li>4th The government <em>cannot</em> arrest a person or <em>search their property</em> unless there is “probable cause.”</li>
  <li>13th Slavery is illegal in the United States. (1865)</li>
  <li>14th Every person <strong>born in the USA is a citizen</strong>. An immigrant can become a naturalized citizen. (1868)</li>
  <li>20th The President is inaugurated in January. Congress begins to meet in January. (1933).</li>
  <li>21st Alcohol is legal. <strong>Each state can make laws</strong> about making, selling, and drinking alcohol. (1933).</li>
  <li>22nd The President <strong>cannot serve for more than two terms</strong>. (1951).</li>
</ul>

<hr />

<p>The <a href="https://openstax.org/books/american-government-3e/pages/2-introduction">textbook</a>’s take on the Constitution:</p>

<ul>
  <li>
    <p>should <em>not</em> be seen as a group of like-minded men aligned in their lofty thinking regarding rights and freedoms; you should not refrain from proposing changes just because you admire the <em>longevity</em></p>
  </li>
  <li>
    <p>was designed largely out of necessity following the failure of the first revolutionary government, and it featured a series of <mark>pragmatic compromises</mark> among its disparate stakeholders. It</p>
  </li>
</ul>

<h3 id="origin-of-the-us-constitution">Origin of the US Constitution</h3>

<blockquote>
  <p>How did the Constitution come about?</p>
</blockquote>

<p>The most significant contributions of <mark>Locke</mark>, a seventeenth-century English philosopher, were his ideas regarding the relationship between <strong>government</strong> and <strong>natural rights</strong>, which were believed to be God-given rights to life, liberty, and property.</p>

<p><img src="https://openstax.org/apps/archive/20221219.191545/resources/142952f76fb24a99b4f7847bb319209606c14d58" alt="A painting shows John Locke." style="zoom:50%;" /></p>

<p>for example:</p>

<ul>
  <li>The English Bill of Rights, heavily influenced by Locke’s ideas, enumerated the rights of English citizens and explicitly guaranteed rights to life, liberty, and property.</li>
  <li>Perhaps the most important of Locke’s ideas was regarding the <strong>origins and purpose of government</strong>.
    <ul>
      <li>Most Europeans of the time believed the institution of monarchy had been created by God, and kings and queens had been divinely appointed to rule. Locke, however, theorized that <em>human beings</em>, not God, had created government.</li>
      <li>Locked believed in <strong>social contract</strong>: people sacrificed a small portion of their freedom and consented to be ruled in exchange for the government’s protection of their lives, liberty, and property.</li>
    </ul>
  </li>
  <li>The desire to limit the power of government is closely related to the belief that people should govern themselves $\iff$ the idea of representative government (people vote for choosing representatives)</li>
</ul>

<hr />

<p>A brief history, starting with <strong>Pre-revolutionary Period</strong></p>

<ol>
  <li><mark>US colonists</mark> lived under the rule of the British government for more than a century</li>
  <li>In 1763, Seven Years War between Great Britain and France came to an end.
    <ul>
      <li>Even though US colonists fought alone side British, they were <em>forbidden to purchase land or settle</em> west of the Appalachian Mountains (belonged to the French).</li>
      <li>To raise revenue for post-war, British also imposed of <em>direct taxes</em>: taxes imposed on individuals, yet North American colonists were <em>not allowed to elect representatives</em> to the British Parliament who made this law.</li>
      <li>other similar regulations include Stamp Act (1765), which required that almost all paper goods, such as diplomas, land deeds, contracts, and newspapers, have revenue stamps placed on them; and Townshend Acts (1767), which imposed taxes on many everyday objects such as glass, tea, and paint.</li>
    </ul>
  </li>
  <li>In 1768, US colonists decided to <em>boycott</em> British goods as a mean to show dissent. The British then sent a warship to the city in 1768.</li>
  <li>on the evening of March 5, 1770, an altercation erupted outside the customs house, and soldiers opened fire on the crowd, killing five colonists and injuring six others. <strong>Boston Massacre</strong></li>
  <li>more resistance in 1773, such as <strong>Boston’s Tea Party</strong>, to threw its cargo of tea, owned by the British East India Company, into the water to protest British policies.</li>
  <li>In 1774, British responded by passing a series of laws called the Coercive Acts, intended to punish Boston for leading resistance
    <ul>
      <li>virtually <strong>abolished</strong> town meetings in Massachusetts and otherwise interfered with the colony’s ability to govern itself.</li>
      <li>This assault on Massachusetts and its economy enraged people throughout the colonies, and delegates from all the colonies except Georgia formed the <strong>First Continental Congress</strong></li>
    </ul>
  </li>
  <li>On July 2, 1776, Congress declared American independence from Britain and two days later signed the <strong>Declaration of Independence</strong>.
    <ul>
      <li>drafted by <strong>Thomas Jefferson</strong>, basically on the belief that “God, he wrote, had given everyone the rights of life, liberty, and the pursuit of happiness. People had created governments to protect these rights and consented to be governed by them so long as government functioned as intended.”</li>
    </ul>
  </li>
</ol>

<p><strong>Articles of Confederation</strong>: basically having</p>

<ul>
  <li>no executive or judicial branches</li>
  <li>unicameral legislature with equal representation</li>
  <li>limited central government powers, state responsible for implementing central laws</li>
</ul>

<ol>
  <li>
    <p>aimed to create a new government strong enough to win the country’s independence but <em>not so powerful that it would deprive people</em>. Thus, a <strong>confederation</strong> was created—an entity in which independent, self-governing states form a union</p>
  </li>
  <li>
    <p>The final draft of the <strong>Articles of Confederation</strong>, which formed the basis of the new nation’s government, was accepted by Congress in November 1777. However, as you will soon see, this faced problem of establishing a <em>(too) weak central government</em> that was unable to fund itself, regulate trade, or enforce laws.</p>
  </li>
  <li>
    <p>However, this soon people realized that the Articles had created a central government <strong>too weak to function effectively.</strong></p>

    <table>
      <thead>
        <tr>
          <th style="text-align: left">Weakness of the Articles of Confederation</th>
          <th style="text-align: left">Why Was This a Problem?</th>
          <th>Collective Action Problem?</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td style="text-align: left">The national government could not impose taxes on citizens. It could only request money from the states.</td>
          <td style="text-align: left">Requests for money were usually not honored. As a result, the national government did not have money to <strong>pay for national defense</strong> or fulfill its other responsibilities.</td>
          <td><strong>free-rider</strong> = central government provides some services, but in return you do not give anything back</td>
        </tr>
        <tr>
          <td style="text-align: left">The national government could not regulate foreign trade or interstate commerce.</td>
          <td style="text-align: left">The government could not prevent <strong>foreign countries</strong> from hurting American competitors by shipping inexpensive products to the United States. It could not prevent states from passing laws that interfered with domestic trade.</td>
          <td><strong>coordination problem</strong> = absent of a single policy for people, hence people act on their own plans</td>
        </tr>
        <tr>
          <td style="text-align: left">The national government could not raise an army. It had to request the states to send men.</td>
          <td style="text-align: left">State governments could choose not to honor Congress’s request for troops. This would make it <strong>hard to defend</strong> the nation.</td>
          <td><strong>free-rider</strong>, etc.</td>
        </tr>
        <tr>
          <td style="text-align: left">Each state had only one vote in Congress regardless of its size.</td>
          <td style="text-align: left">Populous states were <strong>less well represented</strong>.</td>
          <td> </td>
        </tr>
        <tr>
          <td style="text-align: left">The Articles could not be changed without a unanimous vote to do so.</td>
          <td style="text-align: left">Problems with the Articles <strong>could not be easily fixed</strong>.</td>
          <td> </td>
        </tr>
        <tr>
          <td style="text-align: left">There was no national judicial system.</td>
          <td style="text-align: left">Judiciaries are important enforcers of national government power.</td>
          <td> </td>
        </tr>
      </tbody>
    </table>

    <p>Additional collective action problems unaddressed:</p>
    <ul>
      <li>no central currency (coordination problem)</li>
    </ul>
  </li>
  <li>
    <p>In 1786, <strong>Shays’ Rebellion</strong> essentially acted as the trigger for people to find a solution and resolve problems related to commerce, members of Congress called for a revision of the Articles of Confederation.</p>

    <ul>
      <li>Led by Daniel Shays, the heavily indebted farmers marched to a local courthouse demanding relief.</li>
      <li>the incident panicked the governor of Massachusetts, who called upon the national government for assistance.</li>
      <li>However, with no power to raise an army, the government had <em>no troops at its disposal</em>.</li>
    </ul>
  </li>
</ol>

<p><strong>The development of the Constitutions</strong></p>

<blockquote>
  <p>Can be seen as an approach to <strong>solve collective action problems</strong> evident under Articles of Confederation, with a central government being too weak.</p>
</blockquote>

<p>An interesting side note when looking at the debate between those large and small states: <em>Who has the most power in bargaining situation, where agreement is necessary for creation of collective good?</em></p>

<ul>
  <li>a state whose presence for this creation of collective good is <strong>very important</strong>, i.e. will hurt a lot if they decided to drop out</li>
  <li>basically, it depends on the payoff if the agreement is made/fails
    <ul>
      <li>without which: small states more vulnerable to attacks</li>
      <li>with which: large states benefit more (e.g. economically) from stability</li>
    </ul>
  </li>
</ul>

<ol>
  <li>
    <p>Because the shortcomings of the Articles of Confederation proved impossible to overcome, the convention that met in Philadelphia in <strong>1787</strong> decided to create an <strong>entirely new government</strong>.</p>
  </li>
  <li>
    <p>There, a few major points of contention among fifty-five delegates as Philedelphia was</p>

    <ul>
      <li><strong>Small States vs. Large States</strong>: each state one vote (New Jersey Plan) or based on population size (Virginia Plan)?
        <ul>
          <li><strong>Virginia Plan</strong>: preferred by large states and nationalists
            <ul>
              <li>bicameral legislature</li>
              <li>representation based on population</li>
              <li>national government could make any law necessary</li>
            </ul>
          </li>
          <li><strong>New Jersey Plan:</strong>
            <ul>
              <li>unicameral legislature</li>
              <li>equal representation of all states</li>
              <li>limited national government authority, but power of do direct taxation</li>
            </ul>
          </li>
          <li>e.g. still relevant in debate today, whether representation should be proportional to <em>citizen population</em> or <em>just population</em></li>
        </ul>
      </li>
      <li><strong>Slavery and Freedom</strong>: Although some southerners shared similar sentiments, none of the southern states had abolished slavery and none wanted the Constitution to interfere with the institution.</li>
      <li><strong>Federal Supremacy v.s. State Supremacy</strong>: favored a strong national government (necessary for the survival and efficient functioning of the new nation) and those who favored limiting its powers and allowing states to govern
        <ul>
          <li>e.g. overturn of Roe v Wade today.</li>
          <li>e.g. president passing executive orders = president making policy change <em>independent of legislature</em></li>
        </ul>
      </li>
      <li><strong>Individual Liberty v.s. Social Stability</strong> <em>guarantee</em> the rights of life, liberty, and property v.s. more important for the national government to maintain order, and this might require it to <em>limit personal liberty at times</em>.</li>
    </ul>
  </li>
  <li>
    <p>Finally in <mark>1787 September</mark>—after compromising many times—they had worked out a new blueprint for the nation. A overview of US Constitutions have been provided before, and here are the solutions to those major points of contention:</p>

    <ul>
      <li>
        <p><strong>The Great Compromise</strong>. Congress = Senate + House of Representatives = <strong>Bicameral</strong>. (Senate) Each state, regardless of size, would have two senators, making for equal representation as in the New Jersey Plan. (House of Representatives) Representation in the House would be based on population.</p>

        <ul>
          <li>gives collective veto power to smaller states</li>
        </ul>
      </li>
      <li>
        <p><strong>Three-Fifths Compromise</strong>. slaveholding states were allowed to count all their free population, including free African Americans and 60 percent (three-fifths) of their enslaved population.</p>
      </li>
      <li>
        <p><strong>Separation of Power and Checks and Balances</strong>: the idea is to solve the challenge of increasing the authority of the national government while ensuring that it did not become too powerful</p>

        <ul>
          <li><strong>separation of powers</strong> dividing the national government into three separate branches and assigning different responsibilities to each</li>
          <li><strong>checks and balances</strong> by giving each of three branches of government the power to restrict the actions of the others, thus requiring them to work together.</li>
        </ul>

        <p><img src="/lectures/images/2023-05-11-POLS1201_Intro_to_American_Politics/image-20230125231801019.png" alt="image-20230125231801019" style="zoom:40%;" /></p>
      </li>
      <li>
        <p><strong>The Federal System</strong>: power is divided between the federal (or national) government and the state governments.</p>

        <ul>
          <li>Great or explicit powers, called <strong>enumerated powers</strong>, were granted to the federal government (e.g. declare war)</li>
          <li>All powers not expressly given to the national government, i.e. <strong>reserved powers</strong>, are for the states (e.g. intrastate commerce and marriage)</li>
        </ul>
      </li>
      <li>
        <p>How is president chosen?</p>

        <ul>
          <li>state legislature decide how electors are chosen = the electoral voting system today</li>
          <li>without majority, i.e. electoral college is in deadlock, then House chooses president</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>After drafting, the last task is to <strong>be ratified by 9 out of 13 states</strong> in Article VII, but obviously while some people are happy, there are some who would be opposing it $\implies$ Federalists and Anti-Federalists</p>

    <ul>
      <li><strong>Federalists</strong> supported the Constitution. They tended to be among the elite members of society, e.g. being wealthy</li>
      <li><strong>Anti-Federalists</strong> feared the power of the national government and believed state legislatures, with which they had more contact, could better protect their freedoms.</li>
    </ul>
  </li>
  <li>
    <p>In the end after major persuasion efforts, the last two to sign were the wealthy, populous states of Virginia and New York.</p>

    <ul>
      <li>In Virginia, <mark>George Washington</mark>, who wrote letters to the convention, changed the minds of many.</li>
      <li>In New York, <mark>Alexander Hamilton, James Madison, and John Jay</mark> wrote a series of essays, beginning in 1787, arguing for a strong federal government and support of the Constitution</li>
    </ul>
  </li>
</ol>

<p><strong>Constitutional Change:</strong> One of the strengths they built into the Constitution v.s. prior Articles of Confederation</p>

<ol>
  <li>Having drafted nineteen proposed amendments, <mark>James Madison</mark> submitted them to Congress. only ten were accepted by three-quarters of the state legislatures. In 1791, these first ten amendments were added to the Constitution and became known as the <strong>Bill of Rights</strong>.</li>
  <li>The Bill of Rights was intended to quiet the fears of Anti-Federalists that the Constitution did not adequately protect individual liberties and thus encourage their support of the new national government.</li>
  <li>Other important ones include: the Thirteenth, Fourteenth, and Fifteenth Amendments, ratified at the end of the <strong>Civil War</strong>, changed the lives of African Americans who had been held in <strong>slavery</strong>.</li>
</ol>

<h3 id="political-foundation-of-the-us">Political Foundation of the US</h3>

<blockquote>
  <p><em>Some important terms</em>:</p>

  <ul>
    <li><strong>Tocqueville’s Democracy in America</strong>: America has been most shaped by the unusually free and egalitarian ideas and material conditions that prevailed at its found- ing-captures important truths</li>
    <li><strong>Feudalism</strong>: a system where the relationship in society was derived from the holding of land
      <ul>
        <li>collective ownership and control of the means of production.</li>
        <li>land is controlled by a small group of nobles, who hold power and privileges over the common people</li>
        <li>want a <em>stronger government power</em></li>
      </ul>
    </li>
    <li><strong>Socialism</strong>: means of production, distribution, and exchange should be owned or regulated by the community as a whole</li>
    <li><strong>Bourgeoisie</strong>: the middle class/capitalist class who own most of society’s wealth and means of production</li>
    <li><strong>Egalitarianism</strong>: doctrines are generally characterized by the idea that all humans are equal in <em>fundamental worth or moral status</em>.</li>
    <li><strong>Romanticism</strong>: American Romanticism is a frame of thought that places value on the individual above the group, the <em>subjective response and instinct over objective thought</em>, and emotion over logic.
      <ul>
        <li>Romanticism was a literary, artistic, and philosophical movement that first began in Europe late in the 18th century. American Romanticism developed toward the end of the Romantic movement in Europe.</li>
      </ul>
    </li>
  </ul>
</blockquote>

<ul>
  <li><strong>Previously</strong>, analysts have described American political culture as the preeminent example of <strong>modern liberal democracy</strong>, of government by popular consent with respect for the equal rights of all. Here, the idea is that “<strong>inegalitarian ideologies and conditions</strong> that have shaped the participants and the substance of American politics just as deep”.
    <ul>
      <li>for over 80% of U.S. history, its laws declared most of the population to be ineligible for full American citizenship due to race, nationality, or gender.</li>
      <li>Tocqueville is story is centered on relationships among a minority of Americans (e.g. white), and via reference to economic statuses men have held in Europe</li>
      <li>(<strong>race</strong>) Tocqueville treated “Indians and Negros” as <em>tangents</em> to the American nation = exceptions not considered into discussion</li>
      <li>(<strong>gender inequality</strong>) Tocqueville believes that women should be treated in a distinct sphere of action = making them <em>not civic equivalent</em> of men. e.g. denied of ruling at home or taking most professional offices</li>
    </ul>
  </li>
  <li>The author (smith) then gave a few examples work/authors for excluding/<strong>marginalizing</strong> those problems (i.e. see them as minor/external exceptions to the framework) to pretend <em>egalitarian inclusiveness</em> as the norm for US politics. “None of these mainstream approaches to American politics has given prominence to the racial, ethnic, or gender makeup of the American citizenry, though neither have they wholly avoided those issues.”
    <ul>
      <li>e.g. scholars construct the identities of marginal groups as <em>irrational, passionate, dangerous</em> “others,” both to defend their exploitation and to deny the presence of such qualities in mainstream citizens</li>
      <li>but note that colonial British American pursued practices of racial/gender dominance long before any types of liberal and republican idelogies came to play in America $\implies$<mark>racial/gender inegalitarianism is technically *more rooted*</mark> than egalitarian principles.</li>
      <li>e.g. <strong>Higram’s</strong> book had many ingredients to correct the Tocqueville thesis (e.g. American nativism built on ethnocentric attitudes), but did not compel any major reinterpretation of American politics</li>
      <li>e.g. <strong>Fuchs’s</strong> book contained analysis of exclusive civic cultures of America, but does not discuss exclusion of women $\implies$ tend to omit/minimize excluded groups as every author in the Tocquevillian transition do</li>
    </ul>
  </li>
  <li>Therefore, the author offers a <mark>multiple traditions</mark> view of America: we should not presume US politics are rooted in essentially liberal or democratic values and conditions. Instead, we must analyze America as the ongoing <strong>product of often conflicting multiple traditions</strong>.
    <ul>
      <li>i.e. US culture is shaped by a complex and multiple groups interacting with each other, and is thus a result of <strong>recurring conflicts</strong> amongst the apparently inconsistent combinations of the multiple traditions</li>
      <li>additionally, those conflicts often involve each group trying to “<em>valorize their own traits</em>” while “denigrading those of others”</li>
      <li>e.g. for a long time, there is a “separate but equal” treatment to the <strong>blacks</strong> (e.g. segregation of public school) $\implies$ inequal citizens</li>
      <li>e.g. <mark>Chinese</mark> Exclusion Act in 1882 prohibiting all immigration of Chinese laborers for 10 years; in 1889 Chinese Exclusion Case still upheld requirements for Chinese-American to have certificates of citizenship not required of whites</li>
      <li>e.g. <strong>Women</strong> suffrage passed by Congress only on June 4, 1919</li>
    </ul>
  </li>
</ul>

<h2 id="problems-in-the-us-constitution">Problems in the US Constitution</h2>

<p>“How Democratic Is the American Constitution?” by Robert A. Dahl contains a more <strong>critical view</strong> of the US constitutions</p>

<blockquote>
  <ul>
    <li>
      <p>He argues that the Constitution, as originally written and interpreted, has always had <mark>significant undemocratic features</mark>, and that these have been reinforced by subsequent developments.</p>
    </li>
    <li>
      <p>He also points out that the Constitution has been amended over time to address some of its undemocratic features, but that many others remain.</p>
    </li>
  </ul>
</blockquote>

<p>A few selected quotes/key points he mentioned include:</p>

<ul>
  <li>
    <p>The US constitutions was not that “smartly framed”:</p>

    <ul>
      <li>
        <p>framers’ reliable knowledge about constitutions appropriate to a large representative republic was, at best, meager.</p>
      </li>
      <li>
        <p>The necessity for compromise and the opportunities this gave for coalitions and logrolling meant that the Constitution <em>could not possibly reflect a coherent, unified theory of government</em></p>
      </li>
      <li>
        <p>(On why we got the Senate and House of Representative system) The <strong>solution of equal representation</strong> was not a product of constitutional theory, high principle,or grand design. It was nothing more than a practical outcome of a <strong>hard bargain</strong> (e.g. by Delaware) that its opponents finally agreed to in order to achieve a constitution</p>
      </li>
    </ul>
  </li>
  <li>
    <p><mark>Undemocratic</mark> Elements in the Framers’ Constitution</p>

    <ol>
      <li><strong>Slavery</strong>. First, it neither forbade slavery nor empowered Congress to do so</li>
      <li><strong>Suffrage</strong>. the constitution failed to guarantee the right of suffrage, leaving the qualifications of suffrage to the states $\implies$ It implicitly left in placethe exclusion of half the population—women—as wellas African Americans and Native Americans</li>
      <li><strong>Election of the President</strong>. To ensure president election is insulated from both popular majorities and congressional control, the Framer’s solution is a body of presidential electors <em>composed of men of exceptional wisdom</em> and virtue who would choose the chief executive unswayed by popular opinion $\implies$ was almost immediatelycast into the dustbin of history</li>
      <li><strong>Choosing senators</strong>. senators were to bechosen not by the people but by the <em>state legislatures</em> $\implies$ senators would be <em>less responsive to popular majorities</em> and perhaps more sensitive to the needs of property holders</li>
      <li><strong>Equal representation in the Senate</strong>.  each state was, as we have seen, awarded the same number of senators $\implies$ placed and highly privileged minorities—slaveholders, for example—gained disproportionate power</li>
      <li><strong>Judicial power.</strong> failed to <em>limit</em> the powers of the judiciary to declare as unconstitutional laws (i.e. laws opposing the US constitutions) that is passed by the Congress and signed by president $\implies$judges can then affect law making (even though none would have supported this idea)</li>
      <li><strong>Congressional power</strong>. the powers of Congress were <em>limited</em> in a way that could prevent the federal government from regulating or controlling the economy. Without the power to tax incomes, for example, <em>fiscal policy</em>, not to say measures like Social Security, would be <em>impossible</em>.</li>
    </ol>
  </li>
</ul>

<h2 id="why-these-50-states-land-policy-and-state-formation">Why these 50 States? Land Policy and State Formation</h2>

<p>Some facts at current days:</p>

<ul>
  <li>
    <p>Tension in US constitutional design on representation based on population. What percent of US residents (people physically in the US) do no have voting representations in the House or Senates?</p>

    <ul>
      <li>note that you should count in Commonwealth of Puerto Rico, Guam, US Virgin Islands, American Samoa, etc.</li>
      <li>as a result, $1.6$% of US residents have no voting representation (if they physically move to US mainland, then they can vote)</li>
    </ul>
  </li>
  <li>
    <p>When did the US states became “states”? Red is the earliest, and blue the latest</p>

    <table>
      <thead>
        <tr>
          <th style="text-align: center">When became States</th>
          <th style="text-align: center">Land Acquisition</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td style="text-align: center"><img src="https://www.ereferencedesk.com/resources/statehood/images/us-states-by-date-of-statehood.png" alt="Statehood Order by Dates: Statehood by Dates" style="zoom: 33%;" /></td>
          <td style="text-align: center"><img src="/lectures/images/2023-05-11-POLS1201_Intro_to_American_Politics/image-20230201164014190.png" alt="image-20230201164014190" style="zoom: 33%;" /></td>
        </tr>
      </tbody>
    </table>
  </li>
  <li>
    <p>How to become an independent state? Being a state gives 2 US senators, and representation in US house proportional to share of total population. Therefore, this could impose <em>high influence on future policy making</em>:</p>

    <ul>
      <li>
        <p>new states <em>cannot</em> be granted different privileges than others</p>
      </li>
      <li>requires passage of bill through House and Senate</li>
      <li>it is formed out of a state, then the state legislature has to agree as well</li>
      <li>as statehood changes the balcen of votes in national legislature, hence can be <em>vetoed</em> by national legislative majority</li>
    </ul>
  </li>
  <li>
    <p>Any current movements to change number of states?</p>

    <ul>
      <li>statehood for DC, PR</li>
      <li>cession from California (e.g. state of Jefferson), OR, also WA, UT, etc, as people feels like large cities dominate politics</li>
    </ul>
  </li>
</ul>

<blockquote>
  <p>In this section, we consider the question: <strong>does the selection of these statehood have anything to do with policy making in the federal government?</strong> As you shall see soon, why “states” get to be “states” depends a lot on the motivation of reducing conformity cost when implementing government policies.</p>
</blockquote>

<p>Certain backgrounds on relevant US history:</p>

<ul>
  <li>
    <p>scholarly consensus: US government had little ruling capacity <em>before Civil War</em>. As a result, many federal land policy was used to gain control over territory through <strong>private effort</strong> i.e. cannot govern the large territories they owned, hence encourage private individuals to do it</p>

    <ul>
      <li>controlling territory is expensive and difficult, gov has no resource</li>
      <li>can offer reward (e.g. land) to populations with military expertise</li>
      <li>compact settlement enabled effective territorial control</li>
    </ul>
  </li>
  <li>
    <p>however, while all framers agreed to expand territory, they had different <em>vision</em> what their expansion will look like (starting from 13 states). These ideals can be separated into two schools:</p>

    <ul>
      <li>opposition to presense of non-white</li>
      <li>opposition to non-white people with rights</li>
    </ul>

    <p>as a result, this gives</p>

    <ul>
      <li>justification of ethnic cleansing against indigenous population</li>
      <li>
        <p>justified ensalving subset of population</p>
      </li>
      <li>generated opposition to giving political rights to new territory with non-white majorities</li>
    </ul>
  </li>
  <li>
    <p>obviously for federal government to pass a policy, you need <strong>approvals by many states</strong></p>
  </li>
</ul>

<blockquote>
  <p>As a result, lots of strategies arise to <mark>limit conformity cost</mark> in federal gov policy making:</p>

  <ol>
    <li><strong>limit who has right to participate in decision-making</strong> to ensure preferred outcome: e.g. given statehood until there is a sufficiently large white population
      <ul>
        <li>e.g. gerrymandering, franchise restrictions</li>
        <li>e.g. Treaty of Guadalupe Hidalgo, ended war between US and Mexico. then both northerners and southerners are thinking: “How can we get the most territories, with the <em>fewest</em> addition of people”, i.e. “do <em>not</em> want people of Mexico, either as citizens or subjects,” but only land</li>
      </ul>
    </li>
    <li><strong>prevent policy-making/implementation</strong>: limit (e.g. the number of) alternative options to be in favor of your preferred outcome
      <ul>
        <li>e.g. make a policy impossible to happen: e.g. a government weak enough to prevent a future president to pass a law to end slavery</li>
        <li>e.g. limit a government’s action by limiting its fiscal capacity</li>
      </ul>
    </li>
  </ol>
</blockquote>

<p>And as a result these factors <strong>shaped</strong> which states are recognized, and which ones are not.</p>

<p><em>For Example</em>, then under this theory, ceteris paribus (i.e. “all other things being equal”), how could Washington DC or Puerto Rico become a state?</p>

<ol>
  <li>white majority</li>
  <li>their policy do not fly in the face of the federal government’s vision</li>
</ol>

<h3 id="frymers-notes-on-land-policy">Frymer’s Notes on Land Policy</h3>

<p>From the paper <em>A Rush and a Push and the Land Is Ours”: Territorial Expansion, Land Policy, and U.S. State Formation</em></p>

<blockquote>
  <p>“The importance of federal land policies in securing and incorporating territorial borders illuminates an under-examined mechanism by which developing nation states, even those with limited bureaucratic and military capacity, can successfully <strong>assert power over a vast and difficult geographic terrain</strong>.”</p>
</blockquote>

<p>Some major points are:</p>

<ul>
  <li><strong>land policy</strong> such as granting veterans land in conflicted areas $\implies$ increase settlement there which could not only <strong><em>expand its territory</em></strong> but also better defend (e.g. serve as buffer zone). Most often this includes “shrinking the Indian territory”. Examples include
    <ul>
      <li>The <strong>Indian Removal Act</strong> was signed into law by President Andrew Jackson on May 28, 1830, authorizing the president to grant unsettled lands west of the Mississippi in exchange for Indian lands within existing state borders (actions of the United States during this period would constitute genocide under current-day international law)</li>
      <li><strong>“Advancing compactly”</strong> = settle the land “progressively” with “compact” settlements and a “formidable” barrier before advancing on the frontier</li>
      <li>In 1842, Congress passed the <strong>Armed Occupation Act</strong> providing 160 acres of land to those settlers who were armed and willing to occupy land south of Gainesville, Florida as a way of ending the Second Seminole War.</li>
      <li>The success of the Armed Occupation Act prompted calls to extend the policy to western territories. Legislation was quickly proposed to induce a volunteer force of mounted men to settle the Oregon Territory that at the time was contested between the US, British, and Indian nations</li>
      <li><strong>Preemption Act and Homestead Act</strong> in 1841 and 1862 fostered an “unparalleled rush for land in Illonois”</li>
    </ul>
  </li>
  <li>the <mark>implication</mark> of those land policies is that those “federal land policies enabled an otherwise constrained American government to <strong>assert authority over the direction and pace of expansion and settlement</strong> and to maintain an official fidelity to constitutional principles while <strong>conquering territory</strong>, removing indigenous populations, and <strong>engineering a dominant racial vision</strong> by manufacturing white majorities in lands populated by diverse peoples.”</li>
  <li>However, as the aim is population movement, you shall also compare against the method of <em>forming sizeable government bureaucracies to mobilize population movements</em>
    <ul>
      <li>The results of American conquest are certainly significant, but the boundaries could well have been <strong>far more expansive</strong> had nation builders not been constrained by a small military and a need for manufacturing white majorities.</li>
      <li>the reliance on land policies—as opposed to more conventional coercive forms—enabled a certain amount of <strong>racial diversity to thrive</strong> on the frontier despite a white hegemonic society. This diversity is not just a result of ideological conflicts and multiple orders. but is also institutionally constructed from weaknesses in the capacity of the American state that enabled these pockets of diversity to withstand eradication, particularly on frontier borderlands.</li>
    </ul>
  </li>
</ul>

<hr />

<p>Note that, as mentioned near the end:</p>

<blockquote>
  <p>“Expansions have been fundamentally opposed/restricted by people motivated to <mark>preserve policy control or other privileges</mark>” hints at certain <em>undemocratic</em>/<em>inegalitarian</em> values in US policy-making in the past</p>

  <ul>
    <li>
      <p>Egalitarian ideas are important for self-identification, but not to determine their collective actions</p>
    </li>
    <li>
      <p>longevity of US government is not explained by abstract commitment to democratic principles. E.g. otherwise to be allowed for statehood you wouldn’t need stuff such as white majority, etc, if you are truly egalitarian</p>
    </li>
  </ul>
</blockquote>

<p>This brings back to America’s political Traditions discussed in Section <a href="#Political Foundation of the US">Political Foundation of the US</a>, so that policy makers are not really “rooted with egalitarianism” but rather:</p>

<ul>
  <li>desire of constrain who gets rights in order to <strong><em>achieve their own policy goals</em></strong></li>
  <li>hence, when looking at a policy, you should think about really: where does this come from? Who made it? What do they want to achieve?</li>
</ul>

<h1 id="american-federalism">American Federalism</h1>

<p>The federal design spelled out in the Constitution divides powers between two levels of government—the <strong>states and the federal government</strong>—and creates a mechanism for them to check and balance one another. As an institutional design, federalism both safeguards state interests and creates a strong union led by a capable central government.</p>

<blockquote>
  <p>This section traces the origins, evolution, and functioning of the <mark>American system of federalism</mark>, as well as its advantages and disadvantages for citizens.</p>
</blockquote>

<p>Recall that other “non-federalist” approach include</p>

<p><img src="https://openstax.org/apps/archive/20221219.191545/resources/df7dffd16667f5c2ff8a13c934b26b0dc1afa256" alt="”." style="zoom:50%;" /></p>

<p>for example</p>

<ul>
  <li>countries such as France, Japan, and Sweden are democratic with unitary systems.</li>
  <li>as with confederation $\implies$ weak national government $\implies$ American system in the past $\implies$ it maximizes regional self-rule at the expense of effective national governance.</li>
</ul>

<h2 id="division-of-powers">Division of Powers</h2>

<p>Modern democracies divide governmental power in two general ways:</p>

<ol>
  <li>the first and more common mechanism shares power among three branches of government—the legislature, the executive, and the judiciary.</li>
  <li>the second, federalism, apportions power between two levels of government: national and sub-national.</li>
</ol>

<p>Some, like the <mark>United States</mark>, use a <strong>combination</strong> of both structures.</p>

<ul>
  <li>US has a sub-national gov = state gov, and national gov = federal gov</li>
  <li>In both level of gov, there are separation of power
    <ul>
      <li>the <em>President</em> assumes executive power, <em>Congress</em> exercises legislative powers, and the <em>federal courts</em> (e.g., U.S. district courts, appellate courts, and the Supreme Court) assume judicial powers.</li>
      <li>In each of the fifty states, a <em>governor</em> assumes executive authority, a <em>state legislature</em> makes laws, and <em>state-level courts</em> assume judicial powers</li>
    </ul>
  </li>
</ul>

<blockquote>
  <p><strong>Federalism</strong> is an institutional arrangement that creates two relatively autonomous levels of government, each possessing the capacity to act directly on behalf of the people. Although many federalism vary by design, they share a lot of key similarities.</p>

  <ul>
    <li>each unit of government has its own set of officials and independent authority</li>
    <li>existence and authority of each level is protected by a constitution</li>
    <li>each unit of government can <mark>pressure others</mark></li>
  </ul>
</blockquote>

<ol>
  <li>First, all federal systems establish two levels of government, with both levels being elected by the people and <strong>each level assigned different functions</strong>. (e.g. federal gov cares more about national affairs, whereas state gov cares more about matters lie within their region)</li>
  <li>National <em>constitution</em> that cannot be changed without the <strong>substantial consent of <em>sub-national</em> governments</strong>. In the US, approval needs two-thirds of both houses of Congress and three-fourths of the states (supermajority)</li>
  <li>allocate legislative, judicial, and executive authority to the two levels of government in such a way as to ensure each level <strong>some degree of autonomy from the other</strong>. (e.g. state gov has its own governor, legislature, and court)</li>
  <li><strong>national courts</strong> commonly resolve disputes between levels and departments of government.</li>
  <li>Finally, <strong><em>sub-national</em> governments are always represented in the upper house</strong> of the national legislature, enabling regional interests to influence national lawmaking. In the US, the Senate functions as a territorial body by representing the fifty states (those are not the same as state governors or state senates)</li>
</ol>

<blockquote>
  <p>Why these different levels in this Federal Design? Mechanism to <strong>minimize conformity costs</strong></p>

  <ul>
    <li>people being represented under the same level of government (e.g. states) <em>wanted the same thing</em> $\implies$ lower interstate conformity cost
      <ul>
        <li>more homogeneous among people being represented</li>
      </ul>
    </li>
    <li>constitution excluding things that might prevent unification/uniform decision</li>
  </ul>
</blockquote>

<p>And again</p>

<blockquote>
  <p><strong>Collective action framework</strong> helps us to see how political institution make certain things more (or less) possible</p>

  <ul>
    <li>institutions can solve coordination or free rider problems</li>
    <li>but they could also <em>not solve</em> certain problems, i.e. so that having an institution could make that harder to happen
      <ul>
        <li>for example, filibuster = use prolonged speechmaking to delay or prevent a vote on a bill.</li>
        <li>The purpose of the filibuster is to prevent the majority from passing a bill that the minority opposes $\implies$ the <em>minority</em> party can use this tactic to try to <em>block the passage of a bill that they oppose</em> $\implies$ a single senator could veto $\implies$ <strong>large conformity costs</strong> as majority preference is vetoed</li>
        <li>poorly designed to solve problems that aren’t represented by eligible voters</li>
      </ul>
    </li>
  </ul>
</blockquote>

<h3 id="federalism-and-constitutions">Federalism and Constitutions</h3>

<p>We have briefly discussed the basics of US constitutions in section <a href="#The US Constitution Basics">The US Constitution Basics</a>. Here we take a more detailed look to see how those articles are related to the US federalist system.</p>

<blockquote>
  <p>In general, some <strong>delineate</strong> the scope of national and state power, while others <strong>restrict</strong> it (e.g. Bill of Rights). The remaining provisions shape relationships among the states and <strong>between</strong> the states and the federal government.</p>

  <ul>
    <li>allow for certain collective actions to be more easily carried out</li>
  </ul>
</blockquote>

<ul>
  <li>
    <p><strong>enumerated</strong> powers of the <strong>national legislature</strong> are found in Article I, Section 8.</p>

    <ul>
      <li>e.g. <strong>elastic clause</strong> or the <em>necessary and proper clause</em>, enables Congress “to make <em>all Laws which shall be necessary and proper</em> for carrying” out its constitutional responsibilities. (this is a rather open construction, hence it did enable national gov to expand authority beyond)</li>
      <li>e.g. <strong>commerce clause</strong> is a provision in the U.S. Constitution (Article I, Section 8, Clause 3) that gives Congress the power “to regulate Commerce with foreign Nations, and among the several States, and with the Indian Tribes.” While this can be interpreted broadly as Congress have a broad power to regulate commerce, the Court has also imposed some limitations on Congress’s power, such as limiting to interstate activity</li>
      <li>establishment of new states</li>
      <li>e.g. <strong>supremacy clause</strong> (see below as well), basically federal laws supersedes all state laws</li>
    </ul>
  </li>
  <li>
    <p>Article I, Sections 9 and 10, along with several constitutional amendments, lay out the <strong>restrictions on federal and state authority</strong>.</p>

    <ul>
      <li>e.g. prevents measures that cause the deprivation of personal liberty (such as slavery, imprisonment without justification)</li>
      <li>e.g. Bill of Rights, including freedom to speech, local police searching you without a warrant</li>
    </ul>
  </li>
  <li>
    <p><strong>supremacy clause</strong> in Article VI of the Constitution regulates <strong>relationships between the federal and state governments</strong> by declaring that the Constitution and federal law are the supreme law of the land.</p>

    <ul>
      <li>however, enforcement is not always that simple.</li>
      <li>In the case of marijuana use, which the federal government defines to be <em>illegal</em>, thirty-six states and the District of Columbia have nevertheless established medical marijuana laws, others have <em>decriminalized its recreational use</em>, and fifteen states have completely <em>legalized</em> it. The federal government could act in this area if it wanted to.</li>
    </ul>
  </li>
  <li>
    <p>powers of the <strong>state governments</strong> were never listed in the original Constitution, but the Tenth Amendment <strong>affirms the states’ reserved powers</strong></p>

    <ul>
      <li>“The powers not delegated to the United States by the Constitution, nor prohibited by it to the States, are reserved to the States respectively, or to the people.”</li>
      <li>most important include police powers = establish mechanism to <em>police</em>, such as rules; and provision of public services; system of local government = <em>how local gov should work</em>; and regulation of intra-state commerce</li>
      <li>however, some reserved powers are no longer exclusively within state domain, e.g. boundary between intrastate and interstate commerce has become indefinable as a result of broad interpretation of the commerce clause.</li>
    </ul>

    <p><img src="/lectures/images/2023-05-11-POLS1201_Intro_to_American_Politics/image-20230202164724977.png" alt="image-20230202164724977" style="zoom:50%;" /></p>
  </li>
  <li>
    <p>Various constitutional provisions <strong>govern state-to-state relations</strong>.</p>

    <ul>
      <li>Article IV, Section 1, referred to as the <strong>full faith and credit clause</strong> or the <em>comity clause</em>, requires the states to accept court decisions, public acts, and contracts of other states. Thus, an adoption certificate or driver’s license issued in one state is valid in any other state.</li>
      <li><strong>privileges and immunities clause</strong> of Article IV asserts that states are prohibited from discriminating against out-of-staters by denying them such guarantees as access to courts, legal protection, property rights, and travel rights. The clause has not been interpreted to mean there cannot be <em>any</em> difference in the way a state treats residents and non-residents. For example, individuals cannot vote in a state in which they do not reside.</li>
    </ul>
  </li>
  <li>
    <p>Some areas <strong>both state and federal governments</strong> can regulate</p>

    <ul>
      <li>militia, both state and federal</li>
      <li>states may act in a federal area, so long as it does not contradict federal law</li>
    </ul>
  </li>
</ul>

<blockquote>
  <p>In a sense, Constitution basically provides a framework + freedom for the institutions to work out. Then, people can use whatever levers at their disposal to change a policy in a state/entire United States.</p>
</blockquote>

<p>However, there are “governments” that are missing from this:</p>

<ul>
  <li>local governments has no status in federal constitution
    <ul>
      <li>are granted power by <strong>states</strong> (e.g. local establish police department, but state could take over if it wants, e.g. due to corruption)</li>
      <li>so people say local gov are “creature of the states”</li>
    </ul>
  </li>
  <li>in many states, there is a the concept of “home rule” for local governments
    <ul>
      <li>provisions in many <strong>state constitution</strong> <em>limit action in certain areas</em> of local government</li>
      <li>this must be specifically conferred, in practice given to most larger cities
        <ul>
          <li>e.g. city of Baffalo is allowed to establish police academy</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="distribution-of-finances">Distribution of Finances</h3>

<p>Where do national, state, and local government get their money from? A graph below in 2018/2020 illustrates some high level info:</p>

<p><img src="https://openstax.org/apps/archive/20221219.191545/resources/054b305607c99d0a3beb557239a4b7a7d57892bc" style="zoom:50%;" /></p>

<ul>
  <li>for federal government, most of the revenue comes from <strong>income taxes</strong> (includes all kinds of income, paid by you) and <strong>payroll taxes</strong> (includes your payroll, paid by both employer and employee)</li>
  <li>For local governments the <strong>property tax</strong>, a levy on residential and commercial real estate, was the most important source of tax revenue</li>
</ul>

<p>How are those money spent?</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Federal Spending</th>
      <th style="text-align: center">State and Local</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="https://openstax.org/apps/archive/20221219.191545/resources/e6c3bfa70d0376658434af0fc26ea87e8de7f31d" alt="." style="zoom:40%;" /></td>
      <td style="text-align: center"><img src="https://openstax.org/apps/archive/20221219.191545/resources/bc79aaf6905e8737edba9d131a249cba4b39654e" alt="" style="zoom: 33%;" /></td>
    </tr>
  </tbody>
</table>

<ul>
  <li>A look at the federal budget in 2019 shows that the three largest spending categories were <strong>Social Security</strong>; <strong>Medicare</strong>, Medicaid, the Children’s Health Insurance Program; and <strong>defense and international security assistance</strong> (18 percent) $\iff$ Constitution assigns the federal government various powers that allow it to <em>affect the nation as a whole</em>.</li>
  <li>for local and state, we see that <strong>educational</strong> expenditures constitute a major category for both; state also allocate comparatively more funds to public welfare programs, such as <strong>health care, income support, and highways</strong>.</li>
</ul>

<blockquote>
  <p>Note that one interesting point here is about “free-rider problem”, since grants are given to states but <em>come from taxes states collect</em>, then a state can impose the lowest amount of tax and still get grants/findings from government.</p>
</blockquote>

<h2 id="the-evolution-of-american-federalism">The Evolution of American Federalism</h2>

<p>How did US Federalism work in real life?</p>

<blockquote>
  <p>Since the constitution does <mark>not</mark> specify the precise ruling of states and federal gov, this has led to</p>

  <ul>
    <li>
      <p>several clashes between national gov and state gov</p>
    </li>
    <li>
      <p>changes in the configuration of federalism over time that capture distinct balances between state and federal authority.</p>
    </li>
  </ul>
</blockquote>

<p>Examples of national gov v.s. state gov include:</p>

<ul>
  <li>establishment of the Bank of the United States, and are <strong>states</strong> allowed to <strong>tax federal property (e.g. that bank)</strong>?
    <ul>
      <li>In <em>McCulloch v. Maryland</em>, Chief Justice John Marshall argued that Congress could establish “all means which are appropriate” to fulfill “the legitimate ends” of the Constitution.</li>
      <li>therefore, state (in many cases) cannot tax national institutions as “the power to tax is the power to destroy.”</li>
    </ul>
  </li>
  <li>commerce clause of Article I, Section 8; specifically, it had to determine whether the <strong>federal government had the sole authority to regulate the licensing of steamboats</strong> operating between New York and New Jersey.
    <ul>
      <li>in the end, federal law trumped the New York State license-monopoly law</li>
      <li>As Marshall pointed out, “the acts of New York must yield to the law of Congress.”</li>
    </ul>
  </li>
  <li>what about doctrine of <strong>nullification</strong>—that states had the right to reject national laws they deemed unconstitutional.
    <ul>
      <li>ultimate showdown between national and state authority came during the Civil War</li>
      <li>pro-state: Supreme Court ruled that the national government <em>lacked</em> the authority to ban slavery in the territories $\implies$ Civil War</li>
      <li>The defeat of the South had a huge impact on the balance of power between the states and the national government.
        <ol>
          <li>First, the Union victory put an <strong>end to the right of states to secede and to challenge</strong> legitimate national laws.</li>
          <li>Second, Congress imposed several conditions for readmitting former Confederate states into the Union; among them was ratification of the Fourteenth and Fifteenth Amendments.</li>
        </ol>
      </li>
      <li>In sum, after the Civil War the power balance <strong>shifted toward the national government</strong>.</li>
    </ul>
  </li>
</ul>

<p>In sum, With the exception of the Civil War, the Supreme Court settled the power struggles between the states and national government. From a historical perspective, the national supremacy principle introduced during this period did not so much narrow the states’ scope of constitutional authority as restrict their encroachment on national powers.</p>

<h3 id="dual-cooperative-and-new-federalism">Dual, Cooperative, and New Federalism</h3>

<blockquote>
  <p><strong>Dual federalism</strong>, the states and national government exercise exclusive authority in <em>distinctly delineated spheres</em> of jurisdiction, i.e. limited only to perform within the enumerated powers. As a result, state and gov are like “equal” players in politics, hence dual.</p>

  <p>This happened in the late <strong>1870s</strong>, motivated mainly by:</p>

  <ul>
    <li>
      <p>several Supreme Court rulings blocked attempts by both state and federal governments to step outside their jurisdictional boundaries.</p>
    </li>
    <li>
      <p>prevailing economic philosophy at the time <em>loathed government interference</em> in the process of industrial development.</p>
    </li>
  </ul>

  <p>but was dealt a legal blow in 1895 and is no longer used.</p>
</blockquote>

<p>In the late 1870s, industrialization changed the socioeconomic landscape of the United States. One of its adverse effects was the <strong>concentration of market power</strong> $\implies$ lead to several new issues to federal ruling</p>

<ul>
  <li>there was no national regulatory supervision to ensure fairness in market practices, <mark>collusive behavior among powerful firms emerged</mark> in several industries. e.g. anti-competitive practices in the railroad industry.</li>
  <li>Congress passed the Interstate Commerce Act in 1887, which created the Interstate Commerce Commission; then three years later, this is broarden by <strong>Sherman Antitrust Act of 1890</strong>, which made it <strong>illegal to monopolize or attempt to monopolize</strong> and conspire in restraining commerce</li>
  <li>In 1895, in <em>United States v. E. C. Knight</em>, the Supreme Court ruled that the national government <strong>lacked the authority to regulate manufacturing</strong>, arguing that the national government’s regulatory authority applied only to commercial activities. (If manufacturing activities fell within the purview of the commerce clause of the Constitution, then “comparatively little of business operations would be left for state control,” the court argued.)</li>
</ul>

<p>However, things start to change in <mark>Great Depression</mark> of the 1930s, which brought economic hardships the nation had never witnessed before</p>

<blockquote>
  <p><strong>Cooperative federalism</strong> was born of necessity and lasted well into the twentieth century as the national and state governments each found it beneficial. Under this model, both levels of government <strong>coordinated their actions to solve national problems</strong>, such as the Great Depression and the civil rights struggle of the following decades.</p>

  <ul>
    <li>federal gov can attempt to intervene in all areas of local/public policy, not limited to their enumerated powers</li>
    <li>layers of government do not coerce each other, but <em>national can take leadership role</em> (i.e. coerce)</li>
    <li>federal resources give it an upper hand, in practice</li>
    <li>federal government can influence through <mark>carrots and sticks</mark> (see <a href="#Grant and Mandates">Grant and Mandates</a>)</li>
  </ul>

  <p>the more dominant in 1932/37 - present.</p>
</blockquote>

<p><img src="/lectures/images/2023-05-11-POLS1201_Intro_to_American_Politics/image-20230208162212758.png" alt="image-20230208162212758" style="zoom: 25%;" /></p>

<p>Essentially there is now a <strong>broadening of federal powers</strong> in concurrent and state policy domains, it is also the era of a <strong>deepening coordination</strong> between the states and the federal government in Washington.</p>

<ul>
  <li>Before the Great Depression, the government offered little in terms of financial aid, social benefits, and economic rights. After the New Deal, it provided old-age pensions (Social Security), unemployment insurance, agricultural subsidies, protections for organizing in the workplace</li>
  <li>The unemployment insurance program, also created by the <strong>Social Security Act</strong>, requires states to provide jobless benefits, but it allows them significant latitude to decide the level of tax to impose on businesses</li>
  <li>coordination between state and national gov is clearest in the social welfare and social insurance programs created during the New Deal and Great Society eras, most of which are <strong>administered by both state and federal authorities and are jointly funded</strong>.</li>
</ul>

<p>Thus, the era of cooperative federalism left two lasting attributes on federalism in the United States:</p>

<ol>
  <li><strong>nationalization of politics</strong> emerged as federal legislative activities were aimed at addressing problem such as <em>marketplace inefficiencies</em>, etc $\implies$ again federal governments gain more policy making power</li>
  <li><strong>flexibility</strong> that states and local authorities were given in the implementation of federal social welfare programs $\implies$ cross-state differences in the levels of benefits and coverage (not to confuse with “full faith and credit clause”)</li>
</ol>

<blockquote>
  <p><strong>New federalism</strong> is based on the idea to <em>restore states’ prominence in policy areas</em> into which the federal government had moved in the past. It is also based on the belief that the decentralization of policies enhances administrative efficiency, reduces overall public spending, and improves policy outcomes.</p>
</blockquote>

<p>The most prominent figure championing this was perhaps Ronald Reagan, along with several efforts by the Supreme Court</p>

<ul>
  <li>
    <p>The election of Ronald Reagan heralded the advent of a “<mark>devolution</mark> revolution” in U.S. federalism, in which the president pledged to return authority to the states according to the Constitution.</p>
  </li>
  <li>in United States v. Lopez, the court struck down the Gun-Free School Zones Act of 1990, which banned gun possession in school zones. It argued that the regulation in question did not “substantively affect interstate commerce” $\implies$ gives this ruling back to state</li>
  <li>However, many would say that the years since the 9/11 attacks have swung the pendulum back in the direction of central federal power.</li>
</ul>

<blockquote>
  <p>Note that it is important <mark>not</mark> to see these systems as “permanently replacing” each other. Each tend to leave some footprints in their succeeding system, and hence it is best to see this as an “evolution process” $\implies$ the combined effect of all of them is more important.</p>
</blockquote>

<h2 id="grant-and-mandates">Grant and Mandates</h2>

<p>The national government’s ability to achieve its objectives often requires the <strong>participation of state and local governments.</strong></p>

<blockquote>
  <p>Intergovernmental grants offer positive financial inducements to get states to work toward selected national goals.</p>

  <ul>
    <li>A <strong>grant</strong> is commonly likened to a “carrot” to the extent that it is designed to entice the recipient to do something.</li>
    <li><strong>Mandates</strong> are typically backed by the threat of penalties for non-compliance and provide little to no compensation for the costs of implementation. Thus, a mandate is commonly likened to a “stick.”</li>
  </ul>

  <p>the revenue used for grants are offered through taxing and spending powers</p>
</blockquote>

<p>In the past, examples of grants include “land grants” e.g. University of Delaware, are land-grant institutions because their campuses were built on land donated by the federal government. But today, grants have become a bit more complicated system</p>

<ul>
  <li><strong>Categorical grants</strong> are federal transfers formulated to limit recipients’ discretion in the use of funds and subject them to strict administrative criteria that guide project selection, performance, and financial oversight, among other things. Medicaid and the food stamp program are examples of categorical grants.
    <ul>
      <li>e.g. establishment of criminal justice at local level was funded by federal gov in the past.</li>
    </ul>
  </li>
  <li><strong>Block grants</strong> come with less stringent federal administrative conditions and provide recipients more flexibility over how to spend grant funds. Example include Workforce Investment Act program, which help youths and adults obtain skill sets that will lead to better-paying jobs</li>
</ul>

<blockquote>
  <p>Grant money can change political calculus (e.g. Medicaid: give extra money to extend health insurance to people otherwise inapplicable. Some states took it and hence changed their policy, some did not.)</p>
</blockquote>

<p>However, the national government has <mark>greatly preferred using categorical grants</mark> to transfer funds to state and local authorities because</p>

<ol>
  <li>this type of grant gives them <strong>more control and discretion</strong> in how the money is spent.</li>
  <li>elected officials who sponsor these grants can <strong>take credit</strong> for their positive outcomes</li>
  <li>block grants lack mechanisms to hold state and local administrators <strong>accountable</strong> for outcomes</li>
  <li>once categorical grants have been established, vested interests in Congress and the federal bureaucracy seek to <strong>preserve</strong> them</li>
</ol>

<p>Block grants have been championed for their <mark>cost-cutting effects</mark> $\implies$ placing a ceiling on funding</p>

<ul>
  <li>By eliminating uncapped federal funding, the national government can reverse the escalating costs of federal grant programs.</li>
  <li>Paul Ryan (R-WI), former chair of the House Budget Committee estimated one could save the federal government upwards of $732 billion over ten years if Medicaid is converted to block grant</li>
</ul>

<hr />

<blockquote>
  <p><strong>Unfunded mandates</strong> are federal laws and regulations that impose obligations on state and local governments <em>without fully compensating them for the administrative costs they incur</em>.</p>

  <p>Penalty of non-compliant often includes either a) threatens civil and criminal penalties for state and local authorities b) suspension of federal grant, or c) a combination of both.</p>
</blockquote>

<p>This is as bad as it sounds, but it is difficult to restrict the temptation of not using it:</p>

<ul>
  <li>The widespread use of federal mandates in the 1970s and 1980s provoked a backlash among state and local authorities, which culminated in the <strong>Unfunded Mandates Reform Act (UMRA)</strong> in 1995. However, since the act’s implementation, states and local authorities have obtained limited relief.</li>
  <li><strong>Real ID Act</strong> of 2005, a federal law designed to beef up homeland security by replacing driver’s license and identification cards (DI/ID) with standardized machine-readable cards. However, while the cost to states of re-issuing DL/IDs is estimated to be $11 billion, the government only reimburse a small portion of the cost. As a result, since 2016 and only thirty-eight were in full compliance with Real ID as of December 2018.</li>
  <li>other examples: National Voter Registration Act.</li>
</ul>

<p>The continued use of unfunded mandates clearly <mark>contradicts new federalism’s call</mark> for giving states and local governments more flexibility in carrying out national goals. As a result, there have been more instances of confrontational interactions between the states and the federal government.</p>

<hr />

<blockquote>
  <p><strong>Preemption</strong>: federal law that assets national government control over an area. Intent is to limit state government authority, hence many of them are also litigated in courts.</p>
</blockquote>

<p>Examples include</p>

<ul>
  <li>recently, over the issue of abortion</li>
  <li>Defensive of Marriage Act (1996) where federal govt took over</li>
</ul>

<h3 id="competitive-federalism-today">Competitive Federalism Today</h3>

<p>One aspect of competitive federalism today is that some policy issues, such as immigration and the marital rights of LGBTQ people, have been redefined as the <strong>roles that states and the federal government play in them have changed</strong> $\iff$ both state and federal government can influence each other.</p>

<p><strong>Contending Issues</strong>: In sum, as the immigration and marriage equality examples illustrate, constitutional disputes have arisen as states and the federal government have sought to <mark>reposition themselves on certain policy issues</mark>, disputes that the federal courts have had to sort out.</p>

<ul>
  <li>before, it was understood that the federal government handled immigration and states determined the legality of marriage.</li>
  <li>Since the late 1990s, <strong>states</strong> have asserted a right to make <strong>immigration policy</strong> on the grounds that they are enforcing, not supplanting, the nation’s immigration laws.
    <ul>
      <li>In 2005, twenty-five states had enacted a total of thirty-nine laws related to immigration;</li>
      <li>In 2012, in <em>Arizona v. United States</em>, the Supreme Court affirmed <strong>federal supremacy on immigration</strong>, as Arizona passed Senate Bill 1070, which sought to make it so difficult for undocumented immigrants to live in the state that they would return to their native country</li>
    </ul>
  </li>
  <li>By passing the Defense of Marriage Act (DOMA) in 1996, the <strong>federal government</strong> stepped into policy making on <strong>marriage</strong>.
    <ul>
      <li>DOMA considered denying same-sex couples from various federal provisions and benefits—such as the right to file joint tax returns and receive Social Security survivor benefits.</li>
      <li>In <em>United States v. Windsor</em>, the Supreme Court changed the dynamic established by DOMA by ruling that the federal government had no authority to define marriage (i.e. laws cannot discriminate between same-sex and different-sex couples based on the equal protection clause of the Fourteenth Amendment)</li>
    </ul>
  </li>
</ul>

<p><strong>Strategizing about new issues</strong>: By creating <mark>two institutional access points</mark>—the federal and state governments—the U.S. federal system enables interest groups such as MADD to strategize about how best to achieve their policy objectives.</p>

<ul>
  <li>Mothers Against Drunk Driving (MADD) was established in 1980 by a woman whose thirteen-year-old daughter had been killed by a drunk driver, and they aim to raise the drinking age and impose tougher penalties
    <ul>
      <li>tried lobbying <strong>state</strong> legislators, but did not succeed</li>
      <li>redirect its lobbying efforts at <strong>Congress</strong>, and <strong>succeeded</strong>. In 1984, the federal government passed the National Minimum Drinking Age Act (NMDAA), raising minimum purchase age to 21.</li>
    </ul>
  </li>
  <li>anti-abortion advocates (in 1973 <em>Roe v. Wade</em> Supreme Court decision making abortion legal nationwide) used the same strategy of venue shopping
    <ul>
      <li>initially targeted at the Congress, but failed</li>
      <li>shift their focus to <strong>state</strong> legislators, where their advocacy efforts have been more successful. By 2015, for example, thirty-eight states required some form of parental involvement in a minor’s decision to have an abortion, etc.</li>
    </ul>
  </li>
</ul>

<blockquote>
  <p>Surely as a result of the borderline between state v.s. federal policy become intermingled.</p>
</blockquote>

<h3 id="advantages-and-disadvantages-of-federalism">Advantages and Disadvantages of Federalism</h3>

<blockquote>
  <p>[discussion] means this point was made during the discussion section</p>
</blockquote>

<p>Among the <strong>merits</strong> of federalism (i.e. separated power) are that it</p>

<ol>
  <li><strong>limits</strong> ability of federal government to oppress (e.g. people)</li>
  <li>promotes policy <strong>innovation</strong>, “a single courageous state may, if its citizens choose, serve as a <em>laboratory</em>;” = <mark>laboratory of democracy</mark>
    <ul>
      <li>For example, a number of New Deal breakthroughs, such as child labor laws, were <strong>inspired by state policies</strong>.</li>
      <li>[discussion] e.g. police training before enforcement (before, all you need is a badge and a gun. In 1959, California and NY required police training/provided financial incentive)</li>
      <li>[discussion] in general might find a better policy</li>
    </ul>
  </li>
  <li>promotes political <strong>participation</strong>, as it creates a government closer to the people (e.g. only for people in this region)</li>
  <li>accommodates <strong>diversity</strong> of opinion.
    <ul>
      <li>the system of checks and balances in our political system often prevents the federal government from imposing uniform policies across the country.</li>
      <li>As a result, states and local communities have the latitude to address policy issues based on the specific needs and interests of their citizens.</li>
    </ul>
  </li>
  <li>states can act when federal government <strong>can’t agree</strong> (if urgent) = less <strong>coordination and transactional cost</strong> when making <strong>intrastate</strong> policies
    <ul>
      <li>[discussion] but of course, interstate coordination becomes more difficult (see #5 below)</li>
    </ul>
  </li>
</ol>

<p><strong>Drawbacks</strong> include (or adv of centralized power):</p>

<ol>
  <li>economic disparities across states, <strong>race-to-the-bottom</strong> dynamics (i.e., states compete to attract business by lowering taxes and regulations)
    <ul>
      <li>economic disparities include
        <ul>
          <li>e.g. in 2017, Maryland had the highest median household income (80,776), while West Virginia had the lowest (43,469).</li>
          <li>In 2016, New York spent 22,366 per student for elementary and secondary education, while Utah spent 6,953.</li>
        </ul>
      </li>
      <li>The economic strategy of using race-to-the-bottom tactics in order to compete with other states in attracting new business growth also carries a <strong>social cost</strong>.
        <ul>
          <li>For example, workers’ safety and pay can suffer as workplace regulations are lifted, and the reduction in payroll taxes for employers has led a number of states to end up with underfunded unemployment insurance programs.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>the difficulty of taking action on issues of <strong>national importance</strong>.
    <ul>
      <li>federal design of our Constitution and the system of checks and balances has jeopardized or outright blocked federal responses to important national issues.</li>
      <li>but with a national government, this becomes much easier</li>
    </ul>
  </li>
  <li><strong>free-riding</strong>: some states rely on contribution of others, e.g. on the grants issue, or raising military for national defense
    <ul>
      <li>can be decreased if having a national government = third party supervising the prisoner’s dilemma</li>
    </ul>
  </li>
  <li>duplication of efforts $\implies$ inefficiency, as you have so many layers of govt and each has its own authority, <strong>making decisions can be much slower</strong>
    <ul>
      <li>lower <strong>transactional cost</strong> to enforce policies/make decisions</li>
    </ul>
  </li>
  <li>interstate <strong>coordination problem</strong> exists = to coordinate the same traffic laws across different states, it is very difficult and still varied today
    <ul>
      <li>[discussion] becomes even greater today as we have more population and more complicated dynamics such as powerful econ people</li>
    </ul>
  </li>
</ol>

<h1 id="urban-politics">Urban Politics</h1>

<p>What counts as a government?</p>

<blockquote>
  <p><strong>US census of Governments</strong> uses the three criteria</p>

  <ul>
    <li>existence of organized entity</li>
    <li>governmental character: power to levy <mark>taxes</mark>, issue debt, i.e. actions that governments usually take</li>
    <li>substantial <em>autonomy</em></li>
  </ul>
</blockquote>

<p>Examples of local governments that <em>satisfy</em> this definition</p>

<ul>
  <li>
    <p>county government/parish</p>
  </li>
  <li>
    <p>city government</p>
  </li>
  <li>
    <p>township</p>
  </li>
  <li>
    <p>school district: raise taxtes, make policies</p>
  </li>
  <li>
    <p>other <strong>special purpose districts</strong>/governments: e.g. levy taxes and provide funding. This include</p>

    <ul>
      <li>airports, cemeteries, corrections, jails</li>
      <li>electric power, fire protecion, gas supply district</li>
      <li>highways, hospitals, housing, and community development</li>
    </ul>

    <p>to what degree can they tax? This is often restricted/predefined by the state government.</p>
  </li>
</ul>

<blockquote>
  <p><strong>Special district</strong> governments are independent, special purpose governmental units, other than school district governments, that exist as separate entities with substantial administrative and fiscal independence from general purpose local governments.</p>
</blockquote>

<p>Why are we discussing this? Why so many special form of governments?</p>

<blockquote>
  <p>When you want to get something new done, you can</p>

  <ul>
    <li>get it done with an existing governemnt</li>
    <li>create a new government with that responsibility</li>
  </ul>

  <p>Hence this is to explain why are we having <strong>90,126</strong> governments (a lot, because <mark>people want different things</mark>) in the US at the time of this note, according to the census.</p>
</blockquote>

<p>A more detailed breakdown:</p>

<table>
  <thead>
    <tr>
      <th>Type of Govt</th>
      <th>Number</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>County</td>
      <td>3,031</td>
    </tr>
    <tr>
      <td>City</td>
      <td>19,522</td>
    </tr>
    <tr>
      <td>Township</td>
      <td>16,364</td>
    </tr>
    <tr>
      <td>Independent School District</td>
      <td>12,884</td>
    </tr>
    <tr>
      <td>others</td>
      <td>37,381</td>
    </tr>
    <tr>
      <td>etc</td>
      <td> </td>
    </tr>
  </tbody>
</table>

<p>With this in 2010, this <em>gives 1 govt per 3800 people.</em></p>

<p>But is having so many forms of government good or bad?</p>

<blockquote>
  <p><strong>Proliferation of government</strong> can result in</p>

  <ul>
    <li>[+] allows for diversity of policy</li>
    <li>[-] raises cost of oversight = hard to keep up with what they are doing, and who to support $\implies$ problem for democratic control</li>
    <li>[-] can create coordination problems/free rider .e.g people inaction</li>
    <li>[+] can allow for greater expertise development = governors becomes better at their job in govt = improves quality of action</li>
    <li>[-] surely duplication effort</li>
    <li>[-] allows for greater preference matching and disparity, as shown in the next section</li>
  </ul>
</blockquote>

<h2 id="political-boundaries">Political Boundaries</h2>

<p>Consider you are the <em>green</em> local government, and you want you policy to pass. ‘O’ indicates people who supports your policy, and ‘X’ against it.</p>

<p>Interestingly, you can get policy change if you <mark>change the boundary</mark> of your affected people/region</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Deadlock</th>
      <th style="text-align: center">3/5 Majority</th>
      <th style="text-align: center">3/4 Super Majority</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2023-05-11-POLS1201_Intro_to_American_Politics/image-20230208180859085.png" alt="image-20230208180859085" /></td>
      <td style="text-align: center"><img src="/lectures/images/2023-05-11-POLS1201_Intro_to_American_Politics/image-20230208180906170.png" alt="image-20230208180906170" /></td>
      <td style="text-align: center"><img src="/lectures/images/2023-05-11-POLS1201_Intro_to_American_Politics/image-20230208180916479.png" alt="image-20230208180916479" /></td>
    </tr>
  </tbody>
</table>

<p>In fact, you can “steal” an election</p>

<p><img src="/lectures/images/2023-05-11-POLS1201_Intro_to_American_Politics/image-20230215161716888.png" alt="image-20230215161716888" style="zoom:15%;" /></p>

<blockquote>
  <p><strong>Gerrymandering</strong> (illegal): manipulate the boundaries of (an electoral constituency) so as to favor one party or class. This is especially done by people who are already in charge. (think of path dependence in <a href="#Institutional Change">Institutional Change</a>)</p>
</blockquote>

<ul>
  <li>e.g. exists, such as in Chicago, it was made so that republicans cannot get enough support</li>
  <li>e.g. NY, which is controlled by democrats, and wanted to redraw on a boundary to increase its chance</li>
</ul>

<p>Therefore, changing jurisdiction boundaries can be beneficial to <mark>control what policy is passed</mark>. This can actually be done in two ways</p>

<blockquote>
  <p><strong>Preference sorting</strong> = change policies that are politically possible, achieved by mechanism indicated above</p>
</blockquote>

<blockquote>
  <p><strong>Economic sorting</strong> = change policies financially possible. Sort the geographical regions such that certain district becomes restricted in funds $\implies$ can no longer enact certain policies. (e.g. many schools are funded by <em>large</em> public money)</p>
</blockquote>

<h2 id="limits-on-local-government">Limits on Local Government</h2>

<p>What can the local government <mark>not do</mark>, given that it seems powerful with all the different mechanics above?</p>

<ul>
  <li><strong>state preemption</strong> = (recall) federal law that asserts national government control over an area. Intent is to limit state government authority</li>
  <li>wealth in jurisdiction/resources</li>
  <li><strong>state restrictions on tax revenue</strong>: state laws restrict what kind of tax revenue or rate a local jurisdiction can set
    <ul>
      <li>hence restricts fiscal ability, and limits what policies are possible</li>
    </ul>
  </li>
  <li><strong>population and business flight</strong> = when you <em>change policy</em> in a region, business and population can just leave = restrict local government’s choices</li>
  <li><strong>elections</strong>: need to cater to people’s wills, otherwise step down of power
    <ul>
      <li>however this is a “twist” to this, being anti-democratic:  can create policies so that a) other policies are much harder to achieve = transactional cost, or b) difficult for people who are against it to “represent” themselves in elections</li>
    </ul>
  </li>
  <li><strong>free-rider</strong> problems (e.g. due to the proliferation of local gov) and <strong>coordination problem</strong> still exists.
    <ul>
      <li>e.g. land policies: local gov has the right to set which area is zoned for what kind of houses. However, they tend to prefer zoning for luxury houses than for affordable houses (wishing other local govs to establish) $\implies$ difficult to build enough affordable housing</li>
    </ul>
  </li>
</ul>

<h2 id="more-on-new-york-city">More on New York City</h2>

<p>ref: <a href="https://clio.columbia.edu/catalog/14759712">Community power in a postreform city: politics in New York City</a>; Pecorella, Robert F, Chapter 1</p>

<blockquote>
  <p>The author presents a <strong>contextual approach</strong> to urban politics, which suggest that</p>

  <ul>
    <li>periodic fiscal crisis $\implies$ regime change in New York’s governance a lot</li>
    <li>politics unfolds within a <strong>social-economic</strong> environment that constraints the breadth of options to public officials</li>
    <li>so that during periods of crisis, local politics becomes <strong>more a function of local economics</strong></li>
  </ul>
</blockquote>

<p>But it is also worth noting the <em>other popular schools of urban politics</em>:</p>

<blockquote>
  <p><strong>Pluralism</strong>, in political science, the view that in liberal democracies power is (or should be) <mark>dispersed among a variety of economic and ideological pressure/interest groups</mark> and is not (or should not be) held by a single elite or group of elites.</p>
</blockquote>

<p><strong>Pluralism believes that</strong></p>

<ul>
  <li><em>diversity</em> is beneficial to society and that autonomy should be enjoyed by disparate functional or cultural groups within a society, including religious groups, trade unions, professional organizations, and ethnic minorities.</li>
  <li><em>continual competition</em> among diverse groups, with none able to accumulate sufficient re­sources to monopolize the political game, is conducive to the development of polyarchy where democratic norms govern</li>
  <li>this plural system thus moves incrementally in <em>balancing</em> the pressures for stability and change</li>
</ul>

<p>Under the pluralist view (in some sense resembles the <a href="#Political Foundation of the US">multi-tradition view of US politics</a>):</p>

<ul>
  <li>New York emphasized group competition when analyzing both periods of normal politics $\implies$ viewed as a <strong>diverse political arena</strong> where competing interest groups interact with city officials to secure some share of the prizes of local politics</li>
  <li>the 1975 fiscal crisis resulted from economic decline following a temporary <strong>imbalance in the city’s interest group configuration</strong></li>
</ul>

<blockquote>
  <p><strong>Statism</strong> is the doctrine that the political authority of the state is legitimate to some degree. This may include economic and social policy, especially in regard to taxation and the means of production.</p>
</blockquote>

<p>Statism differs with Pluraist in</p>

<ul>
  <li>From the statist perspective, then, urban fiscal crises are the predictable con­ sequence of <em>government’s inability</em> to exercise authority and choose among dif­ ferent claims on public resources.</li>
  <li>although resources are noncumulative from a system-wide perspective, the agency-client relationships that characterize group entrenchment represent <em>cumulative power</em> within a particular policy area. The ability of entrenched interests to exclude countervailing groups from their policy domains negates the pluralist concepts of political competition.</li>
</ul>

<blockquote>
  <p><strong>Stratification approach</strong>: local politics is essentially the domain of eco­ nomic elites whose policy influence overrides that of any other group or coali­ tion in the city.</p>
</blockquote>

<p>They differ from previous groups in that:</p>

<ul>
  <li>instead of concentrating their attention on public decision­ making processes group, stratification believes the <em>determinant role that economic elites play</em> in local politics.</li>
  <li><em>elitists</em> researcher thus believes that a) an <em>economic elite</em> controls most major public policy decisions; b) city politics includes a visible political class whose members contest for office but who are, in the final analysis, subservient to the local economic elites</li>
  <li>from the perspective of elite theorists, urban fiscal crises are the consequence of the <em>self-interested policies pursued by the economic elites</em> who control cities</li>
</ul>

<h1 id="us-civil-rights">US Civil Rights</h1>

<p>The U.S Constitution and its founding principles of liberty, equality, and justice are admired and emulated the world over. However, not everyone living in the U.S. has enjoyed the same treatment and freedoms the law promises: e.g. women, immigrants, people of color, LGBTQ people, people with disabilities, and other groups, a majority of Americans have been <em>deprived of basic rights and opportunities</em>.</p>

<p>The belief that people should be treated <strong>equally under the law</strong> is one of the cornerstones of political thought in the United States. Yet not all citizens have been treated equally throughout the nation’s history. Some types of unequal treatment are considered acceptable in some contexts, while others are clearly not.</p>

<blockquote>
  <p>No one would consider it acceptable to allow a ten-year-old to vote, because a child lacks the ability to understand important political issues, but all reasonable people would agree that it is wrong to mandate racial segregation or to deny someone voting rights on the basis of race. It is important to understand <mark>which types of inequality are unacceptable and why</mark>.</p>
</blockquote>

<h2 id="what-are-civil-rights">What are Civil Rights?</h2>

<p>Before we dive in on what is Civil Rights, it is good to know</p>

<blockquote>
  <p>We typically envision <strong>civil liberties</strong> as <mark>limitations on government power</mark>, intended to <mark>protect freedoms</mark> upon which governments may not legally intrude.</p>
</blockquote>

<p>For example</p>

<ul>
  <li>the First Amendment denies the government the power to prohibit “the free exercise” of religion.</li>
  <li>the Eighth Amendment prohibits the application of “cruel and unusual punishments” to those convicted of crimes,</li>
</ul>

<blockquote>
  <p><strong>Civil rights</strong>, on the other hand, are guarantees that government officials will treat <mark>citizens equally</mark> and that decisions will be made on the basis of merit rather than race, gender, or other personal characteristics.</p>

  <p>In a sense this is <em>also limitation on government</em>, but <mark>limiting the government’s ability to discriminate</mark> or treat some people differently, unless the unequal treatment is based on a valid reason, such as age.</p>
</blockquote>

<p>For example:</p>

<ul>
  <li>
    <p><strong>Fifth Amendment</strong>:  “all men are created equal” by providing <em><mark>de jure equal treatment</mark></em> under the law.</p>
  </li>
  <li>
    <p><strong>equal protection clause</strong> of the <strong>Fourteenth</strong> Amendment, which states, in part, that “No State shall . . . deny to any person within its jurisdiction the equal protection of the laws.”; also ensure that the states would respect the civil liberties of <em>formerly enslaved</em> people (from Civil War).</p>
  </li>
</ul>

<p>But how do you identify discrimination? What count as discrimination? Consider the following examples:</p>

<ul>
  <li>need a a minimum age for driving $\to$ age discrimination?</li>
  <li>school only enroll students have a high school diploma or a particular score on the SAT or ACT $\to$ discriminate students with weaker grades?</li>
</ul>

<p>How can the federal, state, and local governments “discriminate” in all these ways even though the equal protection clause seems to suggest that everyone be treated the same?</p>

<blockquote>
  <p>The decision between what is discrimination and what is not lies in the <strong>purpose</strong> of the discriminatory practice, and really, <strong>how justifiable it is</strong>.</p>
</blockquote>

<p>The simple, most general rule is the <strong>rational basis test</strong>. That is, as long as there’s a reason for treating some people differently that is “rationally related to a legitimate government interest,” the discriminatory act or law or policy is acceptable.</p>

<ul>
  <li>e.g. universities discriminate against students with weaker grades and test scores because these students most likely do not yet possess the knowledge or skills needed to do well in their classes</li>
</ul>

<p>However, depending on what group of people is discriminated, courts apply more stringent rules to policies, laws, and actions</p>

<blockquote>
  <p>Discrimination based on <strong>gender or sex</strong> is generally examined with <strong>intermediate scrutiny</strong>.</p>

  <ul>
    <li>need to demonstrate such discrimination is “<em>substantially</em> related to an important governmental objective.”</li>
    <li>e.g. laws that treat men and women differently are <em>sometimes</em> upheld,</li>
  </ul>
</blockquote>

<blockquote>
  <p>Discrimination against members of <strong>racial, ethnic, or religious groups</strong> or those of <strong>various national origins</strong> is reviewed with the <strong>strict scrutiny</strong> standard</p>

  <ul>
    <li>there is a compelling governmental interest in treating people from one group differently</li>
    <li>if there is a <em>non-discriminatory way to accomplish the goal</em> in question, discrimination should not take place.</li>
    <li>e.g. laws and actions that are challenged under strict scrutiny have rarely been upheld</li>
  </ul>
</blockquote>

<p>In summary, a simple helper method for you to <mark>identify true discrimination</mark></p>

<ol>
  <li><em>Which groups?</em> First, identify the group of people who are facing discrimination.</li>
  <li><em>Which right(s) are threatened?</em> Second, what right or rights are being denied to members of this group?</li>
  <li><em>What do we do?</em> Third, what can the government do to bring about a fair situation for the affected group? Is proposing and enacting such a remedy realistic?</li>
</ol>

<h2 id="the-african-american-struggle-for-equality">The African American Struggle for Equality</h2>

<p>Here I summarize some major events related to civil rights and civil war:</p>

<p><em>Antebellum</em>: 1787-1865</p>

<ol>
  <li>In the Declaration of Independence, Thomas Jefferson made the radical statement that “all men are created equal” and “are endowed by their Creator with certain unalienable Rights, that among these are Life, Liberty and the pursuit of Happiness.”</li>
  <li>But at his time, Jefferson also owned dozens of other human beings as his personal property. He recognized this contradiction, and agreed to free those upon his death</li>
  <li>but still, framers of the Constitution <strong>chose not to address the issue in any definitive way</strong>. Political support for abolition was very much a minority stance in the United States at the time</li>
  <li>As US expanded westward $\to$ They feared the expansion of slavery would lead to the political dominance of the South over the North and would deprive small farmers in the newly acquired western territories who could not afford to enslave others.</li>
  <li>President Abraham Lincoln had been willing to allow slavery to continue in the South to preserve the Union, he changed his policies regarding abolition over the course of the war.</li>
  <li><strong>Emancipation Proclamation</strong> on January 1, 1863: Although it stated “all persons held as slaves . . . henceforward shall be free,” the proclamation was limited in effect to the states that had rebelled</li>
</ol>

<blockquote>
  <p>Basically a period where you have:</p>

  <ul>
    <li><strong>anti-slavery thoughts</strong>: abolitionists, black religious, ed, prof, business groups; small farmres, merchants, markers, esp. N &amp; border
      <ul>
        <li>note that they are here for <em>different reasons</em>, e.g. purely economical, ideological, moral.</li>
      </ul>
    </li>
    <li><strong>pro-slavery thoughts</strong>: slave owners, textile; industrialists in N, artisans and working-class, European immigrates</li>
  </ul>
</blockquote>

<hr />

<p><em>Civil Rights in the Court</em>: 1877-1960s</p>

<ol>
  <li>
    <p>After the civil war, changes wrought by Fifth and Fourteens Amendment introduced banning of slavery and equal rights/treatments</p>
  </li>
  <li>
    <p>But soon, violence in the hands of white men was used to discourage Black people from exercising the rights they had been granted.</p>
  </li>
  <li>
    <p>The revocation of voting rights, or <strong>disenfranchisement</strong>, took a number of forms</p>

    <table>
      <thead>
        <tr>
          <th>Method</th>
          <th>How it works</th>
          <th>How it discriminates</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td><strong>literacy tests</strong> and <strong>understanding tests</strong></td>
          <td>call on voter to demonstrate his (and later, her) ability to read a particular passage of text.</td>
          <td>more difficult passages to those whose registration they wanted to deny (typically, Black people).</td>
        </tr>
        <tr>
          <td><strong>grandfather clause</strong></td>
          <td>exempted those who had been allowed to vote in that state prior to the Civil War and their descendants from literacy and understanding tests.</td>
          <td>to protect in some states, poorer, less-literate white voters feared being disenfranchised due to the literacy/understanding test</td>
        </tr>
        <tr>
          <td> </td>
          <td> </td>
          <td>allowed most illiterate white people to vote while leaving obstacles in place for Black people who wanted to vote as well.</td>
        </tr>
        <tr>
          <td><strong>poll tax</strong></td>
          <td>pay to register to vote.</td>
          <td>Because formerly enslaved people were usually quite poor, they were less likely than White men to be able to pay poll taxes.</td>
        </tr>
        <tr>
          <td><strong>white primary</strong></td>
          <td>they held primary elections to choose the Democratic nominee in which only White citizens were allowed to vote.</td>
          <td>make the votes from Black people meaningless since since White voters can agree beforehand to support whoever won the Democrats’ primary</td>
        </tr>
      </tbody>
    </table>
  </li>
  <li>
    <p>alongwith disenfranchisement, there is also <strong>discrimination of treatment</strong> - “<strong>separate but equal</strong>”</p>
  </li>
</ol>

<ul>
  <li>As long as nominally equal facilities were provided for both races, it was legal to require members of each race to use the facilities designated for them.</li>
  <li>state and local governments passed laws limiting neighborhoods in which Black and White people could live.</li>
  <li>Collectively, these discriminatory laws came to be known as <mark>Jim Crow laws = legalized racial segregation</mark></li>
</ul>

<ol>
  <li>
    <p>Then comes a series of <strong>court rulings and accusations</strong> made by organizations such as National Association for the Advancement of Colored People (NAACP) for equal treatment</p>

    <ul>
      <li>e.g. overturning segregation in education.</li>
      <li>Beyond these favorable court rulings, however, progress toward equality for African Americans remained slow in the 1950s.</li>
    </ul>
  </li>
</ol>

<blockquote>
  <p>Basically a period where you have:</p>

  <ul>
    <li><strong>anti-Jim Crow thoughts</strong>: liberal democrats and liberal republicans; black business; most non-white advocacy organizations</li>
    <li><strong>pro-Jim Crow thoughts</strong>: conservative south democrats and republicans, most white business, and most white academic institution</li>
  </ul>
</blockquote>

<hr />

<p><em>Legislating Civil Rights and Post Civil Rights Movement</em>: 1970s - (2016?)</p>

<ol>
  <li>After Rosa Parks refused to give up her bus seat to a White person and was arrested, Civil rights pioneers adopted these measures in the 1955–1956 Montgomery bus boycott.
    <ul>
      <li>prefer more confrontational approaches, including the use of <strong>direct action</strong> campaigns relying on marches and demonstrations.</li>
      <li>The strategies of nonviolent resistance and <strong>civil disobedience</strong>,</li>
    </ul>
  </li>
  <li>As the campaign for civil rights continued and gained momentum, President John F. Kennedy called for Congress to pass new civil rights legislation, which began to work its way through Congress in 1963 $\implies$ for the first time <mark>outlawed segregation/discrimination</mark> and other forms of discrimination by most businesses that were open to the public</li>
  <li>Progress in registering African American voters remained slow in many states despite increased federal activity supporting it, so <mark>civil rights leaders including Martin Luther King, Jr</mark>. decided to draw the public eye to the area where the greatest resistance to voter registration drives were taking place.
    <ul>
      <li>planned a march from <strong>Selma</strong> to Montgomery in March 1965.</li>
      <li>The events at Selma galvanized support in Congress for a follow-up bill solely dealing with the right to vote. The <strong>Voting Rights Act</strong> of 1965 went beyond previous laws by requiring greater oversight of elections by federal officials.</li>
    </ul>
  </li>
  <li>But of course, there are other approaches to black rights. <mark>Malcolm X</mark> expressed significant distrust of White people, and advocated for their <strong>separation</strong> from the United States through eventual emigration to Africa.
    <ul>
      <li>His position was attractive to many young African Americans, especially after Martin Luther King, Jr. was assassinated in 1968.</li>
    </ul>
  </li>
</ol>

<blockquote>
  <p>Basically a period where you have:</p>

  <ul>
    <li><strong>Race-Conscious</strong>: abolitionists; most democrats; non-white advocacy orgs
      <ul>
        <li>recognizes and takes into account the significance of race in society, including its impact on individuals and groups.</li>
        <li>This approach acknowledges that race is an important factor in shaping experiences and outcomes and seeks to address racial disparities and inequities.</li>
      </ul>
    </li>
    <li><strong>Color-blind</strong>: most republicans; conservative democrats; most federal and state judges
      <ul>
        <li>assumes that race should not be a factor in how people are treated or perceived</li>
      </ul>
    </li>
  </ul>

  <p>which is like trying to answer the question: <em>how do you treat</em> people equally</p>
</blockquote>

<hr />

<p>So in short:</p>

<ul>
  <li>
    <p>south wanted slavery, 19th century northern and <strong>westerners</strong> had to fight to end it</p>
  </li>
  <li>
    <p>south wanted to limit black rights post-emancipation - <strong>federal</strong> courts had to stop it</p>
  </li>
  <li>
    <p>civil rights movement removed the last elements of white supremacy from law</p>
  </li>
</ul>

<blockquote>
  <p><strong>Substance of policy debates determines coalition possibilities</strong>. i.e. depending on different time periods/context, there are different racial problems (e.g. due to economic grounds, etc) $\implies$ different support groups, some of which might seem confounding</p>
</blockquote>

<h3 id="geography-of-white-supremacy">Geography of White Supremacy</h3>

<p>It is widely held (but <strong>false</strong>) that racial conflicts in the US caused by <strong>Southern racism</strong>. Why?</p>

<ol>
  <li>federalism allowed variety of tactics to preserve white supremacy</li>
  <li>black population concentrated in South (by design) until 20th century</li>
  <li>Federal restricted non-Black citizenship advocated by western states</li>
</ol>

<p>Another piece of data would be the probability of being <strong>lynched</strong> = 1889 - 1918</p>

<ul>
  <li>physical violence as a tactic to suppress the political rights of people $\implies$ show others to obey more</li>
  <li>a period where white people trying to deter black from political participation</li>
</ul>

<p>There is also discrimination against other groups:</p>

<ul>
  <li><strong>Racial Restrictions on Citizenship</strong>: In 1780-1870: only ‘free whites’ were allowed to naturalize, and for example, Chinese, were only allowed to naturalize in 1943. From 1952, finally no racial restrictions.</li>
</ul>

<blockquote>
  <p>Racial hierarchy is an <strong>American legacy</strong>, not Southern.</p>
</blockquote>

<p>But at the same time:</p>

<blockquote>
  <p>Population change since 1965 has opened new frontiers</p>
</blockquote>

<p>Some of the <strong>very recent issues include</strong></p>

<ul>
  <li><strong>Redistricting</strong>: Changes in population can require redistricting, or the redrawing of electoral boundaries, which can lead to political battles over how to allocate political power and representation.</li>
  <li><strong>Immigration policies:</strong> As immigration patterns have changed, there have been debates and political conflicts over how to manage borders, regulate immigration, and balance concerns around national security and economic growth with issues of human rights and social justice.</li>
  <li><strong>Urban-rural divides:</strong> Population change has also contributed to the urban-rural divide in many countries, with different political priorities and values emerging in urban and rural areas, and political leaders struggling to bridge these differences.</li>
</ul>

<h3 id="voting-rights">Voting Rights</h3>

<p>Several related courts:</p>

<ul>
  <li>Dred Scott v Sanford (1857): held back people with enslaved ancestor could not be citizen. But then supemacy court decided that black <em>does not have the right to sue</em></li>
  <li>Plessy v. Ferguson (1896): whether or not state mandated segregation is a violation of equal protection. Decision: 14th amendment.</li>
  <li>Korematsu v. United States (1944): upheld internment of Japanses-Americans as allowed</li>
  <li>Shelly v. Kraemer (1948): previously allowed private agreements to involve racial restrictions. Now unconstitutional under this one
    <ul>
      <li>the issue here was that private owners created a covenant and the Fourteenth Amendment applies to state action.</li>
      <li>However, the Court reasoned that the Fourteenth Amendment applies to judicial enforcement of such covenants, as that is state action. Thus, the Court concluded that the state is taking action in this case, therefore such an <em>private racial agreement cannot be allowed</em>.</li>
    </ul>
  </li>
  <li>Brown v. Board of Education (1954): banned segregation in public schools</li>
  <li>Shelby County v. Holder (2013): certain states who were racially restrictive are require to pre-clear before elections. Ruling is that those pre-clearance requirement is unconstitutional
    <ul>
      <li>i.e. previously required certain states and localities with a history of discrimination in voting to obtain federal approval, or “preclearance,” before changing their voting laws or procedures</li>
    </ul>
  </li>
</ul>

<blockquote>
  <p>Sometimes the judgment is conservative, and sometimes liberal.</p>
</blockquote>

<p>More on <strong>white primary</strong> (Texas style):</p>

<ul>
  <li>Texas banned white people voting in primary, but then it is sued to be unconstitutional</li>
  <li>In 1935, they won a rule “party rule banning Black voting in primary was private action, so it is <em>allowed</em>”</li>
  <li>In 1944, delegating power to parties to run primary still a form of state action, so it is <em>unconstitutional again</em></li>
</ul>

<p>What does this show us?</p>

<ul>
  <li>white supremacists persistence, that people even try to move discriminatory actions into private sphere to prevent scrutiny</li>
</ul>

<blockquote>
  <p>therefore, it is very difficult to use fixed actions or policy positions to treat discriminatory intent.</p>
</blockquote>

<h2 id="the-fights-for-womens-rights">The Fights for Women’s Rights</h2>

<ol>
  <li>At the time of the American Revolution, women had few rights. Although single women were allowed to own property, married women were not.
    <ul>
      <li>e.g. all personal property they owned legally became their husbands’ property.</li>
      <li>e.g. their husbands were entitled to their wages.</li>
    </ul>
  </li>
  <li>Following the Revolution, women’s conditions did not improve. Women were not granted the right to vote by any of the states except New Jersey.</li>
  <li>In 1848, Stanton and Mott called for a women’s rights convention, the first ever held specifically to address the subject, at Seneca Falls, New York.
    <ul>
      <li>Stanton wrote the <strong>Declaration of Sentiments,</strong> which was modeled after the Declaration of Independence and proclaimed women were equal to men and deserved the same rights.</li>
      <li>The Declaration passed, but the resolution demanding <strong>suffrage</strong> was the only one that <strong>did not pass</strong> unanimously.</li>
    </ul>
  </li>
  <li>The more radical <strong>National Woman’s Party</strong> (NWP), led by Alice Paul, advocated the use of stronger tactics. The NWP held public protests and picketed outside the White House
    <ul>
      <li>Finally, in 1920, the triumphant passage of the Nineteenth Amendment granted all women the <strong>right to vote</strong>.</li>
    </ul>
  </li>
</ol>

<p>Civil Rights and the Equal Rights amendment</p>

<ol>
  <li>Just as the passage of the Thirteenth, Fourteenth, and Fifteenth Amendments did not result in equality for African Americans, the Nineteenth Amendment <em>did not end discrimination</em> against women in education, employment, or other areas of life</li>
  <li>A second women’s rights movement emerged in the 1960s to address these problems. <strong>Title VII of the Civil Rights Act</strong> of 1964 prohibited discrimination in employment on the basis of sex as well as race, etc
    <ul>
      <li>Nevertheless, women continued to be denied jobs because of their sex and were often sexually harassed at the workplace.</li>
    </ul>
  </li>
  <li>National Organization for Women (NOW) = NOW promoted workplace equality, including equal pay for women. NOW also declared its support for the <strong>Equal Rights Amendment</strong> <strong>(ERA)</strong>, which mandated equal treatment for all regardless of sex.
    <ul>
      <li>but until today, ERA failed to be ratified</li>
      <li><strong>Title IX</strong> of the United States Education Amendments of 1972 passed into law as a federal statute (not as amendment) $\implies$ if a school receives federal aid, it cannot spend more funds on programs for men than on programs for women.</li>
    </ul>
  </li>
</ol>

<p>Pressing Issues today</p>

<ol>
  <li><strong>Roe v. Wade,</strong> (1973) was a landmark decision of the U.S. Supreme Court conferred the right to choose to have an abortion. In June 2022, the Supreme Court <mark>overruled</mark> Roe in <em>Dobbs v. Jackson Women’s Health Organization</em> on the grounds that the substantive right to abortion was not “deeply rooted in this Nation’s history or tradition”.</li>
  <li><strong>glass ceiling</strong>, an invisible barrier caused by discrimination, prevents women from rising to the highest levels of American organizations, including corporations, governments, academic institutions, and religious groups. <strong>Women earn less money than men for the same work.</strong></li>
</ol>

<h2 id="civil-rights-for-indigenous-groups">Civil Rights for Indigenous Groups</h2>

<blockquote>
  <p>This includes group such as Native Americans, Alaskans, and Hawaiians</p>

  <ul>
    <li>Ironically, Native Americans were not granted the full rights and protections of U.S. citizenship until long after African Americans and women were, with many having to wait <strong>until the Nationality Act of 1940 to become citizens</strong>.</li>
  </ul>
</blockquote>

<p>NATIVE AMERICANS LOSE THEIR LAND AND THEIR RIGHTS</p>

<ol>
  <li>From the very beginning of European settlement in North America, Native Americans were abused and exploited.</li>
  <li>As White settlement spread westward over the course of the nineteenth century, Indian tribes were forced to move from their homelands.</li>
  <li>In 1830, Congress passed the Indian Removal Act, which forced Native Americans to move west of the Mississippi River.
    <ul>
      <li>Not all tribes were willing to leave their land, however. The <strong>Cherokee</strong> in particular resisted</li>
      <li>Between 1831 and 1838, members of several southern tribes, including the Cherokees, were forced by the U.S. Army to move west</li>
      <li>The forced removal of the Cherokees to Oklahoma Territory, which had been set aside for settlement by displaced tribes and designated Indian Territory, resulted in the death of one-quarter of the tribe’s population. The Cherokees remember this journey as the <strong>Trail of Tears</strong>.</li>
    </ul>
  </li>
  <li>By the time of the Civil War, most Indian tribes had been relocated west of the Mississippi. However, once large numbers of White Americans and European immigrants had also moved west after the Civil War, Native Americans once <em>again found themselves displaced</em>.</li>
  <li>In 1898, the Curtis Act dealt the final blow to Indian sovereignty by <strong>abolishing all tribal governments</strong>.</li>
</ol>

<p>THE FIGHT FOR NATIVE AMERICAN RIGHTS</p>

<ol>
  <li>As Indians were removed from their tribal lands and increasingly saw their traditional cultures being destroyed over the course of the nineteenth century, a movement to protect their rights began to grow.
    <ul>
      <li>e.g. Sarah Winnemucca, member of the Paiute tribe, lectured throughout the east in the 1880s in order to acquaint White audiences with the injustices suffered by the western tribes.</li>
    </ul>
  </li>
  <li>In 1924, the <strong>Indian Citizenship Act</strong> granted citizenship to all Native Americans born after its passage.</li>
  <li>In 1934, Congress passed the <strong>Indian Reorganization Act</strong>, which ended the division of reservation land into allotments. It returned to Native American tribes the right to institute self-government on their reservations.
    <ul>
      <li>However, most tribes remained <em>impoverished</em>, and many Native Americans, despite the fact that they were now U.S. citizens, were <strong>denied the right to vote</strong></li>
    </ul>
  </li>
  <li>In the 1960s, a modern Native American civil rights movement, inspired by the African American civil rights movement, began to grow.
    <ul>
      <li>In 1969, a group of Native American activists from various tribes, took control of <strong>Alcatraz</strong> Island in San Francisco Bay</li>
      <li>In 1973, members of the <strong>American Indian Movement</strong> <strong>(AIM)</strong>, a more radical group than the occupiers of Alcatraz, temporarily took over the offices of the Bureau of Indian Affairs in Washington, DC.</li>
    </ul>
  </li>
  <li>The current relationship between the U.S. government and Native American tribes was established by the <strong>Indian Self-Determination and Education Assistance Act</strong> of 1975.
    <ul>
      <li>tribes assumed control of programs that had formerly been controlled by the BIA, such as education and resource management, and the federal government provided the funding.</li>
    </ul>
  </li>
  <li>In addition to gains in <strong>water rights and land rights</strong>, Native American tribes made other gains in recent decades. Tribes have robust and well-recognized governing institutions based on democratic principles.</li>
  <li>Finally, the appointment by President Biden, and subsequent Senate confirmation, of <strong>Rep. Deb Haaland (D-NM)</strong> as Secretary of the Interior was a powerful and pathbreaking moment. She is the first Native American to hold that position at Interior, which includes the Bureau of Indian Affairs.</li>
</ol>

<h2 id="equal-protection-for-other-groups">Equal Protection For Other Groups</h2>

<p>Many groups in American society have faced and continue to face challenges in achieving equality, fairness, and equal protection under the laws and policies of the federal government and/or the states.</p>

<blockquote>
  <p>Some of these groups are often overlooked because they are <strong>not as large of a percentage of the U.S. population</strong> as women or African Americans, and because organized movements to achieve equality for them are <strong>relatively young</strong>.</p>
</blockquote>

<p><strong>Hispanic/Latino Civil Rights</strong></p>

<ul>
  <li><em>Hispanic</em> usually refers to native speakers of Spanish or those descended from Spanish-speaking countries. <em>Latino</em> refers to people who come from, or whose ancestors came from, Latin America. Not all Hispanics are Latinos and vice versa. People from Spain are Hispanic but are not Latino, while people from Brazil are Latino but not Hispanic.</li>
  <li>Many Latinos became part of the U.S. population following the annexation of <mark>Texas</mark> by the United States in 1845. The Spanish-speaking population of the United States increased following the Spanish-American War in 1898 with the incorporation of <mark>Puerto Rico</mark> as a U.S. territory.
    <ul>
      <li>In the early twentieth century, waves of violence aimed at Mexicans and <strong>Mexican Americans</strong> swept the Southwest. Mexican Americans in Arizona and in parts of Texas were denied the right to vote,</li>
    </ul>
  </li>
  <li>Today, Latinos constitute the largest minority group in the United States. They also have one of the highest birth rates of any ethnic group.</li>
</ul>

<p><strong>Asian American Civil Rights</strong></p>

<ul>
  <li><strong>Asian Americans</strong> have also often been discriminated against and denied their civil rights. Often stereotyped as the “the model minority” (because it is assumed they are generally financially successful and do well academically), the truth is that Asian Americans have long faced discrimination.</li>
  <li>The <mark>Chinese</mark> were the first large group of Asian people to immigrate to the United States.
    <ul>
      <li>Their willingness to work for less money than White workers led White workers in California to call for a ban on Chinese immigration. In 1882, Congress passed the <strong>Chinese Exclusion Act</strong>, which prevented Chinese from immigrating to the United States for ten years</li>
      <li>With the passage of the <strong>Immigration Act</strong> of 1924, all Asian people, with the exception of Filipinos, were prevented from immigrating to the United States or becoming naturalized citizens.</li>
    </ul>
  </li>
  <li>Discrimination against Asian Americans, regardless of national origin, increased during the <strong>Vietnam War.</strong>
    <ul>
      <li>Chinese, Japanese, Koreans, and Vietnamese caused members of these groups to unite around a shared <strong>pan-Asian identity</strong>, much as Native Americans had in the Pan-Indian movement.</li>
      <li>(<em>history</em>) The Vietnam war is fought between the communist forces of North Vietnam and the government forces of South Vietnam (with eventual allies of US troops and Chinese=strong ally of north Vietnam as well). The main cause of the Vietnam war was the spread of communism and the desire of the North Vietnamese to reunify the country under a communist government. The war was characterized by guerrilla tactics and unconventional warfare, and resulted in a significant loss of life and widespread destruction.</li>
    </ul>
  </li>
  <li>Unfortunately, recently racist vitriol related to the origin of COVID-19 has recently highlighted discrimination against Asian Americans again</li>
</ul>

<h1 id="civil-liberties">Civil Liberties</h1>

<p>In writing the Declaration of Independence in 1776, Thomas Jefferson drew on the ideas of English philosopher John Locke to express the colonists’ belief that they had certain <strong>inalienable or natural rights</strong> that no ruler had the power or authority to deny to their subjects.</p>

<blockquote>
  <p>The framers of the Constitution wanted a government that <em>would not repeat the abuses of individual liberties</em> and rights that caused them to declare independence from Britain.</p>
</blockquote>

<p>What are those freedoms? And how should we balance them against the interests of society and other individuals?</p>

<h2 id="what-are-civil-liberties">What are Civil Liberties?</h2>

<p>Recall that we defined a distinction between civil liberties and civil rights in <a href="#What are Civil Rights?">What are Civil Rights?</a>: <strong>civil liberties</strong> as limitations on government power, intended to <mark>protect freedoms upon which governments may not legally intrude</mark>.</p>

<blockquote>
  <p>Two general <strong>form of protection</strong></p>

  <ul>
    <li><strong>substantive</strong> restraints (i.e. to a particular action). For example, get contraception; neither states nor the national government can forbid people to follow a religion of their choice, even if politicians and judges think the religion is misguided.</li>
    <li><strong>procedural</strong> restraints. For example, police must follow certain procedure when arresting/interrogating people</li>
  </ul>

  <p>That said, the <strong><em>way</em></strong> you practice your religion, like any other practice, may be regulated if it impinges on the rights of others.</p>
</blockquote>

<p>The first tool you think of as to “restrict the government on regulating civil freedom” could be the “<mark>bill of rights</mark>”:</p>

<ol>
  <li>
    <p>The Constitution as drafted in 1787 <strong>did not include a Bill of Rights</strong>, although the idea of including one was proposed and, after brief discussion, dismissed in the final week of the Constitutional Convention.	The framers of the Constitution believed they</p>

    <ul>
      <li>faced much more pressing concerns—most notably keeping the fragile union together in the light of internal unrest and external threats.</li>
      <li>had adequately covered rights issues in the main body of the document
        <ul>
          <li><strong>bills of attainder</strong>: prohibit convicts or punishes someone for a crime without a trial,</li>
          <li><em>prohibiting</em> <strong>ex post facto laws</strong>: prohibit the retroactive effect that it can be used to punish crimes that were not crimes at the time they were committed,</li>
          <li>limiting the ability of Congress to suspend the <strong>writ of habeas corpus</strong>: allow a neutral judge decide whether someone has been lawfully detained.</li>
        </ul>
      </li>
      <li>Hamilton went on to argue that listing some rights might actually be dangerous, because it would provide a pretext for people to claim that rights <em>not</em> included in such a list were not protected.</li>
    </ul>
  </li>
  <li>
    <p>However, many large states—New York and Virginia in particular—believed the Constitution’s lack of specified rights became a serious point of contention, and hence did not want to ratify the constitution. As a result, the framers agreed to consider incorporating provisions (i.e. later the <strong>Bill of Rights</strong>). Ultimately, <mark>James Madison</mark> proposed ten of the amendments were successfully ratified</p>

    <table>
      <thead>
        <tr>
          <th>First Amendment</th>
          <th>Right to freedoms of religion and speech; right to assemble and to petition the government for redress of grievances; right to a free press</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>Second Amendment</td>
          <td>Right to keep and bear arms to maintain a well-regulated militia</td>
        </tr>
        <tr>
          <td>Third Amendment</td>
          <td>Right to not house soldiers during time of war</td>
        </tr>
        <tr>
          <td>Fourth Amendment</td>
          <td>Right to be secure from unreasonable search and seizure</td>
        </tr>
        <tr>
          <td>Fifth Amendment</td>
          <td>Rights in criminal cases, including due process and indictment by grand jury for capital crimes, as well as the right not to testify against oneself</td>
        </tr>
        <tr>
          <td>Sixth Amendment</td>
          <td>Right to a speedy trial by an impartial jury</td>
        </tr>
        <tr>
          <td>Seventh Amendment</td>
          <td>Right to a jury trial in civil cases</td>
        </tr>
        <tr>
          <td>Eighth Amendment</td>
          <td>Right to not face excessive bail, excessive fines, or cruel and unusual punishment</td>
        </tr>
        <tr>
          <td>Ninth Amendment</td>
          <td>Rights retained by the people, even if they are not specifically enumerated by the Constitution</td>
        </tr>
        <tr>
          <td>Tenth Amendment</td>
          <td>States’ rights to powers not specifically delegated to the federal government</td>
        </tr>
      </tbody>
    </table>
  </li>
</ol>

<blockquote>
  <p>BoR can be thought of a way to limit conformity cost. i.e. to limit the ability of the majority to impose their preferences on minority groups through legislation or other means. $\implies$ certain <strong>minority preference/rights are still preserved</strong></p>

  <p>However, the meaning and intent of BoR is often unclear.</p>
</blockquote>

<p>For example:</p>

<ul>
  <li><strong>ambiguous language</strong>
    <ul>
      <li>in 8th amendment What is “curel and unusual punishment”</li>
      <li>establishment clause and prayer (does praer in public school count as religious )</li>
    </ul>
  </li>
  <li><strong>practical contradictions</strong>
    <ul>
      <li>press freedom (1st), but public trial with impartial jury (8th) $\implies$ very hard if facts have been exposed in media, even illegal, can make it hard to make impartial decisions</li>
    </ul>
  </li>
  <li><strong>omissions</strong>
    <ul>
      <li>who does the BoR restrict? Does it apply to state governments? What about local governments?</li>
    </ul>
  </li>
</ul>

<blockquote>
  <p>As a result, the Supreme Court had to make a lot of decisions.</p>
</blockquote>

<ol>
  <li>the Barron Case (1830) ruled that BoR does not applied to state $\implies$ then BoR has no meaning really as states are the implementations</li>
  <li>then, after the Civil War, succeeded states had to agree to amendments (e.g. 14th) in order to rejoin US</li>
  <li>in the 14th amendment, obligated states to provide equal protectoin, due procecss
    <ul>
      <li>national citienship (e.g. for black people)</li>
      <li>equal protection: but note that police department was not there</li>
      <li>due process: without due proces of law, state cannot deprice any person of life and liberty</li>
    </ul>
  </li>
  <li>establishment of a monopoly of slaughter house in Arizona
    <ul>
      <li>decided that BoR does not apply to states $\to$ the decision limited the ability of the federal government to protect the rights of citizens against state abuses, and it helped to reinforce the power of state governments to regulate the activities of their citizens.</li>
      <li>It was only later, through other landmark cases such as Brown v. Board of Education and Roe v. Wade, that the Supreme Court began to expand the scope of federal power and protect the rights of citizens against state infringement.</li>
    </ul>
  </li>
  <li>over time, more and more elements of BoR gets incorporated into state $\to$ **selective incorporation **(see below as well)</li>
</ol>

<hr />

<p>EXTENDING THE BILL OF RIGHTS TO THE STATES</p>

<ol>
  <li>In the decades following the Constitution’s ratification, the Supreme Court <strong>declined to expand the Bill of Rights to curb the power of the states</strong></li>
  <li>The festering issue of the rights of enslaved persons and the convulsions of the <strong>Civil War</strong> and its aftermath forced a reexamination of the prevailing thinking about the application of the Bill of Rights to the states.
    <ul>
      <li>e.g. after the civil war, states passed “Black codes” that restricted the rights of formerly enslaved people</li>
    </ul>
  </li>
  <li>Their long-term solution was to propose and enforce two amendments to the Constitution to guarantee the rights of freed men and women.
    <ul>
      <li>With the ratification of the <strong>Fourteenth Amendment</strong> in 1868, the scope and limits of civil liberties became clearer: “<strong>no State</strong> shall make or enforce any law which shall abridge the privileges or immunities of citizens of the United States”</li>
      <li>second provision of the Fourteenth Amendment pertaining to the application of the Bill of Rights to the states is the <strong>due process clause</strong>, which requires fair treatment and procedural safeguards (e.g. the right to a trial, and that people be treated <em>fairly and impartially by government officials</em>) before the government can deprive a person of life, liberty, or property.</li>
    </ul>
  </li>
  <li>there has been a process of <strong>selective incorporation</strong> of the Bill of Rights into the practices of the states: c<em>ertain provisions must be upheld by the states</em>, even if their state constitutions and laws (and the Tenth Amendment itself) do not protect them
    <ol>
      <li><strong><em>when issue arises</em></strong>, the Supreme Court decides whether state laws violate the Bill of Rights and are therefore unconstitutional.</li>
      <li>it this still consistent with the supremacy clause? The key is that <em>if there is a conflict</em>, then supremacy clause overrules.</li>
      <li>e.g. It was only in the <em>McDonald v. Chicago</em> case two years later that the Supreme Court incorporated the Second Amendment (keep and bear arms) into state law.</li>
    </ol>
  </li>
</ol>

<h2 id="securing-basic-freedoms">Securing Basic Freedoms</h2>

<p>We can broadly divide the provisions of the Bill of Rights into three categories</p>

<p><img src="/lectures/images/2023-05-11-POLS1201_Intro_to_American_Politics/image-20230215170855266.png" alt="image-20230215170855266" style="zoom:25%;" /></p>

<ul>
  <li>protect basic individual freedoms;</li>
  <li><strong>criminal procedural protections</strong>:  protect people suspected or accused of criminal activity or facing civil litigation;</li>
  <li>express the view that Bill of Rights is not necessarily an exhaustive list of all the rights people have and guarantees a role for state as well as federal government</li>
</ul>

<p>A bit more details into the different amendments</p>

<ol>
  <li><strong>The first amendment</strong>: guarantees both religious freedoms and the right to express your views in public.
    <ul>
      <li><strong>establishment clause</strong>. Congress is prohibited from creating or promoting a state-sponsored religion (this now includes the states).</li>
      <li><strong>free exercise clause</strong>, on the other hand, limits the ability of the government to control or restrict religious practices.</li>
      <li>basically, it not only forbids the creation of a “Church of the United States” or “Church of Ohio” it also forbids the government from favoring one set of religious beliefs over others or favoring religion (of any variety) over non-religion.</li>
    </ul>
  </li>
  <li><strong>The second amendment</strong>: the right of the people to keep and bear Arms
    <ul>
      <li>however, due to school shootings and gun violence. As a result, gun rights have become a highly charged political issue.</li>
    </ul>
  </li>
  <li><strong>The third amendment</strong>: “No Soldier shall, in time of peace be quartered in any house, without the consent of the Owner, nor in time of war, but in a manner to be prescribed by law.”
    <ul>
      <li>citizens remembered having their cities and towns occupied by British soldiers and mercenaries during the Revolutionary War, and they viewed the British laws that required the colonists to house soldiers particularly offensive</li>
    </ul>
  </li>
  <li><strong>The fourth amendment</strong>: indicates that government officials are required to apply for and receive a <strong>search warrant</strong> prior to a search or seizure;
    <ul>
      <li>sits at the boundary between general individual freedoms and the rights of those suspected of crimes.</li>
      <li>can be seen as to protects us from overzealous efforts by law enforcement to root out crime by ensuring that police have good reason before they intrude on people’s lives with criminal investigations.</li>
      <li><em>however</em>, the courts have found that police <strong>do not</strong> generally need a warrant to search the passenger compartment of a car, or to <strong>search people entering the United States from another country</strong>.
        <ul>
          <li>but they must demonstrate to a judge that there is probable cause to believe a crime has been committed or evidence will be found.</li>
          <li><strong>Probable cause</strong> is the legal standard for determining whether a search or seizure is constitutional or a crime has been committed; it is a lower threshold than the standard of proof at a criminal trial.</li>
        </ul>
      </li>
      <li><strong>exclusionary rule</strong>: obtained <em>without</em> a warrant could not be counted as evidence in a trial</li>
    </ul>
  </li>
</ol>

<h2 id="rights-of-suspects">Rights of Suspects</h2>

<blockquote>
  <p>In addition to protecting the personal freedoms of individuals, the Bill of Rights <strong>protects those suspected or accused of crimes</strong> from various forms of unfair or unjust treatment.</p>
</blockquote>

<p>The next four amendments pertain to those suspected, accused, or convicted of crimes, as well as people engaged in other legal disputes.</p>

<ol>
  <li><strong>the fifth amendment</strong>:
    <ul>
      <li>protection against <strong>self-incrimination</strong>: you have the right <em>not to give evidence</em> in court or to law enforcement officers that <em>might constitute an admission of guilt</em> or responsibility for a crime.</li>
      <li>protects individuals against <strong>double jeopardy</strong>, a process that subjects a suspect to prosecution twice for the same criminal act.</li>
    </ul>
  </li>
  <li><strong>the sixth amendment</strong>: contains the provisions that govern criminal trials, i.e. after which a person is charged with crime
    <ul>
      <li>the right to have a <em>speedy, public trial by an impartial jury</em> (i.e. excessively lengthy delays must be justified and balanced against the potential harm to the defendant.)</li>
      <li><strong>plea bargain</strong>, an agreement between the defendant and the prosecutor in which the defendant pleads guilty to the charge(s) in question, or perhaps to less serious charges, in exchange for more lenient punishment than they might receive if convicted after a full trial.</li>
    </ul>
  </li>
  <li><strong>the seventh amendment</strong>: deals with the rights of those engaged in civil disputes</li>
  <li><strong>the eighth amendment</strong>: cannot impose bail or fines that are unreasonably high or disproportionate to the alleged offense, and prohibits any cruel and unusual punishment
    <ul>
      <li>e.g. drawing and quartering, burning people alive, and the electric chair—are prohibited by this provision.</li>
    </ul>
  </li>
</ol>

<p>Examples include (criminal procedural protections)</p>

<ul>
  <li><em>Mapp v. Ohio</em> - materials obtained by unconstitutional searches cannot be used in criminal courts</li>
  <li><em>Gideon v. Wainwright</em> -  Can’t afford lawyers? State required to pay for lawyer for anyone who cannot afford it</li>
  <li><em>Miranda v. Arizona</em> - police must notify suspects of rights prior to interrogation</li>
  <li><em>In re Gault</em> - can this 15 year old be protected? Decision: procedural constitutional protections apply to juveniles as well</li>
</ul>

<h2 id="interpreting-the-bill-of-rights">Interpreting the Bill of Rights</h2>

<blockquote>
  <p>Ninth and Tenth Amendments indicate <strong>how the Constitution and the Bill of Rights should be interpreted</strong>, and lay out the residual powers of the state governments - these two amendments affect our understanding of the Constitution as a whole.</p>
</blockquote>

<ol>
  <li>
    <p><strong>the ninth amendment</strong>: “The enumeration in the Constitution, of certain rights, shall not be construed <em>to deny or disparage others</em> retained by the people.”</p>

    <ul>
      <li>i.e. James Madison and the other framers were aware they might endanger some rights if they listed a few in the Constitution and omitted others.</li>
    </ul>
  </li>
  <li>
    <p><strong>the tenth amendment</strong>: “The powers not delegated to the United States by the Constitution, nor prohibited by it to the States, are reserved to the States respectively, or to the people.”</p>

    <ul>
      <li>also allows states to guarantee rights and liberties more fully or extensively than the federal government does</li>
      <li>however, by the supremacy clause, if the federal government passes a law or adopts a constitutional amendment that restricts rights or liberties, or a Supreme Court decision interprets the Constitution in a way that narrows these rights, the state’s protection no longer applies.</li>
    </ul>
  </li>
  <li>
    <p><mark>the right to privacy</mark>: scholars have interpreted <em>several Bill of Rights provisions</em> as an <em>indication</em> that James Madison and Congress sought to protect a common-law right to privacy: a right to be free of government intrusion into our personal life, particularly within the bounds of the home.</p>

    <ul>
      <li>
        <p>stem from the 9th amendment, i.e. implicitly reasoned from the other amendments/laws</p>
      </li>
      <li>
        <p><strong>sexual privacy</strong>: including right to obtain contraception, <strong>abortion</strong> rights (overturned recently), the rights for adults to have noncommercial, consensual sexual relationships in private.</p>

        <ul>
          <li><em>Dobbs v. Jackson Women’s Health Organization</em>: now abortion is not protected by constitution (overruled <em>Joe v. Wade</em>)</li>
        </ul>
      </li>
      <li>
        <p><strong>privacy of communication and property</strong>: this has been complicated in modern era where the society is under pervasive surveillance.</p>

        <ul>
          <li>pervasive use of GPS; and research shows that even metadata—information about the messages we send and the calls we make—can tell governments and businesses a lot about what someone is doing.</li>
          <li>increased use of drones, small preprogrammed or remotely piloted aircraft.</li>
          <li>In the United States, many advocates of civil liberties are concerned that laws such as the USA <strong>PATRIOT Act</strong> (i.e., Uniting and Strengthening America by Providing Appropriate Tools Required to Intercept and Obstruct Terrorism Act), passed weeks after the 9/11 attacks in 2001, have given the federal government too much power by making it easy for officials to seek and obtain search warrants or, in some cases, to bypass warrant requirements altogether.</li>
        </ul>

        <p>as a result, the emergence of these technologies (while unarguably beneficial) means calls for vigilance and limits on what businesses and governments can do with the information they collect and the length of time they may retain it.</p>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>other “found” rights</strong> (implied by interpreting other laws)</p>

    <ul>
      <li>to procreate, i.e. people do have fundamental right to have children
        <ul>
          <li>living with extended family</li>
          <li>To control own child’s upbringing (e.g. <em>Meyer v NE</em>, to teach a child a foreign language)</li>
          <li>etc.</li>
        </ul>
      </li>
    </ul>
  </li>
</ol>

<blockquote>
  <p>One takeaway message from the privacy issues. e.g. abortion case with Dobbs</p>

  <ul>
    <li>the same conclusion can be reasoned to by multiple paths</li>
    <li>part of the US Supreme Court reasoning is very political palatable, given the current context
      <ul>
        <li>Hence to make a case successful it largely depends on *how you reason your case</li>
      </ul>
    </li>
  </ul>
</blockquote>

<p>And fundamentally, both the Constitutions and the BoR can be seen as an attempt to solve the collective action problem.</p>

<blockquote>
  <p>By having the Constitutions and BoR:</p>

  <ol>
    <li>Constitution $\to$ a separation of powers $\to$ ensures that decisions are made through a <strong>collective process</strong> involving multiple branches of government
      <ul>
        <li>by requiring cooperation and compromise among different groups and branches of government, it encourages coordination and limiting the ability of any one group to dominate the decision-making process</li>
      </ul>
    </li>
    <li>the Bill of Rights provides protections for individual rights and freedoms that can help to <strong>reduce conformity costs</strong> and <strong>encourage political participation.</strong>
      <ul>
        <li>By guaranteeing freedoms such as free speech, freedom of assembly, and the right to petition the government, the Bill of Rights helps to ensure that minority groups are able to have their voices heard in the decision-making proces</li>
      </ul>
    </li>
    <li>the Constitution and Bill of Rights establish a legal framework $\to$ disputes can be resolved without resorting to violence or coercion $\to$ providing a means for <strong>resolving conflicts and coordinating actions</strong>
      <ul>
        <li>e.g. as there is a law, you have knowledge of what other people can or not do to you</li>
      </ul>
    </li>
  </ol>
</blockquote>

<h1 id="problem-of-delegation">Problem of Delegation</h1>

<p>we will discuss agency models,and then discuss house and senate system in US</p>

<h2 id="agency-model">Agency Model</h2>

<blockquote>
  <p><strong>Agency Model</strong>: developed most in economics, to analyze the phenomenon that one person <strong>delegates some task to another</strong> to get something done (in stead of doing it yourself)</p>
</blockquote>

<p><em>For Example</em>:</p>

<ul>
  <li>voters delegate policy making to governments</li>
  <li>government don’t provide service directly, but sometimes ask private companies</li>
  <li>congress delegates enforcement of laws (but makes a lot of laws) to president and bureaucracy</li>
  <li>school departments delegates teaching to professors</li>
  <li>professor delegate teaching instructors/discussion sections to TAs</li>
  <li>students/parents delegate education and safety to the college they attend</li>
</ul>

<blockquote>
  <p>Sometimes really consequential decisions/responsibilities being delegated to others</p>
</blockquote>

<p>in general, leaders in an organization delegate certain decisions and responsibility to lower members $\implies$ occurs everywhere. <mark>But why did it occur?</mark></p>

<ul>
  <li>take advantage of <strong>specialization</strong> = those delegated with narrow set of tasks can develop better skills at it</li>
  <li>overcome individual <strong>time/resource constraints</strong> = simply too difficult for a single person to control everything
    <ul>
      <li>e.g. all polices report to the chief $\to$ at some point too overwhelming for that single chief to understand what is happening $\to$ hierarchical</li>
    </ul>
  </li>
  <li><strong>mitigate collection action problems</strong> (e.g. free rider) . for example, this <em>small</em> group of people has this responsibility</li>
  <li><strong>deflect responsibility</strong>: let other people enact certain harsh decisions/implementations
    <ul>
      <li>e.g. let IRS collect taxes, but when using it to build infrastructure such as bridges, MC shows up</li>
    </ul>
  </li>
</ul>

<p>While this sounds great, <mark>what can go wrong in this agency model</mark>?</p>

<ul>
  <li>they might not do what you want $\to$ <strong>moral harzard problem</strong> = personal interest for those agents could come first</li>
  <li>they might just be bad at it $\to$ <strong>adverse selection problem</strong></li>
</ul>

<blockquote>
  <p>This basically comes down to <strong>Agency Loss</strong> = different between the quality of you doing it v.s. someone else doing it = i.e. cost of due to delegating power to others</p>
</blockquote>

<p>(note that this is applicable to the proliferation of local government = different lens to the same problem)</p>

<hr />

<p>How do you reduce agency loss?  (i.e. cost of delegating power to others)</p>

<ul>
  <li><strong>Intentional disobedience</strong> can be <strong>mitigated</strong> by
    <ul>
      <li>set clear rules and instructions, be explicit what the agent should do</li>
      <li>punishment/reward, e.g. monitoring</li>
    </ul>
  </li>
  <li><strong>incompetence</strong> can be <strong>mitigated</strong> by
    <ul>
      <li>careful selection of agent with right skills</li>
      <li>dismissing agents without skills, e.g. competitions</li>
    </ul>
  </li>
</ul>

<p>But of course, this might not be easy to implement in real life</p>

<ul>
  <li>how do you keep certain FBI work on law enforcement but not CIA, so that if you tried to remove them they threaten with some compromised documents?</li>
</ul>

<h2 id="the-us-congress">The US Congress</h2>

<p>Recall that:</p>

<ul>
  <li>Instead of having all power delegate to a president (after years of tyranny under a king), framers, while recognizing the need for centralization in terms of a stronger national government with an elected executive wielding its own authority, those at the Constitutional Convention <strong>wanted a strong representative assembly at the national level</strong>: the congress</li>
  <li>Thus, Article I of the Constitution <strong>grants several key powers to Congress</strong>, which include overseeing the budget and all financial matters, introducing legislation, confirming or rejecting judicial and executive nominations, and even declaring war.</li>
</ul>

<blockquote>
  <p>Background:</p>

  <ol>
    <li><strong>Speaker of the House</strong>: The Speaker of the House is the presiding officer of the House of Representatives and is responsible for overseeing the House’s proceedings, setting the agenda, and managing its operations. The Speaker is also second in line to the <em>presidency</em>, after the Vice President. The <em>Speaker is elected by the members of the House</em> and is <strong>typically the leader of the majority party.</strong></li>
    <li><strong>Majority Leader</strong>: The Majority Leader is responsible for managing and scheduling the House’s legislative agenda. They work with the Speaker of the House to set the legislative agenda and help guide legislation through the House. The Majority Leader is typically the second-ranking member of the majority party in the House.</li>
    <li><strong>Minority Leader</strong>: The Minority Leader is responsible for representing the minority party in the House and works with the Majority Leader and Speaker of the House to negotiate and craft legislation. The Minority Leader is typically the leader of the minority party in the House.</li>
    <li><strong>Whip</strong>: The Whip is responsible for counting votes and ensuring that members of their party <strong>vote in accordance with the party’s position</strong>. They work closely with the Majority and Minority Leaders to build support for legislation and to ensure that their party’s position is reflected in the House’s votes.</li>
  </ol>

  <p>What’s special about the Congress system in the US?</p>

  <ul>
    <li>The bicameral system established at the Constitutional Convention and still followed today requires the two houses to pass <strong>identical bills</strong>, or proposed items of legislation. This is not easy, hence
      <ul>
        <li>reduce hasty decisions</li>
        <li>large-scale dramatic reform is exceptionally difficult to pass and that the status quo is more likely to win the day</li>
        <li>difficult for a single faction or interest group to enact laws and restrictions</li>
      </ul>
    </li>
    <li>The congress is a <em>bicameral</em> system
      <ul>
        <li>the <strong>Senate</strong> every state will have two senators who each serve a six-year term.</li>
        <li>the <strong>House of Representatives</strong> are distributed among the states based on each state’s population</li>
      </ul>
    </li>
  </ul>
</blockquote>

<p>Certain <strong>powers of the congress</strong> include (granted by the Constitution)</p>

<ol>
  <li><strong>levy taxes</strong>: quite possibly the most important power Congress possesses, i.e. controls the money.</li>
  <li>setting budget and regulate interstate and international commerce</li>
  <li><strong>introduce legislation</strong></li>
  <li><strong>oversight</strong> of the actions of the president and the administration: the Senate’s final say on many presidential nominations and treaties signed by the president, and the House’s ability to impeach or formally accuse the president or other federal officials of wrongdoing</li>
  <li><strong>war declaration</strong>: they don’t run military, but they can decide whether if war can happen</li>
  <li>also have a “necessary and proper clause”</li>
</ol>

<p>How does <strong>Constitution limit Congress’ power</strong> (therefore incurs conformity costs)</p>

<ul>
  <li>need periodic (2y) <strong>elections</strong> = congressmen needs to respond to people’s needs</li>
  <li>separation of power
    <ul>
      <li>president being able to veto legislations</li>
      <li>house + senate</li>
    </ul>
  </li>
  <li>different elections
    <ul>
      <li>some people could be representing parts of NY, and certain the entire state of NY</li>
      <li>different goals</li>
    </ul>
  </li>
  <li>BoR limiting what congress can do</li>
</ul>

<p>The traditional process by which a bill becomes a law is called the <em>classic legislative process</em>. How does a bill get passed in the congress?</p>

<ol>
  <li>legislation must be drafted</li>
  <li>majority leadership consults with the parliamentarian about which committee to send it to.</li>
  <li>hold a hearing on the bill.
    <ul>
      <li>If the chair decides to not hold a hearing, this is tantamount to killing the bill in committee.</li>
    </ul>
  </li>
  <li>Once hearings have been completed, the bill enters the <strong>markup</strong> stage.
    <ul>
      <li>This is essentially an amending and voting process.</li>
      <li><em>Tabling a bill</em> typically means the bill is dead, but there is still an option to bring it back up for a vote again.</li>
      <li>If the committee decides to advance the bill, however, it is printed and goes to the chamber, either the House or the Senate.
        <ul>
          <li>House can debate and add amendments. Once the limits of debate and amendments have been reached, the House holds a vote. A majority (51%) is needed to pass</li>
          <li>in the Senate, the bill is placed on the calendar so it can be debated. Typically, senators allow each other to talk and debate as long as the speaker wants = the filibuster problem. To invoke <em>cloture</em> (prevent filibuster), the Senate had to get a two-thirds majority.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>Post-fixing:</strong> recall that for a legislation to pass, both House and the Senate need to pass identical bills. Typically one of the two approach is taken:
    <ul>
      <li>the chamber to simply accept the bill that ultimately makes it out of the second chamber.</li>
      <li>first chamber to further amend the second chamber’s bill and send it back to the second chamber.</li>
    </ul>
  </li>
  <li>Pass to <strong>president for signature</strong>.
    <ul>
      <li>If the president does veto the bill, both chambers must muster a two-thirds vote to overcome the veto and make the bill law without presidential approval</li>
    </ul>
  </li>
</ol>

<p><img src="/lectures/images/2023-05-11-POLS1201_Intro_to_American_Politics/image-20230224232743479.png" alt="image-20230224232743479" style="zoom:30%;" /></p>

<h2 id="congress-with-agency-model">Congress with Agency Model</h2>

<p>How do <strong>collective action problem</strong> limit Congress</p>

<ul>
  <li>need for information
    <ul>
      <li>free-rider: the acquisution of knowledge incurrs some costs, but once you know it everybody can take advantage of it</li>
    </ul>
  </li>
  <li>compromise/building coalitions
    <ul>
      <li>legislation need majorities to make decisions</li>
    </ul>
  </li>
  <li>need to <strong>decide</strong> what to prioritize, since workload is inhuman (coordination problem)</li>
  <li>getting members of congress to work towards the <strong>same goal</strong>. Arises since individual and collective goals could be different
    <ul>
      <li>individual goals: reelection/higher office; power in Washington. i.e. MC might be better of
        <ul>
          <li>doing casework = directly helping a person = getting support back</li>
          <li>focus on pet legislation = what you personally really cared about</li>
          <li>just spend a lot of time campaigning in the district</li>
          <li>not drafting legislation (which is technically the job as congress member)</li>
        </ul>
      </li>
      <li>collective goal: good public policy, maintaining the institution</li>
    </ul>
  </li>
</ul>

<blockquote>
  <p>Collective action of the congress (e.g. drafting good polict) significantly <strong>undermined by individual interests</strong></p>
</blockquote>

<p>But this is not without hope:</p>

<ul>
  <li><strong>Specific members</strong> (i.e. a hierarchy) have special powers to <strong>induce coordination</strong> (solve coordinate action)
    <ul>
      <li><strong>legislative parties</strong>: Members of Congress are organized into political parties, and party leaders play a critical role in p<em>romoting coordination among members</em>.
        <ul>
          <li>Party leaders work to <strong>build consensus</strong> (balance individual interests) and ensure that their party’s positions are <strong>reflected in legislative outcomes</strong>.</li>
          <li>reduce the cost of information exchange and promote the exchange of information and ideas</li>
        </ul>
      </li>
      <li><strong>committee system</strong>: allows for members to work together to craft policy and can help to <strong>balance individual interests</strong> with the interests of the legislative body as a whole; can also seen as being <strong>delegated</strong> some power
        <ul>
          <li>so that this <em>smaller group of people</em> can do collective action stuff more easily, e.g. gathering information</li>
          <li>but the tradeoff is of course that there is still agency loss? How do we mitigate that?
            <ul>
              <li>select the right members (e.g. to control what kind of bills show up at the first place, e.g. giving leadership positions to loyal members)</li>
              <li>deploy reward and punishments (e.g. reward specific members things they are interested in)</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>shift some of the benefits of individual goals/powers</strong> to speakers of the house/whips
    <ul>
      <li>Speaker of the House and the Majority Leader have the ability to decide which bills are brought to the floor for consideration, and they have the power to shape the legislative agenda. This allows them to prioritize certain issues and work to build consensus among members, rather than allowing individual members to dictate the agenda based solely on their own interests.</li>
      <li>the Whips do focus on getting votes for their party’s positions, they also work to ensure that party members are represented and that their interests are taken into account in the legislative process.</li>
      <li>MC give up some individual freedom for collective benefits</li>
      <li>but given speaker of house’s power, this means that:
        <ul>
          <li>[-] e.g. Gaetz v.s. McCarthy. Gaits said we are not voting for you unless you change the powers to limit yourself. Note that in republican there are extreme factions = members want restraints on the speaker of house.</li>
          <li>[+] e.g. can use reward/punishment = essentially their power to achieve what they want. Nacy Pelosi to get AOC (Alexandria Ocasio-Cortez) if you do what;
            <ul>
              <li>threats = cut you out on majority committee</li>
              <li>get another candidate to compete with you</li>
            </ul>
          </li>
          <li>in summary, leader use reward and penalty to motivate the party. But party can change what power leaders have correspondingly</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><mark>agency model as a solution:  delegation of power</mark> from the house, and intended to use them to solve the collection problem
    <ul>
      <li>Resources of delegated to Party Leaders
        <ul>
          <li><strong>scheduling (agenda control)</strong>: setting rules of <em>how to make decisions</em> can affect the final decision!
            <ul>
              <li>e.g. preference for three senators A&gt;B&gt;C v.s. B&gt;C&gt;A v.s. C&gt;A&gt;B</li>
              <li>then A v.s. B will have A win; A v.s. C will have C win = what actually gets passed</li>
              <li>hence, this could <em>also be misused</em> for bad purposes</li>
            </ul>
          </li>
          <li>can control campaign money = solve coordination problem by giving reward and threats = controlling priority and working towards the same goal
            <ul>
              <li>e.g. Pelosi denying party members of Campaign funds when they don’t do their job (in Pelosi’s eyes)</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>Resource for Party in Senate (some what weaker and much more limited)
        <ul>
          <li>no rules committee</li>
          <li>unlimited debate and amendments
            <ul>
              <li>less efficient = small member of senate can kill legislation</li>
            </ul>
          </li>
          <li>decide committee leadership by seniority</li>
        </ul>
      </li>
      <li>delegate work to a committee: as explained before, a committee with less people have a smaller collective action problem. But</li>
    </ul>
  </li>
</ul>

<blockquote>
  <p>In the collective action framework, those are strategies to get one policy/preference passed among many conflicting preferences.</p>
</blockquote>

<hr />

<blockquote>
  <p>In general, political change is hard</p>

  <ul>
    <li>federal system has created a lot of veto points, so people can maintain policies they liked</li>
    <li>entrenched political power extensive, used to preserve status quo (e.g. the conservatism in the bicameral Congress)</li>
  </ul>
</blockquote>

<p>Hard to change, but not impossible. It is important for you to understand <em>what it takes/you need to do</em> to change the world.</p>

<ul>
  <li>abortion now banned 12 states now</li>
  <li>slavery and Jim Crow segregation ended</li>
</ul>

<h2 id="typology-of-legislation">Typology of Legislation</h2>

<blockquote>
  <p>crucial to explain <em>what</em> legislation can be passed more easily in the congress. A lot of this depends on:</p>

  <ul>
    <li>who/how many is going to <em>come to you</em> and complain (e.g. people being unhappy)</li>
    <li>who/how many is going to is going to <em>come to you</em> and reward/support you (e.g. people being happy)</li>
  </ul>
</blockquote>

<p>To see why this happens, we can first understand how <strong>targeted a particular legislation will be</strong></p>

<ul>
  <li>e.g. if you take a <em>particular group</em> benefit away/give, people will notice. If everybody pays a little, is fine = diffuse cost</li>
</ul>

<table>
  <thead>
    <tr>
      <th> </th>
      <th>Concentrated Costs</th>
      <th>Diffuse Costs</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Concentrated Benefits</td>
      <td>NA Free Trade Agreement<br />Cigarette tax to fund inner city education</td>
      <td>Farm subsidies (farmers get money for keeping land but funded by taxation)<br />Automotive subsidies</td>
    </tr>
    <tr>
      <td>Diffuse Benefits</td>
      <td>Environmental Protection<br />Eminent domain</td>
      <td>Military<br />Public education</td>
    </tr>
  </tbody>
</table>

<p>why the above:</p>

<ul>
  <li>NA Free Trade Agreement: any business can have the entire NA for trade; all those business that depends on the tariff needs to bear a huge costs</li>
  <li>Environmental Protection: business who pollutes need to bear the immense costs; benefit is for everyone in general = diffuse</li>
  <li>Eminent domain: government taking over some property (e.g. land) for a public project</li>
  <li>Military: the US entirely benefits form the strong military; paid by the broad tax based</li>
</ul>

<p>In general:</p>

<ul>
  <li>if costs/benefits are concentrated = leads to recipients <em>very likely</em> to provide feedback/show up</li>
  <li>if costs/benefits are diffuse = leads to recipients <em>unlikely</em> to notice</li>
</ul>

<blockquote>
  <p>Hence</p>

  <ul>
    <li><strong>MC biased toward</strong> well organized <strong>narrow interests</strong> = concentrated benefits and diffuse costs $\to$ benefited people will more likely show up to support the bill</li>
    <li><strong>MC will be bad passing</strong> at diffuse benefits and concentrated cost = not a lot of people show up to support it, but a lot showing up to condemn</li>
  </ul>
</blockquote>

<h1 id="the-presidency">The Presidency</h1>

<p>Some background</p>

<ul>
  <li>
    <p><strong>Election Process: primaries and electoral college</strong></p>

    <ul>
      <li>The rise of the <strong>presidential primary</strong> and <strong>caucus</strong> system as the main means by which presidential <mark>candidates</mark> are selected has had a number of anticipated and unanticipated consequences.
        <ul>
          <li>i.e. the political <strong>party system</strong>, + primaries, which are elections in which candidates vied for the support of state delegations to the party’s nominating convention.</li>
          <li><em>caucus</em> or large-scale gathering was made up of legislators in the Congress who met informally to decide on nominees from their respective parties.</li>
          <li>Hence, to win in primaries $\to$ candidates seek to align themselves with committed partisans,</li>
        </ul>
      </li>
      <li>then, the candidate who wins the popular vote in November receives <strong>all the state’s electoral votes</strong>.
        <ul>
          <li>the Electoral College consists of a body of 538 people called electors, each representing one of the fifty states or the District of Columbia.</li>
          <li>this system created certain irregularities: e.g. Donald Trump comfortably won the Electoral College by narrowly winning the popular vote in several states, while Hillary Clinton collected nearly 2.9 million more votes nationwide.</li>
          <li>Should no candidate receive a majority of the votes cast, the <em>House of Representatives</em> would select the president, with each state casting a single vote, while the <em>Senate</em> chose the vice president.</li>
        </ul>
      </li>
    </ul>

    <p><img src="/lectures/images/2023-05-11-POLS1201_Intro_to_American_Politics/image-20230225003637956.png" alt="image-20230225003637956" style="zoom:33%;" /></p>
  </li>
  <li>
    <p><strong>Impeachment</strong>: removing the president over serious wrongdoing</p>

    <ol>
      <li>the House of Representatives could impeach the president by a simple <strong>majority</strong> vote.</li>
      <li>the Senate could remove the president from office by a <strong>two-thirds majority</strong></li>
    </ol>

    <p>e.g. the most recent impeachments were of President Donald Trump, who was impeached in the House twice. However, support for removal in the Senate did not meet the super-majority requirement,</p>
  </li>
  <li>
    <p><strong>Power of the president</strong>: a few note-worthy ones include</p>

    <ol>
      <li><strong>commander-in-chief</strong> of the armed forces of the United States
        <ul>
          <li>today, this has been expanded greatly, with presidents waging undeclared wars,</li>
        </ul>
      </li>
      <li>negotiate treaties with the advice and consent of the Senate, and receive representatives of foreign nations</li>
      <li><strong>nominating federal judges, including Supreme Court justices</strong>, as well as other federal officials, and making appointments to fill military and diplomatic posts.</li>
      <li><strong>veto</strong> legislation if necessary, although a two-thirds supermajority in both houses of Congress could override that veto;</li>
      <li>(later developed) <strong>executive privilege</strong>, the right to withhold information from Congress, the judiciary, or the public.</li>
    </ol>

    <p>The rather vague wording in Article II, which says that the “<em>executive power shall be vested</em>” in the president, has been subject to broad and sweeping interpretation in order to <strong>justify actions beyond those specifically enumerated</strong></p>
  </li>
</ul>

<p>In general, we now see a growth of presidential power attributable to the growth of the United States $\to$ rising profile of the United States on the international stage has meant that the president is a far more important figure as leader of the nation.</p>

<hr />

<p>After winning an election:</p>

<ul>
  <li>
    <p><strong>appointments</strong></p>

    <ul>
      <li>most importantly selection of a <strong>cabinet</strong>.
        <ul>
          <li>today in total there are 15 members</li>
          <li>inner cabinet—the heads of the Departments of Defense, Justice, State, and the Treasury (echoing Washington’s original cabinet)—receive the most attention from the president, the Congress, and the media.</li>
          <li>president nominate those positions, while the <strong>Senate confirms or rejects these nominations</strong>. Though most of the time it is confirm.</li>
        </ul>
      </li>
      <li>selection of <strong>the West Wing of the White House</strong> = president’s staff, and the name is where they worked
        <ul>
          <li>e.g. political advisers, speechwriters, and a press secretary to manage the politics and the message of the administration</li>
          <li><em>not</em> subject to Senate approval</li>
        </ul>
      </li>
      <li>selection of <strong>vice president</strong>: before, vice presidents were often sent on minor missions or used as mouthpieces for the administration. But now they are taking a much more active role + collaboration with the president.</li>
    </ul>
  </li>
  <li>
    <p><strong>forging an agenda</strong>: decide how to deliver upon what was promised during the campaign.</p>
    <ul>
      <li>most presidents do recognize that they must address their major initiatives during their <strong>first two years</strong> in office.</li>
      <li>the delivery of an <strong>inaugural address</strong>: set forth priorities within the overarching vision of what they intend to do.</li>
    </ul>
  </li>
</ul>

<hr />

<p>The public presidency: can you use media + IT to get more political popularity?</p>

<ul>
  <li>before, using radio to broadcast the president’s voice into many of the nation’s homes.</li>
  <li>now, <strong>television and the internet</strong>, but it remains a question <mark>whether choosing to go public actually enhances a president’s political position</mark> in battles with Congress.
    <ul>
      <li>[-] polarize political debate</li>
      <li>[-] increase public opposition to the president</li>
      <li>[-] complicate the chances to get something done.</li>
      <li>[+] rallying supporters</li>
    </ul>
  </li>
  <li>but also the <strong>first lady</strong>: help to gain public support and help their husbands
    <ul>
      <li>e.g. increasing public political role of the first lady continued in the 1980s with Nancy Reagan’s “Just Say No” antidrug campaign</li>
    </ul>
  </li>
</ul>

<hr />

<p>President’s action during office:</p>

<ul>
  <li><strong>direct action</strong>, it may break a policy deadlock or establish new grounds for action
    <ul>
      <li>exercises the power of <strong>pardon</strong> without conditions, i.e. fully forgiven for their offense, and their criminal record is effectively erased</li>
      <li><strong>line-item veto</strong> is a type of veto that keeps the majority of a spending bill unaltered but nullifies certain lines of spending within it.</li>
      <li><strong>signing statements</strong> are statements issued by a president when agreeing to legislation</li>
      <li><strong>executive orders</strong> or proclamations to achieve policy goals = direct government agencies to pursue a certain course, but are subject to court rulings or changes in policy enacted by Congress
        <ul>
          <li><mark>often used in cases of national security</mark>, e.g. aggressively deploy U.S. military force.</li>
          <li><strong>rally around the flag effect</strong>, in which presidential popularity spikes during international crises = during national emergencies and war, presidents need to act independently and vigorously</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>informal powers</strong> of <strong>persuasion</strong> and negotiation essential to working with the legislative branch $\to$ to secure policy achievements in cooperation with Congress.
    <ul>
      <li>e.g. when the president nominates and the Senate confirms persons to fill vacancies on the Supreme Court</li>
      <li>e.g. In times of divided government (when one party controls the presidency and the other controls one or both chambers of Congress), it is up to the president to cut deals and make compromises that will attract support from at least some members of the opposition party</li>
    </ul>
  </li>
</ul>

<h2 id="how-powerful-is-the-us-president">How Powerful is the US President</h2>

<blockquote>
  <p>19th century president had weak power, more like clerks than leaders</p>

  <ul>
    <li>limited role in domestic policy making</li>
    <li>limited capacity in federal agencies</li>
    <li>cabinet (parties) made most of the policy choices</li>
    <li>exceptions of this include
      <ul>
        <li>Lincoln: assumed unpredence tpower during civil <em>war</em></li>
        <li>Jackson - incredibly popular so can go against Congress and courts</li>
      </ul>
    </li>
  </ul>

  <p>20 century - instead of lead by congress, federal government lead by the <strong>executives</strong></p>

  <ul>
    <li>due to industrial revolution = a lot happened and <strong>Congress appointed</strong> those stuff to the <em>executives</em></li>
    <li>New Deal programs expanded purview of <em>executives</em></li>
    <li>Great Society continued</li>
    <li>eventually the Congressional monitoring resource did not keep pace with executives work, could not monitor anymore</li>
  </ul>
</blockquote>

<p><strong>Advantage/Disadvantage of extensive delegation of power to executives</strong> by the Congress</p>

<ul>
  <li>[+] specialization: possibly greater expertise acquisition</li>
  <li>[+] reduced a lot of workload congress</li>
  <li>[+] more flexible policy-making
    <ul>
      <li>faster to change = congress might want certain policy changes more <em>up-to-date</em> with economic, medical, advances in science situations today</li>
      <li>but of course in the Congress’s perspective, you are <em>giving up power</em> = delegation problem</li>
    </ul>
  </li>
  <li>[+] avoid contentious policy issues (a political benefit for the congress, deflect responsitbility)</li>
  <li>[-] policy control becomes harder (one solution they employed is to make <em>rules</em> on how those policy can be made)</li>
</ul>

<p>As a result, the <strong>president’s power today can hugely affect policy-making</strong></p>

<ul>
  <li><strong>veto</strong> power of president
    <ul>
      <li>even if president doesn’t veto = still huge impact because policies being written, hidden in mind, want to comply to president = but incredible difficult to measure its impact</li>
      <li><strong>veto bargining</strong></li>
    </ul>
  </li>
  <li><strong>persuasion</strong>: if the congress passed something the president doesn’t like, one choice is to appeal to/persuade the public and let the public put pressure on the congress! (it is often very easy for the president to gather media attention)</li>
  <li><strong>unilateral executive action</strong>: allow presidents to “make” policy outside of the regular lawmaking process, allowing them to <a href="https://doi.org/10.1111/j.1741-5705.2005.00258.x">move first and act alone</a> in policy-making
    <ul>
      <li>i.e. “if the congress is not doing it, I will do it”.</li>
    </ul>
  </li>
</ul>

<h2 id="veto-bargaining">Veto Bargaining</h2>

<p>What will happen to the <em>bill devised by the Congress leaders</em> (ignoring Senator for now), if they know it can be vetoed by president?</p>

<ul>
  <li>sometimes it is <strong>not about passing a policy</strong>, but to <strong>send message</strong>
    <ul>
      <li>e.g. objective was to signal to policy maker that they are committed to change the policy</li>
    </ul>
  </li>
  <li>ordinarily, presidential veto is taken into account <strong>when coming up with a policy</strong>.
    <ul>
      <li>
        <p><strong>spatial model:</strong> a single dimension of <code class="language-plaintext highlighter-rouge">&lt;----- P ------- C -----&gt;</code>. Let SQ be the status quo policy, and distance being how disliked it is</p>

        <ol>
          <li><code class="language-plaintext highlighter-rouge">&lt;--SQ-- P ------- C -----&gt;</code>. Congress can draft a policy $p$ <em>towards their ideal upto</em> here <code class="language-plaintext highlighter-rouge">&lt;--SQ-- P --p---- C -----&gt;</code> and president won’t veto.</li>
          <li><code class="language-plaintext highlighter-rouge">&lt;----- P ------- C --SQ--&gt;</code>. Congress can draft a policy <em>exactly at their ideal</em>, to <code class="language-plaintext highlighter-rouge">&lt;----- P ------- Cp --SQ--&gt;</code>, and the president will also pass it</li>
          <li><code class="language-plaintext highlighter-rouge">&lt;----- P ---SQ--- C -----&gt;</code>. Then status quo cannot be changed = congress <em>cannot</em> propose a new legislation different from this = <mark>gridlock</mark>. (i.e. <strong>P and C want to move the policy in opposite direction</strong>). For example,
            <ul>
              <li>immigration reform = Republican want to make immigrant less pleasant, and democrats want to improve</li>
              <li>Environmental policy = Biden want to increase control on env, but Congress want to decrease environmental monitor;</li>
              <li>Abortion</li>
            </ul>
          </li>
        </ol>
      </li>
      <li>what can politicians do if it is in gridlock?
        <ul>
          <li>omnibus = pack something the president like into the policy, but also something you like so that president more likely pass it</li>
          <li>C: best option is to pass/think about other policies, or if they can, change what P wants</li>
          <li>P: can perform <mark>unilateral executive action</mark> = change policy on their own, and wait for congress to stop them. Why <mark>executives are so powerful today</mark></li>
        </ul>
      </li>
      <li>from the spatial model
        <ul>
          <li><strong>if $P$ and $C$ are aligned</strong>, the interval of opposite pull will be smaller = pass policy easier as they have the same interest</li>
          <li><strong>greater polarization</strong>: the gridlock interval becomes wider = president party very very different from the Congress = harder to make policy</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p>but of course, several nuances in the spatial model</p>

<ul>
  <li>
    <p>Congress can overrule veto with super-majority = then this model doesn’t work = need to also model senators</p>
  </li>
  <li>
    <p><strong>First-Mover Advantage</strong>: whoever passes something first will <em>force the other to either veto it or pass it</em>. Consider the three scenarios above</p>

    <ul>
      <li>Congress moves first (because they are legislative anyway):
        <ul>
          <li>case 1) [+] congress can draft a policy $p$ <em>towards their ideal upto</em> here <code class="language-plaintext highlighter-rouge">&lt;--SQ-- P --p---- C -----&gt;</code></li>
          <li>case 2) [+] can draft <em>exactly at their ideal</em>, to <code class="language-plaintext highlighter-rouge">&lt;----- P ------- Cp --SQ--&gt;</code></li>
          <li>case 3) no gain no loss</li>
        </ul>
      </li>
      <li>President move first by passing <mark>executive order</mark>, so Congress is forced to either veto or pass it
        <ul>
          <li>case 1) [+] president can move directly at his/her ideal</li>
          <li>case 2) [+] can move to <code class="language-plaintext highlighter-rouge">&lt;----- P ----p-- C --SQ--&gt;</code> hence becomes closer to the president than before</li>
          <li>case 3) no gain no loss</li>
        </ul>
      </li>
    </ul>

    <p><mark>in all cases, whoever moves first gains advantage!</mark> An example IRL is Biden’s 400billion student loan relief program passed using executive order. Now congress/USSC is unhappy and checking it.</p>
  </li>
</ul>

<p>Therefore: agreements will be much harder to reach, but it depends the above strategies</p>

<h2 id="unilateral-executive-action">Unilateral Executive Action</h2>

<blockquote>
  <p><strong>Executive orders</strong>: direct/ask agencies in how they should carry out their job but technically cannot touch on law-making</p>
</blockquote>

<p>Example: Case of DACA: how executive orders can be used to “change” policy</p>

<ul>
  <li>DACA stands for Deferred Action for Childhood Arrivals. It is a program that offers work permits and deportation relief to more than 640,000 undocumented immigrants <strong>brought to the U.S. when they are children</strong></li>
  <li>One memo signed by President Biden <strong>ordered</strong> the Departments of Homeland Security to safeguard the Obama-era DACA program</li>
</ul>

<p>Legislative orders:</p>

<ul>
  <li>immigration reform has been an issue = federal gov failed to pass any significant policy in immigration</li>
  <li>2012- Obama admin issued rule on discretoin over deportatoin</li>
  <li>USSC said Trump had this power but the way he uses it is wrong</li>
</ul>

<blockquote>
  <p>Conclusion: president is powerful, but</p>

  <ul>
    <li>limited on political circumstances.</li>
    <li>mismatch in expectations bending the laws = innovation</li>
  </ul>
</blockquote>

<h1 id="the-courts">The Courts</h1>

<p>Some backgrounds:</p>

<ul>
  <li>along with part of the <strong>check and balance system</strong>, the judiciary is arguably the branch where the <strong>individual has the best chance to be heard</strong>. For the most part, the Supreme Court is an appeals court, operating under <strong>appellate jurisdiction</strong> (i.e. hearing appeals from the lower courts)</li>
  <li>
    <p>the power of <strong>judicial review</strong>: as part of the system of checks and balances, to look at actions taken by the other branches of government and the states and determine whether they are constitutional.</p>
  </li>
  <li>
    <p>before, the basic structure of the judicial branch was:</p>

    <ul>
      <li>At the lowest level are the <strong>district courts</strong>, where federal cases are tried, witnesses testify, and evidence and arguments are presented.</li>
      <li>A losing party who is unhappy with a district court decision may appeal to the circuit courts, or <strong>U.S. courts of appeals</strong>, where the decision of the lower court is reviewed.</li>
      <li>Still further, appeal to the U.S. Supreme Court is possible, but of the thousands of petitions for appeal, the Supreme Court will typically hear fewer than one hundred a year.</li>
    </ul>
  </li>
  <li>
    <p>the judiciary today continues as a <strong>dual court system</strong></p>

    <ul>
      <li>
        <p>with courts at <mark>both the national and state levels</mark>.</p>
      </li>
      <li>
        <p>Both levels have three basic tiers consisting of <strong>trial court</strong>, appellate court, and finally courts of last resort, typically called supreme courts</p>

        <p><img src="/lectures/images/2023-05-11-POLS1201_Intro_to_American_Politics/image-20230225023717252.png" alt="image-20230225023717252" style="zoom:22%;" /></p>

        <p>in case of federal courts:</p>

        <ul>
          <li>there are ninety-four U.S. <strong>district courts</strong> in the fifty states and U.S. territories, of which eighty-nine are in the states (at least one in each state).</li>
          <li>On the U.S. Supreme Court, there are nine justices—one chief justice and eight associate justices. Circuit courts each contain three justices, whereas federal district courts have just one judge each.</li>
          <li>court system operates on the principle of <strong><em>stare decisis</em></strong> (Latin for <em>stand by things decided</em>), which means that today’s decisions are based largely on rulings from the past = if legal facts of today’s court is the same as before, then it should be treated the same way. <mark>court interpretations can change as times and circumstances change</mark>, hence changes is still possible.</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p>Courts and Public Policy</p>

<ul>
  <li>United States has a <strong>common law</strong> system. With code law in place, as it is in many nations of the world, it is the job of judges to simply apply the law. Under common law, as in the United States, they <em>interpret</em> it</li>
  <li><strong>last resort</strong> for individuals or a group believing there as been a wrong
    <ul>
      <li>e.g. employment <strong>discrimination</strong> based on their religious attire,</li>
      <li>e.g. put limits on the ability to impose the death penalty, ruling, for example, that the government may not execute a person with cognitive disabilities</li>
    </ul>
  </li>
</ul>

<hr />

<p><strong>Courts and Federalism</strong></p>

<ul>
  <li>
    <p>State courts really are the core of the <strong>U.S. judicial system</strong>, and they are responsible for a huge area of law.</p>

    <ul>
      <li>Although the Supreme Court tends to draw the most public attention, it typically hears fewer than one hundred cases every year.</li>
      <li>The federal courts, on the other hand, will hear any case that involves a foreign government, patent or copyright infringement.</li>
    </ul>

    <table>
      <thead>
        <tr>
          <th style="text-align: left">State Courts</th>
          <th style="text-align: left">Federal Courts</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td style="text-align: left">Hear most day-to-day cases, covering 90 percent of all cases</td>
          <td style="text-align: left">Hear cases that involve a “federal question,” involving the Constitution, federal laws or treaties, or a “federal party” in which the U.S. government is a party to the case</td>
        </tr>
        <tr>
          <td style="text-align: left">Hear both civil and criminal matters</td>
          <td style="text-align: left">Hear both civil and criminal matters, although many criminal cases involving federal law are tried in state courts</td>
        </tr>
        <tr>
          <td style="text-align: left">Help the states retain their own sovereignty in judicial matters over their state laws, distinct from the national government</td>
          <td style="text-align: left">Hear cases that involve “interstate” matters, “diversity of citizenship” involving parties of two different states, or between a U.S. citizen and a citizen of another nation (and with a damage claim of at least $75,000)</td>
        </tr>
      </tbody>
    </table>
  </li>
  <li>
    <p>this federal design has both pluses and minuses</p>
    <ul>
      <li>[+] more than just one court system ready to protect that</li>
      <li>[-]  judicial rulings about what is legal or illegal may differ from state to state $\leftarrow$ state law that governs the authority of state courts
        <ul>
          <li>different courts in which a person could face charges for a crime or for a violation of another person’s rights.</li>
          <li>Just as the laws <strong>vary</strong> across the states, so do <strong>judicial rulings and interpretations</strong>, and the judges who make them.</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<hr />

<p><strong>The federal court system</strong>: the basics has been mostly covered before with the three level. Here we discuss the <strong>selection of judges</strong></p>

<ul>
  <li>
    <p>At the federal level, the <strong>president nominates a candidate</strong> to a judgeship or justice position, and the <strong>nominee must be confirmed</strong> by a majority vote in the U.S. Senate</p>

    <ul>
      <li>through such <strong>senatorial courtesy</strong>, senators exert considerable influence on the selection of judges in their state,</li>
    </ul>
  </li>
  <li>
    <p>All judges and justices in the <em>national courts</em> (from US District to USSC) serve <strong>lifetime</strong> terms of office. This is to provide the judicial branch with enough independence such that it could not easily be influenced by the political winds of the time.</p>
  </li>
  <li>
    <p>What was once a predominately White, male, Protestant institution is today much more diverse:</p>

    <table>
      <thead>
        <tr>
          <th>First Catholic</th>
          <th>Roger B. Taney (nominated in 1836)</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>First Jew</td>
          <td>Louis J. Brandeis (1916)</td>
        </tr>
        <tr>
          <td>First (and only) former U.S. President</td>
          <td>William Howard Taft (1921)</td>
        </tr>
        <tr>
          <td>First African American</td>
          <td>Thurgood Marshall (1967)</td>
        </tr>
        <tr>
          <td>First Woman</td>
          <td>Sandra Day O’Connor (1981)</td>
        </tr>
        <tr>
          <td>First Hispanic American</td>
          <td>Sonia Sotomayor (2009)</td>
        </tr>
      </tbody>
    </table>

    <p>However, the number of women and people of color on the courts <strong>still lags behind the overall number of White men</strong>.</p>

    <ul>
      <li>As of 2021, the federal judiciary consists of 67 percent men and 33 percent women.</li>
      <li>In terms of race and ethnicity, 74 percent of federal judges are White, 12 percent African American, 8 percent Latinx, and 4 percent Asian American.</li>
    </ul>
  </li>
</ul>

<hr />

<p><strong>The US Supreme Court</strong></p>

<ul>
  <li>structure
    <ul>
      <li>There is one <strong>chief justice</strong>, who is the lead or highest-ranking judge on the Court, and eight <strong>associate justices</strong></li>
      <li>Each justice has three or four <strong>law clerks</strong>: law clerks’ work and recommendations influence whether the justices will choose to hear a case</li>
    </ul>
  </li>
  <li>selecting cases
    <ul>
      <li>Case names, written in italics, list the name of a petitioner versus a respondent, as in <em>Roe v. Wade</em>, for example. Since the petitioner is the one bringing up the case and the party unhappy with the decision of the lower court will be the one $\to$ can tell which party lost at the lower level of court (e.g. Roe, for example)</li>
      <li>accepts <strong>fewer than 2 percent</strong> of the as many as ten thousand cases it is asked to review every year.
        <ul>
          <li>most often it is <strong>writ of <em>certiorari</em></strong>, a request that the lower court send up its record of the case for review. Then four of the nine justices must vote to accept a case. This is called the <strong>Rule of Four</strong>.</li>
          <li><strong>solicitor general</strong> is the lawyer who represents the federal government before the Supreme Court: He or she decides which cases (<strong>in which the United States is a party</strong>) should be appealed from the lower courts and personally approves each one presented. Most of the cases the solicitor general brings to the Court will be given a place on the docket.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>supreme court procedures
    <ul>
      <li>Once a case has been placed on the docket, <strong>briefs</strong>, or short arguments explaining each party’s view of the case, must be submitted
        <ul>
          <li>first by the petitioner and respondent</li>
          <li>other non-involving groups may also file may file an <strong>*amicus curiae*</strong> (“friend of the court”) brief giving their opinion, analysis, and recommendations about how the Court should rule.</li>
        </ul>
      </li>
      <li>After brief filed, USSC hears <strong>oral arguments</strong> in cases from October through April. The proceedings are quite ceremonial.
        <ul>
          <li>each side’s lawyers have thirty minutes to make their legal case, though the justices often interrupt the presentations with questions.</li>
          <li>decide the case in a (private) conference by discussions and then voting</li>
          <li>Oral arguments are open to the public.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Judicial opinions
    <ul>
      <li>along with the decision, there will be a published <strong>majority opinion</strong> = explanation of the majority vote, and a <strong>dissenting opinion</strong>, being written by the people assigned by most senior justice in the dissenting group</li>
    </ul>
  </li>
  <li>Influencing the decision
    <ul>
      <li>courts must rule on its facts. Although the courts’ role is interpretive, judges and justices are still constrained by the facts of the case, the Constitution, the relevant laws, and the courts’ own precedent.</li>
      <li>but in reality <strong>many factors play a role in its decision-making</strong>
        <ul>
          <li>including law clerks, the solicitor general, interest groups, and the mass media. But additional legal, personal, ideological, and political influences weigh on the Supreme Court and its decision-making process.</li>
          <li>judges personal beliefs and political attitudes also matter</li>
          <li>affected by another “court”—the court of public opinion, e.g. swayed by special-interest pressure, the mass media, etc.</li>
        </ul>
      </li>
      <li>Both the <strong>executive and legislative branches check and balance</strong> the judiciary in many different ways.
        <ul>
          <li>President appoint nominees, Congress retains the power to modify the federal court structure and its appellate jurisdiction, and the Senate may accept or reject presidential nominees to the federal courts.</li>
          <li>court rulings matter only to the extent they are heeded and followed = <strong>judicial implementation</strong>. While it is true that courts play a major role in policymaking, they have <em>no mechanism to make their rulings a reality</em> = <mark>relies on the executive to implement</mark> or enforce its decisions.</li>
          <li>in general both the president and other branches <em>tend to provide support</em> rather than opposition $\to$ what becomes of court decisions is largely due to their credibility, their viability, and the assistance given by the other branches of government.</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p>Therefore, <strong>US legal system is federalized</strong> with the legislatures:</p>

<ul>
  <li>50 state court systems and 50 state constitutions</li>
  <li>federal courts can declare <strong>state laws invalid</strong> if they conflict with the federal constitution (supremacy clause)
    <ul>
      <li>e.g. abortion is explicitly protected in some states while not in the constitution = allowed under this framework</li>
    </ul>
  </li>
</ul>

<h2 id="judiciary-court-and-the-agency-problem">Judiciary Court and the Agency Problem</h2>

<p>What’s the aim of federal court?</p>

<ul>
  <li><strong>resolving disputes</strong>: often <em>state</em> and <em>federal</em> governments disagree, or <em>congress</em> and <em>president</em> disagree
    <ul>
      <li>e.g. Trump admin threatening California air quality standards (i.e. your cars need to meet a particular efficiency threshold, and they set their own standards). California wanted to raise the standard due to the large amount of cars there, but Trump disagrees.</li>
      <li>e.g. ACA medicaid expansion</li>
      <li>e.g. Trump v. Hawaii</li>
    </ul>
  </li>
  <li><strong>judicial review</strong> = declare laws invalid/enforce state agencies to do stuff = <mark>most important for political science</mark></li>
</ul>

<p>Structure: USSC is really the court of <strong>final appeal</strong></p>

<ul>
  <li>justices vote whether or not to accept a case, usually important ones such as from solicitors (represent US gov)</li>
  <li>judgments from USSC set precedent for the entire country = so laws are <strong>even across states</strong></li>
</ul>

<p>Agency problem and USSC:</p>

<ul>
  <li>government chooses USSC members, hence delegation = <strong>judges act as agents of Congress and President</strong>
    <ul>
      <li>to help implement decisions</li>
      <li>to help adjudicate bureaucracti obedience</li>
      <li>but of course, the aim of USSC is to reduce agency loss (e.g. congress has 800+ people)</li>
    </ul>
  </li>
  <li>Regular criticism: life appointment inconsistent with democratic policy control</li>
  <li>Regular defense: protect the rights to unpopular people/minority (i.e. even against popular idea, you will not be removed = less impetus to conform simply to majority)</li>
</ul>

<p><strong>How can the agency loss be <em>limited</em></strong>?</p>

<ul>
  <li>careful selection: president appoints judges and senate confirms</li>
  <li>reasonably <strong>controlled/monitored</strong> by the congress and other branches:
    <ul>
      <li>congress sets structure of fedearl courts</li>
      <li>if congress is unhappy with it, congress can change laws, e.g. start the process of amending the constitution</li>
    </ul>
  </li>
</ul>

<p>What factors <strong>motivate USSC’s decision</strong> in a case?</p>

<ol>
  <li>follow the <strong>rules/constitution/federal statutes</strong>, which can be vague sometimes, and sometimes <em>contradictory</em>/inconsistent with others
    <ul>
      <li>how do they interpret those complex laws? (a) Intent of <em>authors</em> (b) purpose of the <em>law</em> (c) the plain meaning of the text</li>
    </ul>
  </li>
  <li>follow their <strong>own ideology</strong> = a preconceived notion of what is good or bad
    <ul>
      <li>this can be a big influencer, the cases that <em>reached USSC are often hard to decide by just following the rules</em></li>
    </ul>
  </li>
  <li>care about the <strong>legitimacy</strong> of the institution itself = want it to be revered and respected</li>
</ol>

<p><strong>Why might USSC still care about public opinion/maintaining legitmacy?</strong></p>

<ul>
  <li>they have no enforcement power, so what happens in reality depends on if policy enforcers will do it (e.g. only if it is popular)</li>
  <li>themselves suffer from delegation problem, e.g. they <mark>cannot control the president to actually perform those decisions</mark></li>
</ul>

<h2 id="how-ussc-is-affected-by-public-opinion">How USSC is affected by Public Opinion</h2>

<blockquote>
  <p><strong>Key idea</strong>: supreme court cares about their public approval, even though they will never be thrown out = wants to maintain legitimacy in the <strong>eyes of the public</strong></p>
</blockquote>

<p>But if an external event/some social forces affects both the public opinion and the USSC in a same way, it will look like public opinion affecting USSC but in reality this is a <strong>spurious correlation</strong>.</p>

<p>In the paper, they show that</p>

<p><img src="/lectures/images/2023-05-11-POLS1201_Intro_to_American_Politics/image-20230306220636520.png" alt="image-20230306220636520" style="zoom: 33%;" /></p>

<ul>
  <li>e.g. positive correlation of “Public Mood” is $1.59^*\pm0.78$ being statistically significant</li>
  <li>therefore, changing public mood and court ideology drive USSC decision making</li>
</ul>

<p>in the first section, they concluded that USSC will follow public opinions when:</p>

<ul>
  <li><strong>high profile decisions</strong> mattered the most, so justices care the most = had to stick to their personal ideologies/principles = most <strong><em>costly</em></strong> for the justice to just go with public opinion</li>
  <li>so for <strong>low profile decisions</strong> = USSC care more about public opinion</li>
</ul>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Table 2</th>
      <th style="text-align: center">Figure 1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2023-05-11-POLS1201_Intro_to_American_Politics/image-20230306220736599.png" alt="image-20230306220736599" style="zoom:33%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2023-05-11-POLS1201_Intro_to_American_Politics/image-20230306220711393.png" alt="image-20230306220711393" style="zoom:33%;" /></td>
    </tr>
  </tbody>
</table>

<p>so that in this table:</p>

<ul>
  <li>following “public mood” is <strong>correlated with non-salient court cases</strong>, but no clear correlation with salient court cases</li>
</ul>

<blockquote>
  <p><strong>Conclusion</strong>: good evidence that USSC sometimes responds to public opinions = justices are balancing between public opinion and their legitimacy</p>
</blockquote>

<h2 id="democratic-trade-offs">Democratic Trade-offs</h2>

<p>To some extent, this is also related to the agency problem/limiting agency loss:</p>

<blockquote>
  <p>USSC <strong><em>can</em> prevent</strong> majority actions by elected branches = in some sense an anti-democratic institution. But, in those cases, many USSC blocks can be overcome through other means:</p>

  <ul>
    <li>US Constitution can be amended</li>
    <li>over time, USSC justices can be replaced</li>
  </ul>
</blockquote>

<p>What are the mechanisms that federal courts can use to <strong>affect policy making</strong></p>

<ol>
  <li>restrain federal/state action, e.g. your action violates some rights of people = <strong>blocks</strong> majoritarian policy making</li>
  <li>remove/change the set of restraints on federal/state actions, e.g. Dobbs v. Jackson on Women’s health = <strong>changes venue</strong> for majoritarian policy making</li>
  <li>change the rules of electoral competition = <strong>changes the means</strong> for majoritarian policy making
    <ul>
      <li>e.g. USSC have expanded the set of question they adjudicate = <strong>can determine the rules on how parties compete in redistricting</strong> = can affect the policy that comes out!
        <ul>
          <li>previously, the court cannot tampered with political actions, and the constitution does not specify this power as well. Now, USSC can review redistricting</li>
          <li>(Wesberry v. Sanders) USSC brings in 14th amendment ad requires US <em>house</em> districts on basis of population</li>
          <li>(Reynolds v. Sims) 14th Amendment requires <em>state</em> legislative districts on the basis of population = cannot have a city has only 1 senate for million, and a rural area 1:1000.</li>
        </ul>
      </li>
      <li>the above example results in massive shift in the balance of power between city and rural areas = came out from the USSC decisions even though they did not explicit tamper with the redistricting process itself</li>
    </ul>
  </li>
</ol>

<p>Note that:</p>

<ul>
  <li>it is often difficult for the USSC to entirely prevent a societal goal from happening (e.g. segregation), but to only <strong>block/remove a particular mechanism</strong> from achieving a goal:
    <ul>
      <li>e.g. recall the segregation fight between people (education segregation, white primaries, racial covenant, etc) and the courts</li>
      <li>i.e. difficult to fix all bugs all at once, but a few at a time when it pops up</li>
    </ul>
  </li>
  <li>if USSC had been weaker = would not block majoritarian policy making. e.g. DACA would be gone
    <ul>
      <li>recall that DACA is an administrative relief that protects eligible immigrants who came to the United States when they were children from deportation. DACA gives undocumented immigrants: 1) protection from deportation, and 2) a work permit</li>
      <li>DACA is created by the executive branch/Obama, but Trump admins want to revoke = <em>USSC decided</em> that is inconsistent with administrative rule, hence kept it in place</li>
    </ul>
  </li>
</ul>

<p><strong>A democratic bargain</strong> = whatever you do to the opposition when in power, that party can do the same to you when you step our of power</p>

<ul>
  <li>this alternation of power mechanism therefore act as a deterrent = a threat to tyranny</li>
  <li>but works if that party can wield the power when in place</li>
  <li>therefore, this alternation of power can protect <em>powerful</em> groups</li>
</ul>

<blockquote>
  <p><strong>Conclusion</strong>: courts are part of the rules of the game = e.g. decide how policies are made. Solve certain problems but also introduces others</p>
</blockquote>

<h1 id="the-bureaucracy">The Bureaucracy</h1>

<p>the many arms of the federal <strong>bureaucracy</strong>, often considered the fourth branch of government, are valuable components of the federal system.</p>

<ul>
  <li>elevated certain types of <mark>nonelected workers</mark> (i.e. hired) are elevated to positions of relative <strong>power</strong> within the governmental structure.</li>
  <li>Collectively, these essential workers are called the bureaucracy.</li>
  <li>examples in include: The Interstate Commerce Commission, Federal Reserve Board, etc</li>
</ul>

<blockquote>
  <p>A <strong>bureaucracy</strong> is an administrative group of nonelected officials charged with carrying out functions connected to a series of policies and programs.</p>

  <ul>
    <li>fundamentally, implementing the laws (e.g.) passed by Congress. Also include <strong>writing the more specifics laws, enforcing them,</strong> etc.</li>
    <li>public administration: the implementation of <strong>public policy</strong> as well as the academic study that prepares civil servants to work in government</li>
    <li>but, their roles are <mark>barely mentioned in the Constitution</mark>, despite being seen as “the <mark>fourth branch</mark> of the government”</li>
  </ul>
</blockquote>

<p><em>The origin of US Bureaucracy</em></p>

<ul>
  <li>For example, Article II, Section 2, provides the president the power to appoint officers and department heads. In the following section, the president is further empowered to see that the laws are “faithfully executed.” $\to$ Granting the president and Congress such responsibilities appears to anticipate a bureaucracy of some size, yet the design of the bureaucracy is <mark>not described</mark>.</li>
  <li>first developed in 1820s with the rise of <strong>centralized party politics</strong> is the <strong>spoils system</strong>: political appointments were transformed into political patronage = appointing federal posts as rewards for supporters swelled over the following decades.</li>
  <li>next, there is <strong>industrial revolution</strong> that increases the economic size of the US and brought people together with railroads and telegraphs</li>
  <li>President Woodrow Wilson believes that administrative activities should be <mark>devoid of political manipulations</mark> (while politics does set tasks for administration, public administration should be built on a science of management)</li>
</ul>

<p><em>Fall of political patronage</em></p>

<ul>
  <li>supporting the patronage system held that their positions were well earned; those who condemned it argued that federal legislation was needed to ensure jobs were awarded on the <strong>basis of merit</strong>.</li>
  <li><strong>Civil Service Reform Act</strong> of 1883 (<mark>Pendleton</mark> Act). The act established the Civil Service Commission, a centralized agency charged with <mark>ensuring that the federal government’s selection</mark>, retention, and promotion practices were based on open, competitive examinations in a <mark>merit system</mark></li>
</ul>

<p><em>The Bureaucracy comes of Age</em></p>

<ul>
  <li>With the onset of the Great Depression in 1929, President Roosevelt and U.S. Congress rapidly reorganized the government’s problem-solving efforts into a series of programs designed to revive the economy $\to$ In the 1930s, the <strong>federal bureaucracy grew</strong>, and by 1940, approximately 700,000 U.S. workers were employed in the federal bureaucracy.</li>
</ul>

<p><em>The Civil Service Commission</em></p>

<ul>
  <li>the Pendleton act had important consequences due to
    <ol>
      <li>the law attempted to reduce the impact of politics on the civil service sector by making it <strong>illegal to fire</strong> or otherwise punish government workers <strong>for strictly political reasons</strong>.</li>
      <li>raised the qualifications for employment in civil service positions by <strong>requiring applicants to pass exams</strong> designed to test their competence in a number of important skill and knowledge areas.</li>
      <li>allowed for the creation of the United States <strong>Civil Service Commission (CSC)</strong>, which was charged with enforcing the elements of the law.</li>
    </ol>
  </li>
  <li>Congress and the president responded (to prior skepticism on bureaucracy) with the <mark>Civil Service Reform Act of 1978</mark>, which abolished the Civil Service Commission. In its place, the law created two new federal agencies:
    <ul>
      <li><strong>Office of Personnel Management (OPM)</strong> has responsibility for recruiting, interviewing, and testing potential government employees in order to choose those who should be hired.</li>
      <li><strong>Merit Systems Protection Board (MSPB)</strong>, responsible for investigating charges of agency wrongdoing and hearing appeals when corrective actions are ordered.</li>
    </ul>
  </li>
</ul>

<p><em>Merit-Based Selection</em></p>

<ul>
  <li>
    <p>In this system, the large majority of jobs in individual bureaucracies are <strong>tied to the needs of the organization</strong> rather than to the political needs of the party bosses</p>
  </li>
  <li>
    <p>Before, a civil service exam is required, stipulated by the Pendleton Act. This mandatory testing has since been <strong>abandoned</strong>, and now approximately <strong>eighty-five percent of all federal government jobs are filled through an examination</strong> of the applicant’s education, background, knowledge, skills, and abilities. (amongst them a few still requires testing)</p>
  </li>
  <li>
    <p>Civil servants receive pay based on the U.S. Federal General Schedule.</p>

    <p><img src="/lectures/images/2023-05-11-POLS1201_Intro_to_American_Politics/image-20230319022934917.png" alt="image-20230319022934917" style="zoom: 25%;" /></p>

    <p>this system is to create an environment in which those most likely to succeed are in fact those who are ultimately appointed. However</p>

    <ul>
      <li>[+] naturally result in organizations composed of experts who dedicate their lives to their work and their agency.</li>
      <li>[-] permanent employees can become too independent of the elected leaders. While a degree of separation is intentional and desired, too much can result in <strong>bureaucracies that are insufficiently responsive to political change</strong>.</li>
      <li>[-] accepted expertise of individual bureaucrats can sometimes <strong>hide their own chauvinistic impulses</strong>.</li>
    </ul>
  </li>
</ul>

<p><em>Models of Bureaucracy</em></p>

<ul>
  <li>The patronage system tied the livelihoods of civil service workers to their party loyalty and discipline. Without the patronage network (spoils system), <strong>bureaucracies form their own motivations</strong>.</li>
  <li>models for understanding how bureaucracy works
    <ul>
      <li><strong>Weberian Model</strong>:
        <ul>
          <li>ideal type of bureaucracy, the Weberian model, was one in which <strong>agencies are apolitical, hierarchically organized, and governed by formal procedures</strong>.</li>
          <li>specialized bureaucrats would be better able to solve problems through <strong>logical reasoning</strong></li>
          <li>as a result, it would impose order and efficiency, create a clear understanding of the service provided, reduce arbitrariness, ensure accountability, and limit discretion.</li>
        </ul>
      </li>
      <li><strong>Acquisitive Model</strong>: bureaucracy compete for limited resources
        <ul>
          <li>bureaucracies are naturally competitive and power-hungry $\to$ they recognize that limited resources are available to feed bureaucracies, so they will work to <strong>enhance the status of their own bureaucracy to the detriment of others</strong>.</li>
          <li>e.g. attempt to emphasize their work to Congress and maximize its budget by depleting all its allotted resources each year</li>
          <li>In this way, the bureaucracy will eventually grow far beyond what is necessary and <strong>create bureaucratic waste</strong></li>
        </ul>
      </li>
      <li><strong>Monopolistic Model</strong>: <em>absence</em> of competition in bureaucracy
        <ul>
          <li>recognize the similarities between a bureaucracy like the Internal Revenue Service (IRS) and a private monopoly like a regional power company</li>
          <li>there are rare bureaucratic exceptions that typically compete for presidential favor, most notably organizations such as the CIA, the National Security Agency, and the intelligence agencies in the Department of Defense. Apart from these, bureaucracies have <strong>little reason to become more efficient or responsive</strong> due to absence of competition.</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><em>Types of Bureaucractic Organizations</em></p>

<ul>
  <li>
    <p>In the U.S. government, there are four general types: <strong>cabinet departments</strong>, <strong>independent executive agencies</strong>, <strong>regulatory agencies</strong>, and <strong>government corporations</strong>.</p>
  </li>
  <li>
    <p><strong>Cabinet departments</strong> are major executive offices that are directly accountable to the president.</p>

    <ul>
      <li>
        <p>they include the Departments of State, Defense, Education, Treasury, and several others = <strong>headed by a single person nominated by the pres</strong>.</p>
      </li>
      <li>
        <p>usually have many smaller agencies within them, e.g. FBI within DoJ.</p>
      </li>
      <li>
        <p>individual cabinet departments are composed of numerous levels of bureaucracy. These levels descend from the department head in a mostly <strong>hierarchical</strong> pattern</p>

        <p><img src="/lectures/images/2023-05-11-POLS1201_Intro_to_American_Politics/image-20230319143221201.png" alt="image-20230319143221201" style="zoom: 50%;" /></p>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>Independent Executive Agencies and Regulatory Agencies</strong></p>

    <ul>
      <li>Like cabinet departments, independent executive agencies report directly to the president.</li>
      <li><strong>Unlike</strong> cabinet, independent executive agencies:
        <ul>
          <li>they are assigned far <strong>more focused tasks</strong>.</li>
          <li>These agencies are considered independent because they are <strong>not subject to the regulatory authority</strong> of any specific department.</li>
          <li>located outside of cabinet departments (obv.)</li>
        </ul>
      </li>
      <li>examples of <em>Independent Executive Agency</em> include Central Intelligence Agency (CIA), National Aeronautics and Space Administration (<strong>NASA</strong>), and Environmental Protection Agency (EPA)</li>
      <li><strong>Independent Regulatory commissions</strong>
        <ul>
          <li>to grant control and limit agency loss = Congress writes a law, these are the people who can oppose it even if popular
            <ul>
              <li>e.g. a federal reserve system = people insulated from popular anger; in the long term people will be better-off</li>
            </ul>
          </li>
          <li>independent from President as well</li>
        </ul>
      </li>
      <li>examples of <em>Regulatory Agency</em> include Interstate Commerce Commission (ICC), charged with regulating that most identifiable and prominent symbol of nineteenth-century industrialism, the railroad; Securities and Exchange Commission (SEC) expanded significantly in the digital era beyond mere regulation of stock floor trading</li>
    </ul>
  </li>
  <li>
    <p><strong>Government Corporations</strong></p>

    <ul>
      <li><strong>subject to market forces</strong> and tend to generate enough profit to be self-sustaining, but they also <strong>fulfill a vital service the government has</strong> an interest in maintaining.</li>
      <li>Unlike a private corporation, a government corporation does not have stockholders. Instead, it has a board of directors and managers; they are also exempted from taxes</li>
      <li>examples: most widely used government corporation is the <strong>U.S. Postal Service (USPS)</strong>. Another widely used government corporation is the National Railroad Passenger Corporation, which uses the trade name <strong>Amtrak</strong></li>
    </ul>
  </li>
</ul>

<p><em>Bureaucracy Rule-Making</em>: the processes of <strong>rulemaking and bureaucratic oversight are equally complex</strong> (since bureaucracy is complex)</p>

<ul>
  <li>before, <strong>notice-and-comment rulemaking</strong>: bureaucracy publicize its proposals, and allow for the public to comment.
    <ul>
      <li>if you want to deletage a task to an agent, what would you do? = <mark>monitoring</mark>: notice and comment rule-making</li>
      <li>e.g. <strong>FDA</strong> = which packaged food can be labeled healthy. This rule was put up , and would limit added sugars and other changes
        <ul>
          <li>of course, some unhappy as certain cereals would be <em>not</em> be labeled as healthy</li>
          <li>several manufacturing lobbied and this ruling is <em>still</em> in process = <mark>allows interest groups to "self-fix" them</mark> = interest groups to monitor bureaucrat compliance = and also policy to be influenced by science and the public!</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>now, some uses the <strong>negotiated rulemaking process</strong>: neutral advisors known as convenors put together a committee of those who have vested interests in the proposed rules $\to$ then, with the help of neutral mediators, the committee eventually reaches a general consensus on the rules.</li>
</ul>

<p><em>Government Bureaucratic Oversight</em></p>

<ul>
  <li>The ability for bureaucracies to develop their own rules and in many ways control their own budgets has often been a matter of great concern for elected leaders. As a result, elected leaders have employed a number of strategies and devices to <strong>control public administrators in the bureaucracy</strong>.</li>
  <li><strong>The Congress</strong>
    <ul>
      <li>because of its power to <strong>control funding</strong> and approve presidential appointments.</li>
      <li>perhaps the most powerful oversight tool is the Government Accountability Office (GAO) $\to$ produce <strong>reports</strong>, mostly at the insistence of Congress.
        <ul>
          <li>e.g. from Bureau of Prisons = needed to report the number of prisoners they incarcerate, and Congress found that 45% of the prisoners who are released are re-arrested within 3 years.</li>
          <li>Congress thinks this is too high, and decided to require BoP create programs to fix this (e.g. to help them during incarceration), and also metrics to evaluate its effectiveness</li>
          <li>BoP has still yet implemented an evaluation plan due to various difficulties = <strong>in reality you might need to do more to push bureaucracies to do what you want</strong></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>The president</strong>:
    <ul>
      <li>Most directly, the president controls the bureaucracies by <strong>appointing the heads</strong> of the fifteen cabinet departments and of many independent executive agencies, such as the CIA, the EPA, and etc.</li>
      <li>other way to conducts oversight over the federal bureaucracy is the Office of Management and Budget (OMB) $\to$ produce the president’s annual budget for the country</li>
      <li><strong>repealing bureaucratic rules</strong> = if you are appointed new president but disagree with previous admins. What can you do with the bureuacracies?
        <ul>
          <li>wanted to make sure that <mark>TODO</mark></li>
          <li>new President directed agencies to review <em>every single rule</em> that was promulgated between that period</li>
          <li>Department of Labor issued a new rule = note that Presidents can’t write rules themselves, <mark>make new rules through agencies under control</mark></li>
          <li>Congress passed resolution to overrule the rule</li>
          <li>President vetoed that resolution on Monday, so this new rule will probably stand</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>The citizens</strong>
    <ul>
      <li><mark>Freedom of Information Act of 1966</mark> = provides journalists and the general public the right to <strong>request records from various federal agencies</strong>. These agencies are required by law to release that information unless it qualifies for one of nine exemptions.</li>
      <li><mark>Government in Sunshine Act of 1976</mark> = requires all multi-headed federal agencies to <strong>hold their meetings in a public forum on a regular basis</strong>.
        <ul>
          <li>this name comes from the belief that corruption thrive in secrecy but shrink when exposed to the light of public scrutiny.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>Within Bureaucracy itself</strong>
    <ul>
      <li>When Congress drafted the Civil Service Reform Act of 1978, it specifically included rights for federal <strong>whistleblowers</strong>, those who <strong>publicize misdeeds committed within a bureaucracy</strong> or other organization, and set up protection from reprisals.</li>
      <li>Over time, Congress and the president have strengthened protections of those whistleblowers with Whistleblower Protection Act of 1989 and the Whistleblower Protection Enhancement Act of 2012.</li>
    </ul>
  </li>
</ul>

<p><em>Government Privitization</em>: a more controversial solution to the perceived and real inefficiencies</p>

<ul>
  <li>[+] rhetoric of privatization—that market competition would <strong>stimulate innovation and efficiency</strong>—sounded like the proper remedy to many people and still does.</li>
  <li>[-] certain government functions are simply <strong>not possible to replicate in a private context</strong>.</li>
  <li>ways of privitization
    <ul>
      <li><strong>Divestiture, or full privatization</strong>, occurs when government services are transferred, usually through sale, from government bureaucratic control into an entirely market-based, private environment. Rare but: <strong>Student Loan Marketing Association</strong> in 1973 to full privatization in 2004</li>
      <li><strong>Issuing government contracts to private companies</strong> in order for them to provide necessary services. e.g. By 2006, reliance on contracting to run the war was so great that contractors outnumbered soldiers. = a <strong>very routine form of privatization</strong></li>
      <li><strong>Third-party financing</strong> = the federal government signs an agreement with a private entity so the two can form a <em>special-purpose vehicle</em> to take ownership of the object being financed. The special-purpose vehicle is empowered to reach out to private financial markets to borrow money.</li>
    </ul>
  </li>
</ul>

<h2 id="bureaucratic-structure-and-independence">Bureaucratic Structure and Independence</h2>

<blockquote>
  <p>Structure of the bureaucracy depends a lot on the leadership (who is in charge), funding, and mandate</p>
</blockquote>

<p>How does Congress decide on structure?</p>

<ul>
  <li>how similar are the goals: if a bureaucracy is often making decision on political <em>unpopular</em> matters</li>
  <li>can change the legislation of bureaucracy to prevent tyranny = achieve 51% $\gets$ may want a group of people in charge instead of a single person on sensitive/contradictory issues.</li>
</ul>

<p>Creating bureaucracy creates <strong>agency problem</strong></p>

<ul>
  <li>[-] a hired bureaucrat can have a different incentive compared to what you wanted</li>
  <li>[-] hard to watch everything = monitoring problem
    <ul>
      <li>e.g. the stuff they do is so complicated, it is difficult to assess how well they are doing it</li>
    </ul>
  </li>
  <li>As a result
    <ul>
      <li>[-] (w.r.t President and Congress) making policies President and the Congress dislikes, especially if staffed with extreme preferences</li>
      <li>[-] corruption can happen</li>
      <li>[-] shirking, difficult to fire a person due to political reason by design (as those jobs are politically protected to decouple from politics)</li>
    </ul>
  </li>
</ul>

<p>How can congress control this agency loss:</p>

<ul>
  <li>Pass new laws; senate confirmation when appointing offices</li>
  <li>hold hearing where bureaucrats must answer</li>
  <li><strong>Congressional Review Act</strong> = allows congress to <strong>override a rule</strong> through joint resolution</li>
  <li><strong>Administrative Procedures Act</strong> = establishes rules for <strong>how bureaucracies make policy</strong>, and requires them to solicit comments, allow time, and etc.</li>
  <li><strong>Freedom of Information Act</strong> = requires certain records from the bureaucrats be made public</li>
</ul>

<p><strong>Bureaucratic Autonomy</strong> - where does it come from?</p>

<ul>
  <li>
    <p>bureaucracies develop a <strong>reputation</strong> for competence</p>

    <p><img src="/lectures/images/2023-05-11-POLS1201_Intro_to_American_Politics/image-20230323120545278.png" alt="image-20230323120545278" style="zoom:40%;" /></p>

    <p>where interests groups are the people who vote/have interest</p>
  </li>
  <li>
    <p>with unique organizationl abilities</p>

    <ul>
      <li>have well-resourced mezzo-level bureaucrats to figure out what people likes, and do more of that</li>
    </ul>
  </li>
  <li>
    <p>has distinct political agendas</p>
  </li>
</ul>

<p><strong>Why bureaucracy are really the fourth branch</strong></p>

<ul>
  <li>bureaucracies also have constituencies = people supporting them = very specific group of people who are benefited</li>
  <li>this is different from the constituency for electing president/Congress</li>
</ul>

<h2 id="bureaucratic-private-enforcement-regime">Bureaucratic Private Enforcement Regime</h2>

<p>Why was there a massive increase in federal litigation before?</p>

<blockquote>
  <p><strong>Private enforcement regime</strong> refers to the system of legal mechanisms and procedures that allow <strong>individuals or private entities to enforce</strong> their legal rights against other individuals, companies, or government entities. This can involve seeking compensation for harm suffered or seeking an injunction to prevent harm from occurring.</p>

  <p>This is to be in contrast to public enforcement, where regulatory bodies such as the <em>government or law enforcement agencies are responsible</em> for enforcing the law.</p>
</blockquote>

<ul>
  <li><strong>allow private citizens to be able to sue</strong> private entities = stop violation of laws; rather have federal bureaucracy agents to enforce this</li>
  <li>e.g. law in Taxes that empowered individuals to sue people</li>
  <li>motivates people because people will be receiving benefits (e.g. suing employment inequality)</li>
  <li>emerged as a strategic choice (see benefits and drawbacks below)</li>
</ul>

<p>Why PER is beneficial?</p>

<ul>
  <li>[+] decouples with president = president who disagrees <strong>cannot prevent</strong> this</li>
  <li>[+] tie the enforcement process with the American population = ensure it is proportional to public preference
    <ul>
      <li>i.e. <strong>self-correction</strong> relative to the interest groups of that entity</li>
    </ul>
  </li>
  <li>[+] by creating individual benefit from those private enforcement process (e.g. money), <strong>less free-rider</strong> = people waiting others to sue</li>
</ul>

<p>but also comes with certain costs</p>

<ul>
  <li>[-] more litigation, hence need <em>more judges</em> to hear them, or the entire process become <em>slow</em></li>
  <li>[-] selective use of PER: people who are more wealthy gets more attention; an uneven advantage <em>favoring the more powerful</em> = <mark>more inequality</mark>
    <ul>
      <li>so uncertain areas are more vulnerable to judicial backlogs = e.g. not getting attention and went into backlogs to be “waitlisted”</li>
    </ul>
  </li>
  <li>[-] gives judiciary large role in determining policy (bad if you want more unpolitical opinions)</li>
</ul>

<p>How to <strong>motivate more people to do PER</strong>:</p>

<ul>
  <li>
    <p>if you win a PER:</p>

    <ul>
      <li>=’win damages, legal fees to be paid, time lost’</li>
      <li>therefore, you can increase probability of wining, reduce legal fees, etc, to motivate people do PER more</li>
      <li>basically find ways to increase the expected benefit by changing various components/burdens</li>
    </ul>
  </li>
  <li>
    <p>if you lose:</p>

    <ul>
      <li>=’no damages, legal fees to be paid, time lost’</li>
    </ul>
  </li>
  <li>
    <p>hence there is a balance between how to “assign” those burdens</p>

    <p><img src="/lectures/images/2023-05-11-POLS1201_Intro_to_American_Politics/image-20230323115914771.png" alt="image-20230323115914771" style="zoom:33%;" /></p>
  </li>
</ul>

<p>But in general, PER has been used a lot. The grey line being US plaintiffs litigation has been shifted to private people.</p>

<p><img src="/lectures/images/2023-05-11-POLS1201_Intro_to_American_Politics/image-20230323115653828.png" alt="image-20230323115653828" style="zoom: 40%;" /></p>

<blockquote>
  <p>Bureaucracy is not the only option to stop violation of law/promote equality, but PER can also have drawbacks.</p>

  <ul>
    <li><strong>inequality occurs in PER</strong>.
      <ul>
        <li>e.g. greater employment inequality due to employers know, depending on how wealthy/powerful the employee is, how likely they are being sued</li>
        <li>e.g. to uphold environmental protection standards, company will select poorer community to dump all the environmental wastes</li>
      </ul>
    </li>
    <li>a strong bureaucracy could prevent the above from happening. But there is the <strong>other problem of president oversights, etc</strong></li>
  </ul>
</blockquote>

<h2 id="progressive-reformers">Progressive Reformers</h2>

<blockquote>
  <p>A <strong>trade-off</strong> between controlling (e.g. bureaucracies) with expertise v.s. controlling with democracy</p>

  <ul>
    <li>more expertise = to protect policy from being changed by simply winning a majority vote</li>
    <li>more democracy = less corruption/tyranny</li>
  </ul>
</blockquote>

<p>During the progressive era, people worked to change governments at all levels from 1890s to 1920s and wanted gov to run like a business. They focused on the bureaucracies to have:</p>

<ul>
  <li>less corruption = fix voting systems</li>
  <li>more efficient</li>
  <li>immorality = e.g. alcohol ban</li>
  <li>social improvement and safety = e.g. more on women’s suffrage, so that they care more about limiting corruption = who supported their goal</li>
</ul>

<p>During this era, changes to achieve this include</p>

<ul>
  <li>16th = can levy taxes and require more from healthier states</li>
  <li>17th = popular electrion of senators = less corruption</li>
  <li>18th = prohibition of alcohol</li>
  <li>19th = women’s right to vote</li>
</ul>

<p>And this gives some <strong>hint to “ideal” bureaucratic designs</strong></p>

<ul>
  <li>need a mix of bureaucrats with expertise/political independence + bureaucrats with “democratic” opinions
    <ul>
      <li>e.g. <strong>Federal Reserve System</strong> reflects this. There are 12 regional banks getting regional interests (democracy), but 7 governors serving 14-years term to be less affected by politics (expertise)</li>
      <li>e.g. <strong>Council-Manager form of city government</strong>. Professional manager serves longer in charge of government functions (expertise), and manager reports to council who does final decision incorporating public opinions</li>
    </ul>
  </li>
  <li>so basically there is a <strong>trade-off</strong> between “listening to people” and “making expert decisions”
    <ul>
      <li>if main threat is incompetence, the “solution” is political independence = <mark>complex/technical policy areas often fit this</mark></li>
      <li>if main concern is subversion/extremism, then more political control is a good solution</li>
    </ul>
  </li>
</ul>

<h2 id="welfare-state">Welfare State</h2>

<blockquote>
  <p>Welfare state = A series of agencies through which <strong>government</strong> takes care of health and well-being of the people</p>

  <ul>
    <li>you will see how this becomes an example of agency loss and a debate/conflict between fed and state</li>
  </ul>
</blockquote>

<p>What are the major elements of US welfare state?</p>

<ul>
  <li>social security = pension for older people</li>
  <li>Medicare and Medicaid = health insurance</li>
  <li>Unemployment insurance</li>
  <li>etc.</li>
</ul>

<p>Examples <em>not</em> counted as welfare include: public education, mortgage assistance, policing, etc. Hence as you can see:</p>

<blockquote>
  <p>Surly, boundaries of ‘welfare state’ is politically contested.</p>
</blockquote>

<p>But who runs the welfare state?</p>

<ul>
  <li>social security = by federal government</li>
  <li>medicare = by fed government</li>
  <li>medicaid = by state governments</li>
  <li>earned income tax credit = by federal</li>
  <li>etc.</li>
</ul>

<p>Why are some programs managed by fed, some by state? Specifically, why give states power to decide criterion for eligibility for Medicaid, for example?</p>

<ul>
  <li>reduces agency loss for political majorities in states = they might not trust the federal bureaucrat</li>
  <li>increases agency loss for majority in congress = as states can do what they want</li>
  <li>
    <p>a lower level government in general also lower agency loss of voter = more responsive.</p>
  </li>
  <li>e.g. max income for medicaid for parent eligibility is different for different states (e.g. Texas very low, hence few Medicaid eligibility)</li>
</ul>

<blockquote>
  <p>This therefore also results in long history of conflict over <strong>who should be eligible for the benefits</strong> $\gets$ government and states want different group of people to be receiving the benefits</p>
</blockquote>

<h2 id="police-reform">Police Reform</h2>

<p>This topic is not on midterm, but has a lot on bureaucracy and agency problems, also a research project by the professor.</p>

<blockquote>
  <p><strong>Research question</strong>: how well did police policy-making process serve Black people?</p>

  <ul>
    <li>how democratic responsible are they = are they listening to the people?</li>
    <li>how well did police policies actually protect black people.</li>
  </ul>
</blockquote>

<p>A policy-making process for police:</p>

<ol>
  <li>(many) black people unhappy with policing</li>
  <li>advocacy groups propose solutions, e.g. more training, Police Community Relations (PCR), more black cops, break policy department into smaller units = more accountability</li>
  <li>policing experts settle on PCR and hiring Black officers</li>
  <li>other solutions pruned</li>
</ol>

<p>Empirical questions answered by the reading/paper:</p>

<ul>
  <li>Did PCR programs change arrest rates for Black people?</li>
  <li>Did PCR programs reduce crime rates?</li>
</ul>

<p>The short summary is a decreased low level arrest for white, <strong>not</strong> a lot for black people.</p>

<hr />

<p>Historical context: 1945-70</p>

<ul>
  <li>Popular constraints in 1955:
    <ul>
      <li>complaint that black victims were not concerned</li>
      <li>brutality, e.g. police hurting the suspect during arrest</li>
      <li>unreliable protetion from white vigilantes</li>
      <li>wide-spread complaints on disrespect</li>
    </ul>
  </li>
  <li>reform proposals
    <ul>
      <li>training = give officers a different set of skills
        <ul>
          <li>e.g. introduce police officers to prejudices and make them aware of those</li>
          <li>e.g. teach cops to see crimes not as race but environemntal efforts</li>
        </ul>
      </li>
      <li>hiring black officers = believing it happened due to adversarial selection problem</li>
      <li>civilian review board</li>
      <li>police community relations = began in 1955
        <ul>
          <li>how do we get black leaders and police together, work together and solve</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>during this time, there was also a lot on women reform, but also on Vietnam war</li>
  <li>this results in the most common features of PCR programs
    <ul>
      <li>training</li>
      <li>community advisory councils or meetings; residents come to police and can file complaints</li>
      <li>specialized outreach officers= sell the police department to residents of various colors</li>
    </ul>
  </li>
  <li>however, the result is
    <ul>
      <li>Dallas had no PCR and ended with decreasing arrests</li>
      <li>so we are not uniforming seeing PCR helping it. Raises the question: what effect does PCR have? Control variables?</li>
    </ul>
  </li>
</ul>

<p>Related works</p>

<ul>
  <li>no studies of PCR program effect on punishment</li>
  <li>black perference $\neq$ low punishment; black people wanted a bunch of diverse things to be safe. But
    <ul>
      <li>high rates of crime victimization drive support for punitive approaches</li>
      <li>black officers took these jobs to be police officer, often <em>not</em> to change the racial-police relationship = should not expect that just putting black police will make them act different from other polices</li>
    </ul>
  </li>
  <li>conjecture that policy-making environment may bias against black preference</li>
</ul>

<blockquote>
  <p>Hypothesis:</p>

  <ol>
    <li>these programs effects will depend on city racial conposition</li>
    <li>PCR increase arrest rates for low-level offenses, if
      <ul>
        <li>reduced risk of intervention for officers = don’t want to be involved with brutal cases to hurt themselves</li>
        <li>increased service for crime victims, i.e. more police is answering your help</li>
      </ul>
    </li>
    <li>PCR decrease arrest rates for low-level offenses, if
      <ul>
        <li>greater deference to community preferences, e.g. want less arrests for gambling</li>
        <li>officers working less hard = greater shirking</li>
        <li>effort switched to serious crimes</li>
      </ul>
    </li>
  </ol>
</blockquote>

<p>The empirical study then considers data of PCR program status, population, black and white minor crimes arrest rates. Then perform mixed effect models and measure how PCR changed things.</p>

<blockquote>
  <p>Results summary:</p>

  <ul>
    <li>PCR units reduced minor crime arrest rates for white, no clear effect on Black arrests rates</li>
    <li>PCR units reduced violent crime rates</li>
  </ul>

  <p>so unfortunately one of the major policy used in policy departments, PCR, had no clear effect in helping the black</p>
</blockquote>

<p>But why? This is still being worked on.</p>

<p>But be careful that arrest rates can mean different things, e.g. if they are not perpetrators, then this indicates police wrongdoings.</p>

<ul>
  <li>e.g. can look at dismissal rates <em>in addition</em> to arrest rates = a lot of people who were arrested have not committed the crime.</li>
</ul>

<h1 id="public-opinion">Public Opinion</h1>

<blockquote>
  <p><strong>Public opinion</strong>: aggregation of people’s view about issues, situations, &amp; public figures.</p>

  <ul>
    <li>e.g. when situations arise internationally, polling companies survey whether citizens support U.S. intervention in places like Syria or Ukraine. These individual opinions are collected together to be analyzed and interpreted for politicians and the media.</li>
  </ul>

</blockquote>

<p>But where do people’s opinions come from? Most citizens base their political opinions on their <strong>beliefs</strong> and their <strong>attitudes</strong></p>

<p><strong>Belief</strong>: closely held ideas that support our values and expectations about life and politics.</p>

<ul>
  <li>for example, the idea that we are all entitled to equality, liberty, freedom, and privacy is a belief most people in the United States share.</li>
  <li>i.e. what we <em>think</em> are true about the world, e.g. who do we <em>think</em> are responsible for xxx.</li>
  <li>can change rapidly over time</li>
</ul>

<p><strong>Attitude</strong>: surveys want to measure people’s view on an issue = measuring their attitude</p>

<ul>
  <li>represent the <em>preferences</em> (e.g. like or dislike) we form based on our life experiences and values.
    <ul>
      <li>more specific than ideologies; people of the same ideology can have different attitudes on the same issue (e.g. due to a variety of factors)</li>
      <li>can be <strong>more effective affecting survey responses</strong> than belief (e.g. I believe this is true, but I still dislike it.)</li>
    </ul>
  </li>
  <li>organized and consistent manner of thinking, feeling, and reacting to people/groups/social issues
    <ul>
      <li>but <strong>most</strong> people’s attitudes are <strong>quite losely structured</strong>/inconsistent</li>
      <li>but still more stable than beliefs</li>
      <li>e.g. consumer confidence = belief in economy changes rapidly during Trump/Pandemic/Biden, despite in reality the real change in economy is much less = <em>people’s attitudes on presidency/certain events affect their belief on the economy</em></li>
    </ul>
  </li>
  <li>attitude might be strong/weak = can change over time or not = depends on people and on issues
    <ul>
      <li>e.g. racial attitudes</li>
    </ul>
  </li>
</ul>

<p><strong>Ideology</strong>/Belief system: configuration of your beliefs and attitudes such that it can <strong>explain/connect one’s belief and attitudes</strong></p>

<ul>
  <li>established beliefs and ideals about how government and public policy should work</li>
  <li>in theory, this promotes consistency among political attitudes</li>
  <li>in practice, ideology combine attitudes linked by policy groups</li>
</ul>

<hr />

<p>Some examples of contemporary idelogies</p>

<ul>
  <li><strong>liberal</strong> positions
    <ul>
      <li>pro-choice</li>
      <li>higehr and more progressive taxation</li>
      <li>environmental protection</li>
      <li>social welfare programs</li>
    </ul>
  </li>
  <li><strong>conservative</strong> positions
    <ul>
      <li>pro-life</li>
      <li>lower taxes</li>
      <li>‘traditional’ values</li>
    </ul>
  </li>
  <li>one interesting issue is on <strong>military intervention</strong>
    <ul>
      <li>it seems party identification (democrat or republican) is <em>not</em> a good predictor for military intervention</li>
      <li>party identification is not identical to ideology but <em>a reasonably good proxy recently</em></li>
    </ul>
  </li>
</ul>

<p>On gross, what are majorities ideologies? Liberal-Conservative Self-Identification shows:</p>

<ul>
  <li>
    <p><strong>about half of the population don’t identify</strong> with any of those labels</p>
  </li>
  <li>
    <p>(a survey of 7 point scale, extremely conservative; …; extreme liberal; don’t know)</p>
  </li>
</ul>

<p><strong>Influence of Public Opinion</strong> on public policy</p>

<ul>
  <li>US constitution give mechanism to make it easier for folks to express and develop their public opinons
    <ul>
      <li>broad suffrage</li>
      <li>freedom of speech and press</li>
    </ul>
  </li>
  <li>public opinion affect politicians making decisions = they need to monitor public opinions
    <ul>
      <li>e.g. need to deal with regular elections</li>
    </ul>
  </li>
</ul>

<p>Origin/factors that <strong>influence public opinion</strong></p>

<ul>
  <li>they have shared political <strong>values</strong> (e.g. equlity of opportunity, individual freedom)
    <ul>
      <li><strong>basic model: people form opinion using those values they have</strong></li>
      <li>but those values are not <em>born with those values</em> = political socializatoin</li>
    </ul>
  </li>
  <li><strong>political socialization</strong>
    <ul>
      <li>influenced by family, social groups (e.g. unions and churches)</li>
      <li>education = years of formal education associated with more tolerance; more participation in politics</li>
      <li>major political events = people who have gone through those major events (e.g. Civil War, new Deals) have a shared opinions; this makes their opinions more similar to each other than people from other times</li>
    </ul>
  </li>
</ul>

<h2 id="us-opinion-over-time">US Opinion over time</h2>

<p>Many events which has <strong>opinions change over time</strong> (measured from public opinion pool)</p>

<ul>
  <li><strong>abortion</strong>: in the past (1988) about 40% opposing abortion, now only 10-15% opposes it
    <ul>
      <li>a further breakdown for recent opinions = about 30-40% thinks it abortion should be permitted when rape, etc. And another 25-40% thinks it should be woman’s freedom</li>
    </ul>
  </li>
  <li><strong>guns</strong>: about 5% people thinks it should be made easier to acquire guns; about 50% more difficult, and 45% keep same.
    <ul>
      <li>interestingly, this trend has been remarkably stable</li>
      <li>why more stable? several possible reasons
        <ul>
          <li>this is a distant issue, v.s. abortion is recent = unstable</li>
          <li>in reality, there had been decisions <em>making gun purchases easier</em>.
            <ul>
              <li>e.g. recently expired ban on buying assault rifles = more easier;</li>
              <li>e.g. USSC also passed laws to make it easier</li>
            </ul>
          </li>
          <li>an example where decisions can go against political opinion</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>income difference</strong>: should government take action to reduce the difference
    <ul>
      <li>about 50% agree that government should try to reduce income diff, about 20% thinks status quo</li>
    </ul>
  </li>
  <li><strong>public schools</strong>: about 70% wanted increase in public schools</li>
  <li><strong>social security</strong>: about 50% wanted increase in social security</li>
  <li><strong>more aid to poor</strong>: about 50% thinks that federal should spend more to aid the poor, and about 40% thinks status quo</li>
  <li><strong>reduce deficit</strong>: about 75% people think it is very to extremely important</li>
</ul>

<p>The above is very weird: everybody wanted more spending on income/social security/more aid, but also reduce deficit = less spending = <strong>inconsistency</strong>.</p>

<ul>
  <li>
    <p>wrong question wording/wrong measurement</p>
  </li>
  <li>maybe public opinon should influence but <em>not used to determine</em> policy</li>
  <li>elite notions of policy coherency should be abandoned</li>
</ul>

<blockquote>
  <p><strong>Interpretation of those surveys are often complicated</strong>, and <strong>consistency</strong> in aggregate opinion is rare (e.g. see above).</p>
</blockquote>

<h2 id="what-can-go-wrong-in-public-pooling">What can go wrong in Public Pooling?</h2>

<p><strong>Can public opinion be manipulated/what can affect people’s attitudes?</strong></p>

<ul>
  <li>
    <p>first of all, this is difficult because many contributing factors are fixed, i.e. are steadfast and hard to change</p>

    <ul>
      <li>e.g. culture, religion. Have impact on your opinons, and they don’t change much over time</li>
    </ul>
  </li>
  <li>
    <p>opinions on contradictory issues can manipulate through <strong>framing</strong></p>

    <ul>
      <li>given an issue, how you frame the issue affects how people think about it (e.g. religious freedom problem v.s. discrimination problem)</li>
      <li>basically answer could change based on how you frame the question</li>
    </ul>
  </li>
  <li><strong>sampling error</strong></li>
  <li>
    <p>drawing random samples is subject to <strong>trade-off</strong> between more data/less error v.s. more time/money costly</p>
  </li>
  <li><strong>selection bias</strong>, often selective non-response: might have missed certain populations.
    <ul>
      <li>e.g. survey in college and apply it to real life</li>
      <li>
        <p>e.g. the survey results we did in class is <em>different</em> than the results in public poll</p>

        <ul>
          <li>e.g. folks don’t trust the government won’t answer surveys, hence missed</li>
        </ul>
      </li>
      <li>
        <p>solution is a random sample of the entire population where everyone has chance of selection, and over-sampling plus re-weighing</p>

        <ul>
          <li>but this is difficult to implement in real life. e.g. no single directory to entire US population, and no reliable way to reach everyone (e.g. no internet access)</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>measurement error</strong>: people’s answer might not be what they actually think</p>

    <ul>
      <li>you asked the wrong question, so data you collected <strong>does <em>not</em> answer what you wanted to measure</strong></li>
      <li>often this happens when your question is unclear/too simple
        <ul>
          <li>e.g. LA Times poll in 1980s “Do you think a pregnant women should or should not be able to get a legal abortion, <em>no matter what the reason?</em>” 57% says no.</li>
          <li>e.g. CBS poll a few months later “If a woan wants to have an abortion, and here doctor agrees to it, should she be allowed to have an abortion?” 58% said yes</li>
          <li>yea, questions are a bit different, but the point is that people’s majority opinion changes on the issue of abortion.</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><strong>Measurement Validation</strong>: But how do you even <mark>quantify how good your methodolgy is</mark>, given that there is no “ground-truth to begin with”?</p>

<ul>
  <li>the simple idea is to ask the public if they think the methodology will answer the question you have in mind</li>
  <li>e.g. want to research how changing a priming text can change how people want to run for office
    <ul>
      <li>idea is to manipulate sense of racial discrimination, group solidarity, difficult etc.</li>
      <li>then by this validation technique, you can <strong>reduce (some) measurement errors</strong> (i.e. people did not answer the way you wanted) by:
        <ul>
          <li>e.g. just survey/interview people what they <em>think</em> the answer is asking (vast majority to just make sure this)</li>
          <li>e.g. in this research ask people in survey if they think those text approximately induce what you wanted to do</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>e.g. want to research: does the exposure of racial identity (e.g. people of Asian descent) change your support to the republican party?
    <ul>
      <li>Idea is to have a two sets of people: White and Asian American. Then random subset of both groups were treated with micro-aggression “I forgot that this study is only for US citizens. Are yuo a US citizen I cannot tell.” = cue a sense of exclusion to Asian Americans. The hypothesis is that this should only affect results for Asian Americans, not white.</li>
      <li>Result: Asian descent after micro-aggression had less support for republicans, v.s. White descent after micro-aggression. = <em>exposure to racialized micro-aggression caused Asian-identifiers to be more supportive of Democrats</em></li>
      <li><strong>Why is this useful?</strong> Implication that trend in democratic voting among Asian America may due to experiences of discrimination. = Hence republicans can have more support if they break this association with discrimination.</li>
    </ul>
  </li>
</ul>

<h1 id="elections">Elections</h1>

<p>How do you select a candidate? <strong>What are some “metrics” you would use to evaluate competence</strong>?</p>

<ul>
  <li>their policy proposals</li>
  <li>
    <p>policy priorities and party alignments; endorsements (who sponsored them)</p>
  </li>
  <li>their identity (age, race, gender, class)</li>
  <li>political track records/resume</li>
  <li>ask yourself: how are things going for you/others given that he/she will be in office?</li>
</ul>

<p>What are elections for?</p>

<ul>
  <li>
    <p><strong>mechanism for principals (votres) to keep agents in line/accountable</strong> (reduce agency loss)</p>

    <ul>
      <li>allow selection of candidates with desirable qualities</li>
      <li>prospect of fture electrions creates incentive for office-holders to behave themselves/care about eopple</li>
      <li>possibility of unseating incumbent creates incentive to monitor</li>
    </ul>

    <p>basically tie policy to what voters are interested in</p>
  </li>
  <li>
    <p>voting produces collective goods</p>

    <ul>
      <li>victory for party</li>
      <li>signal voter (dis)satisfaction to officials (so they can react)</li>
      <li>an opportunity to remove agents who are not performing well</li>
    </ul>
  </li>
</ul>

<h2 id="rational-theory-of-elections">Rational Theory of Elections</h2>

<p><strong>Elections/voting as a free-rider problem</strong>: it can be costly</p>

<ul>
  <li>
    <p>if voters wanted to maximize their individual well-being, would you vote?</p>

    <ul>
      <li>benefits: voting gives greater tie to the community</li>
      <li>costs: you have to do all the effort/studying, or the party you don’t like wins</li>
    </ul>
  </li>
  <li>
    <p><mark>a classical model of voting</mark></p>

\[V = P*B - C + D\]

    <p>where $V$ whether to vote, $P$ the prob of individual vote will change outcome, $B$ the benefit if candidate wins, $C$ the cost of voting, and $D$ duty of psychological gratification. Therefore in this simple model, you would vote if:</p>

\[P*B + D &gt; C\]

    <p>some factors</p>

    <ul>
      <li>if a coup/vote manipulation occurs, then $P\to 0$.</li>
      <li>$P$ would go up if: the vote is currently tied, there is a small voting population</li>
      <li>$B$ would go up if there are big difference between candidate policy goals</li>
      <li>$C$ would go up if: the financial status of the person, registration/voting laws, intimidation/violence</li>
      <li>$D$ would go up if: peer/social group pressure want you to vote</li>
    </ul>
  </li>
  <li>
    <p><strong>low-info rationality</strong>. In reality, it is found that <strong>on average, people know little about politics</strong></p>

    <ul>
      <li>does this mean that they are bad voters? Not necessarily</li>
      <li>learning all these info is time-consuming, but good substitutes around
        <ul>
          <li>can rely on cues
            <ul>
              <li>e.g. relying on price to infer quality when buying clothes</li>
              <li>hence, can making choosing an agent (who is better for you) much simpler</li>
            </ul>
          </li>
          <li>examples of cues involve
            <ul>
              <li>party labels/involvement</li>
              <li>endorsements: what kind of organization is backing him/her
                <ul>
                  <li>American Civil Liberties Union: civil liberties focused, on the rights of racial minorities</li>
                  <li>Newspaper can give endorsement as well (e.g. editorial board)</li>
                </ul>
              </li>
              <li>identity feature such as gender or race</li>
              <li>candidate experience</li>
            </ul>
          </li>
          <li>it turns out that providing this informational is <strong>indeed a major objective of campaigns</strong></li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h2 id="research-example-candidate-evaluation">Research Example: Candidate Evaluation</h2>

<p>2021 World Bank data: US ranks below other rich liberal democracy in the proportional of national legislative seats (senate+house) held by women.</p>

<blockquote>
  <p>Does this indicate US is behind in terms of gender discrimination? This is a complicated question.</p>
</blockquote>

<ul>
  <li>
    <p>Q: if imbalance in office matches imbalance in candidate pool, does this mean no discrimination?</p>

    <p>Not if candidates are strategic</p>
  </li>
  <li>
    <p>Q: does euqal win rates in general elections mean on discrimination?</p>

    <p>Not if selection process produces different candidate pools</p>
  </li>
  <li>
    <p>What would be the “good” questions to ask? We need to consider: <strong>would the voter’s evaluation change if gender were different</strong>?</p>
  </li>
</ul>

<p>Path to (federal) office:</p>

<ol>
  <li>decision to run for office
    <ul>
      <li>women might have a harder time getting their main messages out due to discrimination in voters</li>
    </ul>
  </li>
  <li>wining in primary (need more fund-raising)</li>
  <li>winning general election</li>
</ol>

<p>The discrimination process <em>may</em> happen <em>anywhere</em> in this trajectory. Therefore even if in the end you have “equal win rates” there might still be discrimination. (e.g. discrimination against women in 1 and 2, but reversed in 3)</p>

<blockquote>
  <p>Takeaway: total effect of social features like gender is <strong>more expansive</strong> than quantitative studies we have today</p>

  <ul>
    <li>quantitiative tools are useful for testing a <em>single change</em></li>
    <li>therefore, all the estimates of effects we measure will be partial</li>
  </ul>
</blockquote>

<blockquote>
  <p>Research Question: Association of the task with gender implications can affect women’s win rate</p>
</blockquote>

<p>Hypothesis:</p>

<ol>
  <li>women have a larger advantage over men in <em>legislative</em> than in executive (women better at talking)</li>
  <li>women have a larger advantage where policy domain are <em>perceived towards women’s task</em> (e.g. school boards)</li>
  <li>women have  a larger advantage over men in constituents that are more <em>liberal</em> (so voters have less attachment with traditional gender values = more likely to vote for women)</li>
</ol>

<p>The idea is to study this from the election result in 2021. Assuming there is</p>

<ul>
  <li>
    <p><strong>no candidate quality different between genders</strong></p>
  </li>
  <li>
    <p><strong>similar selection process in the different elections</strong> (e.g. school board, mayor=more executive, city council=more legislative)</p>
  </li>
</ul>

<p>The result is:</p>

<ul>
  <li>women win rate does seem higher in school boards, and also higher in city council than mayor</li>
  <li>women’s win rate gaped more than men in school boards when there are more liberal voters. But there is a mixed effect in council elections and mayor</li>
</ul>

<h2 id="campaigns-and-persuasion">Campaigns and Persuasion</h2>

<p>How do I gather more more votes?</p>

<ul>
  <li>should I persuade those who disagree (involves democratic value of listening to people)?</li>
  <li>should I mobilize those who agree (just want them to show up and actually vote for me)?</li>
</ul>

<p>How do you decide voting?</p>

<ul>
  <li><strong>issue-based voting</strong>:
    <ul>
      <li>a person’s vote depends on if you agree with the candidate’s take on it</li>
      <li>a person’s vote depends on the weights of those issues (how important)</li>
      <li>but in reality, you will see that many people also vote <em>just for the candidate</em> regardless of his positions</li>
    </ul>
  </li>
  <li>how can campaigns change things?
    <ul>
      <li>can change weights of those issues</li>
      <li>can add new considerations to the issue
        <ul>
          <li>not an easy task = voters can be saturated with considerations</li>
          <li>there is only a small number of people who are persuadable</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>J. Kalla and Broockman in 2017 did a study on <strong>if campaigns are helpful in changing people’s votes</strong>
    <ul>
      <li>finding: little evidence of impact = all those money spent on campaigns have a net effect of zero</li>
      <li>why?
        <ul>
          <li>persuasion <mark>TODO</mark></li>
          <li>there may be an impact in the beginning, but wears off when actually voting</li>
          <li>odd cases <mark>TODO: how does this relate to spending money</mark>.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Then why do campaigns spend so much money?
    <ul>
      <li>maybe: <strong>in the real world campaigns are to “cancel” each other out</strong>. One party says bad things about others, and vice versa = zero net output.</li>
      <li>the change of the campaigns <strong>might have long term effects</strong> (e.g. decade), hence measuring in a single season is not suitable</li>
      <li>even if peoples votes didn’t change, those campaigns can <strong>affect people’s values/belief about the world</strong></li>
    </ul>
  </li>
</ul>

<h2 id="does-policy-derive-how-people-vote">Does Policy Derive how People Vote?</h2>

<p><strong>Voter Competence Test</strong>:</p>

<ul>
  <li>should we see elections as driven by voters, or do voters follow their politicians they prefer</li>
  <li>elections not by what voters want, but what the campaigns</li>
</ul>

<p>Research:</p>

<ul>
  <li>
    <p>focus on respondents who only learned the policy positions during campaigns</p>
  </li>
  <li>
    <p>when people <em>realized</em> their candidates is different from position they support, they still voted for them = it looks like <strong>people are following politicians</strong> instead of the policies</p>

    <ul>
      <li>e.g. Bush v Gore, who is social security funds handled</li>
      <li>
        <p>e.g. Carter v. Ford - whether federal gov should fund more <mark>TODO</mark></p>
      </li>
      <li>then ask people: Q: do you know who is supporting what position? Tell them the info, and ask again. Some people who knows about this issue got it right in the first round. Some people (learners) learns it afterwards.</li>
    </ul>
  </li>
  <li>
    <p>Finding: voters (learners) <strong>don’t change their votes even when there’s changes in their candidate support</strong></p>
    <ul>
      <li>Does this mean candidates <em>face no pressure</em> to take certain issue positions? No
        <ul>
          <li>the study is only on voters who <em>learned</em> the positions taken by the candidate. Hence this excludes the cases of those voters who already know the positions (and changed their votes)</li>
          <li>excludes interest groups, who typically take a strong hold/attention to the positions taken</li>
        </ul>
      </li>
      <li>If pressure comes mostly from interest groups, is it bad?</li>
    </ul>
  </li>
</ul>

<p>What are politician punished for?</p>

<ul>
  <li>strong evidence that <em>shark</em> attacks depressed Wilson vote in NJ (beach state) = people blindly attribute this to Wilson</li>
  <li>strong evidence <em>drought</em> reduces incumbent party vote share</li>
</ul>

<blockquote>
  <p>So based on all those “bad” findings, <strong>are US voters incompetent</strong>? A really complicated question.</p>
</blockquote>

<blockquote>
  <p>This shows that many voters’ voting behavior <strong>does not really represent their interest</strong> (e.g. blind rationale, learners, etc). Therefore, we may need to <strong>re-think elections</strong> = collecting votes as a mechanism to <strong>aggregate people/voters’s interest</strong> to form policies</p>
</blockquote>

<ul>
  <li>Politics not as competition between policies but competitions between groups for government</li>
  <li>politics as policy competition leaves more room for compromise</li>
</ul>

<h2 id="democratic-benchmarks">Democratic Benchmarks</h2>

<p>Whenever assessing the performance of a political system, you should to think about alternatives (what it <em>can</em> do). Why?</p>

<p>It turns out there is a <mark>limit on democratic choice system</mark>. <mark>No choice aggregation rule can satify four conditions simultaneously</mark></p>

<ol>
  <li>if everyone prefers A to B, the rule will pick A</li>
  <li>choice between two optins not influenced by third</li>
  <li>responds to more than one person’s wants</li>
  <li>decision cannot be manipulated by choice order</li>
</ol>

<blockquote>
  <p>All institutions doesn’t do at least some of the four.</p>
</blockquote>

<p>As a result, this means all of the following features of US political system are not “really” democratic = influence the final aggregated result</p>

<ul>
  <li>influence the aggregation process</li>
  <li>eventually all procedures are flawed</li>
</ul>

<p>all of the above features influence what public policy is.</p>

<h1 id="political-party">Political Party</h1>

<p>What is a political party, and how would you tell if the party is changing?</p>

<blockquote>
  <p><strong>political parties</strong> are groups of people with similar interests who work together to create and implement policies.</p>
</blockquote>

<p>On a high level: what do they do? Essentially they gain control over the government by winning elections.</p>

<ul>
  <li><strong>recruit</strong> candidates = exercise control over who they want
    <ul>
      <li>v.s. why not let candidates apply by themselves? = the party might have a different set of interest than candidates who are applying</li>
      <li>e.g. Trump candidacy in 2015/16</li>
    </ul>
  </li>
  <li><strong>nominate</strong> candidates (run for state government, Congress, and the presidency.)
    <ul>
      <li>different state has different rules (e.g. top two in votes end up in a runoff)</li>
      <li>in the end, state laws affect this selection progress significantly</li>
    </ul>
  </li>
  <li>guide members of Congress in <strong>drafting</strong> legislation.</li>
  <li>etc.</li>
</ul>

<p>But it is also helpful to break down political party into the three categories</p>

<ul>
  <li>party in government</li>
  <li>party in electorate,</li>
  <li>party organizations (fight for what the rules should be)</li>
</ul>

<p><strong>What can political party do for politicians?</strong> solve <strong>collection action</strong> problems</p>

<ul>
  <li>provide a host of funds/resources (people needed to) to help a politician win an office
    <ul>
      <li>especially to gather votes and sure <em>people</em> vote consistently if they are in the party</li>
    </ul>
  </li>
  <li>compromise/coordination when lawmaking = parties guide proposed laws through Congress and inform party members how they should vote on important issues.
    <ul>
      <li>e.g. you can ask party to pressure people if they want things different than what you want</li>
    </ul>
  </li>
  <li>agency problem/trade-off: politicians only want help to achieve office position
    <ul>
      <li>e.g. politicians want parties to leave them alone after helping, but party members prefer the opposite!</li>
    </ul>
  </li>
</ul>

<h2 id="who-identifies-with-which-party">Who identifies with which party?</h2>

<p>This is decided over a range of empirical studies, and it is found that</p>

<blockquote>
  <p>People align with a political party <strong>not because of its policies</strong>, but to <strong>compete</strong> against/dislike groups who share different values/identity = really for their own interest.</p>
</blockquote>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Data 1</th>
      <th style="text-align: center">Data 2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2023-05-11-POLS1201_Intro_to_American_Politics/image-20230417202032980.png" alt="image-20230417202032980" /></td>
      <td style="text-align: center"><img src="/lectures/images/2023-05-11-POLS1201_Intro_to_American_Politics/image-20230417202150189.png" alt="image-20230417202150189" /></td>
    </tr>
  </tbody>
</table>

<p>here we see that there is a</p>

<ul>
  <li>fair amount of stability in party memberships = those party members usually vote for their parties</li>
  <li>but one place you see change is “how intensely” are you partisan
    <ul>
      <li>see a rise of strong partisan to 44% from around 35% and less weak partisanship</li>
      <li>intensity of people’s commitment to the identity increases = shift in partisan system is not more people coming but <strong>more committed to partisanship</strong> = affect how politicians make electoral strategy</li>
    </ul>
  </li>
</ul>

<p>But what do people/voters really think of the political party as?</p>

<ul>
  <li>Q: which party is more conservative? 80% answered republicans correctly, but 20% either don’t know or answered wrongly
    <ul>
      <li>= hints that some people align with a party without really knowing its policy</li>
    </ul>
  </li>
  <li>Q: do you think the two parties are different? a lot of people think the parties are the same in the past, now mostly different, but still
    <ul>
      <li>= hints that some people align with a party without really knowing its policy</li>
      <li>making polarization increasing, but people at least know</li>
    </ul>
  </li>
  <li>
    <p>Q: how do you feel about the rival party? On average 19.3% happy with members of the other party, and 71.5% happy with own members.</p>

    <ul>
      <li>^ but specifically what traits are different? e.g. close-mindedness/unintelligent
        <ul>
          <li>are very parallel observation that both parties share the same trend of disliking other parties</li>
          <li>but it is also found that in general, people dislike <em>any other</em> groups, not necessarily rival</li>
          <li>yet still, the <strong>increase in dis-likeness=polarization</strong> is important</li>
        </ul>
      </li>
    </ul>

    <table>
      <thead>
        <tr>
          <th style="text-align: center">Anti-Group</th>
          <th style="text-align: center">Increasing Polarization</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td style="text-align: center"><img src="/lectures/images/2023-05-11-POLS1201_Intro_to_American_Politics/image-20230417202830606.png" alt="image-20230417202830606" style="zoom:50%;" /></td>
          <td style="text-align: center"><img src="/lectures/images/2023-05-11-POLS1201_Intro_to_American_Politics/image-20230417202620818.png" alt="image-20230417202620818" style="zoom: 33%;" /></td>
        </tr>
      </tbody>
    </table>
  </li>
  <li>
    <p>Q: what groups of people tilt the politician group? Here we member within each party <em>grouped by their traits</em></p>

    <table>
      <thead>
        <tr>
          <th style="text-align: center">Tilt Republican</th>
          <th>Tile Democratic</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td style="text-align: center"><img src="/lectures/images/2023-05-11-POLS1201_Intro_to_American_Politics/image-20230417203202854.png" alt="image-20230417203202854" style="zoom:33%;" /></td>
          <td><img src="/lectures/images/2023-05-11-POLS1201_Intro_to_American_Politics/image-20230417203212104.png" alt="image-20230417203212104" style="zoom:33%;" /></td>
        </tr>
      </tbody>
    </table>

    <ul>
      <li>= increasing <strong>separation</strong> of the identities between people in each parties = how social group change opinion = politics as <mark>competition between groups</mark> (a newer theory today) v.s. competition between policy (older)</li>
      <li>also implies politician within group may only care about moving powers to people who think like yourself</li>
    </ul>
  </li>
  <li>
    <p>finding: misconceptions of the parties can influence how people feel of the other party = also support the above conclusion that <strong>party alignment may have not much to do with the real policy they put out</strong> = people are bit egoistic</p>

    <ul>
      <li>perceived of the republican supporters:
        <ul>
          <li>folks in the survey think the republican are 40% over 65 aged people, in reality 20%, etc.</li>
          <li>in conclusion: many folks don’t have an accurate impression of the party composition</li>
        </ul>
      </li>
      <li>perceived of the democratic supporters:
        <ul>
          <li>folks in the survey think the democrats are 30% gay, lesbian, or bisexual, and 40% black, but in reality the proportion is much lower</li>
          <li>same conclusion as above.</li>
        </ul>
      </li>
      <li><strong>when corrected of those impressions, people’s view of the other party improved</strong></li>
      <li>and that those mis-perceptions are most skewed among those who look at political news most often</li>
    </ul>
  </li>
</ul>

<blockquote>
  <p>Conclusion: today we may have a shift in how we understand people’s stance for their political party/competition between them</p>
</blockquote>

<ul>
  <li>older models: members of each party have <em>many overlapping interest/identities</em> (but conflicts/argues over a few ideologies)</li>
  <li>today: parties are more not very related/very polarized/huge difference between political groups
    <ul>
      <li>perhaps due to <strong>political sorting</strong> = people are much more polarized = members inside the same group aligned / <strong>hate other groups</strong></li>
      <li>also results in <strong>stronger partisanship</strong> = greater/more negative affects against other parties</li>
      <li>partisan identification and sense of difference has increased</li>
      <li>but this increasing political difference may come at a cost (TBD)</li>
    </ul>
  </li>
</ul>

<h2 id="median-voter-theorem">Median Voter Theorem</h2>

<blockquote>
  <p><strong>Median Voter Theorem</strong>: in a majority-rule voting system, the outcome will be determined by the preferences of the median voter.</p>
</blockquote>

<p>Why would this happen? Consider the following leader position, where <code class="language-plaintext highlighter-rouge">x</code> goes with the Left and <code class="language-plaintext highlighter-rouge">o</code> goes with the right</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>xxxLxxxoooRooo
</code></pre></div></div>

<p>assuming that</p>

<ul>
  <li>candidates <code class="language-plaintext highlighter-rouge">L</code> and <code class="language-plaintext highlighter-rouge">R</code> want to win electrions</li>
  <li>people vote for candidates whose policy is <em>closest</em> to their ideal</li>
</ul>

<p>then you have on a <strong>single dimension</strong></p>

<ul>
  <li>
    <p>if <code class="language-plaintext highlighter-rouge">L</code> moves further from the center then <code class="language-plaintext highlighter-rouge">L</code> will be <strong>losing</strong>: <code class="language-plaintext highlighter-rouge">Lxxxx-ooooRooo</code></p>
  </li>
  <li>
    <p>if <code class="language-plaintext highlighter-rouge">R</code> moves to the closer to the center then <code class="language-plaintext highlighter-rouge">R</code> will be winning: <code class="language-plaintext highlighter-rouge">xxxLxxooRooooo</code></p>
  </li>
  <li>
    <p>therefore, both parties would need to move closer to the center so that the other party cannot gain advantage. This results in</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>xxxxxxLRoooooo
</code></pre></div>    </div>
  </li>
</ul>

<p>therefore, rational parties will converge to center = <mark>2-party competition results in moderate parties</mark></p>

<p><strong>How well does this describe actual elections in US? Is this model too simplified?</strong></p>

<ul>
  <li>
    <p>but of course, the above assumes that voter is still enthusiastic to vote despite this sad situation, etc.</p>
  </li>
  <li>At district level this is plausible, but there are at least two violations
    <ul>
      <li>candidates of parties are selected by the <em>primary</em> system = primary candidates really diverge from each other</li>
      <li>elections in states influence each other</li>
      <li>as seen last time (<a href="#Who identifies with which party?">Who identifies with which party?</a>), people often vote <em>not because</em> of similar policies to their idea, but if they heard of them, or if they share similar physical identity, etc.</li>
    </ul>
  </li>
  <li>in general, many voters might not vote based on “whose policy is <em>closest</em> to their ideal”, but
    <ul>
      <li>if they have heard of them</li>
      <li>if they have endorsement/trusted sources support them (i.e. weird reason people vote)</li>
      <li>if they share identity with the voters (i.e. weird reason people vote)</li>
      <li>and candidate recruits (e.g. party organizations) can <em>manipulate</em> all these things in a district</li>
    </ul>
  </li>
  <li>this means, <strong>in reality, to recover MVT</strong> you would need at least:
    <ul>
      <li>name-recognition not too skewed towards a candidate</li>
      <li>endorsement not to skewed</li>
      <li>candidate ideneity not too skewed</li>
    </ul>
  </li>
</ul>

<h2 id="a-theory-of-parties-as-interest-group-coalitions">A Theory of Parties as Interest Group Coalitions</h2>

<p><strong>Who affects</strong> the political parities?</p>

<ul>
  <li>
    <p><strong>politician</strong> centered theory: politicians (when selected in office) drive changes in political parties</p>
  </li>
  <li>
    <p><strong>interest group</strong> centered theory: interest groups exert huge influence on <em>who</em> gets elected during primaries (e.g. fund a guy to be prominent) = can exert influence in political parties</p>
  </li>
</ul>

<blockquote>
  <p><strong>Provisional conclusions</strong></p>

  <ul>
    <li>interest groups play a major role shaping the political party, especially in affecting the <em>candidate</em> before he/she is elected in office</li>
    <li>once politicians are in office, they themselves surely exert large influence the political party</li>
  </ul>
</blockquote>

<p>(Democratic) Parties mimic levels of national government</p>

<ul>
  <li>you have democratic party in Manhattan; democratic party in New York; democratic party in the National level
    <ul>
      <li>in theory, all those political parties should be <strong>independent</strong> = e.g. Manhatton GoP more liberal than Bonner Counter GoP.</li>
      <li>this held true mostly in the past</li>
      <li>but since the 1970s, state parties have become much more <em>similar</em> = they don’t respond to voters in their district, but <strong>aimed at a national agenda</strong> = “How national parties transformed state parties”</li>
    </ul>
  </li>
</ul>

<p>Why might interest groups and parties shift policy making to <strong>focus on a state level</strong> instead of a national level?</p>

<ul>
  <li>[+] some policies only apply to certain states
    <ul>
      <li>no easy “one size fits all” given variantions betweem states</li>
    </ul>
  </li>
  <li>[+] you can get more done in state houses than national houses = more money efficient</li>
  <li>[+] many folks do not pay attention to issues on the state level
    <ul>
      <li>in theory, the lower the government (e.g. local/state) the more attention people pay</li>
      <li>but empirically many people do the reverse: people don’t pay much attention to state levels but more to national affairs</li>
      <li>hence easier to get (bad) policies passed if nobody pays attention</li>
    </ul>
  </li>
</ul>

<h3 id="federalism-and-parties">Federalism and Parties</h3>

<p>What are some <strong>evidences</strong> that lower level political parties are do not listen much to the public/become more centralized to <strong>national agenda</strong>?</p>

<ul>
  <li>
    <p>since 1970s, <em>states</em> are taking in more policy making spending</p>
  </li>
  <li>
    <p>state parties are becoming more <em>similar to each other</em> = responding more to a national agenda than public opinon</p>

    <ul>
      <li>evidence = direction of <strong>policy change</strong> is increasingly predicted by <strong>whether or not the party has uniform control</strong></li>
      <li>graph: if a party has uniform control, what would the average state policy look like?</li>
    </ul>

    <p><img src="/lectures/images/2023-05-11-POLS1201_Intro_to_American_Politics/image-20230424173436164.png" alt="image-20230424173436164" style="zoom: 33%;" /></p>

    <ul>
      <li>
        <p>findings 1: before, states “do what they want” hence averages out to zero despite national control; nowadays, which party is taking charge greatly shapes <em>individual state’s policies</em></p>
      </li>
      <li>
        <p>findings 2: some exceptions are civil rights and criminal justice</p>

        <p><img src="/lectures/images/2023-05-11-POLS1201_Intro_to_American_Politics/image-20230424173529209.png" alt="image-20230424173529209" style="zoom:33%;" /></p>
      </li>
      <li>
        <p>conclusion = national party control is a <strong>strong predictor of policies on a state level</strong></p>
      </li>
    </ul>
  </li>
  <li>
    <p>test the counter-argument: do changes/trend in state policy follow changes/trend in public opinion policy?</p>

    <p><img src="/lectures/images/2023-05-11-POLS1201_Intro_to_American_Politics/image-20230424173602178.png" alt="image-20230424173602178" style="zoom:50%;" /></p>

    <ul>
      <li>most policy areas doesn’t work = state policies affected by other factors
        <ul>
          <li>abortion: public opinion looks flat, but significant shits in policies;</li>
          <li>civil rights: the other way around; in both cases the two look unrelated</li>
        </ul>
      </li>
      <li>but there are ones that works, e.g. LGBTQ</li>
    </ul>
  </li>
</ul>

<blockquote>
  <p>Conclusion: divergence in state level policy is <strong>not explained by changes in public opinion</strong>, but increasingly by <strong>partisan control</strong>.</p>
</blockquote>

<p>Why? <strong>Interest groups</strong> involvement in <strong>parties</strong> can be one explanation as a strong force</p>

<ul>
  <li>
    <p>regular donors are more extreme (than ordinary donors)</p>

    <p><img src="/lectures/images/2023-05-11-POLS1201_Intro_to_American_Politics/image-20230424173810661.png" alt="image-20230424173810661" style="zoom:33%;" /></p>

    <p>where those who donates to Interest Groups (IG) and/or legislation are more extreme in their political ideology (most liberal and most conservative)</p>
  </li>
  <li>
    <p>contacted with the legislators more (than ordinary donors)</p>

    <p><img src="/lectures/images/2023-05-11-POLS1201_Intro_to_American_Politics/image-20230424173855509.png" alt="image-20230424173855509" style="zoom:33%;" /></p>

    <p>similar to above, those who donated to IG and/or legislations contacted more</p>
  </li>
  <li>
    <p>better predictor of legislative ideologies (than ordinary donors)</p>

    <p><img src="/lectures/images/2023-05-11-POLS1201_Intro_to_American_Politics/image-20230424173930676.png" alt="image-20230424173930676" style="zoom:33%;" /></p>

    <p>there is a strong association between <strong>identity of donors and characteristics of the candidates</strong></p>
  </li>
</ul>

<blockquote>
  <p>Conclusion:</p>

  <ul>
    <li>
      <p>parties responsiveness seem to <strong>follow money</strong> (from specific sources), not public opinion = political party evolving with interest group system</p>
    </li>
    <li>
      <p>party system being more <strong>nationalized</strong> = <strong>polarized</strong></p>
      <ul>
        <li>nationalized parties <em>at state level</em> mean polarized policies not driven by state-level opinion anymore</li>
        <li>MVT theorem disrupted = left and right position being more affected by <strong>other factors than just policy preferences</strong></li>
        <li>state has less freedom to find policy through experimentation = <strong>less creative</strong> policy making</li>
      </ul>
    </li>
  </ul>
</blockquote>

<h1 id="interest-groups-and-lobbying">Interest Groups and Lobbying</h1>

<blockquote>
  <p><strong>Interest groups</strong>: <mark>individuals</mark> would band together in <mark>an attempt to use government in their favor</mark>. In general formal association of individuals or organizations that attempt to influence government decision-making and/or the making of public policy.</p>
</blockquote>

<p>How is interest groups different from political parties?</p>

<ul>
  <li>interest groups are much <strong>narrower</strong> in their pursuits. e.g. focused on areas like taxes, the environment, and gun rights or gun control, or their membership is limited to specific professions.</li>
  <li><strong>do not</strong> function primarily to <strong>elect candidates</strong> under a certain party label or to directly control the operation of the government</li>
</ul>

<p>Categories of IG</p>

<ul>
  <li><strong>trade association</strong>: any economically based grouping. consumer brands association (e.g. for food regulation)</li>
  <li><strong>labor union</strong>: AFL-CIO, FOP, highly active in politics</li>
  <li><strong>individual membership associations</strong> (grassroot): random people who joined that cared abotu the same thing</li>
  <li><strong>professional associations</strong>: membership is individual, and goal is to participate in that occupation group. AMA, ABA</li>
</ul>

<p>What do IGs do?</p>

<ul>
  <li><strong>elections</strong>: mobilize voters to vote for campaigns, and act as <mark>endorsements for candidates</mark> (see previous sections)</li>
  <li><strong>legislatures</strong>: help draft bills, etc.</li>
  <li><strong>courts</strong>: if something bad happened, threatening to sue; file briefs when brought by others</li>
  <li><strong>bureaucracies</strong>: certain professional licensing run by interest group</li>
  <li>A very diverse branching = IGs use every aspect of the US political system to achieve their goal.</li>
</ul>

<p>Imagine you are a legislator and you heard the following from a lobbyist:</p>

<p><em>“Our research indicates the accessibility of guns is leading to unnecessary deaths”</em></p>

<ul>
  <li>if you heard this from a national rifle association v.s. Mom’s association of Gun sense…; former more convincing</li>
</ul>

<p><em>“Our research indicates that carbon emissions need to be significantly curtailed in the next few yeras or the US will face significant ecnomic har from climate change”</em></p>

<ul>
  <li>if you heard this from greenpeace v.s. american petroleum association; latter more convincing</li>
</ul>

<blockquote>
  <p>Intuition: <strong>source bias</strong> makes some statement harder to believe = less persuasive if it comes from IG who anyway wanted you to do this.</p>
</blockquote>

<p>But then <strong>why spend money to lobbying</strong>, if everyone knows what your group wants?</p>

<ul>
  <li>persuade those who <strong>disagree</strong> with you: often hard</li>
  <li>convince those who <strong>agree</strong> with you to <strong>focus on the issues</strong> you care the most.
    <ul>
      <li>i.e. subsidizing the efforts of those who agree with you = reduce your efforts</li>
      <li>lobbists do more things than persuasion = providing resource subsidies for people who want to sue</li>
    </ul>
  </li>
</ul>

<hr />

<p><em>For Example</em> Colorado Juvenile Defend Center</p>

<ul>
  <li>2012 they found that 45% kids charge with offenses had no council representing them</li>
  <li>2013 contacted sympathetic legislator, convinced them to form an interim committee</li>
  <li>2014 participated in negotiations and re-drafting of bill = the law changed <strong>because of this IG’s efforts</strong></li>
</ul>

<p>But given this effort, does this <em>process correct for poor representation through elections</em>, or <em>subvert democracy of people</em>? (interesting arguments to consider)</p>

<hr />

<p>Lobbying at the state level: (i.e. groups that lobby)</p>

<ul>
  <li>municipal leagues</li>
  <li>county commissioner associations</li>
  <li>school board associations</li>
  <li>local government: e.g. Colorado wanted bars to be closed at 2am. Then people and local government/mayor lobbied state legislators for change.</li>
  <li>etc.</li>
</ul>

<p>California require every lobby group to file forms. From data collected, it is found that</p>

<ul>
  <li>
    <p>local government spent by far the most among IGs in California ;</p>
  </li>
  <li>many cities do lobby, and especially in California cities lobby a lot</li>
  <li>and it is not just cities, over 500 cases are lobbied by counties, and over 1500 from special districts.</li>
  <li>lobbying at the state government is most common, at national government reasonably common</li>
</ul>

<blockquote>
  <p><strong>On local lobbying:</strong></p>

  <ul>
    <li>
      <p>it is a pervasive practice, and targets a lot on state government</p>
    </li>
    <li>
      <p>has the potential to compound disadvantage for poor regions = don’t have money for IGs to toss around</p>
    </li>
  </ul>

  <p><strong>In general, lobbying</strong></p>

  <ul>
    <li>is baked in to democracy = is a <strong>crucial part of US politics</strong></li>
    <li>but has a trade-off between the influence of interest groups/anti-democracy</li>
    <li>interest group environment may not be a leveling playing field
      <ul>
        <li>not every issues have an interest group</li>
        <li>IGs have <strong>different resource distribution</strong>; some group has more power/money = features of the group can also affect if how far can you get this issue solved</li>
        <li>Strolovitch finds that organizations are substantially less active when it comes to issues affecting <strong>disadvantaged subgroups</strong> than they are when it comes to issues affecting more advantaged subgroups.</li>
      </ul>
    </li>
  </ul>
</blockquote>

<p>e.g. current measures to restrict IG’s power:</p>

<ul>
  <li>requires lobbying data be recorded and <strong>disclosed</strong></li>
  <li><strong>cooling-off period</strong> = laws that require a person who works for a legislator cannot lobby for two years after they leave; to prevent them lobbying on things that are advantageous for them (but they can ask others to lobby)</li>
  <li>campaign donation limits</li>
  <li>tax disclosure laws</li>
</ul>

<h2 id="collective-action-and-free-riding-in-igs">Collective Action and Free Riding in IGs</h2>

<p>As mentioned before, an example of IGs in US is the labor organization/unions. But think about this:</p>

<ul>
  <li>The benefits sought by <strong>unions</strong>, such as higher wages, collective bargaining rights, and safer working conditions, are often enjoyed by <strong>all workers regardless of whether they are members</strong>.</li>
  <li>therefore, <strong>free riders</strong> can receive the benefit of the pay increase without helping defray the cost by paying dues, attending meetings or rallies, or joining protests,</li>
</ul>

<blockquote>
  <p>If <strong>free riding</strong> is so prevalent, why are there so many interest groups and <strong>why is interest group membership so high</strong> in the United States?</p>
</blockquote>

<p>One explanation is that free riding is overcame by:</p>

<ol>
  <li>Groups with <strong>financial</strong> resources/patrons outside the group have an advantage in mobilizing in that they can <strong>offer incentives</strong> or hire a lobbyist.</li>
  <li>opinions within <strong>smaller</strong> IGs may be
    <ul>
      <li><em>easier</em> to reach consensus</li>
      <li>if you don’t voice your opinion and the policy is not what you liked, high chance your <em>preference will not be taken into account</em></li>
      <li>easier to <em>spot if you are not contributing</em></li>
    </ul>
  </li>
  <li>Group <strong>leaders</strong> also play an important role, for example
    <ul>
      <li>offer <strong>material incentives</strong>, which are tangible benefits of joining a group. (AARP, for example, offers discounts on hotel accommodations and insurance rates for its members)</li>
      <li>offer <strong>solidary incentives</strong>, which provide the benefit of joining with others who have the same concerns or are similar in other ways, as people are naturally drawn to others with similar concerns.</li>
    </ul>
  </li>
  <li><strong>disturbance theory</strong>: why groups mobilize <strong>due to an event</strong> in the political, economic, or social environment = people will naturally join groups in response to <strong>disturbances</strong>. for example
    <ul>
      <li>in 1962, Rachel Carson published <em>Silent Spring</em>, a book exposing the dangers posed by pesticides such as DDT $\to$ many individuals start to worry about environment and dangers of pesticides $\to$ an increase in both the number of environmental interest groups, such as Greenpeace and American Rivers,</li>
      <li>In May 2020, George <em>Floyd</em> died shortly after police officer Derek Chauvin leaned his knee on Floyd’s neck for nine and half minutes, while Floyd was handcuffed and laying face down on the ground $\to$ massive protests across US</li>
    </ul>
  </li>
</ol>

<h1 id="the-media">The Media</h1>

<p>Freedom of the press and an independent media are important dimensions of a liberal society, and the media can have a huge impact in how we see the society today.</p>

<p>Some basic terms:</p>

<ul>
  <li>The collection of all forms of media that communicate information to the general public is called <strong>mass media</strong> (e.g. television, print, radio, and Internet.)</li>
  <li>The Internet also facilitates the flow of information through <strong>social media</strong>, which allows users to instantly communicate with one another and share with audiences that can grow exponentially.</li>
</ul>

<blockquote>
  <p>Regardless of where we get our information, the various media avenues available today, versus years ago, make it <strong>much easier for everyone to be politically and socially engaged</strong>.</p>
</blockquote>

<p>But who controls the media we rely on? Suprisingly today, most media is controlled by a limited number of conglomerates (a collection of companies, organizations, and media networks)</p>

<p><img src="/lectures/images/2023-05-11-POLS1201_Intro_to_American_Politics/image-20230503164855628.png" alt="image-20230503164855628" style="zoom: 25%;" /></p>

<p>what does this mean? When a media conglomerate has <strong>policies or restrictions</strong>, they will apply to all stations or outlets under its ownership, potentially limiting the information citizens receive.</p>

<ul>
  <li>This raise the question whether the media still operate as an independent source of information. Is it possible that <strong>corporations and CEOs now control the information flow</strong>, making profit more important than the impartial delivery of information?</li>
  <li>The reality is that media outlets, whether newspaper, television, radio, or Internet, are <strong>businesses</strong>, they need to raise revenue! How do they get revenue? Get advertising and sponsors. How do they get them? You need active viewers. In the end, <strong>what attracts viewers and advertisers is what survives</strong>.</li>
</ul>

<h2 id="functions-of-the-media">Functions of the Media</h2>

<p>So what do those media do? What can they control?</p>

<ul>
  <li><strong>help maintain democracy</strong> and keeps the government accountable for its actions, even if a branch of the government is reluctant to open itself to public scrutiny.</li>
  <li>
    <p><strong>promote the public good</strong> by offering a platform for public debate and improving citizen awareness. Network news informs the electorate about national issues, elections, and international news.</p>
  </li>
  <li><strong>agenda setting</strong>, which is the act of choosing which issues or topics deserve public discussion. e.g. In the spring of 2015, when the Dominican Republic was preparing to exile Haitians and undocumented (or under documented) residents, major U.S. news outlets remained silent.</li>
</ul>

<blockquote>
  <p>Large network newscasts and major newspapers are still more powerful at <mark>initiating or changing a discussion</mark>.</p>
</blockquote>

<h2 id="regulating-the-media">Regulating the Media</h2>

<p>The approval of the First Amendment, as a part of the Bill of Rights, demonstrated the framers’ belief that a <strong>free and vital press was important</strong> enough to protect = serves as the basis for the political freedoms of the United States. It said:</p>

<blockquote>
  <p>“Congress shall make no law respecting an establishment of religion, or prohibiting the free exercise thereof; or abridging the freedom of speech, or of the press; or the right of the people peaceably to assemble, and to petition the government for a redress of grievances.”</p>
</blockquote>

<p>Although the media are independent participants in the U.S. political system, their liberties are not absolute and <mark>there are rules they must follow</mark>.</p>

<ol>
  <li>First, the media do not have the right to commit <strong>slander</strong>, speak false information with an intent to harm a person or entity, or <strong>libel</strong>, print false information with an intent to harm a person or entity. But it seems that newspaper has been doing this a lot?
    <ul>
      <li>libel and slander occur only in cases where false information is presented as <strong>fact</strong>.</li>
      <li>When editors or columnists write <em>opinions</em>, they are protected from many of the libel and slander provisions because they are not claiming their statements are facts.</li>
      <li>the defamed individual or company to bring a <em>lawsuit</em>, and the courts have different standards depending on whether the claimant is a private or public figure.</li>
    </ul>
  </li>
  <li>media have only a limited right to publish material the <strong>government says is classified</strong>.
    <ul>
      <li>If the journalist calls the White House or Pentagon for quotations on a classified topic, the president may order the newspaper to stop publication in the interest of national security. The <strong>courts</strong> are then asked to rule on what is censored and what can be printed.</li>
      <li>e.g. in 19721, US gov sued New York Times and Washington Post to stop release information from a classified study of the Vietnam war. In the end, the court gave the newspapers the right to publish much of the study, but revelation of troop movements and the names of undercover operatives are some of the few approved reasons for which the government can stop publication or reporting.</li>
    </ul>
  </li>
  <li>television and radio broadcasters are monitored by both the courts and a <strong>government regulatory commission</strong>.
    <ul>
      <li>Radio Act of 1927 was the first attempt by Congress to regulate broadcast materials.</li>
      <li>Communications Act of 1934 replaced the Radio Act and created a more powerful entity to monitor the airwaves—a seven-member <strong>Federal Communications Commission (FCC)</strong> to oversee both radio and telephone communication.</li>
      <li>the idea is to ask radio/TV stations to apply for <strong>licenses</strong>, which is granted only if stations follow rules about limiting advertising, providing a public forum for discussion, and serving local and minority communities. The licensing requires
        <ul>
          <li><strong>equal-time rule</strong>: registered candidates running for office must be given equal opportunities for airtime and advertisements at non-cable television and radio stations beginning forty-five days before a primary election and sixty days before a general election.</li>
          <li>While the idea behind the equal-time rule is fairness, it may <em>not apply</em> to supporters of that candidate or of a cause. Hence, there potentially may be a loophole in which broadcasters can give free time to just one candidate’s supporters.</li>
          <li><strong>indecency regulations</strong>: limit indecent material and keep the public airwaves free of obscene material.
            <ul>
              <li>However, broadcasters can show indecent programming or air profane language between the hours of 10 p.m. and 6 a.m.</li>
            </ul>
          </li>
        </ul>
      </li>
      <li><strong>net neutrality</strong>: required internet service providers to give everyone equal access to their services and disallowed biased charging of internet access fees.</li>
    </ul>
  </li>
  <li>and many more</li>
</ol>

<h2 id="impact-of-the-media">Impact of the Media</h2>

<p>Since media release information consumed by the people, this information may <strong>affect what we think and the actions we take.</strong></p>

<p>There are many theories debating how much impact the media has, e.g.</p>

<ul>
  <li>Lippmann’s statements led to the <strong>hypodermic theory</strong>, which argues that information is “shot” into the receiver’s mind and readily accepted.</li>
  <li><strong>minimal effects theory</strong>, which argues the media have little effect on citizens and voters. Information is transmitted in two steps, with one person reading the news and then sharing the information with friends.</li>
  <li><strong>cultivation theory</strong>, hypothesized that media develop a person’s view of the world by presenting a perceived reality, and the media can set norms for readers and viewers by choosing what is covered or discussed.</li>
</ul>

<p>and some common techniques the Media use to sway peoples opinions:</p>

<ul>
  <li><strong>framing</strong>: the creation of a narrative, or context, <em>for</em> a news story.</li>
  <li><strong>priming</strong>: when media coverage predisposes the viewer or reader to a particular perspective on a subject or issue.
    <ul>
      <li>e.g. If a newspaper article focuses on unemployment, struggling industries, and jobs moving overseas, the reader will have a negative opinion about the economy. If then asked whether they approve of the president’s job performance, the reader is primed to say no.</li>
    </ul>
  </li>
</ul>

<p>In the end, the consensus among observers is that media have some effect, even if the effect is subtle. Some <mark>important ways</mark> include</p>

<ul>
  <li>effects on governance and caompaigns</li>
  <li>effects on the society</li>
</ul>

<h3 id="medias-effect-on-governance-and-campaigns">Media’s Effect on Governance and Campaigns</h3>

<p>Some historical examples:</p>

<ul>
  <li>in 1972, candidates with the most media coverage build momentum and do well in the first few primaries and caucuses.</li>
  <li>In the 1980s, campaigns learned that tight control on candidate information created more favorable media coverage.</li>
  <li>In 1992, both Bush’s and Bill Clinton’s campaigns maintained their carefully drawn candidate images by also limiting photographers and television journalists to photo opportunities at rallies and campaign venues.</li>
</ul>

<p>However, <strong>campaign coverage now focuses on shallow reports</strong></p>

<ul>
  <li>i.e. colorful personalities, strange comments, lapse of memories, and embarrassing revelations are more likely to get air time than the candidates’ issue positions.</li>
  <li>i.e. citizens want to see updates on the race and electoral drama, not boring issue positions or substantive reporting.</li>
</ul>

<p>As a result, all these factors have likely led to the shallow press coverage we see today, sometimes dubbed <strong>pack journalism</strong> because journalists follow one another rather than digging for their own stories.</p>

<ul>
  <li>
    <p>In 1968, the average sound bite from Richard Nixon was 42.3 seconds, while a recent study of television coverage found that sound bites had decreased to only eight seconds in the 2004 election.</p>
  </li>
  <li>
    <p>that study also found the news showed images of the candidates, but for an average of only twenty-five seconds while the newscaster discussed the stories.</p>
  </li>
  <li>
    <p><strong>media’s discussion of campaigns has also grown negative</strong>.</p>

    <ul>
      <li>During the 2012 campaign, seventy-one of seventy-four MSNBC stories about Mitt Romney were highly negative</li>
      <li>FOX News’ coverage of Obama had forty-six out of fifty-two stories with negative information</li>
      <li>major networks—ABC, CBS, and NBC—were somewhat more balanced, yet the overall coverage of both candidates tended to be negative.</li>
    </ul>

    <p><img src="/lectures/images/2023-05-11-POLS1201_Intro_to_American_Politics/image-20230504013541363.png" alt="image-20230504013541363" style="zoom: 25%;" /></p>
  </li>
</ul>

<blockquote>
  <p>Due in part to the lack of substantive media coverage, campaigns increasingly use <strong>social media</strong> to relay their message.</p>
</blockquote>

<p>So this includes:</p>

<ul>
  <li>using Facebook, Twitter, and YouTube accounts to provide information to voters. The best example would be Donald Trump, who took social media posts to a new level, both in terms of the number of posts and the intensity.</li>
  <li>Yet, on social media, candidates still need to combat negativity.</li>
</ul>

<h3 id="medias-effects-on-society">Media’s Effects on Society</h3>

<blockquote>
  <p>The media choose what they want to discuss. This <strong>agenda setting</strong> creates a reality for voters and politicians that affects the way people think, act, and vote.</p>
</blockquote>

<p>Even if the crime rate is going down, for instance, citizens accustomed to reading stories about assault and other offenses still perceive crime to be an issue. More dominant examples today include, especially on issues of <mark>race and gender</mark>:</p>

<ul>
  <li>
    <p>that local news shows were more likely to show pictures of <strong>criminals</strong> when they were African American,</p>
  </li>
  <li>Network news similarly <strong>misrepresents the victims of poverty</strong> by using more images of African Americans than White people in its segments.</li>
  <li>media coverage of <strong>women</strong> has been similarly biased.
    <ul>
      <li>The media’s historically uneven coverage of women continues in its treatment of <mark>women candidates</mark>. Early coverage was sparse.</li>
      <li>Women were often seen as a <em>novelty</em> rather than as serious contenders who needed to be vetted and discussed.</li>
    </ul>
  </li>
</ul>

<h1 id="side-notes">Side Notes</h1>

<p>A few topics that is not on the US politics, but related</p>

<h2 id="data-and-descriptive-representation">Data and Descriptive Representation</h2>

<p>Republicans become more conservative over time.</p>

<p>(vertical graph here)</p>

<p>How do you rate if a policy is conservative v.s liberal?</p>

<ul>
  <li>
    <p>a few easy ones:</p>

    <ul>
      <li>
        <p>tax rates</p>
      </li>
      <li>
        <p>military spending</p>
      </li>
    </ul>
  </li>
  <li>
    <p>some hard ones</p>

    <ul>
      <li>economic regulation = republicans are not all against it, but certain kinds of it</li>
    </ul>
  </li>
</ul>

<p>On what basis do you decide <strong>if a person is liberal or conservative</strong>?</p>

<ul>
  <li>self-identification</li>
  <li>policy goals, using fixed defintions</li>
  <li>who they vote with</li>
</ul>

<p><strong>DW-Nominate:</strong> spatially representing where people stand on the political spectrum, and explain what factor causes the clustering</p>

<ul>
  <li>
    <p>procedure sketch:</p>

    <ul>
      <li>takes all members and their votes for 2 yeras</li>
      <li><mark>who they vote with</mark> and who they vote against (similarity embedding between each other)</li>
    </ul>
  </li>
  <li>
    <p>found that</p>

    <ul>
      <li>just using the economic dimension + race can almost explain the clustering</li>
      <li>the clustering is changing over time, being now very <strong>polarized</strong></li>
    </ul>

    <p><img src="/lectures/images/2023-05-11-POLS1201_Intro_to_American_Politics/image-20230228193056148.png" alt="image-20230228193056148" style="zoom:33%;" /></p>

    <ul>
      <li>the polarization movement is <strong>asymmetric</strong>: <strong>republican</strong> have moved towards polarization/clustering earlier</li>
      <li><strong>high predictability of political decision</strong>/policy as groups are very polarized = less variety in a pro-econ people voting for a con-econ policy</li>
    </ul>
  </li>
</ul>

<p><strong>Polarization as a feature of congress</strong>: more agreement inside group and aggression outside. This</p>

<ul>
  <li>makes legislation a lot harder since we need votes across the entire house</li>
  <li>hence explains why policies are polarized</li>
  <li>but note that the definition/baseline changes over time = e.g. democrats worried by econ problems could have voted with republicans</li>
</ul>

<p>To note: important to think about descriptive representation from different <strong>dimensions</strong>:</p>

<p>e.g. consider the following data representing women in congress</p>

<p><img src="/lectures/images/2023-05-11-POLS1201_Intro_to_American_Politics/image-20230227170321928.png" alt="image-20230227170321928" style="zoom:33%;" /></p>

<ul>
  <li>doesn’t show the proportion of how is running and how is a candidate</li>
  <li>other dimension include profession of those women, economic background, etc.</li>
</ul>

<h2 id="reading-empirical-research-paper">Reading Empirical Research Paper</h2>

<blockquote>
  <p>What are the goals of quantitivative emprical research?</p>

  <ul>
    <li><strong>reduce</strong> the number of competing explanations (i.e. which existing theories might be wrong)</li>
    <li><strong>refine</strong> theories that mostly work (i.e. we had a good theory, but we need to patch it a bit to explain this as well)</li>
  </ul>
</blockquote>

<p>Therefore, we will first</p>

<ul>
  <li><strong>experiments</strong>: good at identifying causal effects, have controlled variables, but it is very difficult to know if your variable is indeed the cause</li>
  <li><strong>observational studies</strong>: a big dataset, but is that correlation driven by stuff in the dataset or something else</li>
</ul>

<p>We want:</p>

<ul>
  <li><strong>explanation</strong> for a particular event, e.g. <em>rule out</em> theories</li>
  <li><strong>prediction</strong> of what will happen in the future</li>
</ul>

<hr />

<p>Therefore, for quantitative empirical research paper will be organized like:</p>

<ol>
  <li><strong>introduction</strong>: previews of the arguments to be made in this paper</li>
  <li><strong>theory</strong>: situates question and aguments
    <ul>
      <li>also contains justifications why they used this particular approach</li>
      <li>also look for defensive language = reviewers had criticism on those</li>
    </ul>
  </li>
  <li><strong>data and methods</strong></li>
  <li><strong>results/discussion</strong>: here is what we think we have learned</li>
</ol>

<blockquote>
  <p>Therefore, <strong>just with abstract and introduction</strong>, you can get a descent summary of what is happening</p>

  <ul>
    <li>but this will only give you what the author <em>wants you to remember</em>. to critique you will have to read the entire paper</li>
  </ul>
</blockquote>]]></content><author><name></name></author><category term="2022@Columbia" /><summary type="html"><![CDATA[Note that a lot of content comes from relevant publications and the OpenStax book (Krutz, G., &amp; Waskiewicz, S. (2021). American Government 3e. Houston, Texas: OpenStax.)]]></summary></entry><entry><title type="html">UN1494 Intro to Exp</title><link href="/lectures/2022@columbia/UN1494_Intro_to_Exp.html/" rel="alternate" type="text/html" title="UN1494 Intro to Exp" /><published>2023-05-11T00:00:00+00:00</published><updated>2023-05-11T00:00:00+00:00</updated><id>/lectures/2022@columbia/UN1494_Intro_to_Exp</id><content type="html" xml:base="/lectures/2022@columbia/UN1494_Intro_to_Exp.html/"><![CDATA[<h1 id="introduction-and-logistics">Introduction and Logistics</h1>

<ul>
  <li><strong>Lecturer</strong>: Emily Tiberi ect2158@columbia.edu. Office hours: TBA or by appointment</li>
  <li><strong>Expectations</strong>
    <ul>
      <li>your data analysis should be on <code class="language-plaintext highlighter-rouge">Python</code>  or <code class="language-plaintext highlighter-rouge">Mathematica</code>, but <em>not</em> <code class="language-plaintext highlighter-rouge">Excel</code></li>
      <li>Background physics: have taken any physics class at college level</li>
      <li>Time commitment: expected to spend on average <em>less than 10 hours on your lab report each week</em></li>
    </ul>
  </li>
  <li><strong>Absence Policy</strong>
    <ul>
      <li>Attendance includes lab participation and lab report submission</li>
      <li>You are allowed two excused absences and one unexcused absence</li>
    </ul>
  </li>
  <li><strong>Lab sessions</strong>:
    <ul>
      <li>Each lab session will begin with a brief recap with the TA.</li>
      <li>Your lab group will collect raw data</li>
      <li>There will be in-lab discussions. Work in groups, analyze data and answer the discussion questions.</li>
      <li>You will have <mark>a week</mark> to finish the lab report</li>
      <li>bring your laptop, recommend recording <em>raw data</em> using excel and export</li>
    </ul>
  </li>
  <li><strong>Lab report</strong>: your lab report should be your own, but all the others will be/<em>can be</em> collaborative
    <ul>
      <li>your first week lab report will only be personal feedback, no grade</li>
      <li>there <mark>will be a rubric</mark> for lab reports</li>
    </ul>
  </li>
  <li><strong>Grading</strong>: no quizzes, 90% lab report, and 10% in-lab discussion and participation (discussion with the TA)</li>
</ul>

<h1 id="scientific-writing">Scientific Writing</h1>

<p>Readers interpret prose more easily when it flows smoothly… From background rationale conclusion</p>

<p><img src="/lectures/images/2023-05-11-UN1494_Intro_to_Exp/image-20230123150215405.png" alt="image-20230123150215405" style="zoom:33%;" /></p>

<ul>
  <li>Don’t force the reader to figure out your logic – clearly state the rationale.</li>
  <li>Clear writing is also concise writing. The report should be fairly brief (<mark>up to 4 pages</mark>).</li>
</ul>

<p>Your report should look like:</p>

<p><img src="/lectures/images/2023-05-11-UN1494_Intro_to_Exp/image-20230123150517402.png" alt="image-20230123150517402" style="zoom:50%;" /></p>

<p>where</p>

<ul>
  <li>
    <p>“<strong>References</strong>” most of the time empty</p>
  </li>
  <li>
    <p><strong>Abstract</strong> can be there, but is optional. For example</p>

    <p><img src="/lectures/images/2023-05-11-UN1494_Intro_to_Exp/image-20230123150706887.png" alt="image-20230123150706887" style="zoom:33%;" /></p>
  </li>
  <li>
    <p>the <strong>introduction</strong> should usually be <mark>no more than half a page in single column</mark></p>

    <ul>
      <li>describe the research question, why it is important, and what approaches (briefly) you used (optional: briefly mention the results if you want)</li>
    </ul>
  </li>
  <li>
    <p><strong>method</strong>: you really want to talk about your setup, including your apparatus and instruments used, any techniques, etc.</p>

    <ul>
      <li>this <em>should be brief</em> in general</li>
    </ul>

    <p><img src="/lectures/images/2023-05-11-UN1494_Intro_to_Exp/image-20230123151119020.png" alt="image-20230123151119020" style="zoom:50%;" /></p>
  </li>
  <li>
    <p><strong>results and analysis</strong>: the <mark>most important section</mark> in your report. You should <mark>succinctly</mark> give</p>

    <ul>
      <li>data obtained, graphs and tables</li>
      <li>how you calculated those quantities (if not obvious)</li>
      <li>comments on uncertainties. Why are certain error bars so big?</li>
      <li>is your result good?</li>
    </ul>
  </li>
  <li>
    <p><strong>conclusions</strong>: should be short. Contain your interpretation of the result, what you expected</p>
  </li>
</ul>

<p>Other notes for writing <mark>these reports</mark></p>

<ul>
  <li>example, annotated lab reports are also provided in Courseworks</li>
</ul>

<h1 id="error-analysis">Error Analysis</h1>

<blockquote>
  <p>When we measure any quantity, we <em>cannot</em> expect to measure it exactly = we will have <strong>errors/uncertainties</strong> in our experiment!</p>
</blockquote>

<p>Therefore, instead of giving each of your friend $2.3684$ slices of pizza, you might say:</p>

\[2.37 \pm 0.01 \quad \mathrm{slices}\]

<p>note that</p>

<ul>
  <li>you may want to <em>match</em> the number of significant figures in your number and your uncertainty</li>
  <li>usually keep up to 2 sig. figs.</li>
</ul>

<h2 id="type-of-errors">Type of Errors</h2>

<p>There are mainly two types of errors you get in your experiment</p>

<blockquote>
  <ul>
    <li><strong>Statistical/Random Errors</strong> = no going around this, but are <strong>quantifiable</strong>
      <ul>
        <li>Due to random fluctuations from measurement to measurement</li>
        <li>Can be reduced by taking <em>more measurements</em>, computing their <mark>mean and std</mark></li>
      </ul>
    </li>
    <li><strong>Systematic Errors</strong> = e.g. how you are measuring
      <ul>
        <li>Always bias the data in one direction</li>
        <li>“do you best” to identify and correct it</li>
        <li><em>Hard</em> to quantify</li>
      </ul>
    </li>
  </ul>
</blockquote>

<p>How do we quantify statistical/random errors?</p>

<ul>
  <li>
    <p>calculate mean $\bar{x}$, std $\sigma$</p>
  </li>
  <li>
    <p>but also Standard Error of the Mean $\sigma_\bar{x}$ = uncertainty we have on our measured average = <mark>uncertainty in your lab report</mark></p>

\[\sigma_\bar{x} = \frac{s}{\sqrt{N}}\]

    <p>because each time one more measurement is taken, your mean will change. So here is that measure of “<strong>precision in our measurement of the mean</strong>”</p>
  </li>
</ul>

<blockquote>
  <p>What happens when you have different measurements all with different precisions and you want to combine them into a unique result?</p>
</blockquote>

<p>For example, consider you are measuring a length with:</p>

<ul>
  <li>4 different rulers, each time measure once = $x_1\pm \sigma_1, x_2\pm \sigma_2,x_3 \pm \sigma_3,x_4 \pm \sigma_4$</li>
  <li>4 different rulers, with each ruler you measured a lot of times, hence four averages $\bar{x}<em>1 \pm \sigma</em>{1}, \bar{x}<em>2 \pm \sigma</em>{2}, \bar{x}<em>3 \pm \sigma</em>{3}, \bar{x}<em>4 \pm \sigma</em>{4}$</li>
</ul>

<p>And you want to report a <em>single length</em> measurement by a <strong>weigthed average</strong> of them. Then you can do this:</p>

\[\bar{x} = \frac{\sum_i w_i x_i}{\sum_i w_i}, \quad w_i = \frac{1}{\sigma_i^2}\]

<p>and then your <strong>error</strong> for this weighted mean is:</p>

\[\frac{1}{\sigma^2} = \sum_{i=1}^N \frac{1}{\sigma_i^2}\]

<p>(the more general way to derive those uncertainty is in the section: <a href="#Error Propagation">Error Propagation</a>)</p>

<h2 id="confidence-intervals">Confidence Intervals</h2>

<blockquote>
  <p>You want to see <strong>if</strong> a theoretically calculated = true average, $\mu$, <strong>falls at a certain distance from the statistical mean=your measured mean, $\bar{x}$</strong> in your experiments.</p>
</blockquote>

<p>The idea is, say, your measurement follows a <strong>Gaussian distribution</strong></p>

<p><img src="/lectures/images/2023-05-11-UN1494_Intro_to_Exp/image-20230130155232209.png" alt="image-20230130155232209" style="zoom:50%;" /></p>

<p>then we can “<em>estimate</em>” whether a certain result is reasonable:</p>

<ul>
  <li>if within $1\sigma_x$, then in general you can say it is good agreement</li>
  <li>within $1\sigma \sim 2\sigma$, it is consistent (but probably need more measures)</li>
  <li>beyond that it is not very good</li>
</ul>

<p>note that <strong>if the error bar is very large</strong>, it does not mean your measurement is automatically good = caveat to mention in your report</p>

<h2 id="error-propagation">Error Propagation</h2>

<p>Given some function $f(x,y,z)$, where each variable has uncertainty $x \pm \sigma_x$ etc, then:</p>

\[\sigma_f^2 = \left( \frac{\partial f}{\partial x} \right)^2 \sigma_x^2 + \left( \frac{\partial f}{\partial y} \right)^2 \sigma_y^2 + \left( \frac{\partial f}{\partial z} \right)^2 \sigma_z^2\]

<p>which is valid if the errors on x, y and z are uncorrelated.</p>

<blockquote>
  <p><strong>Note</strong>: you may want to automate this calculation in your python code.</p>
</blockquote>

<hr />

<p><em>Examples</em>:</p>

<p><img src="/lectures/images/2023-05-11-UN1494_Intro_to_Exp/image-20230130152506629.png" alt="image-20230130152506629" style="zoom: 33%;" /></p>

<p>where notice that</p>

<ul>
  <li>relative uncertainty = $1\pm (\sigma_x / \bar{x})$, absolute uncertainty $\sigma_x$</li>
  <li>relative uncertainty is useful when you are doing multiplication</li>
</ul>

<h2 id="graphical-analysis-of-data">Graphical Analysis of Data</h2>

<p>When plotting data, you want to show <em>at minimum</em> a) uncertainty = error bars; b) axis labels</p>

<p><img src="/lectures/images/2023-05-11-UN1494_Intro_to_Exp/image-20230130152733661.png" alt="image-20230130152733661" style="zoom:50%;" /></p>

<p>But often you would also want to <strong>fit a linear model</strong> given this data, i.e.</p>

\[y_i = ax_i + b\]

<p>where your measurements are $(x_i, y_i)$. Obviously you will not be able to get a perfect fit, so we consider:</p>

\[\hat{y}_i = ax_i + b\]

<p>and hope to pass as close as possible to the highest number of points = <strong>linear regression</strong> = <strong>minimize least square errors</strong></p>

<p><img src="/lectures/images/2023-05-11-UN1494_Intro_to_Exp/image-20230130152902895.png" alt="image-20230130152902895" style="zoom:50%;" /></p>

<p>given the error = residuals $\Delta y_i = y_i - \hat{y}_i$, then you consider a</p>

\[\min_\beta J = \min_\beta \frac{1}{2N}\sum_{i=1}^N \left( y_i - \hat{y}_i \right)^2 = \min_\beta \frac{1}{2n}\sum_{i=1}^N \Delta y_i^2\]

<p>where $\beta = (a, b)$ in this example.</p>

<ul>
  <li>
    <p>the more general case if to of course consider linear algebra formulation</p>

\[\mathbf{y} = \mathbf{X\alpha + \beta} = \mathbf{[1,X] \beta} \equiv \mathbf{X\beta}\]

    <p>where $\beta = [\alpha_1, \alpha_2…,\alpha_n, \beta]$. This is so that you can more easily find your least square solution.</p>
  </li>
  <li>
    <p>one interpretation of <em>why</em> your model is not perfect is to consider <em>how $y$ are constructed</em>. Consider a process where you have a <strong>random Gaussian noise</strong> to generate those data</p>

\[\mathbf{y} = \mathbf{X\beta} + \epsilon\]

    <p>meaning the residuals you have $\Delta y_i = \epsilon_i$, so that if the your model is correct you should see</p>

    <p><img src="/lectures/images/2023-05-11-UN1494_Intro_to_Exp/image-20230130153058507.png" alt="image-20230130153058507" style="zoom:50%;" /></p>

    <p>which would be a good way to perform <strong>sanity check</strong>.</p>
  </li>
</ul>

<p>But there are cases when you see that plotting $\Delta y_i$ gives (not limited to only those two cases):</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Case 1</th>
      <th style="text-align: center">Case 2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2023-05-11-UN1494_Intro_to_Exp/image-20230130171539106.png" alt="image-20230130171539106" style="zoom:50%;" /></td>
      <td style="text-align: center"><img src="/lectures/images/2023-05-11-UN1494_Intro_to_Exp/image-20230130171552081.png" alt="image-20230130171552081" style="zoom:50%;" /></td>
    </tr>
  </tbody>
</table>

<p>where:</p>

<ul>
  <li>in case 1 it could be you are fitting a <em>wrong model</em>, or you have some <em>systematic error</em></li>
  <li>in case 2, you might need a some form of a <em>weighted fit</em></li>
</ul>

<h1 id="lab-1">Lab 1</h1>

<p>Basically we are re-imagining Galileo’s ramp experiment, where basically we are considering:</p>

<ul>
  <li>motion under constant acceleration</li>
  <li>forces will affect the acceleration of a mass (newton’s second law)</li>
</ul>

<p>The apparatus we will be using is the Fritionless Air-Track</p>

<p><img src="/lectures/images/2023-05-11-UN1494_Intro_to_Exp/image-20230206150149419.png" alt="image-20230206150149419" style="zoom:50%;" /></p>

<p>where Timing is performed by Sonic Ranger.</p>

<ul>
  <li>Sonic Ranger: Measuring Velocity: It simply computes the average velocity over very small time intervals</li>
</ul>

<p>Then, one can then have a measure of the <strong>elasticity</strong> of a collision by computing the <strong>coefficient of restitution</strong></p>

\[e = \left| \frac{v_f}{v_i} \right| = \begin{cases}
1 &amp; \text{elastic}\\
&lt;1 &amp; \text{non elastic}
\end{cases}\]

<p>Three main parts</p>

<ol>
  <li>
    <p>Leveling the ramp</p>
  </li>
  <li>
    <p>Measuring the elasticity of the bumper (under constant velocity)</p>

    <ul>
      <li>
        <p>By comparing the velocity before and after, you can compute elasticity (note to propagate uncertainty to compute $e$)</p>
      </li>
      <li>
        <p>note that since $e = \vert v_f / v_i\vert$, then the uncertainty is:</p>

\[\sigma_e^2 = \frac{1}{v_i^2}\sigma_{v_f}^2 + \frac{v_f^2}{v_i^4}\sigma^2_{v_i}\]
      </li>
      <li>
        <p>will measurements/error of $v_i$ be dependent on $v_f$? In this experiment, theses two are treated as independent variables so intuitively no. But practically you need to be careful about this.</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Measuring the acceleration due to gravity (under constant acceleration</p>

    <ul>
      <li>
        <p>When you incline the ramp, the size of the gravitational force along the ramp is proportional to the angle of the ramp incline</p>

        <p><img src="/lectures/images/2023-05-11-UN1494_Intro_to_Exp/image-20230206152530984.png" alt="image-20230206152530984" style="zoom:50%;" /></p>

        <p>for which you can estimate acceleration with both $v(t)=a_x t$ and $x(t)=…$.</p>
      </li>
      <li>
        <p>then, once you have measured $a_x$, you can compute your $g$ by</p>

\[a_x = g \sin(\theta) = g\frac{h}{L}\]
      </li>
      <li>
        <p>Do you expect steeper slopes to be more accurate than shallower ones? Why or why not?</p>
        <ul>
          <li>measurement readings error as there is less time when $h$ is high $\implies$ $a_x$ is high $\implies$ less time to collect data $\implies$ more error introduced</li>
          <li>if there is systematic uncertainty, then relative uncertainty of height <em>becomes less</em></li>
          <li>the higher velocity means other contributions such as air resistance becomes more significant</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>Challenge: estimate friction by looking at the loss of energy</p>
  </li>
</ol>

<blockquote>
  <p><strong>Check</strong>: when you doing linear regression for this lab, you are <em>probably</em> going to just do the unweighted version $\implies$ do not need to capture uncertainty</p>
</blockquote>

<h1 id="lab-2-projectile-motion-and-conservation-of-energy">Lab 2: Projectile Motion and Conservation of Energy</h1>

<p>Overview: basically <strong>launching a ball of a ramp</strong>, so that you can</p>

<ul>
  <li>estimate friction</li>
  <li>predicting landing position</li>
</ul>

<p><img src="/lectures/images/2023-05-11-UN1494_Intro_to_Exp/image-20230213144921560.png" alt="image-20230213144921560" style="zoom:33%;" /></p>

<blockquote>
  <p><strong>Primary objectives</strong></p>

  <ul>
    <li>understanding distributions of data</li>
    <li>Gaussian statistics</li>
    <li>write (at least some part) of your derivation in your lab report</li>
  </ul>
</blockquote>

<p>So how does this work? We are essentially exchanging potential and kinetic energy in a closed system</p>

<p><img src="/lectures/images/2023-05-11-UN1494_Intro_to_Exp/image-20230213145210803.png" alt="image-20230213145210803" style="zoom: 33%;" /></p>

<p>Then, since kinetic energy is</p>

\[E_{k} = \frac{1}{2}mv^2 + \frac{1}{2}I\omega^2\]

<p>for rolling without slipping, $\omega R = v$. and potential energy is</p>

\[E_{p}(r) = -G \frac{M_e m }{r} \approx mgh\]

<p>But of course, often we get energy “leaked” to friction, e.g. $W_f$ work done by friction</p>

\[E_{k}^{ini} = E_k^{fin} + W_f\]

<p>or the canonical form from work-energy theorem</p>

\[W = \frac{1}{2}mv_f^2 - \frac{1}{2}mv_i^2\]

<p>Then, the position of the ejected ball can be described by</p>

\[x(t) = x_0 + v_{x,0}t\\
y(t) = y_0 + v_{y,0}t - \frac{1}{2}gt^2\]

<p>This should summarize all you need. You basically get</p>

<ul>
  <li>$E$</li>
  <li>$\Delta E_p = mg \Delta h$</li>
  <li>$\Delta E_k = (7/10) m v_0^2$</li>
  <li>$W_f = mg \Delta h’$ for $\Delta h’$ being the height at which the ball stops</li>
  <li>..blablabla</li>
</ul>

<p>with which you can find out the final landing position $x(t)$</p>

<blockquote>
  <p><strong>Note that</strong></p>

  <ul>
    <li>the friction force we are estimating is technically velocity dependent. So measuring friction at one configuration might not mean you have the same friction in later setups</li>
    <li>The experiment is <mark>extremely sensitive to the value of $W_f$</mark>, so measure it as carefully as possible!</li>
  </ul>
</blockquote>

<hr />

<p><strong>Taking Data</strong></p>

<p>Basically you will record the position of the landing by having the ball hitting a carbon paper:</p>

<ul>
  <li>draw a marker of where you <em>expect</em> it to land</li>
  <li>compare against the actual data</li>
</ul>

<p><img src="/lectures/images/2023-05-11-UN1494_Intro_to_Exp/image-20230213151427100.png" alt="image-20230213151427100" style="zoom: 33%;" /></p>

<p>Then, we can look at the <strong>distribution of the data</strong></p>

<p><img src="/lectures/images/2023-05-11-UN1494_Intro_to_Exp/image-20230213151532695.png" alt="image-20230213151532695" style="zoom:28%;" /></p>

<blockquote>
  <p><strong>Note</strong></p>

  <ul>
    <li>
      <p>you should expect your data to look like a normal distribution (even if your model is wrong) if you are testing stuff in the <em>same configuration</em></p>
    </li>
    <li>
      <p>error propagation in this lab is onerous. It is then highly recommended that you define</p>

\[x_{app} = \frac{D\sqrt{2h_2h_E}}{L};\quad h_E = \frac{10}{7}(\Delta h - \Delta h')\]

      <p>$h_2$ and $h_E$ are <mark>not independent</mark>. Therefore you should really calculate $\sigma_u$ for $u = h_2h_e$</p>
    </li>
  </ul>
</blockquote>

<h1 id="lab-4">Lab 4</h1>

<p>Primary Learning Goals:</p>

<ul>
  <li><strong>Weighted</strong> linear regressions</li>
  <li><strong>Weighted</strong> means of population of data</li>
</ul>

<p>And we will be probing <strong>atomic structures</strong>. Before, we understood the <strong>classical macroscopic force</strong> between matter, but <strong>not</strong> really what the constituents of matter were</p>

<ul>
  <li>JJ Thomson shows that matter has constituents that are negatively charged and whose charge/mass ratio is <strong>constant</strong> = <mark>quantization</mark>!</li>
  <li>proposed the plum pudding model (not quite right, improved by latter models)</li>
  <li>today, quantum mechanics! Ann the standard model of elementary particles</li>
</ul>

<p>Experiment: <strong>measure $e/m$</strong> by using lorentz force giving a circular motion</p>

<ol>
  <li>
    <p>given a loop current, we can compute the magnetic field created</p>

    <p><img src="/lectures/images/2023-05-11-UN1494_Intro_to_Exp/image-20230227145721191.png" alt="image-20230227145721191" style="zoom: 33%;" /></p>

    <p>specifically, we will use a <strong>Helmholtz coil</strong>, which is basically two coils:</p>

    <p><img src="/lectures/images/2023-05-11-UN1494_Intro_to_Exp/image-20230227150611603.png" alt="image-20230227150611603" style="zoom:33%;" /></p>

    <p>and $C$ will be given.</p>

    <p>magnetic field at the <mark>center</mark> of experimental apparatus. Finally we also want to <em>not have contribution from external field</em>, hence you want to <strong>align your apparatus with any external field</strong> (<mark>very important</mark>)</p>

    <p><img src="/lectures/images/2023-05-11-UN1494_Intro_to_Exp/image-20230227150800379.png" alt="image-20230227150800379" style="zoom:33%;" /></p>
  </li>
  <li>
    <p>Then, in this field (around the axis of the loop) <strong>if we send in a moving charge</strong>:</p>

\[F = q\vec{v}\times \vec{B} = m \frac{v^2}{R}\]

    <p>which performs a circular motion with radius $R$. Hence</p>

\[\frac{q}{m} = \frac{2v}{R^2 B^2}\]
  </li>
  <li>
    <p>but we don’t have an easy way to measure the velocity $v$. One solution to this problem is to speed the electrons up thanks to a known potential difference</p>

\[K_{\mathrm{gain}} = e V = \frac{1}{2}mv^2\]

    <p>assuming $v_0=0$ is at rest and accelerated across $V$.</p>

    <p>Spefically:</p>

    <p><img src="/lectures/images/2023-05-11-UN1494_Intro_to_Exp/image-20230227150903458.png" alt="image-20230227150903458" style="zoom:33%;" /></p>
  </li>
  <li>
    <p>measure the radius of curvature</p>

    <p><img src="/lectures/images/2023-05-11-UN1494_Intro_to_Exp/image-20230227151108697.png" alt="image-20230227151108697" style="zoom:33%;" /></p>
  </li>
</ol>

<p>Finally, plot with a <strong>line of best fit</strong> to a equation = shows that the equation is linear hence has more <em>physical meaning</em> (e.g. than computing $e/m$ for each of your trial and averaging across)</p>

<ul>
  <li>note that you will need to pick different $I$, one good way is to pick it such that it hits one of the markers</li>
  <li>what about the error of the $I$? You will notice that the marker is quite thick. So you can take $I_\min$ and $I_\max$ that hits that marker, and then take $\bar{I}\pm \sigma_I$ as uncertainty</li>
</ul>

<h1 id="lab-5-polarization-and-interference">Lab 5: Polarization and Interference</h1>

<p>A few background:</p>

<ul>
  <li>
    <p>light as EM wave = oscillating E and B fields</p>
  </li>
  <li>
    <p>Electric and magnetic fields <strong>are always perpendicular to each other</strong></p>
  </li>
  <li>
    <p>Everyday light is usually <strong>unpolarized</strong>. All directions of the electric field are equally probable</p>

    <ul>
      <li>
        <p>a <strong>polarized</strong> light, e.g. electric fields points in one direction only</p>

        <p><img src="/lectures/images/2023-05-11-UN1494_Intro_to_Exp/image-20230306145053943.png" alt="image-20230306145053943" style="zoom:50%;" /></p>
      </li>
      <li>
        <p>so a better definition/visualization of <strong>unpolarized light = cannot define a plane where it oscillates in</strong></p>
      </li>
    </ul>
  </li>
</ul>

<p>Then how much field will be transmitted is given by a <mark>linearly polarized light</mark>:</p>

\[|\vec{E}_{trans}| = | \vec{E}_0 | \cos\theta\]

<p><img src="/lectures/images/2023-05-11-UN1494_Intro_to_Exp/image-20230306145519617.png" alt="image-20230306145519617" style="zoom: 33%;" /></p>

<p><strong>Experiment 1 Background Mauls’ law</strong>: but all we care is <strong>its intensity</strong> because that is what <em>our eyes can observe</em></p>

\[I \propto | \vec{E} |^2\]

<p>Therefore we get <strong>Malus’ Law</strong> (at the second polarizer)</p>

\[I=I_0 \cos^2\theta\]

<p>so you should see something like this</p>

<p><img src="/lectures/images/2023-05-11-UN1494_Intro_to_Exp/image-20230306145638472.png" alt="image-20230306145638472" style="zoom:33%;" /></p>

<p>So how do you measure this? You will get a setup with a rotatable polarizer:</p>

<p><img src="/lectures/images/2023-05-11-UN1494_Intro_to_Exp/image-20230306153933205.png" alt="image-20230306153933205" style="zoom: 33%;" /></p>

<p>So that you can</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Measure this</th>
      <th style="text-align: center">Plot this</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2023-05-11-UN1494_Intro_to_Exp/image-20230306154027663.png" alt="image-20230306154027663" /></td>
      <td style="text-align: center"><img src="/lectures/images/2023-05-11-UN1494_Intro_to_Exp/image-20230306154048970.png" alt="image-20230306154048970" /></td>
    </tr>
  </tbody>
</table>

<p>where in the plot you will need to extract at least 20 points = 20 different values of $\cos^2\theta$</p>

<hr />

<p><strong>Experiment 2 Background: Young’s Double Slit</strong></p>

<ul>
  <li>
    <p>constructive interference = same propagation direction, same frequency, in phase</p>
  </li>
  <li>destructive interference = same propagation direction, same frequency, but out of phase</li>
  <li>(recall that standing wave = <em>opposite</em> propagation direction, same frequency)</li>
</ul>

<p>Here we focus on the constructive and destructive interference</p>

<p><img src="/lectures/images/2023-05-11-UN1494_Intro_to_Exp/image-20230306150046067.png" alt="image-20230306150046067" style="zoom:33%;" /></p>

<p>the idea is to measure <mark>where the peaks/dark spots</mark> are. The key insight is that:</p>

<p><img src="/lectures/images/2023-05-11-UN1494_Intro_to_Exp/image-20230306150331011.png" alt="image-20230306150331011" style="zoom: 33%;" /></p>

<p>assumption to make thing easier: two waves are parallel, as $D » d$</p>

<ul>
  <li>
    <p>for <strong>bright spot to appear</strong>, then the $\Delta l$ must be an <em>integer multiple of wavelength</em> = $m\lambda$</p>
  </li>
  <li>
    <p>for <strong>dark spot to appear</strong>, then $\Delta l$ will be $(m+1/2)\lambda$</p>
  </li>
</ul>

<p>Then for the positions for the bright spot is</p>

<p><img src="/lectures/images/2023-05-11-UN1494_Intro_to_Exp/image-20230306150627704.png" alt="image-20230306150627704" style="zoom:50%;" /></p>

<p>How do you measure this? There will be a sensor you can move <em>along $x$</em>, and record intensity $I(x)$ so that you can find $x_m$</p>

<p><img src="/lectures/images/2023-05-11-UN1494_Intro_to_Exp/image-20230306151618379.png" alt="image-20230306151618379" style="zoom:50%;" /></p>

<hr />

<p><strong>Experiment 3 Background: Diffraction</strong>: can be thought of as self-interference:</p>

<p><img src="/lectures/images/2023-05-11-UN1494_Intro_to_Exp/image-20230306151014923.png" alt="image-20230306151014923" style="zoom:50%;" /></p>

<p>where the <strong>diffraction single-slit minima</strong> occurs at</p>

<p><img src="/lectures/images/2023-05-11-UN1494_Intro_to_Exp/image-20230306150927858.png" alt="image-20230306150927858" style="zoom:50%;" /></p>

<p>so that you can <em>overlay</em> your single-slit minima envelop on top of your double slit experiment. How did this happen?</p>

<ul>
  <li>in an ideal double slit, all the amplitudes will be constant. In an “ideal” single split, you get your envelope</li>
  <li>therefore in the practical double split, the observed intensity is actually an <em>ideal double split $\times$ single slit</em></li>
</ul>

<p>How would yuo measure this? Once again take measurements by moving the sensor in the transverse direction</p>

<p><img src="/lectures/images/2023-05-11-UN1494_Intro_to_Exp/image-20230306151823319.png" alt="image-20230306151823319" style="zoom:50%;" /></p>

<hr />

<p>What are some questions to think about:</p>

<ul>
  <li><strong>What limits the precision of these measurements with light?</strong> theory, physical limitations, aberration, diffraction, ambient lights</li>
</ul>

<p>Some tips:</p>

<ol>
  <li>For all the three parts: Move the RMS slowly when recording data.</li>
  <li>For the polarizer part: Try your best to minimize the amount of environmental light coming in. E.g. using the dim light in the room, move components closer to the sensor, etc.</li>
  <li>For the last part: move the laser closer to the light sensor to see more fringes but remember to <strong>record the value of D</strong>!</li>
</ol>

<h1 id="lab-6-interferometer">Lab 6: Interferometer</h1>

<p>The idea that we can use light as a precision measurement tool. Recall that some key properties include</p>

<ul>
  <li>
    <p><strong>interference</strong></p>

    <p><img src="/lectures/images/2023-05-11-UN1494_Intro_to_Exp/image-20230320145027594.png" alt="image-20230320145027594" style="zoom:33%;" /></p>

    <p>basically when <em>two</em> waves interfere under different conditions</p>
  </li>
  <li>
    <p><strong>refraction</strong>, governed by snell’s law</p>

    <p><img src="/lectures/images/2023-05-11-UN1494_Intro_to_Exp/image-20230320145320632.png" alt="image-20230320145320632" style="zoom: 33%;" /></p>

    <p>so that basically, as Maxwell’s equation is “different” in medium, we get</p>

\[v = c/n,\quad n \text{ being index of refraction}\]
  </li>
  <li>
    <p><strong>optical path length</strong>: how many “cycles” the light spend during the a physical distance</p>

    <p><img src="/lectures/images/2023-05-11-UN1494_Intro_to_Exp/image-20230320150452652.png" alt="image-20230320150452652" style="zoom:33%;" /></p>

    <p>in the case of different medium (but same physical distance), then you can simply calculate the <strong>number of wavelength we can fit</strong> in each “box” (i.e. physical distance)</p>

    <p><img src="/lectures/images/2023-05-11-UN1494_Intro_to_Exp/image-20230320150625225.png" alt="image-20230320150625225" style="zoom: 33%;" /></p>

    <p>why would this quantity be useful? Recall that in the previous lab this difference in wavelength relates to constructive/destructive interf.</p>
  </li>
</ul>

<p>Finally, <strong>interferometry</strong>, the idea being</p>

<ol>
  <li>Split single beam into two, then recombine.</li>
  <li>Observer sees interference patterns projected onto a small screen.</li>
  <li>By moving one of the mirrors, the observer can change the path length difference  . The consequence is a shift in the interference pattern.</li>
</ol>

<p>so that as you move the $M_1$ length back and forth, you will see a different interference pattern</p>

<p><img src="/lectures/images/2023-05-11-UN1494_Intro_to_Exp/image-20230320151553834.png" alt="image-20230320151553834" style="zoom:33%;" /></p>

<p>where basically you get two rays because <strong>one is being transmitted and other being reflected</strong></p>

<p>measure the gravitational wave=stretching/compressing space=<strong>changes the physical distance=interference pattern</strong></p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Inteferometers Today</th>
      <th>Recorded Interference due to Gravitational Wave</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/lectures/images/2023-05-11-UN1494_Intro_to_Exp/image-20230320151329891.png" alt="image-20230320151329891" style="zoom:50%;" /></td>
      <td><img src="/lectures/images/2023-05-11-UN1494_Intro_to_Exp/image-20230320151437742.png" alt="image-20230320151437742" style="zoom: 50%;" /></td>
    </tr>
  </tbody>
</table>

<p>Alternatively, the beams that are transmitted and reflected+transmitted will have interference = can measure the gap</p>

<p><img src="/lectures/images/2023-05-11-UN1494_Intro_to_Exp/image-20230320152244339.png" alt="image-20230320152244339" style="zoom:50%;" /></p>

<blockquote>
  <p>If we change the path length by a certain distance</p>

\[2d_m = m \lambda,\]

  <p>where $d$ is the distance you moved the mirror w.r.t the original position, then you will <strong>restore the original intereference pattern</strong>.</p>

  <ul>
    <li>be careful that the drawings we did are “assuming” a single light ray, but of course in reality is a “spherical wave front”</li>
    <li>therefore, if you moved $d_{10}$, then you would have seen the bright spot reappeared $10$ times <em>during the time you moved it</em></li>
  </ul>
</blockquote>

<hr />

<p><strong>Experiment: you will use both the Michelson and the Fabry-Perot interferometers</strong></p>

<p><img src="/lectures/images/2023-05-11-UN1494_Intro_to_Exp/image-20230320152916248.png" alt="image-20230320152916248" style="zoom:33%;" /></p>

<p>How to read the micrometers</p>

<p><img src="/lectures/images/2023-05-11-UN1494_Intro_to_Exp/image-20230320152419592.png" alt="image-20230320152419592" style="zoom:33%;" /></p>

<p>You will turn the knob and count how many fringes have passed.</p>

<p>Then you will do this again:</p>

<p><img src="/lectures/images/2023-05-11-UN1494_Intro_to_Exp/image-20230320153053961.png" alt="image-20230320153053961" style="zoom:33%;" /></p>

<blockquote>
  <p>To think about:</p>

  <ul>
    <li>in the end both setup measures the same thing. Which configuration is better?</li>
    <li>sometimes count the first fringe might be hard. It could be better to count the second ring, etc = the <mark>largest error is most likely mis-counting the number of fringes</mark>. So that should be <mark>included in your uncertainty measurement</mark></li>
  </ul>
</blockquote>

<p>The last part is we can change the optical distance <strong>by changing the medium</strong> (before we are changing the physical distance)</p>

<p><img src="/lectures/images/2023-05-11-UN1494_Intro_to_Exp/image-20230320153256202.png" alt="image-20230320153256202" style="zoom:50%;" /></p>

<p>so that we can <strong>change the pressure=change index of refraction</strong> and observe different interference patterns.</p>

<p>Therefore, since the interference patterns re-occur every integer number of wavelengths apart:</p>

<p><img src="/lectures/images/2023-05-11-UN1494_Intro_to_Exp/image-20230320153435220.png" alt="image-20230320153435220" style="zoom: 50%;" /></p>

<p>Then finally from this we can compute $n_{air}$ by</p>

<p><img src="/lectures/images/2023-05-11-UN1494_Intro_to_Exp/image-20230320153539028.png" alt="image-20230320153539028" style="zoom: 50%;" /></p>

<blockquote>
  <p><strong>Tips</strong></p>

  <ul>
    <li>start turning the knob <strong>from</strong> the 500 $\mu m$ mark</li>
  </ul>
</blockquote>

<h1 id="feedback-received">Feedback Received</h1>

<p>Feedback for Lab 1:</p>

<p>Total score: 13.5/20</p>

<p><strong>Overall Communication/Organization rubric items: Full points</strong></p>

<p><strong>Data Vis: -1</strong>
Plots must have titles as well as captions.
Note: A short table or two with some of your measurements would not have been out of place here, but it’s not strictly necessary and in this case, you wouldn’t lose points</p>

<p><strong>Data Manipulation &amp; Error Analysis rubric items: -1</strong>
- Uses Python, Mathematica, or similar: Yes
- Only most relevant equations or analyses are explicitly shown: Yes
- Analysis and modeling are connected to physical concepts: Yes
- Uncertainties are justified: There is <mark>no such thing as “human error.” This will fall under “random error”</mark> but never use the phrase “human error” or anything like it.</p>

<p><strong>Discussion rubric items: -3.5</strong>
- Comparison of results to expectation with justification: <mark>Agreement of measured e with expected value (1) is not reported</mark>. When discussing whether results are in agreement with predictions, don’t say that your results are “satisfactory” or “close” or anything like that (e.g. when you talked about your result for b, the y-intercept). When it comes to analyzing results, there’s only one thing that matters. <mark>Are your measurements the same as the predicted values within 3 sigma?</mark> If yes, they’re in agreement with predictions. If not, there’s a statistically significant error and they’re not in agreement. Once you have established this, you go into <mark>discussing the quality of your results (why they were or weren’t in agreement), and then you can potentially use more qualitative descriptions</mark>, but only once the quantitative actual analysis has been established.
- Discussion of quality (quantitative and qualitative) of results: Whether or not your results are in agreement with expectation, need to comment on why. This hasn’t been done fully.
- Sources of errors reference model, assumptions, and technical limitations: Sources of error for e not commented on.
- Responds to discussion questions: Not all</p>

<p>Narrative flow &amp; context rubric items: -1
- Sufficiently contextualize results and discussion: Yes
- Include only necessary and relevant background: Yes. If you want it to be perfect, you need to include just one or two sentences that <mark>capture the really big picture (why do we even care about any of the things we investigated in this experiment).</mark> You’re really almost there, but think of the intro as the part that will convince the reader that this is worth reading. Think of a scientific journal article where the intro always has something to make the project sound <mark>immediately relevant to everyone</mark>, no matter their background.
- Separate information appropriately: Yes
- Summarize concisely: Yes</p>]]></content><author><name></name></author><category term="2022@Columbia" /><summary type="html"><![CDATA[Introduction and Logistics]]></summary></entry><entry><title type="html">APPH4010 Intro to Nuclear</title><link href="/lectures/2022@columbia/APPH4010_Intro_to_Nuclear.html/" rel="alternate" type="text/html" title="APPH4010 Intro to Nuclear" /><published>2022-12-20T00:00:00+00:00</published><updated>2022-12-20T00:00:00+00:00</updated><id>/lectures/2022@columbia/APPH4010_Intro_to_Nuclear</id><content type="html" xml:base="/lectures/2022@columbia/APPH4010_Intro_to_Nuclear.html/"><![CDATA[<p>Equations and Concepts for Intro to Nuclear</p>

<h1 id="1-basic-concepts">1. Basic Concepts</h1>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Name of Concept/Equation</th>
      <th style="text-align: left">Definition/Equation</th>
      <th style="text-align: left">Notes</th>
      <th style="text-align: left">Example</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">Isotopes</td>
      <td style="text-align: left">same atomic number but different neutrons</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Electron Volt</td>
      <td style="text-align: left">energy equal to the amount gained to accelerate rest electron through a potential difference of 1 volt</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Atomic Mass Unit/Dalton</td>
      <td style="text-align: left">1/12 of the mass of a neutral atom of $^{12}_6C$</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Magnetic Moment</td>
      <td style="text-align: left">Magnetic Dipole Moment associated with spin of nucleus</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Spin Quantum Number</td>
      <td style="text-align: left">nucleons have spin of 1/2 in units of $h / (2\pi)$</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Mass to Energy</td>
      <td style="text-align: left">$E^2 = p^2c^2 + m_0^2 c^2$</td>
      <td style="text-align: left">$m_0$ is rest mass, and if at rest, $p=0$</td>
      <td style="text-align: left">$E_{\mathrm{electron}}=511keV$</td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">$E_{\mathrm{amu}}=931.5keV$</td>
    </tr>
    <tr>
      <td style="text-align: center">Binding Energy</td>
      <td style="text-align: left">Energy required to separate its constituent nucleus</td>
      <td style="text-align: left">using $E=mc^2$</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">$B = [Z\cdot m_H + N\cdot m_N - m(A,Z)]c^2$</td>
      <td style="text-align: left">energy used for binding, so the actual atomic mass $m(A,Z)$ is smaller</td>
      <td style="text-align: left">consider for carbon $^{12}_6C$ we have $m(A,Z)=12$, but $m_H=1.007825$ and $m_N=1.008665$</td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">$m_H$ is mass of hydrogen so that it includes weight of electron</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Binding Energy Curve</td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221013004334846.png" alt="image-20221013004334846" /></td>
      <td style="text-align: left">$B/A$ plotted because binding energy increases just as there are more proton to hold</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">the more $A$, much much more $B$ is needed due to short range of internuclear force</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">but the above only works until a point where there is only a fixed number of neutrons affecting a proton</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">since higher $B$ also means more energy required to break = more energy released when making bonds, we want fission to go from right</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Nuclide Stability Curve</td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221013005606999.png" alt="image-20221013005606999" /></td>
      <td style="text-align: left">more neutrons is needed for more protons, hence this stability curve in the middle</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">so above it is more proton then needed = proton rich</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Properties of Radioactivity</td>
      <td style="text-align: left">Decay is a random process, but the probability of occurring can be modelled, and macro quantity such as $t_{1/2}$ can be computed</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">usually an unstable nuclide “parent” transforms into a more stable nuclide “daughter”</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">radioactivity measured in Becquerel = 1 decay per second</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">often heavy nuclei gives $\alpha$, and light nuclei $\beta$</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Alpha Emission Properties</td>
      <td style="text-align: left">$(A,Z) \to (A-4, Z-2)$</td>
      <td style="text-align: left">preferred by heavy nuclides</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">$\alpha$-particle is preferred because it is <strong>very</strong> stable, hence net effect of decay releases energy</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">(see below)</td>
    </tr>
    <tr>
      <td style="text-align: center">Decay Energy Released</td>
      <td style="text-align: left">$Q = \Delta m c^2 =  (m_{\mathrm{left}}-m_{\mathrm{right}})c^2$</td>
      <td style="text-align: left">if net mass loss = net energy released = RHS more stable = RHS less actual mass</td>
      <td style="text-align: left">U(238)$\to$ Th(234) + He(4)</td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">$Q_\alpha = \mathrm{KE}<em>{\mathrm{daughter}}+ \mathrm{KE}</em>{\mathrm{\alpha}}$</td>
      <td style="text-align: left">for alpha decay</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">$Q_\alpha = E_\alpha[1+ \frac{m_\alpha}{m_D}]$</td>
      <td style="text-align: left">conservation of momentum</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">since $Q_\alpha,m_\alpha/m_D$ is known, this means KE energy spectrum for $\alpha$ will be discrete in this case</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Beta Decay Properties</td>
      <td style="text-align: left">for proton-rich nuclides, often see $\beta^+$ decay or electron capture to convert $P \to N$</td>
      <td style="text-align: left">$p \to n + e^+ + \nu$</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">$p+e^- \to n + \nu$</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">otherwise, light nuclides often have $\beta^-$, which is $N\to P$</td>
      <td style="text-align: left">$n \to p + e^- + \bar{\nu}$</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221013014759439.png" alt="image-20221013014759439" /></td>
      <td style="text-align: left">KE Spectrum of electron becomes continuous because you have three particles released</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Gamma Decay Property</td>
      <td style="text-align: left">occurs when excited nucleus lose energy $\Delta E$ as photons</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Rate of Radioactive Decay</td>
      <td style="text-align: left">$\frac{dN}{dt} = -\lambda N$</td>
      <td style="text-align: left">Given that macroscopically the rate is proportional to number of radioactive nuclei</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">$N(t)=N_0e^{-\lambda t}$</td>
      <td style="text-align: left">$\lambda$ is probability per unit time that a nuclide decays</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">$A=\lambda N$</td>
      <td style="text-align: left">since $\lambda$ is prob/time, activity is rate of decay of a sample, measured in Becquerel</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Relativistic Effect</td>
      <td style="text-align: left">$\Delta T’ = \gamma \Delta T$</td>
      <td style="text-align: left">high energy particle emitted so that $v \approx c$, then the actual half life becomes $\Delta T’$</td>
      <td style="text-align: left">$v=0.995c$ when $\nu$ is released with large energy</td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">$\gamma = \frac{1}{\sqrt{1-v^2/c^2}}$</td>
      <td style="text-align: left">is Lorentz fraction</td>
      <td style="text-align: left"> </td>
    </tr>
  </tbody>
</table>

<h1 id="5-interaction-of-radiation-and-matter">5. Interaction of Radiation and Matter</h1>

<p>Nuclear radiation normally consists of <mark>any particle with energy</mark> or photons (particle radiation is the <strong>radiation of energy by means of fast-moving subatomic particles</strong>). Its <strong>interactions with matter</strong> gives us opportunity for all experimental work. Therefore, this chapter we consider:</p>

<ul>
  <li>how charged particle interact with matter</li>
  <li>how uncharged particle interact with matter</li>
  <li>how photons interact with matter</li>
</ul>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Name of Concept/Equation</th>
      <th style="text-align: left">Definition/Equation</th>
      <th style="text-align: left">Notes</th>
      <th style="text-align: left">Example</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">Num Atoms and Atom Density</td>
      <td style="text-align: left">$N = \frac{m}{M}N_A$</td>
      <td style="text-align: left">$m$ is mass of the substance you care, $M$ is the atomic weight of it</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">$N/V = \frac{m}{V\cdot M}N_A = \frac{\rho}{M}N_A$</td>
      <td style="text-align: left">$\rho$ is the density of the substance you are</td>
      <td style="text-align: left">$H_2O$ has $\rho \approx 1g/\mathrm{cm}^3$, and $M=18.0153$</td>
    </tr>
    <tr>
      <td style="text-align: center">Heavy Charged Particles Interaction Properties</td>
      <td style="text-align: left">Two Ways of Interaction:<br />1) its electric field can ionize atoms in its passage<br />2) collision (e.g. with electrons)</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">Deflect very little from path because its heavy</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">Well-defined range, depending on its energy, mass, charge, and the stopping medium</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">$\Delta E \approx E_\alpha(\frac{4m_e}{M_\alpha})$</td>
      <td style="text-align: left">max energy lost per collision</td>
      <td style="text-align: left">incident alpha particle</td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">Though short range, as it can produce ionization = excited nuclei produces x-rays = need thicker $&gt;R$ protection layer</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Stopping Power</td>
      <td style="text-align: left">Rate at which a particle loses energy per unit path length</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221013235440171.png" alt="image-20221013235440171" /></td>
      <td style="text-align: left">Bethe-Bloch Formula</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Energy Dependence of Stopping Power</td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221013235351944.png" alt="image-20221013235351944" style="zoom:50%;" /></td>
      <td style="text-align: left">variation of stopping power with energy if incident proton. This general shape works for any charged ion</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221025164843434.png" alt="image-20221025164843434" style="zoom: 33%;" /></td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">$\frac{dE}{dx} \approx \frac{\mathrm{const}}{E^k},k\approx 0.8$</td>
      <td style="text-align: left">the faster the ion travels, the less chance it interacts with stopping medium, hence negative slope</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">$R=\int_{E}^0 dE/(dE/dx) \propto E^{k+1}$</td>
      <td style="text-align: left">derived from above</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Projectile Dependence of Stopping Power</td>
      <td style="text-align: left">$dE/dx \propto z^2 f(v)$</td>
      <td style="text-align: left">depends on particle charge</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">$R \propto (m/z^2) F(v)$</td>
      <td style="text-align: left">range depends on incident particle mass and charge, derived from above</td>
      <td style="text-align: left">if two charged particle has the same energy, then $R_1/R_2 = (m_1/m_2)(z_2/z_1)^2$ because velocity is the same</td>
    </tr>
    <tr>
      <td style="text-align: center">Stopping Medium Dependence of Stopping Power</td>
      <td style="text-align: left">$\frac{R_1}{R_2} \approx \frac{\rho_2 \sqrt{A_1}}{\rho_1 \sqrt{A_2}}$</td>
      <td style="text-align: left">depends on stopping medium’s density and mass number</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Bragg Curve</td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221014000422271.png" alt="image-20221014000422271" /></td>
      <td style="text-align: left">utilize the fact that stopping power increases when energy decreases</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">particle travels slower = can produce more ions per unit path</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">hence Brag Peak = peak stopping power = peak ionization energy</td>
      <td style="text-align: left">hit tumor at this distance</td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">when all energy is lost, it does nothing and stops/halts</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Electrons/$\beta$-particle Properties</td>
      <td style="text-align: left">Two Ways of Interaction:<br />1) its electric field can ionize atoms in its passage<br />2) collision (e.g. with electrons)</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">a zig-zag path</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">a much faster speed = less stopping force</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">less well-defined range, hence uses mean-free-path</td>
      <td style="text-align: left">mean free path is the average distance over which a moving particle travels before substantially changing its direction or energy</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">you can also use max-range $R_{\max}$ as a measure, in which case$\rho  R_{\max} \propto E_{\max}$</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Stopping Power v.s. Electron Energy</td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221014142135607.png" alt="image-20221014142135607" /></td>
      <td style="text-align: left">as electrons accelerate by rapidly changing directions, it emits a lot of Bremsstrahlung radiation meaning $-\frac{dE}{dx}_{\mathrm{rad}}$ contributes a lot to stopping power</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Reaction Cross Sections</td>
      <td style="text-align: left">measures area within which if you hit the particle near the target $T$, reaction will occur</td>
      <td style="text-align: left">can be used for both Neutron and Photon</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">hence measures how strongly target $T$ reaction will occur</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Microscopic Cross Section</td>
      <td style="text-align: left">$\sigma = \sigma(E)$</td>
      <td style="text-align: left">$E$ is energy of incident particle</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">unit is uslaly $\mathrm{cm}^2$ or in Barnes ($10^{-24}\mathrm{cm}^2$)</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">$\sigma_{\mathrm{total}} = \sigma_{\mathrm{abs}}+\sigma_{\mathrm{sca}}+\sigma_{\mathrm{n,2n}}+…$</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Reaction Rate</td>
      <td style="text-align: left">$R=N \cdot \sigma \phi = \Sigma \phi$</td>
      <td style="text-align: left">$N$ is atomic density, $\phi$ is particle flux (particle per cm$^2$ per second)</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">$\sigma \phi$ measures number of reactions triggered per second</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Macroscopic Cross Section</td>
      <td style="text-align: left">$\Sigma \equiv N \sigma$</td>
      <td style="text-align: left">is the macroscopic cross section</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Gamma Ray Interaction Properties</td>
      <td style="text-align: left">Primary ways of interaction:<br />1) photo-electric effect<br />2) Campton scattering<br />3) pair production</td>
      <td style="text-align: left">because gamma rays are very energetic and they are photons</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">we consider attenuation coefficient $\mu_m$ as a measure of <strong>probability the photon interact with material = photon vanished</strong></td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Photoelectric Effect</td>
      <td style="text-align: left">photon absorbed by electrons (near nucleus for conservation of momentum) to be ejected</td>
      <td style="text-align: left">hence that photon disappeared = attenuated</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">$T=E_\gamma - B_e = hv - B_e$</td>
      <td style="text-align: left">$T$ is the emitted photoelectron and $B_e$ is the binding energy of the electron</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">secondary reactions might occur if<br />1) rest of the electrons rearrange themselves for de-excitation and release $\gamma$-ray<br />1) eject low energy electrons for de-excitation and hence <strong>Auger</strong> electrons  to deal with the excess energy</td>
      <td style="text-align: left">The Auger effect is a physical phenomenon in which the filling of an inner-shell vacancy of an atom, by an electron, is accompanied by the <em>emission of another electron</em> from the same atom <em>instead of releasing energy</em>.</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">$\sigma_{PE} \propto z^5 / E_\gamma^{3.5}$</td>
      <td style="text-align: left">free electron = low probability of reaction</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">higher electron binding energy = more tightly bound electron has a higher chance (also for <strong>conservation of momentum</strong>)</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Campton Scattering</td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221014150725380.png" alt="image-20221014150725380" /></td>
      <td style="text-align: left">$\gamma$ ray scattered off electron and hence we get an electron recoiling and a lower energy photon</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">$T = E_\gamma - E_{\gamma ‘} = E_{\text{KE of elec}}$</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">$E_{\gamma ‘} = E_{\text{KE of elec}} = E_e - m_ec^2$</td>
      <td style="text-align: left">for $E_e$ is the total energy of the recoil electron</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">$E_{\gamma ‘} = \frac{E_\gamma}{1+(E_\gamma/mc^2)(1-\cos \theta)}$</td>
      <td style="text-align: left">energy of scattered photon from conservation of energy and momentum</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">a problem for shielding in real life as $\gamma$ photon didn’t disappear</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Pair Production</td>
      <td style="text-align: left">creates an electron-positron pair (when heavy nucleus is near to conserve momentum)</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">$E_\gamma = 2m_ec^2 + T_- + T_+$</td>
      <td style="text-align: left">$2m_ec^2$ is the rest mass energy of positron and electron</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">has secondary effect when positron recombine with electron $\to$ annihilate and produce two oppositely traveling photon $\to$ can do PE or scattering</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Photon Attenuation</td>
      <td style="text-align: left">from the three mechanism above, photon either disappear or scattered = not observed by detector = attenuated</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221014151515070.png" alt="image-20221014151515070" /></td>
      <td style="text-align: left">can measure and find out attenuation dependence on the three mechanism</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221014151526416.png" alt="image-20221014151526416" /></td>
      <td style="text-align: left">difficult to measure</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Collimated Photon Attenuation</td>
      <td style="text-align: left">$dI = - N\sigma I dx$</td>
      <td style="text-align: left">$x$ is thickness of the material, $N$ is material atomic density, and $\sigma$ is interaction cross section</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">$\mu \equiv N\sigma$</td>
      <td style="text-align: left">linear attenuation coefficient</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">represents the probability per unit path length of a photon undergoing an interaction that would remove it from the beam</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">$I = I_0 e^{-N\sigma x} = I_0 e^{-\mu x}$</td>
      <td style="text-align: left">intensity observed is $I$</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">$\mu_m = \mu / \rho$</td>
      <td style="text-align: left">mass attenuation coefficient</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Photon Attenuation Coefficient Graph</td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221014152131327.png" alt="image-20221014152131327" /></td>
      <td style="text-align: left">again, there are three phenomenon contributing to $\sigma$ hence $\mu_m$</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Neutron Interactions</td>
      <td style="text-align: left">A variety of interactions but mostly nuclear reactions:<br />1) fission if neutrons at few MeV<br />2) scattering<br />3) slowed neutrons can give neutron absorption</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Fission Fragments</td>
      <td style="text-align: left">When $N$ and $_{238}U$ react, it will create two <strong>fission fragment</strong> and 2-3 neutrons</td>
      <td style="text-align: left">hence neutron attenuated</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">those neutrons can then start chain reactions</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">requires low neutron energy</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Neutron Moderation</td>
      <td style="text-align: left">if elastic collision, can calculate energy $E$ of neutron with initial energy $E_0$ <strong>after colliding</strong> with some target nucleus at rest</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">$n = (1/\varepsilon) \ln(E_0 / E_n)$</td>
      <td style="text-align: left">$n$ is the number of collisions of neutrons</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">$E_n$ is the energy of neutron after $n$ collisions</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">$\varepsilon = (2/A) - (4/(3A^2))$</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">if reached low neutron energy = thermal neutron, can do fission</td>
      <td style="text-align: left">hence attenuated (see above)</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Attenuation in Neutrons</td>
      <td style="text-align: left">$\sigma_T \approx \sigma_a + \sigma_s$</td>
      <td style="text-align: left">mostly scattering and absorption</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">$I = I_0 e^{-N \sigma_T x}$</td>
      <td style="text-align: left">same equation as photon attenuation</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">$I = I_0 e^{-\Sigma x} = I_0 e^{- x/\lambda}$</td>
      <td style="text-align: left">same $\Sigma = N\sigma_T$ as before</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">$\lambda = 1 / \Sigma$</td>
      <td style="text-align: left">mean attenuation length = <strong>mean free path</strong></td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">$1/\lambda = (1/\lambda_a) + (1/\lambda_s)$</td>
      <td style="text-align: left">since $\Sigma = \Sigma_a + \Sigma_s$ from the first equation</td>
      <td style="text-align: left"> </td>
    </tr>
  </tbody>
</table>

<h1 id="6-detectors-and-instrumentation">6. Detectors and Instrumentation</h1>

<p>Here, we consider the principle at systems for</p>

<ul>
  <li>detection radiation</li>
  <li>producing controlled beams of radiation</li>
</ul>

<p>In general, any detector gets its signal from the <strong>interaction of radiations with matter</strong>:</p>

<ul>
  <li>collect charge released by ionization of gas (cased by radiation)</li>
  <li>excitation of electrons in semi-conductors (cased by radiation)</li>
  <li>observing fluorescent photons emitted due to de-excitation (cased by radiation)</li>
  <li>making ionization trails visible in film/solid gas (cased by radiation)</li>
</ul>

<p>and in addition to detecting those radiations, we also want detectors to tell us more information such as <strong>energy of the radiation</strong>, type of the radiation, dose rate, etc.</p>

<ul>
  <li>
    <p><strong>dose rate</strong> is quantity of radiation absorbed or delivered per unit time</p>
  </li>
  <li>
    <p>Dose equivalent (or effective dose) combines the amount of radiation absorbed and the medical effects of that type of radiation.</p>
  </li>
</ul>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Name of Concept/Equation</th>
      <th style="text-align: left">Definition/Equation</th>
      <th style="text-align: left">Notes</th>
      <th style="text-align: left">Example</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">Observe Current by Collecting Charge</td>
      <td style="text-align: left">$Q = \int_{0}^t i(t)dt$</td>
      <td style="text-align: left">typically, radiation interact with matter and produces an electric charge (and ion)</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221014155430476.png" alt="image-20221014155430476" /></td>
      <td style="text-align: left">can collect that charge using an electric field = observe a current</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">notice the <strong>pulse like shape</strong></td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221014155617597.png" alt="image-20221014155617597" /></td>
      <td style="text-align: left">In reality, since radiation is random, it is better described by Poisson statistics</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">Poisson statistics = probability of a given number of events occurring in a fixed interval of time if the events occur with a known average rate and independently of the time since the last event</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Modes of Detector Operation</td>
      <td style="text-align: left">Pulse mode: when low radiation flux hence each radiation can be recorded as separate pulse</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">Current mode: high particle flux hence average current is recorded</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Detectors Figures of Metric</td>
      <td style="text-align: left">Things to check for a detector:<br />1) Energy Resolution<br />2) Detection Efficiency<br />3) Dead Time</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Energy Resolution</td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221014161258795.png" alt="image-20221014161258795" /></td>
      <td style="text-align: left">$E_0$ peak is the source, the Gaussian curve is the fitted energy spectrum <em>measured</em></td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">measures Full-Width at Half Maximum (FWHM)</td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221014161426020.png" alt="image-20221014161426020" /></td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">measured in units of energy or percent of its peak energy $E_0$</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">since it is usually first fitted to a Gaussian curve, then FWHM$=2.35\sigma$</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221014161543558.png" alt="image-20221014161543558" /></td>
      <td style="text-align: left">in reality due to all different effects <em>reaching the device</em></td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Detection Efficiency</td>
      <td style="text-align: left">Measures how much radiation it can capture, and if captured, how much it can record</td>
      <td style="text-align: left">capture = radiation reaches it<br />record = radiation reached AND recorded</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">usually easy to detect charged particles $\alpha$ and $\beta$, but be careful as they have short range</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">harder to deal with $\gamma, n$ because they have deposit little energy per unit path</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221014161857546.png" alt="image-20221014161857546" /></td>
      <td style="text-align: left">depends on geometry of the device</td>
      <td style="text-align: left">if device is liquid so that source submerges in it, then it is $4\pi$ full coverage</td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221014161905351.png" alt="image-20221014161905351" /></td>
      <td style="text-align: left">actual performance, dependent on detector material and thickness, and radiation type and energy</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Dead Time</td>
      <td style="text-align: left">due to physical/electronical problem, there will be dead-time when device becomes <strong>unresponsive</strong> between events</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">e.g. takes time for the captured electron to travel to the cathode</td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">events almost overlap</td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">$\tau$ =  dead time</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221014162158239.png" alt="image-20221014162158239" /></td>
      <td style="text-align: left">so non-paralyzable can recover 4</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">paralyzable has the problem of <strong>extended dead time</strong></td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Dead Time Corrections</td>
      <td style="text-align: left">Paralyzable detector: $n=me^{n\tau}$</td>
      <td style="text-align: left">$n=$ true interaction rate, $m$ = recorded interaction rate, $\tau$ = deadtime</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">Nonparalyzable detector: $n= m/(1-m\tau)$</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221014162313018.png" alt="image-20221014162313018" /></td>
      <td style="text-align: left">when true radiation $n$ is high, paralyzable can mistake it for a low $m$!</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Principles of Gas Detectors</td>
      <td style="text-align: left">detectors by using gas to be ionized by the radiation $\to$ record those ions</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">three types of detectors on this principle<br />1) ionization chamber<br />2) proportional counter?<br />3) GM counter</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Ionization Chamber</td>
      <td style="text-align: left">works by measuring ionization (of gas molecules) produced <em>solely</em> by incident ionizing particles (e.g. $\alpha$ radiation)</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221014162757533.png" alt="image-20221014162757533" /></td>
      <td style="text-align: left">ionizing particles creates ionized gas $\to$ have a high enough field to prevent recombination $\to$ those ions complete the circuit by having electron goes to anode and positive ion to cathode</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">but usually needs an amplifier as current produced could be small</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">need a certain amount of electric field applied</td>
      <td style="text-align: left">see above</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">$A$ = #ions per sec produced $\times$ charge per ion</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">source disposing $1GeV\,s^{-1}$ energy per second and air in the chamber ionizes with $34$eV</td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">#ions per sec produced = $10^9 / 34$</td>
    </tr>
    <tr>
      <td style="text-align: center">Pulse Amplitude v.s. Voltage Applied in Gas Detector</td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221014163205531.png" alt="image-20221014163205531" /></td>
      <td style="text-align: left">the fundamental reason why we have three types of gas detectors</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">pulse <strong>amplitude</strong> can give you information of the <strong>energy</strong> of ionizing particles!</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">region I: increase $V$ means less recombination of ions</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">region II: full charge collection = no recombination</td>
      <td style="text-align: left">Ionization Chamber</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">region where output is independent of applied voltage</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">Gas Amplification Factor (GAF) = 1</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">region III: electrons become more energized $\to$ can cause secondary ionization during collision. Those secondary ionized electrons can further produce ionizations</td>
      <td style="text-align: left">proportional chamber</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">amplification of current = Townsend Avalanche</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">GAF up to about $10^5$, but still proportional to the original ionization</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">region V: electrons so energized that it can excite inner electrons $\to$ UV radiation from de-excitation $\to$ ionizes other irrelevant atoms in the chamber</td>
      <td style="text-align: left">Geiger-Mueller Counter</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">can’t distinguish initial input energy of those ionizing particles</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">hence can only know the presence of those radiations</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Proportional Chamber</td>
      <td style="text-align: left">electric field increased beyond region II, so that secondary ionizations occur</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">pulse amplitude still tells you energy of input ionizing particles</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221014164005297.png" alt="image-20221014164005297" /></td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Geiger-Mueller Counter</td>
      <td style="text-align: left">electric field increased so much that everything is ionized = pulse amplitude does not depend on the energy of input ionizing particles</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">hence can only measure the presence of radiation</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Scintillation Detector Mechanics</td>
      <td style="text-align: left">energy of radiation $\to$ excitation of electrons of scintillation material $\to$ de-excitation/Compton scattering which emits UV/visible light</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">those light photons are directed to the photosensitive surface $\to$ emit photo-<strong>electrons</strong> $\to$ amplified in PMT $\to$ observe pulse of current</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221021173557853.png" alt="image-20221021173557853" /></td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Scintillation Materials</td>
      <td style="text-align: left">need high effiiency of converting energy to photons</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">linear conversion: output proportional to deposited energy from radiation</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">short decay time = quick flash = short dead time</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">maximize conversion to output fluorescence</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">transparent to its own emission (which is photon, which is <em>also</em> energy)</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Scintillation Types</td>
      <td style="text-align: left">Fluorescence=emit visible radiation with emission time approx. 10 ns</td>
      <td style="text-align: left">preferred</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">Delayed fluorescence=above but loner emission time</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">Photofluorescence=longer wavelength and longer emission time</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Semi-Conductor Detector Mechanics</td>
      <td style="text-align: left">energy of radiation creates electron-hole pair $\to$ electron move in the direction of applied field $\to$ current</td>
      <td style="text-align: left">works only if those e-h pairs do not recombine or get trapped in regions of impurity</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Semi-Conductor Detector Properties</td>
      <td style="text-align: left">only requires 3-4 $eV$ to create e-h pair, whereas to create ion pair in gas requires 30 $eV$</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">better energy resolution</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">faster charge collection = shorter dead time</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Semi-Conductor Detector Types</td>
      <td style="text-align: left">diode</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">high purity $Ge$</td>
      <td style="text-align: left">see above</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">lithium drifted $Si$ or $Ge$</td>
      <td style="text-align: left">alternatives to high purity, use $Li$ for drifting as dopant atoms</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Thermoluminscent Detector</td>
      <td style="text-align: left">operates by accumulating radiation energy and read altogether at the end</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">therefore, we want crystals to de-excite as slow as possible when absorbed radiation</td>
      <td style="text-align: left">opposite of scintillation</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">mechanism: electron and holes are elevated but below conduction band, hence “trapped”</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Neutron Detectors Properties</td>
      <td style="text-align: left">cannot detect neutrons directly, but secondary radiation, such as $(n,p)$</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">depending on how fast the neutrons are, there are two types of neutron detectors</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Slow Neutron Detectors Mechanism</td>
      <td style="text-align: left">for slow, thermal neutrons, nuclear reactions such as $(n,p),(n,\alpha), (n,f)$ have large cross section $\sigma \propto 1/v$</td>
      <td style="text-align: left">basically can be triggered easily</td>
      <td style="text-align: left">$(n,p)$ means the reaction of $A+n \to B+p$</td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">mechanics: neutron $\to$ nuclear reactions $\to$ charged outputs (e.g. fission fragments) cause ionization $\to$ which can be measured</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">$^{10} B(n,\alpha)^7 Li$</td>
    </tr>
    <tr>
      <td style="text-align: center">Slow Neutron Detector Types</td>
      <td style="text-align: left">Proportional Counter</td>
      <td style="text-align: left">$BF_3$ proportional counter performs $^{10} B(n,\alpha)^7 Li$ which a large cross section of 4010 b for thermal neutrons, and $Q=2.79MeV$</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">utilizes $(n,\alpha)$</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">Fission Counters: coat detector with fissionable material</td>
      <td style="text-align: left">utilizes $(n,f)$</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">Activation Counter: using activation foils composed of material sensitive of neutron of different energies</td>
      <td style="text-align: left">utilizes neutron capture</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Fast Neutron Detector</td>
      <td style="text-align: left">use plastic or liquid organic scintillation material instead</td>
      <td style="text-align: left">$1/v$ means slow neutron detectors become not efficient</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">in general, materials of rich hydrogen $\to$ recoiling protons produce energy for scintillation</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Particle Identification</td>
      <td style="text-align: left">since radiation = any particle with energy, we might also want to know which particle it is</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">PI: Counter Telescope</td>
      <td style="text-align: left">stack two or more detectors, and can measure $\Delta E$ between detectors and $E$ total</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">$\Delta E$ can tell you stopping power</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">$E\times \Delta E \propto mz^2$</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">PI: Time of Flight</td>
      <td style="text-align: left">measure time between detectors, hence determine $v$</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">if radiation is pulsed beam, then you can just measure arrival time at detector and actual beam pulse</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">PI: Magnetic Analysis</td>
      <td style="text-align: left">use spectrometer with magnetic field to measure the deflection of charged particles</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">$r = mv/qB$, can measure mass to charge if known velocity</td>
      <td style="text-align: left">based on Lorentz Force $F=qv\times B$</td>
      <td style="text-align: left"> </td>
    </tr>
  </tbody>
</table>

<h1 id="midterm-concepts">Midterm Concepts</h1>

<p>Chapter 1</p>

<ul>
  <li>atomic structure
    <ul>
      <li>plum pudding model, Rutherford model and its problems, Quantum Theory and its model, Bohr Model and its energy levels</li>
      <li>Rutherford scattering experiment, result</li>
    </ul>
  </li>
  <li>equivalence of energy and momentum
    <ul>
      <li>mass-energy equation</li>
    </ul>
  </li>
  <li>uncertainty principle</li>
  <li>nuclear models
    <ul>
      <li>liquid drop, shell model, their differences</li>
    </ul>
  </li>
  <li>electron volt, alternative mass unit</li>
  <li>binding energy, mass excess, and Q calculation</li>
  <li>binding energy curve (reproduce)</li>
  <li>nuclear stability curve (reproduce)</li>
  <li>radioactivity equation and activity</li>
  <li>secular equilibrium</li>
  <li>alpha decay
    <ul>
      <li>energy is discrete, etc</li>
    </ul>
  </li>
  <li>beta decay
    <ul>
      <li>continuous energy up to a cut-off</li>
    </ul>
  </li>
  <li>auger electron</li>
  <li>number of atoms and atomic densities calculations</li>
</ul>

<p>Chapter 5</p>

<ul>
  <li>stopping power
    <ul>
      <li>two components, use Bremsstrahlung</li>
    </ul>
  </li>
  <li>Bethe-Bloch that
    <ul>
      <li>stopping power goes $z^2 / v^2$</li>
    </ul>
  </li>
  <li>stopping power v.s. energy curve
    <ul>
      <li>bragg peak curve</li>
    </ul>
  </li>
  <li>heavy charged particles
    <ul>
      <li>how it loses energies, ionizing them and/or exciting them</li>
    </ul>
  </li>
  <li>light charged particles
    <ul>
      <li>zig zag, no well-defined range</li>
    </ul>
  </li>
  <li>cross sections
    <ul>
      <li>reaction rates, linear attenuation coefficient $\mu$</li>
      <li>attenuation and its differential equation</li>
    </ul>
  </li>
  <li>photon ways of interacting
    <ul>
      <li>three ways of how they work, but not formula</li>
    </ul>
  </li>
  <li>neutrons interactions
    <ul>
      <li>three ways, elastic, inelastic, or reaction</li>
      <li>thermal neutrons</li>
    </ul>
  </li>
</ul>

<p>Chapter 6</p>

<ul>
  <li>
    <p>detector two operation mode</p>
  </li>
  <li>
    <p>detectors figure of merit</p>

    <ul>
      <li>equation of FWHM/$E_0$</li>
      <li>efficiency, especially uncharged particles</li>
      <li>definitions of absolute/intrinsic effiency</li>
    </ul>
  </li>
  <li>
    <p>dead time</p>

    <ul>
      <li>paralyzable v.s. non-paralyzable</li>
      <li>dead time correction equation</li>
      <li>dead time curves</li>
    </ul>
  </li>
  <li>
    <p>will need to draw a detector</p>
  </li>
  <li>
    <p>three types of ionization chambers</p>
  </li>
  <li>
    <p>gas-field detector v.s voltage</p>

    <ul>
      <li>its five regions and the graph itself</li>
    </ul>
  </li>
  <li>
    <p>scintillation detector mechanism</p>
  </li>
  <li>
    <p>semi-conductor detector mechanism</p>
  </li>
  <li>
    <p>TLDs</p>
  </li>
  <li>
    <p>Neutron Detectoros</p>

    <ul>
      <li>slow.v.s fast needs hydrogen = moderates</li>
      <li>fission counter</li>
    </ul>
  </li>
  <li>
    <p>particle identification</p>

    <ul>
      <li>
        <p>time-of-flight gives velocity + magnetic anlaysis</p>
      </li>
      <li>
        <p>none of the detector mechanisms except in the particle identification to tell us particle type</p>
      </li>
    </ul>
  </li>
</ul>

<h1 id="nuclear-structure">Nuclear Structure</h1>

<p>Aim:</p>

<ul>
  <li>understanding what happens <strong><em>inside</em></strong> nucleus
    <ul>
      <li>e.g. understand its properties by understanding what <strong>forces are responsible</strong></li>
    </ul>
  </li>
  <li>no complete theory today fully describes the structure and behavior of complex nuclei</li>
</ul>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Name of Concept/Equation</th>
      <th style="text-align: left">Definition/Equation</th>
      <th style="text-align: left">Notes</th>
      <th style="text-align: left">Example</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">liquid drop model</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">nucleus regarded as a <strong><em>collection</em></strong> of neutrons and protons forming a droplet of incompressible fluid</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">good for <strong>systematic behaviors</strong> such as nucleon binding energy</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">discrepancies in liquid drop model = there is an ORDERED STRUCTURE within the nucleus in which neutrons and protons are arraged in stable quantum states in a potential well</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Shell (Single-particle Model)</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">loosely held individual outer nucleons, which account for many of the nucleus’s properties</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">very alike the electron shell model and how electrons arrange themselves</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Nuclear Force</td>
      <td style="text-align: left">binds nucleons in nucleus, n-n, p-p, p-n</td>
      <td style="text-align: left">extremely complicated, derivation from first principle</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Nuclear Force Properties</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">short range</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221214025855146.png" alt="image-20221214025855146" style="zoom:50%;" /></td>
      <td style="text-align: left">for very small separations, nucleons begin to repel = no clump</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">nuclear density approx constant for different sized nuclei = liquid drop</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Nuclear Force Charge Dependency</td>
      <td style="text-align: left">charge symmetric: same nuclear force for  p-p as for n-n</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Nuclear Force Spin Dependency</td>
      <td style="text-align: left">Average force for p-n &gt; p-p or n-n by a factor of about 2</td>
      <td style="text-align: left">both n and p are fermions = obey Pauli Exclusion for spin</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">so for p-p and n-n, you have to have different spin, net $S=0$</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">n-p can have be either anti-parallel or paralell. <strong>Force in $S = 1$ state is stronger</strong> than force in $S = 0$ state. Therefore, avg. force for p-n is greater than that for p-p or n-n (by about factor of 2).</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">Explains why can have bound n-p (deuteron), but not bound n-n or p-p (i.e., nuclear force not strong enough to bind the latter two configurations)</td>
      <td style="text-align: left">p-p repulsion;  n-n free particles + not strong enough force</td>
    </tr>
    <tr>
      <td style="text-align: center">Nuclear Force Spin-Orbit Coupling</td>
      <td style="text-align: left">$\text{Spin-orbit Force}=L \cdot S$</td>
      <td style="text-align: left">$L,S$ being angular momentum and spin, respectively</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">Force is attractive if S and L are parallel, and repulsive if they are anti-parallel</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">zero on average inside an atom</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Semi-Empirical Mass Formula</td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221214030640303.png" alt="image-20221214030640303" /></td>
      <td style="text-align: left">estimating <strong>binding energy</strong>, which can then be used to estimate the <strong>actual nuclear masses</strong> for unknown nuclei (but known $A$ and $N$)</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">based on liquid-drop = estimates <strong>collective properties of a nucleus</strong></td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">SEMF Volume Energy</td>
      <td style="text-align: left">$a_vA$ term</td>
      <td style="text-align: left">nucleon feels the force only from its nearest neighbors and the nucleon density is approx constant = force is constant = <strong>B/A is approx constant</strong> in the interior of the nucleus.</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">SEMF Surface Term</td>
      <td style="text-align: left">$A^{2/3}$ since the first $A\propto \mathrm{Volume}$</td>
      <td style="text-align: left"><strong>reduced</strong> by a factor proportional to the <strong>surface area</strong> of the nucleus</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221214110550694.png" alt="image-20221214110550694" /></td>
      <td style="text-align: left">nucleons on the surface of the nucleus experience the nuclear force from nucleons inside the nucleus, but no force from the outside. hence reduced</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">SEMF Coulomb Term</td>
      <td style="text-align: left">$\propto {Z^2}/{A^{1/3}}$</td>
      <td style="text-align: left">Coulomb repulsion would further reduce binding energy</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">protons repel each other with a long-range Coulomb force; <br />Mean radius of the nucleus is proportional to $R\propto A^{1/3}$<br />Coulomb force also $\propto Z^2$</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">SEMF Symmetry Term</td>
      <td style="text-align: left">$\propto (N-Z)^2$</td>
      <td style="text-align: left">nucleus becomes more <strong>unstable</strong> the greater the difference between <strong>Z and N</strong>. Has the most effect for <strong>light nuclei</strong></td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">shell model result. The term is zero for $Z = N$ and becomes less important for heavy nuclei (high A), where $N &gt; Z$</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">SEMF Pairing Term</td>
      <td style="text-align: left">$\Delta$</td>
      <td style="text-align: left">nucleons tend to <strong><em>couple pairwise</em></strong> into more stable configurations</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">Δ &gt; 0 if N and Z are both even</td>
      <td style="text-align: left">from Pauli Exclusion Principle</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">Δ &lt; 0 if N and Z are both odd</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">Δ = 0 if either N or Z is odd (i.e., A odd)</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Nuclear Fission Energy Barrier</td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221214111507480.png" alt="image-20221214111507480" /></td>
      <td style="text-align: left">barrier to fission is called the fission barrier or activation energy</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">for <strong>Heavy</strong> Nuclei</td>
      <td style="text-align: left">As s $A$ increases, the relative importance of the Coulomb repulsion term increases = it becomes energetically possible for the nucleus to split if it becomes <strong>deformed</strong> enough</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">Odd nuclei (($U_{92}^{235}$)) have very low activation energies, <strong>since the pairing term is zero</strong>, and can fission with low energy neutrons.</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Isobaric Nuclei</td>
      <td style="text-align: left">same number of total nucleons but swapped #neutrons and #protons</td>
      <td style="text-align: left">will affect the coulomb term in SEMF</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Vibrational Model</td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221214112515740.png" alt="image-20221214112515740" /></td>
      <td style="text-align: left"><strong><em>SEMF assumed sphere shape,</em></strong> but in reality can deform</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">vibration can actually be modelled with liquid-drop model</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Rotational States</td>
      <td style="text-align: left">rotation doesn’t produce any change of state</td>
      <td style="text-align: left">Collective rotational states can <strong>only occur in non-spherical nuclei</strong> (otherwise how do you know it is rotating?)</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Shell (Independent Particle) Model</td>
      <td style="text-align: left">aims to model energy level of nucleons</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">neutrons and protons fill energy level in the nucleus according to the Pauli Exclusion Principle</td>
      <td style="text-align: left">similar to electron energy levels</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">those structure like properties are not predicted by SEMF, which only deals with collective states</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">“islands of stability” corresponding to “closed shells,” also called “magic numbers,”</td>
      <td style="text-align: left">2 (1s), 8 (2s, 1p), 20, 28, …</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Nuclear Potential Energy</td>
      <td style="text-align: left">predict <strong><em>energy levels</em></strong> in the nucleus, need to know $V(r)$</td>
      <td style="text-align: left">arises from interactions with other nucleons.</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">infinite well = simplest model</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Woods-Saxon Potential</td>
      <td style="text-align: left">$V(r) = -\frac{V_0}{1+e^{(r-R)/a}}$</td>
      <td style="text-align: left">quite a good approximate</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Spin-Orbital Potential</td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221214113711983.png" alt="image-20221214113711983" /></td>
      <td style="text-align: left">more complicated but <strong>accounted for more splittings</strong> of energy level</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">splittings due to spin $s$ and angular momentum $l$. If <strong>aligned</strong>, $s\cdot l$ positive hence binding energy is increased</td>
      <td style="text-align: left"> </td>
    </tr>
  </tbody>
</table>

<h1 id="nuclear-instability">Nuclear Instability</h1>

<p>Aim: Predict/explain <strong><em>why</em></strong></p>

<ol>
  <li>some <em><strong>half-lives are short</strong> and others are long</em>, and</li>
  <li>why <strong><em>certain energy transitions take place</em></strong> and others don’t</li>
</ol>

<p>In general there will be a) electromagnetic force; b) weak force; c) strong force</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Name of Concept/Equation</th>
      <th style="text-align: left">Definition/Equation</th>
      <th style="text-align: left">Notes</th>
      <th>Example</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">Gamma Emission Mechanism</td>
      <td style="text-align: left">Excited nucleus may de-excite through $\gamma$-emission</td>
      <td style="text-align: left">help understand why certain gamma decay have longer half-lives than another</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">gamma is “everywhere” in the sense that many radioactive decay accompanies gamma emission (see below, due to excited daughter nucleus)</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">Characteristic $\gamma$-emission</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">actually come from the transitions among the energy levels of the <strong>daughter</strong> nucleus.</td>
      <td><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221218182726846.png" alt="image-20221218182726846" style="zoom:67%;" /></td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
      <td>the above means we have two decays:<br /><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221218182834669.png" alt="image-20221218182834669" style="zoom: 15%;" />and then<img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221218182846700.png" alt="image-20221218182846700" style="zoom:10%;" /></td>
    </tr>
    <tr>
      <td style="text-align: center">Selection rules</td>
      <td style="text-align: left">derived from consideration of conservation of <mark>angular momentum and parity</mark>, <strong><em>specify the allowable transitions</em></strong> among energy levels</td>
      <td style="text-align: left">answers: “why are some gamma more likely to happen than others?”</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">1. Photon that carries away energy has angular momentum $L&gt;0$</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">2. Conservation of Angular Momentum: $\vert l_i - l_f\vert \le L \le \vert l_i + l_f\vert$</td>
      <td style="text-align: left">$l_i$, $l_f$ is the angular momentum of the initial and final nuclear state</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">3. Parity (wavefunction even or odd) is also conserved in EM transitions</td>
      <td style="text-align: left">whether or not a parity changed decides $\to$</td>
      <td><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221218204404711.png" alt="image-20221218204404711" style="zoom:50%;" /></td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
      <td><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221218204529542.png" alt="image-20221218204529542" style="zoom:50%;" /></td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">do <strong><em>not</em></strong> provide information on the probability of its occurrence, only if it <em>can</em> occur</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">Competing Process in $\gamma$</td>
      <td style="text-align: left">as gamma usually comes from de-excitaton, other processes such as de-excite with electron is competing (also comes from de-excitation)</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">e.g. Internal Conversion</td>
      <td style="text-align: left">transfer energy to an orbital electron (K-shell or further out), ejecting it from the nucleus</td>
      <td>another way to de-excite = the parent and child would be the same <em>as if performed gamma decay</em></td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"><strong>Single energy peak</strong> for each orbital electron transition unlike continuous β spectrum.</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">$\gamma$ Transition Rates</td>
      <td style="text-align: left">Weisskopf Single Particle γ Transition Rates</td>
      <td style="text-align: left"> </td>
      <td><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221218204742112.png" alt="image-20221218204742112" /></td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">$E_1$ is greatly favored</td>
      <td style="text-align: left"> </td>
      <td>Selection rules allow E2, M3, E4, M5, and E6 transitions, but the E2 radiation is strongly favored.</td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
      <td><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221218214350669.png" alt="image-20221218214350669" /></td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">If transitions have <em>high multipolarity</em>, T$_{1/2}$ may be considerable</td>
      <td style="text-align: left">basically for E6, M6, etc above,  the probabiility is low = long half lives</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">Mixed $\gamma$ transitions</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">can substantially <strong><em>raise the probability</em></strong> that a particular energy γ-ray will be emitted</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">can’t characterize transition probability using the single particle model</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">Beta Decay Equations</td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221218214832570.png" alt="image-20221218214832570" /></td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">allowed reactions = conservation of <strong><em>energy/momentum/charge/lepton number</em></strong></td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">can find the end point of the continous $\beta$ spectrum</td>
      <td style="text-align: left">recall that $Q$ gives the kinetic energy difference $Q = K_f - K_i = (m_i -m_f)c^2$</td>
      <td>$T_{end} = E_0 - m_e c^2$, the end point of the β spectrum. $E_0$ = total energy of the transition.</td>
    </tr>
    <tr>
      <td style="text-align: center">Fermi’s Golden Rule</td>
      <td style="text-align: left">Probability of beta decay, determine the <em>transition rate</em> between an initial state (i) and a final state (f) for $\beta$ decay</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221218220413602.png" alt="image-20221218220413602" /></td>
      <td style="text-align: left">$\lambda$ measures the transition probability</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">Electron Capture</td>
      <td style="text-align: left">competes with β+-decay when both modes are possible<img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221218220610791.png" alt="image-20221218220610791" style="zoom:25%;" /></td>
      <td style="text-align: left">all $\beta$ are due to <mark>weak interaction</mark></td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">Factor affecting EC probability/rate</td>
      <td style="text-align: left">depends on the <strong>overlap</strong> of the electron’s and the nucleus’s wave functions</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">1. electron is most likely to be captured when it is <strong><em>closer</em></strong> to the nucleus</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">2. higher Z = being attracted more = size of $K$-orbit electrons orbit is smaller = being captured</td>
      <td style="text-align: left">EC importance over β+ decay increases with Z</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">Alpha Decay</td>
      <td style="text-align: left">common decay mode for <strong>heavy radionuclides</strong></td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">Shed four units of mass (two neutrons and two protons) in one decay.</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">QM “tunneling” in Alpha Decay</td>
      <td style="text-align: left">heavy nucleus like uranium has barrier of 20MeV, but emitted alpha particle from it can be <em>as low as 5 MeV</em>. now we know it is due to non-zero wave function</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">requires $Q&gt;0$</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221218221142073.png" alt="image-20221218221142073" /></td>
      <td style="text-align: left">explanation of QM tunneling</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">Preformation Probability</td>
      <td style="text-align: left">for alpha decay to happen, you need to first form the alpha particle in the nucleus</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221218221306606.png" alt="image-20221218221306606" /></td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
  </tbody>
</table>

<h1 id="nuclear-reactions">Nuclear Reactions</h1>

<p>Study a bit further on <strong><em>how/when reaction happens</em></strong></p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Name of Concept/Equation</th>
      <th style="text-align: left">Definition/Equation</th>
      <th style="text-align: left">Notes</th>
      <th>Example</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">Types/Classification of Reactions</td>
      <td style="text-align: left"><strong>Elastic</strong> scattering: a + A $\to$ a + A</td>
      <td style="text-align: left">scattering = Incident and outgoing particles are the same</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"><strong>Inelastic</strong> scattering: a + A $\to$ a + $A^*$</td>
      <td style="text-align: left">some energy goes into exciting internal levels in A, and later will go off $\gamma$ decay</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"><strong>Knockout</strong>: a particle is emitted (“knocked out”) from the nucleus</td>
      <td style="text-align: left"> </td>
      <td>e.g. stripping of a proton from a carbon nucleus</td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"><strong>Stripping</strong> reaction if the transfer is from the projectile to the target.</td>
      <td style="text-align: left">Transfer reaction: 1 or 2 nucleons are transferred between the projectile and target.</td>
      <td>C-12 + alpha -&gt; C-8* + alpha*</td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"><strong>Pickup</strong> reaction if the transfer is from the target to the projectile.</td>
      <td style="text-align: left">Transfer reaction, i.e. target nucleus gained</td>
      <td>He-3 + p -&gt; He-4* + gamma</td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"><strong>Direct</strong> nuclear reactions: formation of a “new” nucleus typically involve the transfer of <em>just a few nucleons</em> (protons or neutrons) between the colliding nuclei.</td>
      <td style="text-align: left">without the creation of an intermediate compound nucleus.</td>
      <td>e.g. scattering</td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"><strong>Compound</strong> nuclear reactions: results in the formation of an intermediate compound nucleus, and can result in the emission of several particles</td>
      <td style="text-align: left">involve the transfer of <em>many nucleons</em> between the colliding nuclei</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"><strong>Resonance</strong> reaction: incoming particle has right energy to excite an energy level in the target nucleus, greatly <em>increasing the cross section</em></td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">Discern what Reaction happened with Energy Spectrum</td>
      <td style="text-align: left">can distinguish different mechanism because they give rise to outgoing particles have different energy</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221218222924675.png" alt="image-20221218222924675" /></td>
      <td style="text-align: left"><strong>Discrete</strong> energy peaks at high energies from direct reactions</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">At lower energies, peaks correspond to more closely spaced energy levels can’t be resolved</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">At still lower energies, compound nuclei are formed, where neutrons and protons <strong>share</strong> the incoming particle energy and “evaporate” from the nucleus in a continuous spectrum</td>
      <td>evaporate: formed compound nucleus $\to$ an equilibrium is reached so the compound nucleus <em>loses its energy slowly over time by emitting particles,</em> mostly protons and neutrons</td>
    </tr>
    <tr>
      <td style="text-align: center">Angular Distributions</td>
      <td style="text-align: left">angle of output particles relative to input particle</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">Angular Distributions for Direct Reactions</td>
      <td style="text-align: left"><em>Direct</em> collisions (few nucleons take part) usually produce forward peaked reaction products</td>
      <td style="text-align: left">forward peak = products traveling in the <strong>same direction</strong> as input</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"><em>Direct</em> collisions = exhibit <em>oscillations</em> as a function of scattering angle due to the wave nature of the particles</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">Angular Distributions for Compound Reactions</td>
      <td style="text-align: left">Angular spectrum of evaporated particles from a <em>compound</em> nucleus is more <em>isotropic</em></td>
      <td style="text-align: left">since the emitted particles “<strong>have no memory</strong>” of the direction of the incoming particle</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221218223426199.png" alt="image-20221218223426199" /></td>
      <td style="text-align: left">y-axis = prob of observing this</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">Reaction rate</td>
      <td style="text-align: left">each reaction has its own cross-section = own reaction rate</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">$R =\sigma N_A \phi=\Sigma \phi$</td>
      <td style="text-align: left">σ = reaction cross section<br />φ = particle (e.g., neutron) flux<br />$N_A$ = the number of target atoms per unit volume</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221218223905002.png" alt="image-20221218223905002" /></td>
      <td>DD reaction cross section = higher E better because this is <em>fusion</em></td>
    </tr>
    <tr>
      <td style="text-align: center">Classical Estimate of Reaction Cross Section Assumptions</td>
      <td style="text-align: left">calculate cross section itself (before we were given this)</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">assumptions = reaction happens when come close enough together for the strong nuclear force to act</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">Classical Estimate of Uncharged Particles</td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221218224237587.png" alt="image-20221218224237587" style="zoom: 33%;" /></td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">$\sigma= \pi (R_1 + R_2)^2 = \pi R^2$</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">Classical Estimates of Charged Particles</td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221218224450325.png" alt="image-20221218224450325" style="zoom:150%;" /></td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">Impact parameter, $b$ replaces $R$.<br />$\sigma = \pi b^2 = \pi R^2 (1-B/E)$</td>
      <td style="text-align: left">means if $B&gt;E$ reaction cannot occur</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">QM Estimate</td>
      <td style="text-align: left">classical works when particles is more ‘particle-like’</td>
      <td style="text-align: left">classical approximation of reaction cross section is only decent for particles with <strong>de Broglie wavelength less than the size of the nucleus</strong></td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">also kind of works if we are <em>heavy ions</em> = wavelength often smaller than nuclear dimensions</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">but if wave functions coincide, then reaction occur = can occur even if $B&gt;E$</td>
      <td style="text-align: left">in reality, high energy = looks like particle; low energy = looks like wave</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">Usage of Elastic Scattering for Nuclear Structure</td>
      <td style="text-align: left">force causing scattering depends on the <em>spatial distribution of nucleus</em> =&gt; by analyzing the way particles scatterd = know about the size and distribution of <em>force field</em> = know about the <em>nucleus</em></td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"><strong>Electrons</strong> make good probes of the nucleus since they are not absorbed and interact via the well-know electromagnetic force with the protons</td>
      <td style="text-align: left">if we take particles such as $\alpha$, then it interacts strongly once inside the nucleus = lose its identity and not reappear in the entrance channel</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">Compound Nuclear Reaction Mechanism</td>
      <td style="text-align: left">Many nuclear reactions proceed in two or more steps</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">1.  the <em>incoming</em> particle is absorbed by, and excites, the nucleus</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">2. the nucleus <em>loses</em> its excitation energy (decays) through one of several different, possible exit channels (decay branches or decay channels)</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">Compound Nuclear Reaction Rate</td>
      <td style="text-align: left"><em>Each decay channel</em> is characterized by a probability and mean lifetime, $\lambda = 1/\tau$</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">for compound reaction $A+a\to C\to B+b$<br /> reaction rate is $\sigma_{\alpha, \beta} = \sigma_c (\Gamma_\beta / \Gamma)$</td>
      <td style="text-align: left">$\sigma_c$ is the cross section of forming the compound nucleus<br />$\Gamma_\beta / \Gamma$ is fractional decay width into the final channel $B+b$</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">basically, need $C$ to happen, and then also $\beta$ to happen</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">Energy width of Compound Nuclear Reaction</td>
      <td style="text-align: left">due to the Uncertainty Principle, uncertainties in $\lambda$ and $\tau$ $\to$ <em>uncertainties in energies of the states</em> $\to$ energy spread</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221218230238702.png" alt="image-20221218230238702" /></td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">Cross Section Thresholds</td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221218230654380.png" alt="image-20221218230654380" /></td>
      <td style="text-align: left">each decay mode <em>also has its own ‘excitation energy’</em> required</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">Heavy ion particle accelerator’s goal</td>
      <td style="text-align: left">Heavy ion particle accelerators are used to cause reactions where the <em>target nuclei are blown apart</em> or to attempt to create <em>new heavy elements through absorption</em>.</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
  </tbody>
</table>

<h1 id="fission">Fission</h1>

<p>This section will focus on <strong>induced fission from neutron absorption</strong></p>

<ul>
  <li>Some heavy “transuranic” (near uranium) nuclei can undergo induced fission if supplied with sufficient energy (7-8 MeV)</li>
  <li>about 6 MeV comes from binding of an extra <strong><em>neutron</em></strong> by the <strong><em>strong force</em></strong> and the rest from external sources</li>
  <li>an extra 1-2 MeV from pairing (depends on if your $N$ is odd or even)</li>
</ul>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Name of Concept/Equation</th>
      <th style="text-align: left">Definition/Equation</th>
      <th style="text-align: left">Notes</th>
      <th>Example</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">Why is Fission Energetic Useful?</td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221218235727825.png" alt="image-20221218235727825" style="zoom: 33%;" /></td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">Fissile nuclei can fission with <em>low energy, “thermal,” neutrons</em></td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">Energy during/Mechanism of Fission</td>
      <td style="text-align: left">1. normally, the SEMF surface term provides a restoration force, like disturbing surface tension on water</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">2. if sufficient energy is supplied, the shape will deform to such an extent that the Coulomb repulsion force will dominate = strong force only works locally = nucleus starts to break</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">3. repulsive force will drive the (usually) 2 fission fragments apart and potential energy is <em>converted into kinetic energy</em></td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221219000721638.png" alt="image-20221219000721638" style="zoom: 33%;" /></td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">Fission Activation Energy</td>
      <td style="text-align: left">The energy required to overcome the fission barrier = deform</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221219000459450.png" alt="image-20221219000459450" style="zoom: 33%;" /></td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">Properties of Fission</td>
      <td style="text-align: left">Energetically preferred to have one heavy group and one light group as fission fragment</td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221219000902306.png" alt="image-20221219000902306" /></td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">When a fissionable nucleus absorbs a neutron and forms a compound nucleus, there is a <strong>competition between fission and gamma emission</strong> to release excitation energy, which doesn’t lead to fission</td>
      <td style="text-align: left">$\sigma_a = \sigma_f + \sigma_\gamma$</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">Discovery of Neutron</td>
      <td style="text-align: left">James Chadwick found that if the energetic alpha particles emitted from polonium fell on certain light elements, specifically beryllium, an <em>unusually penetrating radiation</em> was produced (not gamma ray)</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221219001726268.png" alt="image-20221219001726268" style="zoom:33%;" /></td>
      <td style="text-align: left">this radiation’s range, etc. can be measured by placing paraffin a distance away to <strong>perform (n,p) reaction</strong></td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">the first ‘weird’ event that happened about this was: Walther Bothe and Herbert Becker = discovered that when energetic α-particles from the decay of polonium impinged on certain light materials, they would <strong><em>eject high energy, very penetrating, neutral radiation</em></strong>; they thought they were γ-rays</td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221219002009283.png" alt="image-20221219002009283" /></td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">‘Discovery of Fission’</td>
      <td style="text-align: left">Otto Hahn and Frederick Strassmann</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">Observed presence of barium and other middle-weight elements in a uranium sample bombarded by neutrons and noted <em>large release of energy</em>.</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">12/2/1942 – Enrico Fermi – 1st controlled fission chain reaction in Chicago Pile 1</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">Start of Nuclear Weapon</td>
      <td style="text-align: left">7/16/1945 – 1st nuclear weapon test: <strong><em>Trinity</em></strong> in White Sands Proving Grounds, New Mexico.</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">called “The Gadget.” 20 kT (84 TJ). Pu implosion device</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">Types of Nuclear Weapons Mechanism</td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221219002342388.png" alt="image-20221219002342388" style="zoom: 25%;" /></td>
      <td style="text-align: left">normal <strong>plutomium</strong> okay, but densely pressed is not = can go over critical mass</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221219002349437.png" alt="image-20221219002349437" style="zoom:25%;" /></td>
      <td style="text-align: left">simply have separate halfs of sphere = explosion <strong>combine</strong> them = increase density = go react<br />now it is <strong>uranium</strong></td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">Why no Pu+Gun Barrel? <br />1. Because plutonium is less dense than HEU, it would require a larger mass to reach criticality<br />2. even trace amounts of Pu-240 in the plutonium would release enough neutrons from <strong>spontaneous fission</strong> = wouldn’t explode but fizzle</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">Nuclear Power Plant</td>
      <td style="text-align: left">12/20/1951 – <strong>EBR-1</strong>, Idaho National Lab, Idaho Falls, Idaho. First generation of electric power from nuclear power plant</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">Delayed Energy and Delayed Neutrons</td>
      <td style="text-align: left">nuclear reactor core and spent fuel <em>continue to emit considerable energy</em> even after the nuclear chain reaction process has <em>stopped</em>. This happens because</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">1. fission fragments as a by-product are themselves every radio-active = release energy</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">2. delayed neutrons play a critical role in the control of nuclear fission reactions because they are emitted at a <em>slower rate than prompt neutrons</em>, which are emitted immediately following the fission event = helpful to make power change smoother = but still are neutrons</td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221219003325304.png" alt="image-20221219003325304" /></td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">Neutron Economics</td>
      <td style="text-align: left">each fission produces 2-3 neutrons of about 2MeV, but <em>prompt fission neutrons must be thermalized</em> to about 0.025 MeV</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">In the slowing down process, must avoid <br />1. absorption by other nuclei <br />2. leakage out of the system.</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">3. (uncontrollable) absorbed neutron but gave non-fission reaction</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">Chain Reaction</td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221219003615062.png" alt="image-20221219003615062" style="zoom:33%;" /></td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">Neutron Multiplication Factor</td>
      <td style="text-align: left">measure if your chain reaction is sustaining/increasing/decreasing</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221219004107957.png" alt="image-20221219004107957" style="zoom: 25%;" /></td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221219004140291.png" alt="image-20221219004140291" style="zoom:25%;" /></td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221219004201393.png" alt="image-20221219004201393" style="zoom:25%;" /></td>
      <td style="text-align: left">recall the section on neutron economics</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">Thermal Fission Factor</td>
      <td style="text-align: left"><em>probability of a fission event occurring</em> when a neutron collides with a nucleus</td>
      <td style="text-align: left">Not all neutrons absorbed in fuel cause fission</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221219004515942.png" alt="image-20221219004515942" /></td>
      <td style="text-align: left">basically $\sigma_f + \sigma_a = \sigma_T$</td>
      <td>if 99.3% U-238 and 0.7% U-235, then the ratio is<br />$\frac{0.7*\sigma_f(^{235}U)}{(0.7\sigma_T(^{235}U)+99.3\sigma_T(^{238}U))}$</td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"> </td>
      <td>because only $^{235}U$ can fission = Most nuclear reactors and all nuclear weapons <strong>require higher U-235 enrichment</strong></td>
    </tr>
    <tr>
      <td style="text-align: center">Methods for U-235 Enrichment</td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221219005126907.png" alt="image-20221219005126907" style="zoom: 25%;" /></td>
      <td style="text-align: left">Gaseous Diffusion Enrichment: since U238 is a <strong>little bit heavier</strong> (cannot separate them chemically as they are the same, but physicaly not). Therefore smaller would go through more readily at the top</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">and you can repeat this process over and over</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221219005222054.png" alt="image-20221219005222054" style="zoom:25%;" /></td>
      <td style="text-align: left">Gas Centrifuge Enrichment: again, U238 is a little bit heavier than U235, so another approach is to spin it very fast</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">Enrichment Definitions</td>
      <td style="text-align: left">LEU – Low Enrichment Uranium: &lt; 20% U-235</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">HEU – High Enrichment Uranium: &gt; 20% U-235</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">Weapons Grade Uranium: &gt; 90% U-235</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">Components in a Nuclear Power Plant</td>
      <td style="text-align: left"><strong>Fuel pellets</strong> – typically, sintered UO2 enriched to 3-5% in 235U.</td>
      <td style="text-align: left">Fuel pellets and fuel rods are both used to store and transport nuclear fuel in nuclear reactors.</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"><strong>Fuel rods</strong> – typically, clad in Zircalloy to contain fission products and gases</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"><strong>Control</strong> rods – neutron absorbers among fuel assemblies</td>
      <td style="text-align: left">to regulate the number of neutrons available to sustain the chain reaction</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">Reactor core – typically, “square cylinder” shape</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">Coolant/<strong>moderator</strong> – light water most common</td>
      <td style="text-align: left">to slow down neutrons to thermal</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"><strong>Structural</strong> material – alloys of steel (absorber/reflector)</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">PWR and BWR</td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221219005748886.png" alt="image-20221219005748886" style="zoom: 33%;" /></td>
      <td style="text-align: left">pressurized, transfer of heat energy</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221219005817822.png" alt="image-20221219005817822" style="zoom: 33%;" /></td>
      <td style="text-align: left">could have secondary radiation, but more efficient</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">PWR Schematic</td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221219005940524.png" alt="image-20221219005940524" style="zoom:50%;" /></td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
  </tbody>
</table>

<h1 id="fusion">Fusion</h1>

<p>Why could fusion be useful if we had fission already?</p>

<ul>
  <li>much less radioactive waste</li>
  <li>but the major problem is it is <strong>technically harder</strong></li>
</ul>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Name of Concept/Equation</th>
      <th style="text-align: left">Definition/Equation</th>
      <th style="text-align: left">Notes</th>
      <th>Example</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">Why is Fusion Energetic Useful?</td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221219013327992.png" alt="image-20221219013327992" style="zoom:50%;" /></td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">Extra Requirement for Fusion</td>
      <td style="text-align: left">since nuclei are positively charged, so must impart <strong>high kinetic energies</strong> to the to overcome the repulsive Coulomb barrier = close enough for <strong>strong force</strong> to form new nucleus</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">1. high temperature (i.e., kinetic energy)</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">2. high density (close enough)</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">3. confinement time: amount of time that the plasma must be confined in order for the reactions to occur</td>
      <td style="text-align: left">later on will see that density and confinement determines how much energy can be gained</td>
      <td><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221219014048587.png" alt="image-20221219014048587" style="zoom: 50%;" /></td>
    </tr>
    <tr>
      <td style="text-align: center">Magnetic Confinement Basics</td>
      <td style="text-align: left">confine plasma using magnetic fields = quite complicated setup</td>
      <td style="text-align: left">because plasma = lot of <strong><em>charged</em></strong> particles in gaseous form</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">works based on Lorentz Force</td>
      <td style="text-align: left">but will lose them if they move in parallel of the field!</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221219015741263.png" alt="image-20221219015741263" style="zoom:33%;" /></td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">Inertial Confinement</td>
      <td style="text-align: left">Heat and fuse ions so rapidly that they do not have time to escape.</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">typically use laser beams to compress and heat fuel pellets.</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">Fusion Reaction Examples</td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221219014333643.png" alt="image-20221219014333643" /></td>
      <td style="text-align: left">Most uses isotopes of hydrogen to <mark>minimize repulsion</mark></td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">the highlighted ones have high cross section, and non-gamma energy release = can be more easily retrained</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">Helium as a product is <mark>very stable</mark>, hence releases a lot of energy!</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">Properties of DT Fusion Reactions</td>
      <td style="text-align: left">high cross section</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">produces a lot of energy</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">produces an alpha particle, which can be <strong><em>re-used to heat up the plasma</em></strong></td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">shield against neutrons, which are also very energetic</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">tritium (T) don’t occur naturally, so often need to be bred in the reactor factory</td>
      <td style="text-align: left">can be bred from Lithium</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">Why would DT be preferred?</td>
      <td style="text-align: left">1. requires lower energy<br />2. produces more energy</td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221219015116694.png" alt="image-20221219015116694" /></td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">Reaction Rate of Fusion</td>
      <td style="text-align: left">Reaction prob per unit time = $n_2 \sigma v$</td>
      <td style="text-align: left">$v$ speed of the particles<br />$n_2$ is density of particle 2</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">considers prob of particle 1 interacting with particle 2</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">total reaction rate per unit volume: $R=n_1n_2\sigma v$</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">$R=n_1n_2 \lang \sigma v \rang$</td>
      <td style="text-align: left">since plasma = gas particles = velocity is defined by Boltzmann distribution</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">Fusion Energy Output and Break-Even</td>
      <td style="text-align: left">Fusion energy output = $E_f=n_1n_2\lang \sigma v\rang Q \tau$</td>
      <td style="text-align: left">$\tau$ is <mark>confinement time</mark>!<br />$Q$ is energy released per reaction</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">also includes <mark>density $n_1,n_2$</mark></td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">Break-Even $n\tau &gt; \frac{12kT}{\lang v \sigma \rang Q}$</td>
      <td style="text-align: left"><strong>Lawson Criteria</strong>: need to achieve this to get more energy out than input</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221219015523087.png" alt="image-20221219015523087" /></td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">Magnetic Bottle Confinement</td>
      <td style="text-align: left">1. Closed-field geometry (e.g., torus)</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">2. <strong>Toroidal field</strong> (TF) – Coils external and perpendicular to toroidal containment vessel generate TF</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">3. <strong>Poloidal field</strong> (PF) – pass current around axis of torus. Compensates for weakening TF with increasing $r$</td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221219015910587.png" alt="image-20221219015910587" style="zoom: 25%;" /></td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"><mark>Tokamak</mark> is one famous example!</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">Inertial Confinement Mechanism</td>
      <td style="text-align: left">1. the energy from the laser or particle beam pulses is absorbed by the fuel target, heating it to extremely high temperatures and causing it to undergo a rapid <strong>expansion</strong>.</td>
      <td style="text-align: left">difficulty is to generate sufficient power to achieve this</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">2. This expansion creates a shock wave that <strong>compresses</strong> the fuel target, increasing the density and temperature of the plasma and creating conditions suitable for fusion reactions.</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left">therefore, requires lasers and <strong>fuel pellets</strong></td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">National Ignition Facility</td>
      <td style="text-align: left">NIF: 192 laser beams focused onto small target, uses Indirect target</td>
      <td style="text-align: left"> </td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"><img src="/lectures/images/2022-12-20-APPH4010_Intro_to_Nuclear/image-20221219020446322.png" alt="image-20221219020446322" /></td>
      <td style="text-align: left">Laser pulse vaporizes the heavy metal case, generating intense <strong>x-rays inside the hohlraum</strong>, which compresses and heats the DT fuel</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">Hohlraum = the metal cylinder</td>
      <td> </td>
    </tr>
  </tbody>
</table>

<h1 id="final">Final</h1>

<ul>
  <li>Nuclear sturcture
    <ul>
      <li>spin has an effect on energy</li>
      <li>know every term in SEMF, what it represents</li>
      <li>pairing term</li>
      <li>vibrational harmnoics shapes</li>
      <li>nuclear potential energy</li>
    </ul>
  </li>
  <li>Nuclear Instability
    <ul>
      <li>gamma emission comes from nucleus, actually comes fro the daughter</li>
      <li>selection rules for gamma emission, including the table</li>
      <li>transition ratess</li>
      <li>Decay schemes
        <ul>
          <li>high polarity and high half life</li>
        </ul>
      </li>
      <li>internal conversion (eject electron)</li>
      <li>beta decay three possible transitions
        <ul>
          <li>tell by excess protons or neutrons whether if it goes beta plus or beta minus</li>
        </ul>
      </li>
      <li>alpha decay
        <ul>
          <li>QM consideration that as long as Q is positive it will happen</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Nuclear Reactions
    <ul>
      <li>classification
        <ul>
          <li>scattering, inelastic scattering; knockout</li>
          <li>direct reactions and compound-nucleus decay</li>
        </ul>
      </li>
      <li>cross section and density equation and reaction rate
        <ul>
          <li>estimate the cross section such as assuming no coulomb interactions with $\pi R^2$; but with intearaction $\pi b^2$</li>
          <li>cross section calculation for charged particles</li>
          <li>no need to know partial waves</li>
          <li>compound nuclear reactions equation</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Fission
    <ul>
      <li>binding energy curve and why fission is possible</li>
      <li>high cross section with thermal neutrons</li>
      <li>fission activation energy - when you pass the poit of this yuo can fission</li>
      <li>fission history and discovery of neutron</li>
      <li>chain reaction graph of uranium
        <ul>
          <li>neutron multiplication factor</li>
          <li>reactors would want to stay at $k=1$, which is controlled by control rods</li>
          <li>why enrichment is needed</li>
        </ul>
      </li>
      <li>nuclear reactor basics
        <ul>
          <li>fuel pellets</li>
          <li>Pressurized WR and BWR designs; difference is that water doesn’t boil and goes into heat exchange</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Fusion
    <ul>
      <li>why fusion is possible in binding energy curve
        <ul>
          <li>but the hard part is to have a high temperature, etc.</li>
          <li>magnetic confinement v,s, inertial confinement: heating them so quickly</li>
        </ul>
      </li>
      <li>reaction rate for fusion equation with $R=n_1n_2 \sigma v$</li>
      <li>triple product and lawson criterion</li>
      <li>toroidal fields, know stuff like this exists
        <ul>
          <li>tokamak</li>
        </ul>
      </li>
      <li>inertial confinement
        <ul>
          <li>using lasers</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>some shared topisc shuch as alpha and beta decay</p>
  </li>
  <li>Energy calculation, very practical</li>
</ul>]]></content><author><name></name></author><category term="2022@Columbia" /><summary type="html"><![CDATA[Equations and Concepts for Intro to Nuclear]]></summary></entry></feed>