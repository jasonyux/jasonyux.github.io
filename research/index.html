<html>

<header>
    <link rel="stylesheet" href="css/home.css">
</header>

<body>
    <div class="menu-bar no-select">
        <a class="active" href="/index.html">Home</a>
        <a href="/projects/index.html">Projects</a>
        <a href="#">Research</a>
        <a href="/lectures/index.html">Education</a>
        <a href="/learning/index.html">Blog</a>
    </div>
    <div class="title-div no-select">
        <h1 class="title">Research</h1>
    </div>

    <div class="paper-box">
        <div class="paper">
            <img src="images/anon_submission.png" title="">
            <div class="paper-info">
                <a href="#" target="">
                    <h3 class="c">
                        <span class="anonymous">-------------------------</span> Task Oriented Dialog <span class="anonymous">---------</span> Reinforcement Learning
                    </h3>
                </a>
                <p> <i>Xiao Yu</i>, Qingyang Wu, Kun Qian, Zhou Yu </p>
                <h5> ACL, 2023. (In submission) </h5>
            </div>
        </div>
        <div class="paper">
            <img src="images/anon_submission.png" title="">
            <div class="paper-info">
                <a href="#" target="">
                    <h3 class="c">
                        <span class="anonymous">-------------------------</span> Dialogue Generation <span class="anonymous">-----------</span> Prompting
                    </h3>
                </a>
                <p> Maximillian Chen, <i>Xiao Yu</i>, Weiyan Shi, Urvi Awasthi, Zhou Yu </p>
                <h5> ACL, 2023. (In submission) </h5>
            </div>
        </div>
        <div class="paper">
            <img src="images/FastKassim.png" title="Syntax is a fundamental component of language, yet few metrics have been employed to capture syntactic similarity or coherence at the utterance- and document-level. The existing standard document-level syntactic similarity metric is computationally expensive and performs inconsistently when faced with syntactically dissimilar documents. To address these challenges, we present FastKASSIM, a metric for utterance- and document-level syntactic similarity which pairs and averages the most similar dependency parse trees between a pair of documents based on tree kernels. FastKASSIM is more robust to syntactic dissimilarities and runs up to to 5.32 times faster than the baseline method over the documents in the r/ChangeMyView corpus. These improvements allow us to examine hypotheses in two settings with large documents: persuasive online arguments on r/ChangeMyView, and authorship attribution in the Australian High Court Judgment corpus. With FastKASSIM, we are able to show that more syntactically similar arguments tend to be more persuasive, and that syntax provides a key indicator of writing style.">
            <div class="paper-info">
                <a href="https://arxiv.org/abs/2203.08299" target="_blank"><h3 class="c">FastKASSIM: A Fast Tree Kernel-Based Syntactic Similarity Metric</h3></a>
                <p> Maximillian Chen*, Caitlyn Chen*, <i>Xiao Yu*</i>, Zhou Yu </p>
                <h5> EACL, 2023. (Under review) </h5>
            </div>
        </div>
        <div class="paper">
            <img src="images/lwal.png" title="Modern neural network architectures have shown remarkable success in several large-scale classification and prediction tasks. Part of the success of these architectures is their flexibility to transform the data from the raw input representations (e.g. pixels for vision tasks, or text for natural language processing tasks) to one-hot output encoding. While much of the work has focused on studying how the input gets transformed to the one-hot encoding, very little work has examined the effectiveness of these one-hot labels.
            In this work, we demonstrate that more sophisticated label representations are better for classification than the usual one-hot encoding. We propose Learning with Adaptive Labels (LwAL) algorithm, which simultaneously learns the label representation while training for the classification task. These learned labels can significantly cut down on the training time (usually by more than 50%) while often achieving better test accuracies. Our algorithm introduces negligible additional parameters and has a minimal computational overhead. Along with improved training times, our learned labels are semantically meaningful and can reveal hierarchical relationships that may be present in the data.">
            <div class="paper-info">
                <a href="https://arxiv.org/abs/2209.04528" target="_blank"><h3 class="c">Improving Model Training via Self-learned Label Representations</h3></a>
                <p> <i>Xiao Yu</i>, Nakul Verma </p>
                <h5> preprint </h5>
            </div>
        </div>
        <div class="paper">
            <img src="images/mqtt_dissemination.png" title="Edge computing attempts to deliver low-latency services by offloading data storage and processing from remote data centers to distributed edge servers near end users, whereas network protocols, designed for centralized management, do not internally scale to distributed edge scenarios. In this paper, we establish the message dissemination support of MQTT, a de facto protocol for Internet of Things, for fully distributed edge networks. We summarize and formulate existing mechanisms, namely publication flooding and subscription flooding, and propose a topic-centric solution called selective subscription forwarding, which forwards subscriptions only when necessary by leveraging the topic containment of MQTT messages and therefore reduces inter-broker traffics. Evaluation results demonstrate that compared with existing solutions, more than 40% subscription traffic can be reduced with the proposed mechanism.">
            <div class="paper-info">
                <a href="#"><h3 class="c">Distributed MQTT Brokers at Network Edges: A Study on Message Dissemination</h3></a>
                <p> Luoyao Hao, <i>Xiao Yu</i>, Tingrui Zhang, Henning Schulzrinne </p>
                <h5> IEEE (iThings), 2022. </h5>
            </div>
        </div>
    </div>

</body>
<script>
    function changeCSS(cssFile, cssLinkIndex) {
        var oldlink = document.getElementsByTagName("link").item(cssLinkIndex);

        var newlink = document.createElement("link");
        newlink.setAttribute("rel", "stylesheet");
        newlink.setAttribute("type", "text/css");
        newlink.setAttribute("href", cssFile);

        document.getElementsByTagName("header").item(0).childNodes[1].replaceWith(newlink);
    }

    window.mobileCheck = function() {
        return screen.width <= 1330;
    };

    if (window.mobileCheck()) {
        changeCSS("css/home_mobile.css", 0)
    }
</script>
</html>